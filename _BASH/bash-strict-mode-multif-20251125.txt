filename: bash-strict-mode-multif-20251125.txt
https://olivergondza.github.io/2019/10/01/bash-strict-mode.html

Bash strict mode and why you should care

   It has been a while since I have stumbled upon a great post of Aaron Maxwell introducing what he
   refers to as "Unofficial Bash Strict Mode" and started taking advantage of its benefits on
   everyday bases. It has even become part of my bash script template so I never (well, almost) create a
   new file without a strict mode header.

So, what is strict mode?
   I am certain it is no easy task to design a language to serve the purpose of interactive shell and
   well as the one of nontrivial system programing language. However, over the years, one is constantly
   running into situations wishing bash would be more strict, predictable and generally resemble more of
   a, well, more of a programming language.

   Fortunately, there are ways to get a little closer to that to protect ones sanity while working with
   what I (only half jokingly, though) call the most popular esoteric programming language in the world.
   And to the best of my knowledge, Aaron was the first one to popularize the concept of strict mode in
   bash.

   So all in all, the strict mode is nothing more than a small bash snippet to put at the beginning of
   the file to alter is behavior towards the safe side. Here is his proposed strict mode declaration:

#!/bin/bash
set -euo pipefail
IFS=$'\n\t'

   Let me have a brief look of what it attains (see the original post for a ton of relevant details):
     * set -u: Error out in case an undefined variable is substituted. While this is not always an error
       as a fair deal of correct code can be written while substituting undefined variables, typos or
       messed up refactorings manifests this way fairly often.
     * set -e: Exit when any executed command return non-zero code. The obvious exception here are
       commands executed inside loop conditions, conditionals or as arguments to logic operators (||, &&).
     * And its good friend set -o pipefail that aborts command pipeline as soon as some of its
       chained commands fails. This pair of settings attempts to address one of the most frequent
       problems I have come across with bash scripting: scripts continuing execution after some critical
       operation failed, with some of script invariants violated and either failing much later or even
       completing with success exit code in the end.

   So this is the way to ask for extra portion of errors and constrains to handle while working with
   bash. Which, trust me, is a good thing. The original post gets in some lengths on how to adapt common
   code patterns that does not comply to work with the strict mode, and it only seldom makes the code
   less idiomatic while making it more resilient most of the time.

   The very last line adjusts the "Internal Field Separator" to behave more intuitively around
   [https://www.gnu.org/software/bash/manual/html_node/Word-Splitting.html]word splitting strings that contain
   whitespace, where spaces often behaves as undesired separators in buggy code.

Is that it?
   Aaron of course is not alone striving for seamless bash experience so more strict modes has emerged.
   Michael Daffin has published one I really love:

#!/bin/bash
set -uo pipefail
trap 's=$?; echo "$0: Error on line "$LINENO": $BASH_COMMAND"; exit $s' ERR
IFS=$'\n\t'

   It appears to be an alternation of the previous one (albeit it omits set -e), but, what's with the trap?
   [http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_12_02.html]Traps in bash registers a (string) code
   snippet to be executed when script exits with declared error code, or as in the case of ERR, when a command
   returns non-zero code (same exceptions apply as with set -e). I find this to be a true gem when used with
   set -e and set -o pipefail that alone just abort the script, but does not tell you where it failed. With
   this, it clearly reports that script has failed (which you may miss unless you examine the exit code)
   stating the line number and the command that failed! This makes it fail fast, and loud.

Are we saved?
   Well, not quite. While all these contribute to the effort of maintaining developer's sanity, they come to a
   cost. Apart from caveats covered in [http://redsymbol.net/articles/unofficial-bash-strict-mode/]Aaron's
   original post, watch out for these:
     * Composing advanced strict modes is not only making bash a language that is more sane, is also
       getting further from the collective experience with the tool. Think of the team members surprised
       by the cryptic noise at the beginning of the files, not even talking about their reaction when
       they notice the change of the semantics of the code they though they understand. This also impact
       all the documentation and reusable code snippets that becomes less relevant as they silently
       imply default behavior. Who have ever heard of a piece of code copied from Stack Overflow that
       would not work as intended?
     * The IFS thing. The way I look at this, the other tweaks adds safety by refusing to tolerate
       situations that can and arguably should be avoided (like using undefined variable). But changing
       the IFS not to contain space character is merely changing the semantics to compensate one of the
       frequent mistakes while working with variable substitution. It does not force one to write better
       code, it tolerates bad code instead and try to get correct(-ish) results.
     * One hideous caveat of bash trap usage (the one people usually learn about the hard way) is that
       multiple traps are not stacked and executed in sequence, but they replace previously defined trap
       per given signal. Put differently, as soon as one declare another trap bound to ERR, the
       diagnostics provided by the strict mode declaration get replaced. Fortunately, there is not much
       motivation to introduce ERR traps for other reason but diagnostics, so I do not find this very
       likely to collide in production code

Which one to use, then?
   So, I ended up cultivating my own strict mode that, to this day, looks something like this:
#!/usr/bin/env bash
set -euo pipefail
trap 's=$?; echo >&2 "$0: Error on line "$LINENO": $BASH_COMMAND"; exit $s' ERR

     * Always using /usr/bin/env to locate bash interpretter.
     * set -e is not going anywhere.
     * The trap prints to standard error.
     * The IFS is not tempered with.

   Note that set -euo pipefail part (and its subsets) has become quite notorious and a lot of folks is
   using variations of that sporadically. One advantage of using consistent strict mode definition is
   all the scripts are behaving predictably. It is enough we have chosen to deviate from bash defaults,
   let's at least be consistent in doing so.

   Isn't it time to start thinking about bash strict mode in your life?


---
http://redsymbol.net/articles/unofficial-bash-strict-mode/

Use Bash Strict Mode (Unless You Love Debugging)

   Let's start with the punchline. Your bash scripts will be more robust, reliable and maintainable if
   you start them like this:

#!/bin/bash
set -euo pipefail
IFS=$'\n\t'

   I call this the unofficial bash strict mode. This causes bash to behave in a way that makes many
   classes of subtle bugs impossible. You'll spend much less time debugging, and also avoid having
   unexpected complications in production.

   There is a short-term downside: these settings make certain common bash idioms harder to work with.
   Most have simple workarounds, detailed below: jump to Issues & Solutions. But first, let's look at
   what these obscure lines actually do.

The "set" lines
   These lines deliberately cause your script to fail. Wait, what? Believe me, this is a good thing.
   With these settings, certain common errors will cause the script to immediately fail, explicitly and
   loudly. Otherwise, you can get hidden bugs that are discovered only when they blow up in production.

   set -euo pipefail is short for:

set -e
set -u
set -o pipefail

   Let's look at each separately.

set -e
   The set -e option instructs bash to immediately exit if any command  has a non-zero exit
   status. You wouldn't want to set this for your command-line shell, but in a script it's massively
   helpful. In all widely used general-purpose programming languages, an unhandled runtime error -
   whether that's a thrown exception in Java, or a segmentation fault in C, or a syntax error in Python
   - immediately halts execution of the program; subsequent lines are not executed.

   By default, bash does not do this. This default behavior is exactly what you want if you are using
   bash on the command line - you don't want a typo to log you out! But in a script, you really want the
   opposite. If one line in a script fails, but the last line succeeds, the whole script has a
   successful exit code. That makes it very easy to miss the error.

   Again, what you want when using bash as your command-line shell and using it in scripts are at odds
   here. Being intolerant of errors is a lot better in scripts, and that's what set -e gives you.

set -u
   set -u affects variables. When set, a reference to any variable you haven't previously defined - with
   the exceptions of $* and $@ - is an error, and causes the program to immediately exit. Languages like
   Python, C, Java and more all behave the same way, for all sorts of good reasons. One is so typos
   don't create new variables without you realizing it. For example:

#!/bin/bash
firstName="Aaron"
fullName="$firstname Maxwell"
echo "$fullName"

   Take a moment and look. Do you see the error? The right-hand side of the third line says "firstname",
   all lowercase, instead of the camel-cased "firstName". Without the -u option, this will be a silent
   error. But with the -u option, the script exits on that line with an exit code of 1, printing the
   message "firstname: unbound variable" to stderr. This is what you want: have it fail explicitly and
   immediately, rather than create subtle bugs that may be discovered too late.

  set -o pipefail
   This setting prevents errors in a pipeline from being masked. If any command in a pipeline fails,
   that return code will be used as the return code of the whole pipeline. By default, the pipeline's
   return code is that of the last command - even if it succeeds. Imagine finding a sorted list of
   matching lines in a file:


$> grep some-string /non/existent/file | sort
grep: /non/existent/file: No such file or directory
$> echo $?
0

   ($> is the bash prompt.) Here, grep has an exit code of 2, writes an error message to stderr, and an
   empty string to stdout. This empty string is then passed through sort, which happily accepts it as
   valid input, and returns a status code of 0. This is fine for a command line, but bad for a shell
   script: you almost certainly want the script to exit right then with a nonzero exit code... like
   this:

$>  set -o pipefail
$>  grep some-string /non/existent/file | sort
grep: /non/existent/file: No such file or directory
$>  echo $?
2

Setting IFS
   The IFS variable - which stands for Internal Field Separator - controls what Bash calls word
   splitting. When set to a string, each character in the string is considered by Bash to separate
   words. This governs how bash will iterate through a sequence. For example, this script:

#!/bin/bash
IFS=$' '
items="a b c"
for x in $items; do
echo "$x"
done

IFS=$'\n'
for y in $items; do
echo "$y"
done

   ... will print out this:
a
b
c
a b c

   In the first for loop, IFS is set to $' '. (The $'...' syntax creates a string, with
   backslash-escaped characters replaced with special characters - like "\t" for tab and "\n" for
   newline.) Within the for loops, x and y are set to whatever bash considers a "word" in the original
   sequence. For the first loop, IFS is a space, meaning that words are separated by a space character.
   For the second loop, "words" are separated by a newline, which means bash considers the whole value
   of "items" as a single word.

   !!! If IFS is more than one character, splitting will be done on any of those characters. !!!

   Got all that? The next question is, why are we setting IFS to a string consisting of a tab character
   and a newline? Because it gives us better behavior when iterating over a loop. By "better", I mean
   "much less likely to cause surprising and confusing bugs". This is apparent in working with bash
   arrays:

#!/bin/bash
names=(
"Aaron Maxwell"
"Wayne Gretzky"
"David Beckham"
"Anderson da Silva"
)

echo "With default IFS value..."
for name in ${names[@]}; do
	echo "$name"
done

echo ""
echo "With strict-mode IFS value..."
IFS=$'\n\t'
for name in ${names[@]}; do
	echo "$name"
done

   (Yes, I'm putting my name on a list of great athletes. Indulge me.) This is the output:
With default IFS value...
Aaron
Maxwell
Wayne
Gretzky
David
Beckham
Anderson
da
Silva

With strict-mode IFS value...
Aaron Maxwell
Wayne Gretzky
David Beckham
Anderson da Silva

   Or consider a script that takes filenames as command line arguments:

for arg in $@; do
	echo "doing something with file: $arg"
done

   If you invoke this as myscript.sh notes todo-list 'My Resume.doc', then with the default IFS value,
   the third argument will be mis-parsed as two separate files - named "My" and "Resume.doc". When
   actually it's a file that has a space in it, named "My Resume.doc".

   Which behavior is more generally useful? The second, of course - where we have the ability to not
   split on spaces. If we have an array of strings that in general contain spaces, we normally want to
   iterate through them item by item, and not split an individual item into several.

   Setting IFS to $'\n\t' means that word splitting will happen only on newlines and tab characters.
   This very often produces useful splitting behavior. By default, bash sets this to $' \n\t' - space,
   newline, tab - which is too eager.

Issues & Solutions
   I've been using the unofficial bash strict mode for years. At this point, it always immediately saves
   me time and debugging headaches. But at first it was challenging, because many of my usual habits and
   idioms didn't work under under these settings. The rest of this article catalogues some problems you
   may encounter, and how to quickly work around them.


---
https://disconnected.systems/blog/another-bash-strict-mode/

Another Bash Strict Mode

   I have been using Aaron Maxwell's Unofficial Bash Strict Mode for many years now and it has saved
   my loads of time if finding and fixing buggy bash scripts. The main problem I now encounter is
   scripts that fail silently (or far from the last command that output anything). To solve this I have
   started to use the following variant.

#!/bin/bash
set -uo pipefail
trap 's=$?; echo "$0: Error on line "$LINENO": $BASH_COMMAND"; exit $s' ERR
IFS=$'\n\t'

   The major problem with set -e and set -o pipefail is that they are silent forcing you have to rely
   the output of the failed command to debug your script. But not all commands fail loudly and when they
   do they don't tell you where in your script they failed.

   Error traps can give you more information, anything that is available to the bash shell at the time
   they where triggered. Most usefully the command that failed $BASH_COMMAND and the line number $LINENO
   that command was on.


---
https://gist.github.com/robin-a-meade/58d60124b88b60816e8349d1e3938615

Unofficial Bash Strict Mode
November 10, 2025

   Sometimes a programming language has a "strict mode" to restrict unsafe constructs. E.g., Perl has
   use strict, Javascript has "use strict", and Visual Basic has Option Strict. But what
   about bash? Well, bash doesn't have a strict mode as such, but it does have an unofficial strict
   mode:

set -euo pipefail

   set -e
          Setting the -e, a.k.a., errexit, option, causes the script to exit immediately when an
          unhandled error occurs, instead of just continuing on.

   set -u
          Setting the -u option causes the script to treat references to unset variables as errors.
          E.g., if you misspell $MASTER_LINKS as $MASTERLINKS, which is unset, this will be treated as
          an error.

   set -o pipefail
          Setting the pipefail option causes the shell to treat an error in any command of a multi-stage
          pipeline to be an error in the pipeline as a whole. This is in contrast to the surprising
          default behavior of only considering the exit status of the last command in the pipeline.

Further explanation

set -e

   Ways to set and unset this option:
set -e                # Set the errexit option
set -o errexit        # Equivalent
shopt -s -o errexit   # Equivalent (TMTOWTDI FTW!)

set +e                # Unset the errexit option
set +o errexit        # Equivalent
shopt -u -o errexit   # Equivalent

   When set, the errexit option causes the script to exit immediately when an unhandled error occurs.
   See the bash reference manual for details and exceptions:
   https://www.gnu.org/software/bash/manual/bash.html#index-set

   Example:
# remove the temporary files
cd "$JOB_HOME/job001/tmp"
rm *

   If the cd command failed, you wouldn't want to proceed with the execution of the rm command. The
   errexit option helps protect against such blunders.

   Without errexit, you'd need to be vigilant in checking the exit status or each command:
die() {
	echo "$@" >&2
	exit 1
}
...
# remove the temporary files
cd "$JOB_HOME/job001/tmp" || die "Couldn't cd into $JOB_HOME/job001/tmp"
rm *

Criticism of errexit
     * http://mywiki.wooledge.org/BashFAQ/105
     * https://lists.gnu.org/archive/html/bug-bash/2012-12/msg00093.html

Rebuttal of criticism of errexit
   It is true that the use of set -e involves some adjustments to your shell scripting style, but the
   safety it affords is well worth it.

set -u
   Setting the -u option causes the script to treat references to unset variables as errors.

   Consider this example:
# Create or update the hardlink
ln -f proc.mk "$MASTERLINKS"/

   In this example, we accidentally mispelled the $MASTER_LINKS environment variable as $MASTERLINKS,
   which is unset.

   Without the -u option set, the script will attempt to create the hard link at the root of the
   filesystem, /.

   With the -u option, the script's reference to the unset variable $MASTERLINKS will be treated as an
   error, and no attempt to create the hard link at the wrong location will be made.

set -o pipefail
   By default, bash has the POSIX-mandated behavior of only considering the last command in a pipeline
   when determining the exit status of the pipeline as a whole. Setting the pipefail option will cause
   the script to have the less surprising behavior of considering an error in any stage of the pipeline
   to be an error of the pipeline as a whole.

   Consider this example:

$> cat myscript.sh
#!/bin/bash
false | echo 'hi'
echo "$?"
set -o pipefail
false | echo 'hi'
echo "$?"

$> ./myscript.sh
hi
0
hi
1

   You see that when the pipefail option is set, the non-zero exit status of the first stage of the
   pipeline causes the pipeline as a whole to have that same non-zero exit status. Without the pipefail
   option set, the behavior is surprising: the pipeline as a whole has a zero exit status; the error is
   silently ignored!

Inspired by
     * Use the Unofficial Bash Strict Mode (Unless You Looove Debugging)
       http://redsymbol.net/articles/unofficial-bash-strict-mode/

   but without the stuff about changing IFS.

   Discussion of that blog post: https://news.ycombinator.com/item?id=8054440

***
Uh oh!

   Be careful with pipefail, as some constructs are built with the idea the failure (non-zero) value of
   one element in the pipeline might be expected, and indeed even handled in some way. Bash provides a
   volatile indexed variable PIPESTATUS to check for the exit code of each member of the pipeline if you
   need that methodology.

   A simple example of this is when using the find command as non-root and ignoring "Permission denied"
   messages, like so:
$> find /etc -name hosts 2>/dev/null | xargs grep -c 127
/etc/avahi/hosts:0
/etc/hosts:2

$> echo $?
0

   vs.
$> set -o pipefail
$> find /etc -name hosts 2>/dev/null | xargs grep -c 127
/etc/avahi/hosts:0
/etc/hosts:2

$> echo $?
1

   This is a silly example we could code a better way, but it illustrates where the expectation is to
   ignore the first member of the pipe STDERR and not really care if it fails, what we're after is the
   grep output of some sort (which we then might extend this pipeline to feed into something else, again
   it's a silly example).

   An example of using PIPESTATUS in this regard would be a neat logging function that runs a command,
   logs it, then returns the expected output of that pipeline:

# run action, log output, return exit code
# - passing in 'sed' should be avoided
# - functions can only return 0..254
# -- set a global to check as needed
ACTLOG=/var/log/foobar.log
_ACTRET=0
function logact() {
	local ACTION
	ACTION="$*"
	${ACTION} 2>&1 | tee -a "${ACTLOG}"
	_ACTRET=${PIPESTATUS[0]}
	return ${_ACTRET}
}

   In the above, we don't care if tee fails (let's pretend the $ACTLOG is non-writable - bad, but not
   fatal to script operational needs) we only care about the first member of the pipeline, not the
   entire thing as we're returning that to the caller in the above example. Setting a global pipefail
   can have unexpected results (which can be coded around if needed, not saying there isn't a solution),
   just depends what your script code is doing and intending as a result.

***
   The silent behavior of errexit means user might not realize at all the script stopped in the middle.

   https://disconnected.systems/blog/another-bash-strict-mode/ suggests handling the virtual ERR
   trap instead of setting errexit - this approach allows printing an error message and providing more
   details e.g. exact line where the script failed.

***
   @robin-a-meade Great gist! Maybe add shopt -s inherit_errexit to?
shopt -s inherit_errexit
    # shopt              => This builtin allows you to change additional shell optional behavior.
    # -s inherit_errexit => If set, command substitution inherits the value of the errexit option, instead of
unsetting it in the subshell environment.


---

