filename: trap_bash-use-of-exit-and-other-signals-multif_20150325.txt
http://www.thegeekstuff.com/2010/03/bash-shell-exit-status/

Bash Shell Exit Status Tutorial with Practical Examples

   by Sasikala on March 26, 2010

   In our [11]bash introduction article, we learned that a shell-script file contains list of
   commands to be executed by the shell interpreter. In this article let us review about shell
   commands and its internals.

   A command is a sequence of words. The first word indicates the command to be executed and
   remaining words are passed as an arguments, where arguments could be the options or
   parameters to the command.
   Some of the common Unix commands you execute at the command line are shell commands. For
   example, ls, lpr and grep command.
$ ls -alF

$ lpr filename

$ grep "string" filename

Shell Command Exit Status

   The return value of a command is its exit status, or 128 + N if the command is terminated
   by signal N. Exit status is used to check the result (success/failure) of the execution of
   the command. If the exit status is zero, then the command is success. If the command is
   failed the exit status will be non-zero.
   Exit Value    Exit Status
   0 (Zero)   Success
   Non-zero   Failure
   2          Incorrect usage
   127        Command Not found
   126        Not an executable

$? Shell Variable

   The shell variable name $? is a special built-in variable which has the exit status of the
   last command executed.
     * After the shell function execution, $? returns the exit status of the last command
       executed in a function.
     * After the shell script execution, $? returns the exit status of the last command
       executed in the script.

Sample Shell Script that Explains Shell-Command Exit Status

   The following exitstatus.sh shell-script shows examples of various shell-command exit
   status.
$ cat exitstatus.sh
#! /bin/bash

echo -e "Successful execution"
echo -e "====================="
echo "hello world"
# Exit status returns 0, because the above command is a success.
echo "Exit status" $?

echo -e "Incorrect usage"
echo -e "====================="
ls --option
# Incorrect usage, so exit status will be 2.
echo "Exit status" $?

echo -e "Command Not found"
echo -e "====================="
bashscript
# Exit status returns 127, because bashscript command not found
echo "Exit status" $?

echo -e "Command is not an executable"
echo -e "============================="
ls -l execution.sh
./execution.sh
# Exit status returns 126, because its not an executable.
echo "Exit status" $?

   Now, execute the above exitstatus.sh to see the various exit statues given by the sample
   shell script.
$ bash exitstatus.sh
Successful execution
=====================
hello world
Exit status 0
Incorrect usage
=====================
ls: unrecognized option `--option'
Try `ls --help' for more information.
Exit status 2
Command Not found
=====================
exitstaus.sh: line 15: bashscript: command not found
Exit status 127
Command is not an executable
=============================
-rw-r--r-- 1 root root 659 Mar  9 13:36 execution.sh
exitstatus.sh: line 21: ./execution.sh: Permission denied
Exit status 126

   Note: Checking the return value of a function or a command is one of the main
   responsibility of a programmer. This should become your second nature while writing any
   code.



---
http://unix.stackexchange.com/questions/48425/how-to-stop-the-loop-bash-script-in-terminal

[25]How to stop the loop bash script in terminal?

   For example,
#!/bin/bash
while :
do
    sl
done

   How to terminate this bash script?
***
   Give more details. Do you want to stop it interactively or programmatically? –
   [34]manatwork Sep 17 '12 at 15:57
***
   you can press ctrl-c to send the SIGINT signal (in most shells) or you can press ctrl-z
   that sends the SIGTSTP signal (in most shells). In the case you pressed ctrl-z the related
   process isn't killed but paused. You can resume it with fg (at least in bash) –
   [35]user1146332 Sep 17 '12 at 15:59
***
   No, it doesn't work! –  [36]Yinyanghu Sep 17 '12 at 16:16
***
   @manatwork interactively!! –  [37]Yinyanghu Sep 17 '12 at 16:20
***
   The problem is not the script, but the sl command which I believe is an annoing command for
   those who misspell ls, showing a train passing slowly by. As far as I know it traps the
   SIGINT signal and must be killed with SIGKILL. –  user13742 Sep 17 '12 at 16:48
***
6 Answers 6
   The program sl purposely ignores SIGINT, which is what gets sent when you press Ctrl+C. So,
   firstly, you'll need to tell sl not to ignore SIGINT by adding the -e argument.

   If you try this, you'll notice that you can stop each individual sl, but they still repeat.
   You need to tell bash to exit after SIGINT as well. You can do this by putting a trap
   "exit" INT before the loop.
#!/bin/bash
trap "exit" INT
while :
do
    sl -e
done

***
   Perfect answer! –  [45]Yinyanghu Sep 17 '12 at 17:01
***
   I don't have it installed to check, but you might also be able to kill it with SIGQUIT from
   Ctrl-\ –  [46]derobert Sep 17 '12 at 17:36
***
    1. press Ctrl-Z to suspend the script
    2. kill %%

   The %% tells the bash built-in kill that you want to send a signal (SIGTERM by default) to
   the most recently suspended background job in the current shell, not to a process-id.

   You can also specify jobs by number or by name. e.g. when you suspend a job with ^Z, bash
   will tell you what its job number is with something like [n]+ Stopped, where the n inside
   the square brackets is the job number.

   For more info on job control and on killing jobs, run help jobs, help fg, help bg, and help
   kill in bash, and search for JOB CONTROL (all caps) or jobspec in the bash man page.

   e.g.
$ ./killme.sh
./killme.sh: line 4: sl: command not found
./killme.sh: line 4: sl: command not found
./killme.sh: line 4: sl: command not found
./killme.sh: line 4: sl: command not found
./killme.sh: line 4: sl: command not found
...
...
...
./killme.sh: line 4: sl: command not found
^Z
[1]+  Stopped                 ./killme.sh
$ kill %%
$
[1]+  Terminated              ./killme.sh

   In this example, the job's number was 1, so kill %1 would have worked the same as kill %%

   (NOTE: I don't have sl installed so the output is just "command not found". in your case,
   you'll get whatever output sl produces. it's not important - the ^Z suspend and kill %%
   will work the same)
***
   Another good answer! –  [50]Yinyanghu Sep 18 '12 at 2:25
***
   BTW, for rapidly executing loops like this, ^Z can be a more reliable way to kill the
   process than ^C. ^C will be sent to the program (sl) being run in the loop, but the script
   will keep running...and start another sl. If you press ^C a few times really fast, you may
   get to kill both the sl and the script (if neither of them trap SIGINT). ^Z will suspend
   the script almost immediately (immediately if you don't count buffered output that is still
   being printed to your terminal), so you can kill it with kill %% –  [51]cas Sep 18 '12 at
   2:48
***
   Exactly! I have to say "sl is a fun program". This time, it fun me again! @_@ –
   [52]Yinyanghu Sep 18 '12 at 3:07
***
   Only answer that seems to work also when the loop isn't called from a script but from
   command line directly. –  [53]Skippy le Grand Gourou Aug 3 '14 at 10:25
***
   You can terminate that script by pressing Ctrl+C from terminal where you started this
   script. Of course this script must run in foreground so you are able to stop it by Ctrl+C.

   Or you can find PID (Process ID) of that script in other opened terminal by:
ps -ef | grep <name_of_the_script>
kill -9 <pid_of_your_running_script>

   Both ways should do the trick your are asking for.
***
   It can't be terminated by Ctrl+C from terminal. So I have to kill it by ps or top. I just
   want to know how to kill it directly! –  [57]Yinyanghu Sep 17 '12 at 16:15
***
   You can kill the pid of shell (bash).
   I just tried and it works.
   Because I cannot see the process from ps -ef (the job that we run in the looping script).
***
   add a comment |
   up vote -1 down vote
while [ true ]
do

  ps | grep script_name.sh | grep -v grep >/dev/null 2>&1

  if [ "$!" = "0" ] ; then
    break
  else
    kill -9 ` ps -ef | grep script_name.sh | cut -d "a" -f 1`
  fi

done

   this should help.
***
   Why do you think the PID of the last background command will ever be 0? –  [68]manatwork
***
   use set -e to exit from failure.
#!/bin/bash
set -e
while :
do
    sl
done



---
http://bencane.com/2014/09/02/understanding-exit-codes-and-how-to-use-them-in-bash-scripts/

Understanding Exit Codes and how to use them in bash scripts

When writing a script that calls other commands, how do you know if they were successful or not?
The answer is exit codes, exit codes are important and this article describes how to use them in
your scripts and understand them in general.

   Written by [4]Benjamin Cane on 2014/09/02

   Lately I've been working on a lot of automation and monitoring projects, a big part of
   these projects are taking existing scripts and modifying them to be useful for automation
   and monitoring tools. One thing I have noticed is sometimes scripts use exit codes and
   sometimes they don't. It seems like exit codes are easy for poeple to forget, but they are
   an incredibly important part of any script. Especially if that script is used for the
   command line.

What are exit codes?

   On Unix and Linux systems, programs can pass a value to their parent process while
   terminating. This value is referred to as an exit code or exit status. On POSIX systems the
   standard convention is for the program to pass 0 for successful executions and 1 or higher
   for failed executions.

   Why is this important? If you look at exit codes in the context of scripts written to be
   used for the command line the answer is very simple. Any script that is useful in some
   fashion will inevitably be either used in another script, or wrapped with a bash one liner.
   This becomes especially true if the script is used with automation tools like SaltStack or
   monitoring tools like Nagios, these programs will execute scripts and check the status code
   to determine whether that script was successful or not.

   On top of those reasons, exit codes exist within your scripts even if you don't define
   them. By not defining proper exit codes you could be falsely reporting successful
   executions which can cause issues depending on what the script does.

What happens if I don't specify an exit code

   In Linux any script run from the command line has an exit code. With Bash scripts, if the
   exit code is not specified in the script itself the exit code used will be the exit code of
   the last command run. To help explain exit codes a little better we are going to use a
   quick sample script.

   Sample Script:
#!/bin/bash
touch /root/test
echo created file

   The above sample script will execute both the touch command and the echo command. When we
   execute this script (as a non-root user) the touch command will fail, ideally since the
   touch command failed we would want the exit code of the script to indicate failure with an
   appropriate exit code. To check the exit code we can simply print the $? special variable
   in bash. This variable will print the exit code of the last run command.

   Execution:
$ ./tmp.sh
touch: cannot touch â€˜/root/testâ€™: Permission denied
created file
$ echo $?
0

   As you can see after running the ./tmp.sh command the exit code was 0 which indicates
   success, even though the touch command failed. The sample script runs two commands touch
   and echo, since we did not specify an exit code the script exits with the exit code of the
   last run command. In this case, the last run command is the echo command, which did execute
   successfully.

   Script:
#!/bin/bash
touch /root/test

   If we remove the echo command from the script we should see the exit code of the touch
   command.

   Execution:
$ ./tmp.sh
touch: cannot touch â€˜/root/testâ€™: Permission denied
$ echo $?
1

   As you can see, since the last command run was touch the exit code reflects the true status
   of the script; failed.

Using exit codes in your bash scripts

   While removing the echo command from our sample script worked to provide an exit code, what
   happens when we want to perform one action if the touch was successful and another if it
   was not. Actions such as printing to stdout on success and stderr on failure.

Testing for exit codes

   Earlier we used the $? special variable to print the exit code of the script. We can also
   use this variable within our script to test if the touch command was successful or not.

   Script:
#!/bin/bash

touch /root/test 2> /dev/null

if [ $? -eq 0 ]
then
  echo "Successfully created file"
else
  echo "Could not create file" >&2
fi

   In the above revision of our sample script; if the exit code for touch is 0 the script will
   echo a successful message. If the exit code is anything other than 0 this indicates failure
   and the script will echo a failure message to stderr.

   Execution:
$ ./tmp.sh
Could not create file

Providing your own exit code

   While the above revision will provide an error message if the touch command fails, it still
   provides a 0 exit code indicating success.
$ ./tmp.sh
Could not create file
$ echo $?
0

   Since the script failed, it would not be a good idea to pass a successful exit code to any
   other program executing this script. To add our own exit code to this script, we can simply
   use the exit command.

   Script:
#!/bin/bash

touch /root/test 2> /dev/null

if [ $? -eq 0 ]
then
  echo "Successfully created file"
  exit 0
else
  echo "Could not create file" >&2
  exit 1
fi

   With the exit command in this script, we will exit with a successful message and 0 exit
   code if the touch command is successful. If the touch command fails however, we will print
   a failure message to stderr and exit with a 1 value which indicates failure.

   Execution:
$ ./tmp.sh
Could not create file
$ echo $?
1

Using exit codes on the command line

   Now that our script is able to tell both users and programs whether it finished
   successfully or unsuccessfully we can use this script with other administration tools or
   simply use it with bash one liners.

   Bash One Liner:
$ ./tmp.sh && echo "bam" || (sudo ./tmp.sh && echo "bam" || echo "fail")
Could not create file
Successfully created file
bam

   The above grouping of commands use what is called list constructs in bash. List constructs
   allow you to chain commands together with simple && for and and || for or conditions. The
   above command will execute the ./tmp.sh script, and if the exit code is 0 the command echo
   "bam" will be executed. If the exit code of ./tmp.sh is 1 however, the commands within the
   parenthesis will be executed next. Within the parenthesis the commands are chained together
   using the && and || constructs again.

   The list constructs use exit codes to understand whether a command has successfully
   executed or not. If scripts do not properly use exit codes, any user of those scripts who
   use more advanced commands such as list constructs will get unexpected results on failures.

More exit codes

   The exit command in bash accepts integers from 0 - 255, in most cases 0 and 1 will suffice
   however there are other reserved exit codes that can be used for more specific errors. The
   Linux Documentation Project has a pretty good table of [5]reserved exit codes and what they
   are used for.



---
http://www.tldp.org/LDP/abs/html/exitcodes.html

Appendix E. Exit Codes With Special Meanings

Table E-1. Reserved Exit Codes

+-----------------------------------------------------------------------------+
|Exit  |Meaning            |Example        |Comments                          |
|Code  |                   |               |                                  |
|Number|                   |               |                                  |
|------+-------------------+---------------+----------------------------------|
|1     |Catchall for       |let "var1 = 1/ |Miscellaneous errors, such as     |
|      |general errors     |0"             |"divide by zero" and other        |
|      |                   |               |impermissible operations          |
|------+-------------------+---------------+----------------------------------|
|2     |Misuse of shell    |empty_function |Missing keyword or command, or    |
|      |builtins (according|() {}          |permission problem (and diff      |
|      |to Bash            |               |return code on a failed binary    |
|      |documentation)     |               |file comparison).                 |
|------+-------------------+---------------+----------------------------------|
|126   |Command invoked    |/dev/null      |Permission problem or command is  |
|      |cannot execute     |               |not an executable                 |
|------+-------------------+---------------+----------------------------------|
|127   |"command not found"|illegal_command|Possible problem with $PATH or a  |
|      |                   |               |typo                              |
|------+-------------------+---------------+----------------------------------|
|128   |Invalid argument to|exit 3.14159   |exit takes only integer args in   |
|      |exit               |               |the range 0 - 255 (see first      |
|      |                   |               |footnote)                         |
|------+-------------------+---------------+----------------------------------|
|128+n |Fatal error signal |kill -9 $PPID  |$? returns 137 (128 + 9)          |
|      |"n"                |of script      |                                  |
|------+-------------------+---------------+----------------------------------|
|130   |Script terminated  |Ctl-C          |Control-C is fatal error signal 2,|
|      |by Control-C       |               |(130 = 128 + 2, see above)        |
|------+-------------------+---------------+----------------------------------|
|255*  |Exit status out of |exit -1        |exit takes only integer args in   |
|      |range              |               |the range 0 - 255                 |
+-----------------------------------------------------------------------------+

According to the above table, exit codes 1 - 2, 126 - 165, and 255 [1] have
special meanings, and should therefore be avoided for user-specified exit
parameters. Ending a script with exit 127 would certainly cause confusion when
troubleshooting (is the error code a "command not found" or a user-defined
one?). However, many scripts use an exit 1 as a general bailout-upon-error.
Since exit code 1 signifies so many possible errors, it is not particularly
useful in debugging.

There has been an attempt to systematize exit status numbers (see /usr/include/
sysexits.h), but this is intended for C and C++ programmers. A similar standard
for scripting might be appropriate. The author of this document proposes
restricting user-defined exit codes to the range 64 - 113 (in addition to 0,
for success), to conform with the C/C++ standard. This would allot 50 valid
codes, and make troubleshooting scripts more straightforward. [2] All
user-defined exit codes in the accompanying examples to this document conform
to this standard, except where overriding circumstances exist, as in Example
9-2.

Note Issuing a $? from the command-line after a shell script exits gives
     results consistent with the table above only from the Bash or sh prompt.
     Running the C-shell or tcsh may give different values in some cases.

Notes

[1]  Out of range exit values can result in unexpected exit codes. An exit
     value greater than 255 returns an exit code modulo 256. For example, exit
     3809 gives an exit code of 225 (3809 % 256 = 225).

[2]  An update of /usr/include/sysexits.h allocates previously unused exit
     codes from 64 - 78. It may be anticipated that the range of unallotted
     exit codes will be further restricted in the future. The author of this
     document will not do fixups on the scripting examples to conform to the
     changing standard. This should not cause any problems, since there is no
     overlap or conflict in usage of exit codes between compiled C/C++ binaries
     and shell scripts.



---
http://redsymbol.net/articles/bash-exit-traps/

How "Exit Traps" Can Make Your Bash Scripts Way More Robust And Reliable

   There is a simple, useful idiom to make your bash scripts more robust - ensuring they
   always perform necessary cleanup operations, even when something unexpected goes wrong. The
   secret sauce is a pseudo-signal provided by bash, called EXIT, that you can [7]trap;
   commands or functions trapped on it will execute when the script exits for any reason.
   Let's see how this works.

   The basic code structure is like this:

    1. #!/bin/bash
    2. function finish {
    3. # Your cleanup code here
    4. }
    5. trap finish EXIT

   You place any code that you want to be certain to run in this "finish" function. A good
   common example: creating a temporary scratch directory, then deleting it after.

    1. #!/bin/bash
    2. scratch=$(mktemp -d -t tmp.XXXXXXXXXX)
    3. function finish {
    4. rm -rf "$scratch"
    5. }
    6. trap finish EXIT

   You can then download, generate, slice and dice intermediate or temporary files to the
   $scratch directory to your heart's content. [8][1]

    1. # Download every linux kernel ever.... FOR SCIENCE!
    2. for major in {1..4}; do
    3. for minor in {0..99}; do
    4. for patchlevel in {0..99}; do
    5. tarball="linux-${major}-${minor}-${patchlevel}.tar.bz2"
    6. curl -q "http://kernel.org/path/to/$tarball" -o "$scratch/$tarball" || true
    7. if [ -f "$scratch/$tarball" ]; then
    8. tar jxf "$scratch/$tarball"
    9. fi
   10. done
   11. done
   12. done
   13. # magically merge them into some frankenstein kernel ...
   14. # That done, copy it to a destination
   15. cp "$scratch/frankenstein-linux.tar.bz2" "$1"
   16. # Here at script end, the scratch directory is erased automatically

   Compare this to how you'd remove the scratch directory without the trap:


    1. #!/bin/bash
    2. # DON'T DO THIS!
    3. scratch=$(mktemp -d -t tmp.XXXXXXXXXX)
    4.
    5. # Insert dozens or hundreds of lines of code here...
    6.
    7. # All done, now remove the directory before we exit
    8. rm -rf "$scratch"

   What's wrong with this? Plenty:
     * If some error causes the script to exit prematurely, the scratch directory and its
       contents don't get deleted. This is a resource leak, and may have security implications
       too.
     * If the script is designed to exit before the end, you must manually copy 'n paste the
       rm command at each exit point.
     * There are maintainability problems as well. If you later add a new in-script exit, it's
       easy to forget to include the removal - potentially creating mysterious heisenleaks.

Keeping Services Up, No Matter What

   Another scenario: Imagine you are automating some system administration task, requiring you
   to temporarily stop a server... and you want to be dead certain it starts again at the end,
   even if there is some runtime error. Then the pattern is:


    1. function finish {
    2. # re-start service
    3. sudo /etc/init.d/something start
    4. }
    5. trap finish EXIT
    6. sudo /etc/init.d/something stop
    7. # Do the work...
    8.
    9. # Allow the script to end and the trapped finish function to start the
   10. # daemon back up.

   A concrete example: suppose you have MongoDB running on an Ubuntu server, and want a
   cronned script to temporarily stop the process for some regular maintenance task. The way
   to handle it is:


    1. function finish {
    2. # re-start service
    3. sudo service mongdb start
    4. }
    5. trap finish EXIT
    6. # Stop the mongod instance
    7. sudo service mongdb stop
    8. # (If mongod is configured to fork, e.g. as part of a replica set, you
    9. # may instead need to do "sudo killall --wait /usr/bin/mongod".)

Capping Expensive Resources

   There is another situation where the exit trap is very useful: if your script initiates an
   expensive resource, needed only while the script is executing, and you want to make certain
   it releases that resource once it's done. For example, suppose you are working with Amazon
   Web Services (AWS), and want a script that creates a new image.

   (If you're not familar with this: Servers running on the Amazon cloud are called
   "[9]instances". Instances are launched from Amazon Machine Images, a.k.a. "AMIs" or
   "images". AMIs are kind of like a snapshot of a server at a specific moment in time.)

   A common pattern for creating custom AMIs looks like:
    1. Run an instance (i.e. start a server) from some base AMI.
    2. Make some modifications to it, perhaps by copying a script over and then executing it.
    3. Create a new image from this now-modified instance.
    4. Terminate the running instance, which you no longer need.

   That last step is really important. If your script fails to terminate the instance, it will
   keep running and accruing charges to your account. (In the worst case, you won't notice
   until the end of the month, when your bill is way higher than you expect. Believe me,
   that's no fun!)

   If our AMI-creation is encapsulated in a script, we can set an exit trap to destroy the
   instance. Let's rely on the EC2 command line tools:


    1. #!/bin/bash
    2. # define the base AMI ID somehow
    3. ami=$1
    4. # Store the temporary instance ID here
    5. instance=''
    6. # While we are at it, let me show you another use for a scratch directory.
    7. scratch=$(mktemp -d -t tmp.XXXXXXXXXX)
    8. function finish {
    9. if [ -n "$instance" ]; then
   10. ec2-terminate-instances "$instance"
   11. fi
   12. rm -rf "$scratch"
   13. }
   14. trap finish EXIT
   15. # This line runs the instance, and stores the program output (which
   16. # shows the instance ID) in a file in the scratch directory.
   17. ec2-run-instances "$ami" > "$scratch/run-instance"
   18. # Now extract the instance ID.
   19. instance=$(grep '^INSTANCE' "$scratch/run-instance" | cut -f 2)

   At this point in the script, the instance (EC2 server) is running [10][2]. You can do
   whatever you like: install software on the instance, modify its configuration
   programatically, et cetera, finally creating an image from the final version. The instance
   will be terminated for you when the script exits - even if some uncaught error causes it to
   exit early. (Just make sure to block until the image creation process finishes.)

Plenty Of Uses

   I believe what I've covered in this article only scratches the surface; having used this
   bash pattern for years, I still find new interesting and fun ways to apply it. You will
   probably discover your own situations where it will help make your bash scripts more
   reliable.

Footnotes

    1. The -t option to mktemp is optional on Linux, but needed on OS X. Make your scripts
       using this idiom more portable by including this option.
    2. When getting the instance ID, instead of using the scratch file, we could just say:
       instance=$(ec2-run-instances "$ami" | grep '^INSTANCE' | cut -f 2). But using the
       scratch file makes the code a bit more readable, leaves us with better logging for
       debugging, and makes it easy to capture other info from ec2-run-instances's output if
       we wish.



---
http://stackoverflow.com/questions/5033354/run-script-before-bash-exits

[26]Run script before Bash exits

   I'd like to run a script every time I close a Bash session.

   I use XFCE and Terminal 0.4.5 (Xfce Terminal Emulator), I would like to run a script every
   time I close a tab in Terminal including the last one (when I close Terminal).

   Something like .bashrc but running at the end of every session.

   .bash_logout doesn't work


3 Answers 3

   You use trap (see man bash):
trap /u1/myuser/on_exit_script.sh EXIT

   The command can be added to your .profile/.login

   This works whether you exit the shell normally (e.g. via exit command) or simply kill the
   terminal window/tab, since the shell gets the EXIT signal either way - I just tested by
   exiting my putty window.
***
   If you close your session with "exit", might be able to something like alias
   endbash="./runscript;exit" and just exit by entering endbash. I'm not entirely sure this
   works, as I'm running windows at the moment.

   edit: DVK has a better answer.
***
   Write you script in "~/.bash_logout". It executed by bash(1) when login shell exits.
***
   Note that this only works if bash is executed as a login shell, e.g. if you login via SSH
   or check "Run command as a login shell" in gnome-terminal's Profile Preferences. –
***



---
http://stackoverflow.com/questions/2129923/bash-run-command-before-a-script-exits

[26]Bash: run command before a script exits?

   If a bash script has set -e, and a command in the script returns an error, how can I do
   some cleanup before the script exits?

   For example:
#!/bin/bash
set -e
mkdir /tmp/foo
# ... do stuff ...
rm -r /tmp/foo

   How can I ensure that /tmp/foo is removed, even if one of the commands in ... do stuff ...
   fails?
   [28]bash
   [29]share|[30]improve this question
   asked Jan 25 '10 at 2:42
   [31]David Wolever
   40.3k24155311
   add a comment |

4 Answers 4

   [32]active [33]oldest [34]votes
   up vote 55 down vote accepted

   Here's an example of using trap:
#!/bin/bash
set -e
function cleanup {
  echo "Removing /tmp/foo"
  rm  -r /tmp/foo
}
trap cleanup EXIT
mkdir /tmp/foo
asdffdsa #Fails

   Output:
dbrown@luxury:~ $ sh traptest
t: line 9: asdffdsa: command not found
Removing /tmp/foo
dbrown@luxury:~ $

   Notice that even though the asdffdsa line failed, the cleanup still was executed.
   [35]share|[36]improve this answer
   answered Jan 25 '10 at 5:12
   [37]David M. Brown
   1,264814
   add a comment |
   up vote 6 down vote

   From the bash manpage (concerning builtins):

     trap [-lp] [[arg] sigspec ...]
     The command arg is to be read and executed when the shell receives signal(s) sigspec.

   So, as indicated in [38]Anon.'s answer, call trap early in the script to set up the handler
   you desire on ERR.
   [39]share|[40]improve this answer
       [41]edited Jan 25 '10 at 3:04
   answered Jan 25 '10 at 2:59
   [42]dmckee
   55.3k1491165
   1
   You can also trap on EXIT. –  [43]Dennis Williamson Jan 25 '10 at 3:15

   Run help trap to see some help on the built-in. –  [44]Flimm Feb 27 '14 at 13:20
   add a comment |
   up vote 3 down vote

   here is a [45]reference for you on trapping signals and set -e related. Have a look.
   [46]share|[47]improve this answer
   answered Jan 25 '10 at 3:07
   [48]ghostdog74
   99.8k17115183
   add a comment |
   up vote 1 down vote

   From the reference for set:

     -e

     Exit immediately if a simple command (see section 3.2.1 Simple Commands) exits with a
     non-zero status, unless the command that fails is part of an until or while loop, part
     of an if statement, part of a && or || list, or if the command's return status is being
     inverted using !. A trap on ERR, if set, is executed before the shell exits.



---
http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_12_02.html

   #[1]Bash Guide for Beginners [2]Catching signals [3]Signals [4]Summary

12.2. Traps

12.2.1. General

   There might be situations when you don't want users of your scripts to exit untimely using
   keyboard abort sequences, for example because input has to be provided or cleanup has to be
   done. The trap statement catches these sequences and can be programmed to execute a list of
   commands upon catching those signals.

   The syntax for the trap statement is straightforward:

   trap [COMMANDS] [SIGNALS]

   This instructs the trap command to catch the listed SIGNALS, which may be signal names with
   or without the SIG prefix, or signal numbers. If a signal is 0 or EXIT, the COMMANDS are
   executed when the shell exits. If one of the signals is DEBUG, the list of COMMANDS is
   executed after every simple command. A signal may also be specified as ERR; in that case
   COMMANDS are executed each time a simple command exits with a non-zero status. Note that
   these commands will not be executed when the non-zero exit status comes from part of an if
   statement, or from a while or until loop. Neither will they be executed if a logical AND
   (&&) or OR (||) result in a non-zero exit code, or when a command's return status is
   inverted using the ! operator.

   The return status of the trap command itself is zero unless an invalid signal specification
   is encountered. The trap command takes a couple of options, which are documented in the
   Bash info pages.

   Here is a very simple example, catching Ctrl+C from the user, upon which a message is
   printed. When you try to kill this program without specifying the KILL signal, nothing will
   happen:
#!/bin/bash
# traptest.sh

trap "echo Booh!" SIGINT SIGTERM
echo "pid is $$"

while :                 # This is the same as "while true".
do
        sleep 60        # This script is not really doing anything.
done

12.2.2. How Bash interprets traps

   When Bash receives a signal for which a trap has been set while waiting for a command to
   complete, the trap will not be executed until the command completes. When Bash is waiting
   for an asynchronous command via the wait built-in, the reception of a signal for which a
   trap has been set will cause the wait built-in to return immediately with an exit status
   greater than 128, immediately after which the trap is executed.

12.2.3. More examples

12.2.3.1. Detecting when a variable is used

   When debugging longer scripts, you might want to give a variable the trace attribute and
   trap DEBUG messages for that variable. Normally you would just declare a variable using an
   assignment like VARIABLE=value. Replacing the declaration of the variable with the
   following lines might provide valuable information about what your script is doing:
declare -t VARIABLE=value

trap "echo VARIABLE is being used here." DEBUG

# rest of the script

12.2.3.2. Removing rubbish upon exit

   The whatis command relies on a database which is regularly built using the makewhatis.cron
   script with cron:
#!/bin/bash

LOCKFILE=/var/lock/makewhatis.lock

# Previous makewhatis should execute successfully:

[ -f $LOCKFILE ] && exit 0

# Upon exit, remove lockfile.

trap "{ rm -f $LOCKFILE ; exit 255; }" EXIT

touch $LOCKFILE
makewhatis -u -w
exit 0



---
http://linuxcommand.org/wss0160.php

Errors and Signals and Traps (Oh, My!) - Part 2

   Errors are not the only way that a script can terminate unexpectedly. You also have to be
   concerned with signals. Consider the following program:
#!/bin/bash

echo "this script will endlessly loop until you stop it"
while true; do
        : # Do nothing
done

   After you launch this script it will appear to hang. Actually, like most programs that
   appear to hang, it is really stuck inside a loop. In this case, it is waiting for the true
   command to return a non-zero exit status, which it never does. Once started, the script
   will continue until bash receives a signal that will stop it. You can send such a signal by
   typing ctrl-c which is the signal called SIGINT (short for SIGnal INTerrupt).

Cleaning up after yourself

   OK, so a signal can come along and make your script terminate. Why does it matter? Well, in
   many cases it doesn't matter and you can ignore signals, but in some cases it will matter.

   Let's take a look at another script:
#!/bin/bash

# Program to print a text file with headers and footers

TEMP_FILE=/tmp/printfile.txt

pr $1 > $TEMP_FILE

echo -n "Print file? [y/n]: "
read
if [ "$REPLY" = "y" ]; then
        lpr $TEMP_FILE
fi

   This script processes a text file specified on the command line with the [12]pr command and
   stores the result in a temporary file. Next, it asks the user if they want to print the
   file. If the user types "y", then the temporary file is passed to the [13]lpr program for
   printing (you may substitute less for lpr if you don't actually have a printer attached to
   your system.)

   Now, I admit this script has a lot of design problems. While it needs a file name passed on
   the command line, it doesn't check that it got one, and it doesn't check that the file
   actually exists. But the problem I want to focus on here is the fact that when the script
   terminates, it leaves behind the temporary file.

   Good practice would dictate that we delete the temporary file $TEMP_FILE when the script
   terminates. This is easily accomplished by adding the following to the end of the script:
rm $TEMP_FILE

   This would seem to solve the problem, but what happens if the user types ctrl-c when the
   "Print file? [y/n]:" prompt appears? The script will terminate at the read command and the
   rm command is never executed. Clearly, we need a way to respond to signals such as SIGINT
   when the ctrl-c key is typed.

   Fortunately, bash provides a method to perform commands if and when signals are received.

trap

   The trap command allows you to execute a command when a signal is received by your script.
   It works like this:
trap arg signals

   "signals" is a list of signals to intercept and "arg" is a command to execute when one of
   the signals is received. For our printing script, we might handle the signal problem this
   way:
#!/bin/bash

# Program to print a text file with headers and footers

TEMP_FILE=/tmp/printfile.txt

trap "rm $TEMP_FILE; exit" SIGHUP SIGINT SIGTERM

pr $1 > $TEMP_FILE

echo -n "Print file? [y/n]: "
read
if [ "$REPLY" = "y" ]; then
        lpr $TEMP_FILE
fi
rm $TEMP_FILE

   Here we have added a trap command that will execute "rm $TEMP_FILE" if any of the listed
   signals is received. The three signals listed are the most common ones that you will
   encounter, but there are many more that can be specified. For a complete list, type "trap
   -l". In addition to listing the signals by name, you may alternately specify them by
   number.

Signal 9 From Outer Space

   There is one signal that you cannot trap: SIGKILL or signal 9. The kernel immediately
   terminates any process sent this signal and no signal handling is performed. Since it will
   always terminate a program that is stuck, hung, or otherwise screwed up, it is tempting to
   think that it's the easy way out when you have to get something to stop and go away. Often
   you will see references to the following command which sends the SIGKILL signal:
   kill -9

   However, despite its apparent ease, you must remember that when you send this signal, no
   processing is done by the application. Often this is OK, but with many programs it's not.
   In particular, many complex programs (and some not-so-complex) create lock files to prevent
   multiple copies of the program from running at the same time. When a program that uses a
   lock file is sent a SIGKILL, it doesn't get the chance to remove the lock file when it
   terminates. The presence of the lock file will prevent the program from restarting until
   the lock file is manually removed.

   Be warned. Use SIGKILL as a last resort.

A clean_up function

   While the trap command has solved the problem, we can see that it has some limitations.
   Most importantly, it will only accept a single string containing the command to be
   performed when the signal is received. You could get clever and use ";" and put multiple
   commands in the string to get more complex behavior, but frankly, it's ugly. A better way
   would be to create a function that is called when you want to perform any actions at the
   end of your script. In my scripts, I call this function clean_up.
#!/bin/bash

# Program to print a text file with headers and footers

TEMP_FILE=/tmp/printfile.txt

function clean_up {

        # Perform program exit housekeeping
        rm $TEMP_FILE
        exit
}

trap clean_up SIGHUP SIGINT SIGTERM

pr $1 > $TEMP_FILE

echo -n "Print file? [y/n]: "
read
if [ "$REPLY" = "y" ]; then
        lpr $TEMP_FILE
fi
clean_up

   The use of a clean up function is a good idea for your error handling routines too. After
   all, when your program terminates (for whatever reason), you should clean up after
   yourself. Here is finished version of our program with improved error and signal handling:
#!/bin/bash

# Program to print a text file with headers and footers

# Usage: printfile file

# Create a temporary file name that gives preference
# to the user's local tmp directory and has a name
# that is resistant to "temp race attacks"

if [ -d "~/tmp" ]; then
        TEMP_DIR=~/tmp
else
        TEMP_DIR=/tmp
fi
TEMP_FILE=$TEMP_DIR/printfile.$$.$RANDOM
PROGNAME=$(basename $0)

function usage {

        # Display usage message on standard error
        echo "Usage: $PROGNAME file" 1>&2
}

function clean_up {

        # Perform program exit housekeeping
        # Optionally accepts an exit status
        rm -f $TEMP_FILE
        exit $1
}

function error_exit {

        # Display error message and exit
        echo "${PROGNAME}: ${1:-"Unknown Error"}" 1>&2
        clean_up 1
}

trap clean_up SIGHUP SIGINT SIGTERM

if [ $# != "1" ]; then
        usage
        error_exit "one file to print must be specified"
fi
if [ ! -f "$1" ]; then
        error_exit "file $1 cannot be read"
fi

pr $1 > $TEMP_FILE || error_exit "cannot format file"

echo -n "Print file? [y/n]: "
read
if [ "$REPLY" = "y" ]; then
        lpr $TEMP_FILE || error_exit "cannot print file"
fi
clean_up

Creating safe temporary files

   In the program above, there a number of steps taken to help secure the temporary file used
   by this script. It is a Unix tradition to use a directory called /tmp to place temporary
   files used by programs. Everyone may write files into this directory. This naturally leads
   to some security concerns. If possible, avoid writing files in the /tmp directory. The
   preferred technique is to write them in a local directory such as ~/tmp (a tmp subdirectory
   in the user's home directory.) If you must write files in /tmp, you must take steps to make
   sure the file names are not predictable. Predictable file names allow an attacker to create
   symbolic links to other files that the attacker wants you to overwrite.

   A good file name will help you figure out what wrote the file, but will not be entirely
   predictable. In the script above, the following line of code created the temporary file
   $TEMP_FILE:
TEMP_FILE=$TEMP_DIR/printfile.$$.$RANDOM

   The $TEMP_DIR variable contains either /tmp or ~/tmp depending on the availability of the
   directory. It is common practice to embed the name of the program into the file name. We
   have done that with the string "printfile". Next, we use the $$ shell variable to embed the
   process id (pid) of the program. This further helps identify what process is responsible
   for the file. Surprisingly, the process id alone is not unpredictable enough to make the
   file safe, so we add the $RANDOM shell variable to append a random number to the file name.
   With this technique, we create a file name that is both easily identifiable and
   unpredictable.



---
http://www.linuxjournal.com/content/use-bash-trap-statement-cleanup-temporary-files

Use the Bash trap Statement to Clean Up Temporary Files

   Tue, 05/05/2009 - 15:00 — [6]Mitch Frazier

   The trap statement in bash causes your script to execute one or more commands when a signal
   is received. One of the useful things you can use this for is to clean up temporary files
   when your script exits.

   To execute code when your script receives a signal, use the following syntax:
trap arg sigspec...

   The "arg" is the command to execute. If the command contains spaces, quote it. You can
   include multiple commands by separating them with semicolons. For more complex things, put
   your exit code in a function and just invoke the function. The "sigspec" list is a list of
   signals to trap and then execute "arg" (if/when they occur). For example, to remove a file
   on EXIT, do the following:
trap "rm -f afile" EXIT

   Note that EXIT is not a real signal (do kill -l to see all signals); it is synthesized by
   bash.

   Be careful using wildcards in "arg", because if they are unquoted or quoted with double
   quotes, they get expanded when the trap statement is encountered and not when "arg" is
   executed. For example, if you have a file named "abc.tmp" and the following trap statement
   is executed:
trap "rm -f *.tmp" EXIT

   the command that gets executed when the script exits is "rm -f abc.tmp" and not "rm -f
   *.tmp". To avoid this problem, use single quotes.

   If you create temporary files at various places in your code and you don't use a naming
   convention that would allow you to use a wild card in your trap statement and you don't
   want to worry about changing your trap statement as your code evolves, you could write
   something like this to allow you to add new trap commands that get executed on exit:
#!/bin/bash

declare -a on_exit_items

function on_exit()
{
    for i in "${on_exit_items[@]}"
    do
        echo "on_exit: $i"
        eval $i
    done
}

function add_on_exit()
{
    local n=${#on_exit_items[*]}
    on_exit_items[$n]="$*"
    if [[ $n -eq 0 ]]; then
        echo "Setting trap"
        trap on_exit EXIT
    fi
}

touch $$-1.tmp
add_on_exit rm -f $$-1.tmp

touch $$-2.tmp
add_on_exit rm -f $$-2.tmp

ls -la

   Here the function add_on_exit() adds commands to an array, and the on_exit() function loops
   through the commands in the array and executes them on exit. The on_exit function gets set
   as the trap command the first time add_on_exit is called.

Comments

Comment viewing options

   [Threaded list - expanded.]
   [Date - newest first]
   [50 comments per page.]
   Save settings
   Select your preferred way to display the comments and click "Save settings" to activate
   your changes.
   Fri, 09/18/2009 - 20:35 — Isohedral (not verified) [7]Bugs in the article's scripts?

   First, a caveat: I rarely use Bourne-shell scripts. Still, I was unable to get
   the example cited in the article running, and I believe that is caused by at least
   two problems in the illustrative example scripts.

   It seems to me that the exit commands have to be quoted when add_on_exit
   is invoked; i.e., add_on_exit "rm -f $$-1.tmp" instead of add_on_exit rm -f $$-1.tmp ,
   no? Also, shouldn't the command be assigned to a new element of the on_exit_items
   array using on_exit_items="([$n]=$*)" ?

   isohedral
   Mon, 09/21/2009 - 09:30 — [8]Mitch Frazier [9]Works for me

   The example script works for me.

   The exit commands could be quoted when calling add_on_exit but they don't have to be. The
   entire command line (to add_on_exit) is quoted when it is added to the array:
    on_exit_items[$n]="$*"

   and the commands are added to a new element of the array:
    local n=${#on_exit_items[*]}
    on_exit_items[$n]="$*"

   The syntax that you suggest for appending to the array does not preserve the existing
   elements.
   —

   Mitch Frazier is an Associate Editor for Linux Journal.
   Tue, 07/28/2009 - 09:38 — Samual (not verified) [10]bash script to capture stdin

   Hi there, firstly, excellent article!

   I am running a script on my ubuntu system to pair my BT mouse with my laptop. I'd like at
   one to point capture keyboard input to proceed with the pairing. I am running the script
   graphically by double-clicking the executable, and I do NOT wish to open a terminal.

   Is there a way to do this using TRAP? Either to tell the script to wait for a keyboard
   signal, or maybe call some other program that does so?

   Details can be found here:
   [11]http://www.linuxforums.org/forum/linux-programming-scripting/150535-abso...

   -Thanks!
   Tue, 07/28/2009 - 11:50 — [12]Mitch Frazier [13]Keyboard

   There's not a "keyboard" trap that you can catch and beyond that since you haven't opened a
   terminal you don't even have a keyboard "connected" to your script. This is actually an
   important point: when you run a shell script from a GUI launcher, things aren't as you
   perhaps expect them to be. If you run ls -la /proc/$$/fd from a terminal window you'll see
   something like:
lrwx------ 1 user users 64 2009-07-28 09:12 0 -> /dev/pts/1
lrwx------ 1 user users 64 2009-07-28 09:12 1 -> /dev/pts/1
lrwx------ 1 user users 64 2009-07-28 09:12 2 -> /dev/pts/1

   showing your stdin/stdout/stderr connected to the terminal.

   If however you were to run that same command from a script launced by a GUI launcher you
   would see something like this:
lr-x------ 1 user users 64 2009-07-28 09:12 0 -> /dev/null
l-wx------ 1 user users 64 2009-07-28 09:12 1 -> /home/user/.xsession-errors
l-wx------ 1 user users 64 2009-07-28 09:12 2 -> /home/user/.xsession-errors

   So all output ends up in your ~/.xsession-errors file and your input (stdin) is not even
   connected to anything useful. Note that when I said see above, I meant you'd see it in your
   ~/.xsession-errors file.

   That said, seems to me there's a simple solution to this problem: since you don't want to
   open a terminal why don't you use zenity or something to ask the question in a GUI dialog
   box, eg:
if zenity --timeout 2 --question --text 'Connect BT mouse? '; then
    # connect mouse
    ...

   or:
zenity --timeout 2 --question --text 'Connect BT mouse? '
if [ $? -eq 0 ]; then
    # connect mouse
    ...


   zenity
   —

   Mitch Frazier is an Associate Editor for Linux Journal.
   Mon, 08/10/2009 - 23:23 — Samual (not verified) [14]Worked like a charm and had

   Worked like a charm and had the added side-effect of making my pairing process more robust.
   I'm not sure why, but for some reason, I no longer need to physically put the mouse in
   pairing mode (a real blessing) by pressing connect on the mouse!

   Thank you!
   Mon, 08/10/2009 - 15:14 — Samual (not verified) [15]Thanks kindly! Sorry for the

   Thanks kindly!

   Sorry for the delay, I had not noticed how swiftly you'd replied!

   I think your solution solves the problem, and I do understand the problem better now. If
   you don't mind, I am linking to here and marking the forum threads closed.

   Thansk again!



---
http://bash.cyberciti.biz/guide/Trap_statement

Trap statement

   From Linux Shell Scripting Tutorial - A Beginner's handbook
   Jump to: [5]navigation, [6]search
   [7]← Shell signal values [8]Home [9]How to clear trap →
     * While running a script user may press Break or CTRL+C to terminate the process.
     * User can also stop the process by pressing CTRL+Z.
     * Error can occur do to bug in a shell script such as arithmetic overflow.
     * This may result into errors or unpredictable output.
     * Whenever user interrupts a signal is send to the command or the script.
     * Signals force the script to exit.
     * However, the trap command captures an interrupt.
     * The trap command provides the script to captures an interrupt (signal) and then clean
       it up within the script.

Syntax

   The syntax is as follows
trap arg signal
trap command signal
trap 'action' signal1 signal2 signalN
trap 'action' SIGINT
trap 'action' SIGTERM SIGINT SIGFPE SIGSTP
trap 'action' 15 2 8 20

Example

   Create a shell script called testtrap.sh:
#!/bin/bash
# capture an interrupt # 0
trap 'echo "Exit 0 signal detected..."' 0

# display something
echo "This is a test"

# exit shell script with 0 signal
exit 0

   Save and close the file. Run it as follows:
chmod +x testtrap.sh
./testtrap.sh

   Sample outputs:
This is a test
Exit 0 signal detected...

     * The first line sets a trap when script tries to exit with status 0.
     * Then script exits the shell with 0, which would result in running [10]echo command.
     * Try the following example at a shell prompt (make sure /tmp/rap54ibs2sap.txt doesn't
       exits).
     * Define a shell variable called $file:

file=/tmp/rap54ibs2sap.txt

   Now, try to remove $file, enter:
rm $file

   Sample output:
rm: cannot remove `/tmp/rap54ibs2sap.txt': No such file or directory

   Now sets a trap for rm command:
trap "rm $file; exit" 0 1 2 3 15

   Display list of defined traps, enter:
trap

   Sample outputs:
trap -- 'rm /tmp/rap54ibs2sap.txt; exit' EXIT
trap -- 'rm /tmp/rap54ibs2sap.txt; exit' SIGHUP
trap -- 'rm /tmp/rap54ibs2sap.txt; exit' SIGINT
trap -- 'rm /tmp/rap54ibs2sap.txt; exit' SIGQUIT
trap -- 'rm /tmp/rap54ibs2sap.txt; exit' SIGTERM

   Now, try again to remove the $file, enter:
rm $file

   This time rm command did not displayed an error. The $file doesn't exist yet. The trap
   command simply exit whenever it get 0, 1, 2, 3, or 15 signal. Try capturing CTRL+C:
#!/bin/bash
# capture an interrupt # 2 (SIGINT)
trap '' 2
# read CTRL+C from keyboard with 30 second timeout
read -t 30 -p  "I'm sleeping hit CTRL+C to exit..."

   Sample outputs:
I'm sleeping hit CTRL+C to exit...^C^C^C^C

   Retrieved from
   "[14]http://bash.cyberciti.biz/wiki/index.php?title=Trap_statement&oldid=2627"



---
http://www.ibm.com/developerworks/aix/library/au-usingtraps/

Using traps in your scripts

   Trapping signals

   For scripts to be reasonably robust, one of the conditions that should ideally be met is
   the ability to clean up any temporary logs or processes left lying around from a forceful
   termination. Another element to consider is when an interrupt from a user is received, what
   appropriate action should be taken? With the shell built-in trap command and the logger
   utility, these can help to provide your scripts with more robustness when a script is
   forcefully terminated. In this article, I will demonstrate ways trap and logger can be
   used.

   [18]PDF (214 KB) |
   Share:

   [19]David Tansley ([20]david.tansley@btinternet.com), System Administrator, Ace Europe

   [21]Close [x]

   David Tansley David Tansley is a freelance writer. He has 15 years of experience as a UNIX
   administrator, using AIX the last eight years. He enjoys playing badminton, then relaxing
   watching Formula 1, but nothing beats riding and touring on his GSA motorbike with his
   wife.

   26 July 2011

   When writing scripts, it is good practice to have a controlled exit from your script; this
   allows for failed conditions within the script processing. Consider a script that copies or
   replaces certain files in a file system. You could check if each copy completes
   successfully before moving on to the next task in the script. If issues occur, then the
   script exits. This allows the system administrator to inspect where the script failed so
   that immediate action can be taken to back-out the process or take an alternative action in
   completing the task.

   Listing 1 below contains basic conditional code that could achieve this goal. Using a file
   copy process as an example, a test is carried out to make sure the file run_pj actually
   exists. If it does, then a copy is carried out to take a backup of the destination file. If
   the copy is unsuccessful, then the script exits with a message, detailing the error. If the
   file is not present, then the script exits, as no more processing should be carried out. If
   the copy was successful, then the new updated file is copied and overwrites the original
   file. If this is not successful, then the script exits.

Listing 1. Example_replace

#!/bin/bash
#
proj_dir=/opt/pcake/bin
# check file is present
if  [ ! -f "$proj_dir/run_pj" ]
then
 echo " $proj_dir/run_pj not present...exiting"
 exit 1
fi
 # make a backup copy
cp -p $proj_dir/run_pj $proj_dir/run_pj.24042011
if [ $? != 0 ]
then
echo "$proj_dir/run_pj no backup made...exiting"
exit 1
fi

# copy  over updated file
if [ ! -f "/opt/dump/rollout/run_pj" ]
 then
  echo "/opt/dump/rollout/run_pj not present...exiting"
  exit 1
fi
cp -p /opt/dump/rollout/run_pj $proj_dir/run_pj
if [ $? != 0 ]
then
echo " $proj_dir/run_pj was not copied..exiting"
exit 1
fi

   In this demonstration, I am using bash v3.2. The bash shell can be downloaded from the AIX
   Toolbox, see the [32]Resources section.

   Using the approach in [33]Listing 1, the script exits if there is any error in the copy
   process, thus not allowing the script to carry on processing if there is an error. Clearly,
   any error would be fixed before the script is run again.

   Another technique to check for errors and exit is to use the set option:
set -e

   With the set option: -e, if a command fails (that is, it returns a non-zero exit status),
   the script exits (unless it is part of a iteration, &&, || command). The example shown in
   Listing 2 below, copies a non-existent file. The set -e option is used. If the copy command
   fails, the script exits. Notice that when you run the command, the if statement for the
   last exit status is never reached because the script exits upon a non-zero return status of
   the cp command.

Listing 2. Example_fail

#!/bin/bash
set -e
proj_dir=/opt/rollout/v12
# copy a non-existent file
cp $proj_dir/go_sup /usr/local/bin/go_sup
 if [ $? != 0 ]
 then
echo "could not copy $proj_dir/go_sup to /usr/local/bin/"
exit 1
 fi

$ cp_test
cp: /opt/rollout/v12/go_sup: A file or directory in the path name does not exist.

Generating syslog messages

   Using the logger command allows the shell and scripts to write messages to the system
   messages file via the syslogd service. This can be used within a script to log errors or on
   completions of your processes so that is viewable by all who interrogate the messages file.
   Thus keeping you and other system administrators informed of events that have been
   generated from your scripts.

   The most basic format of the command is:
logger -p priority message

   Where -p is the priority or facility level contained within syslog.

   For example, the following logger command contains the calling script name ("rollout" in
   this example) with the message something has happened.
logger -p notice "$(basename $0) - something has happened"

   The the following output appears in /var/adm/messages:
Apr  5 13:20:30 uk01wrs6008 user:notice dxtans: rollout - something has happened

Getting a signal

   The two examples contained in [35]Listing 1 and [36]Listing 2 shows one way that checking
   post command execution can be carried out. However, what happens if a script gets
   terminated during its execution? Scripts can be killed or terminated using the signal
   mechanism (note that not all signals sent are terminal). A signal that is sent to a running
   process interrupts that process to force some sort of event, typically some action. Signals
   can come from, but not restricted to:
     * The kernel or user space via some system event.
     * The actual process itself via the keyboard (Ctrl-C).
     * An illegal instruction from within the process.
     * Another process via another user sending a kill to your process.
     * Notification via a notification of the state of a required device.

   To view the current list of signals, use kill -l (the letter l) command. The list is
   presented in the form (signal number, signal name):
 $ kill -l
 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL
 5) SIGTRAP      6) SIGABRT      7) SIGEMT       8) SIGFPE
 9)SIGKILL     10) SIGBUS      11) SIGSEGV     12) SIGSYS
…....
…....

   To view the signals and their default actions (on an AIX machine), view the file:
$ cat /usr/include/sys/signal.h|more
…..
…..
#define SIGHUP     1    /* hangup, generated when terminal disconnects */
#define SIGINT     2    /* interrupt, generated from terminal special char */
#define SIGQUIT    3    /* (*) quit, generated from terminal special char */
#define SIGILL     4    /* (*) illegal instruction (not reset when caught)*/
#define SIGTRAP    5    /* (*) trace trap (not reset when caught) */
#define SIGABRT    6    /* (*) abort process */
…..
…..


I have received a signal. Now what?

   When a signal has been received by the script, the script can do one of three actions:
    1. Ignore it and do nothing. This is probably what most scripts do without the script
       authors realising it.
    2. Catch the signal using trap and take appropriate action.
    3. Take the default action.

   All the above is true except for the following signals:

   SIGKILL (signal 9)

   SIGSTOP (signal 17)

   SIGCONT (signal 19)

   These cannot be caught and always uses the default action. SIGKILL always kills the
   process. Looking at the listing from the /usr/include/sys/signal.h file, we see the default
   action for each signal. For instance, SIGINT (signal 2) is an interrupt generated from the
   terminal; typically, this is the keyboard. Each defined system signal has a different
   action. There are also two user defined signals: SIGUSR1 (signal 30) and SIGUSR2 (signal
   31).

   It is up to the author of the script to take what action is required if any, if a signal is
   received.

   These can be used by the script author to do bespoke signals. Be sure to view the signal.h
   file for all the default actions.

   Common signals are:
     * SIGHUP - hangup or exit a foreground running process from a terminal
     * SIGINT - Ctrl-C from the keyboard
     * SIGQUIT - Ctrl-\ from the keyboard
     * SIGTERM - software termination signal

   When receiving a signal, actions that can take place are:
     * cleaning up files
     * prompting the users if the script should be actually terminated
     * ignoring the actual signal
     * carry on processing

Catching a signal

   To catch a signal that is sent to your process, use the built-in trap command. When a
   signal is caught, the current command being executed attempts to complete before the trap
   command takes over. If it is a SIGKILL, then termination is immediate. If you ignore
   certain signals, the default action always take place. For example, if you only trap for
   SIGINT but do nothing about SIGQUIT, then if your process gets a SIGQUIT, the default
   action takes place (most likely an untidy termination of your script, which you probably do
   not want).

   The format of the trap command is:
trap 'command_list'  signals

   Where command_list is a list of commands, which can include a function to run upon
   receiving a signal contained in the signals list. And, signals is a list of signals to
   catch or trap.

   To ignore a signal, use two single quotes in place of the command_list:
trap ''  signals

   To reset a trap use:
trap - signals

   Where signals is the signal list.

   Lets now look at a bare bones script that catches SIGINT and SIGQUIT. The script contained
   in Listing 3 below is a counter iteration script. When the user hits Ctrl-C or Ctrl-\ on
   the keyboard, the trap command traps the signal, and echoes a message that the script has
   terminated. The termination is accomplished by using the exit command at the end of the
   command list. If this is not done, the script does not terminate and continues processing.
   In this example, we want it to terminate. There may be occasions when this would not be the
   case and processing should continue.

Listing 3. Trap1

#!/bin/bash
# trap1
trap 'echo you hit Ctrl-C/Ctrl-\, now exiting..; exit' SIGINT SIGQUIT
count=0

while :
 do
   sleep 1
   count=$(expr $count + 1)
   echo $count
 done

$ trap1
1
2
3
^Cyou hit Ctrl-C/Ctrl-\, now exiting..

   It is considered good form that you use the signal names and not the signal numbers within
   the trap command. This is for portability reasons across other systems.

   You can also use a function in place of the command as demonstrated in Listing 4 below:

Listing 4. Trap1a

#!/bin/bash
# trap1a
trap 'my_exit; exit' SIGINT SIGQUIT
count=0

my_exit()
{
echo "you hit Ctrl-C/Ctrl-\, now exiting.."
 # cleanp commands here if any
}

while :
 do
   sleep 1
   count=$(expr $count + 1)
   echo $count
 done

   Signals can also be caught, when a script is running in the background. Listing 5 below,
   contains a simple counter as in the previous examples. In the following example, I have
   again chosen to exit the script upon catching the signal. If this was a file processing
   script, temporary files created would be deleted first.

   The script is submitted into the background using:
$ /home/dxtans/trapbg &
[1] 708790
$ 1
2
3

   Now from another terminal, send a signal SIGHUP to kill it.
$ ps -ef |grep trapbg
 dxtans 708790 2457860 11:49:39 pts/0 0:00 /bin/bash /home/dxtans/trapbg
$ kill -1 708790

   Now back on the terminal where the script was submitted, the following is displayed:
$ /home/dxtans/trapbg &
[1] 708790
$ 1
2
3
Going down on a SIGHUP - signal 1, now exiting..
[1]+ Done   /home/dxtans/trapbg

Listing 5. trapbg

#!/bin/bash
# trapbg
trap 'echo Going down on a SIGHUP - signal 1, now exiting..; exit' SIGHUP
count=0
while :
do
 sleep 10
 count=$(expr $count + 1)
 echo $count
done

   The most common tasks when dealing with signals is to clean up temporary files. Typically,
   these are created with the PID (the script process pid) that are appended to the user
   created files in /tmp. Assume the temp files are in this form:
hold1.$$
hold2.$$

   A common command to remove these files is:
rm /tmp/hold*.$$

   The following piece of code traps for SIGNHUP SIGINT SIGQUIT SIGTERM then remove the files:
trap 'rm /tmp/hold*.$$; exit' SIGNHUP SIGINT SIGQUIT SIGTERM

   Earlier in this article, I demonstrated that using set -e causes a script to terminate upon
   an occurrence on a non-zero exit status from a command. Within trap, you have a similar
   option; it is not really a signal as such but is based on set -e as if it was invoked. It
   traps a non-zero exit status from a command, using the ERR variable. The ERR goes with the
   signal list within the trap command. In the following example, a non-existent file is
   copied, which invokes an error:
#!/bin/bash
# trap1b
trap 'echo I have error in my script..' ERR
cp /home/dxtans/afile /tmp

   When executed, the output is:
$ trap1b
cp: /home/dxtans/afile: A file or directory in the path name does not exist.
I have error in my script.

   There are two variables that come in handy when dealing with traps to give you more
   information on the script termination, LINENO and BASH_COMMAND. The BASH_COMAMND is
   exclusive to bash. These report, or attempt to report, the line number that the script is
   currently executing, and also the current command that is running. The following example,
   Listing 6 below, demonstrates this. The script executes a list of echo and sleep commands.
   When the script is sent either a SIGHUP, SIGINT, SIGQUIT, the script terminates. A message
   displays containing the line number and command when the trap was caught; the script then
   exits (from the exit command on the trap command list). Notice that the trap calls the
   function my_exit to display the information. By parsing the parameters $1 (LINENO) and $2
   (BASH_COMMAND), it also logs a message to /var/adm/messages of the event. Other clean up
   commands would be put in this function, if required.

Listing 6. trap4

#!/bin/bash
# trap4

trap 'my_exit $LINENO $BASH_COMMAND; exit' SIGHUP SIGINT SIGQUIT
my_exit()
{
echo "$(basename $0)  caught error on line : $1 command was: $2"

logger -p notice "script: $(basename $0) was terminated: line: $1, command was $2"
 # cleanp commands here if any
}

echo 1
sleep 1
echo 2
sleep 1
echo 3

   Running this script a couple of times, and then interrupting at different intervals,
   produces the following output.
$ trap4
1
2
^Ctrap4  caught error on line : 15 command was: sleep

$ trap4
1
^Ctrap4  caught error on line : 13 command was: sleep

   In /var/adm/messages, we have an entry for the script termination:
Apr  6 12:12:46 rs6000 user:notice dxtans: script: trap4 was terminated: line: 13,
 command was sleep

   There are occasions when you will want to ignore certain signals. Perhaps you wish to
   prevent someone hitting Ctrl-C or Ctrl-\ on the keyboard by mistake when your script is
   doing some processing on large files, and you wish it to complete, without user
   interruption. The following segment of code achieves this:
trap '' SIGINT SIGQUIT

   You can also ignore certain signals during a portion of your script, then re-instate them
   later on when you do wish to catch the signals so you can take some form of action. The
   script contained in Listing 7 below ignores the signals SIGINT and SIGQUIT until after the
   sleep command has finished. Then when the next sleep command starts, trap takes action if
   the signals are sent and terminates. As in the previous examples, you can assume the sleep
   commands represent some form of processing.

Listing 7. trapoff_on

#!/bin/bash
# trapoff_on

trap '' SIGINT SIGQUIT
echo "you cannot terminate using ctrl-c or ctrl-\, "
# heavy pressing go on here, cannot interrupt !
sleep 10

trap 'echo terminated; exit' SIGINT SIGQUIT
# user can now interrupt
echo "ok you can now terminate me using those keystrokes"
sleep 10

Sending a signal to a child

   Scripts that contain child processes also need to be addressed. Assuming you wish to
   terminate any child processes, you need to kill these as well. This is accomplished using
   the trap command as demonstrated in Listing 8 below. In this example, two sleep commands
   are used as the child processes. These are put into the background; as each process is run,
   the PID of the process is placed into the variable: $pid. This variable holds the two PIDS
   of the child (sleep) processes.

   To kill the main script, either a SIGHUP,SIGINT,SIGQUIT or SIGTERM is sent. Upon catching
   this signal, a kill command is issued to the PID of the child processes contained in the
   variable $pid. Once completed, the script exits. The wait at the end of the script will
   wait for the child processes to terminate or complete. Further signal traps may be required
   that would be contained within the child scripts to do further cleaning up before exit.
   Clearly, this depends on your type of processing.

   The following example kills the children when the parent is sent one of the signals.

Listing 8. trapchild

#!/bin/bash
# trapchild

sleep 120 &

pid="$!"

sleep 120 &
pid="$pid $!"

echo "my process pid is: $$"
echo "my child pid list is: $pid"

trap 'echo I am going down, so killing off my processes..; kill $pid; exit' SIGHUP SIGINT
 SIGQUIT SIGTERM

wait

   Upon execution of the script, the following displays:
$ /home/dxtans/trap/trapchild
my process pid is: 6553626
my child pid list is: 5767380 6488072

   Check from the terminal that the processes are running, along with the child processes (the
   two sleep commands).
$ ps -ef |grep trapchild
    root 6553626 5439516   0 20:51:32  pts/1  0:00 /bin/bash /home/dxtans/trap/trapchild
$ ps -ef |grep sleep
root 5767380 6553626   0 20:51:32  pts/1  0:00 sleep 120
root 6488072 6553626   0 20:51:32  pts/1  0:00 sleep 120

   Let's now send a SIGTERM to the parent process. The script terminates and terminates the
   child processes.
$ kill -15 6553626

   The script then terminates with the following output:
$ /home/dxtans/trap/trapchild
my process pid is: 6553626
my child pid list is: 5767380 6488072
I am going down, so killing off my processes..

   Check that nothing is returned after the termination:
# ps -ef |grep sleep

Conclusion

   Using traps within your scripts requires a little extra effort. The result can be that when
   a trappable signal is inbound to your script, you will be in a good position to take
   action.



---
http://stackoverflow.com/questions/26808727/bash-trap-interrupt-command-but-should-exit-on-end-of-loop

[26]bash trap interrupt command but should exit on end of loop

   I´ve asked [28]Bash trap - exit only at the end of loop and the submitted solution works
   but while pressing CTRL-C the running command in the script (mp3convert with lame) will be
   interrupt and than the complete for loop will running to the end. Let me show you the
   simple script:
#!/bin/bash
mp3convert () { lame -V0 file.wav file.mp3 }

PreTrap() { QUIT=1 }

CleanUp() {
  if [ ! -z $QUIT ]; then
     rm -f $TMPFILE1
     rm -f $TMPFILE2
     echo "... done!" && exit
  fi }

trap PreTrap SIGINT SIGTERM SIGTSTP
trap CleanUp EXIT

case $1 in
     write)
           while [ -n "$line" ]
             do
                mp3convert
                [SOMEMOREMAGIC]
                CleanUp
             done
    ;;
QUIT=1

   If I press CTRL-C while function mp3convert is running the lame command will be interrupt
   and then [SOMEMOREMAGIC] will execute before CleanUp is running. I don´t understand why the
   lame command will be interrupt and how I could avoid them.
   [29]bash [30]shell [31]loops
   [32]share|[33]improve this question
   asked Nov 7 '14 at 19:34
   [34]UsersUser
   1277
   add a comment |

3 Answers 3

   [35]active [36]oldest [37]votes
   up vote 1 down vote accepted

   Try to simplify the discussion above, I wrap up an easier understandable version of
   show-case script below. This script also HANDLES the "double control-C problem": (Double
   control-C problem: If you hit control C twice, or three times, depending on how many wait
   $PID you used, those clean up can not be done properly.)
#!/bin/bash

mp3convert () {
  echo "mp3convert..."; sleep 5; echo "mp3convert done..."
}

PreTrap() {
  echo "in trap"
  QUIT=1
  echo "exiting trap..."
}

CleanUp() {
  ### Since 'wait $PID' can be interrupted by ^C, we need to protected it
  ### by the 'kill' loop  ==> double/triple control-C problem.
  while kill -0 $PID >& /dev/null; do wait $PID; echo "check again"; done

  ### This won't work (A simple wait $PID is vulnerable to double control C)
  # wait $PID

  if [ ! -z $QUIT ]; then
     echo "clean up..."
     exit
 fi
}

trap PreTrap SIGINT SIGTERM SIGTSTP
#trap CleanUp EXIT

for loop in 1 2 3; do
    (
      echo "loop #$loop"
      mp3convert
      echo magic 1
      echo magic 2
      echo magic 3
    ) &
    PID=$!
    CleanUp
    echo "done loop #$loop"
done

   The kill -0 trick can be found in a comment of [38]this link
   [39]share|[40]improve this answer
       [41]edited Nov 14 '14 at 2:15
   answered Nov 12 '14 at 10:25
   [42]Robin Hsu
   5047
   1
   You may just run it and test it. (See what message it prints, Hit many control-C's in
   between, etc...) –  [43]Robin Hsu Nov 12 '14 at 10:26

   Yes - thats the solution. The trick are that all commands that could not interrupt must be
   grouped (via round brackets) and execute as a background job. –  [44]UsersUser Nov 13 '14
   at 9:13

   Parenthesis (round brackets) actually forks a new sub-shell. –  [45]Robin Hsu Nov 14 '14 at
   2:13

   The double(triple or more) control-C problem should be generalized by "double signal/trap
   problem", since it is not limited to control-C (SIGINT), but also other signals. –
   [46]Robin Hsu Nov 14 '14 at 7:46
   add a comment |
   up vote 1 down vote

   One way of doing this would be to simply disable the interrupt until your program is done.
   Some pseudo code follows:
#!/bin/bash

# First, store your stty settings and disable the interrupt
STTY=$(stty -g)
stty intr undef

#run your program here
runMp3Convert()

#restore stty settings
stty ${STTY}

# eof

   Another idea would be to run your bash script in the background (if possible).
mp3convert.sh &

   or even,
nohup mp3convert.sh &

***
   No, I need the chance to interrupt the script but I need a complete loop run. Unfortunaly
   the lame command are the longest running part of the loop and if I disable the interrupt
   I´ve got a minimized chance to interrupt the script because of a very little time slot. –
***

   Ok, now I understand :) - I could use this to disable the interrupt for the whole function
   but not for the script. But I don´t know how robust this code are - I never used stty
   before and I don´t know how compatible it is with other *nix/*bsd os. –  [51]UsersUser Nov
***

   @UsersUser: Well play around with it and try to verify its usability. I just know that it
   works for the example I gave. And, please consider accepting the answer if you find it
   useful. –  [52]mattias Nov 9 '14 at 21:29
***
   Well, it helped me, but the answer from @pm-2ring explains a lot more and it helped me to
   understood your answer :). If I had more reputation points I would vote your answer up. –
   [53]UsersUser Nov 9 '14 at 21:34
***
   After think again: I don´t think that your solution will help me. I could not send a SIGINT
   to the script while running runMp3Convert() and the chance to interrupt the script in the
   other time are short. –  [54]UsersUser Nov 12 '14 at 8:21
***
   When you hit Ctrl-C in a terminal, SIGINT gets sent to all processes in the foreground
   process group of that terminal, as described in this Stack Exchange "Unix & Linux" answer:
   [55]How Ctrl C works. (The other answers in that thread are well worth reading, too). And
   that's why your mp3convert function gets interrupted even though you have set a SIGINT
   trap.

   But you can get around that by running the mp3convert function in the background, as
   mattias mentioned. Here's a variation of your script that demonstrates the technique.
#!/usr/bin/env bash

myfunc()
{
    echo -n "Starting $1 :"
    for i in {1..7}
    do
        echo -n " $i"
        sleep 1
    done
    echo ". Finished $1"
}

PreTrap() { QUIT=1; echo -n " in trap "; }

CleanUp() {
    #Don't start cleanup until current run of myfunc is completed.
    wait $pid
    [[ -n $QUIT ]] &&
    {
        QUIT=''
        echo "Cleaning up"
        sleep 1
        echo "... done!" && exit
    }
}

trap PreTrap SIGINT SIGTERM SIGTSTP
trap CleanUp EXIT

for i in {a..e}
do
    #Run myfunc in background but wait until it completes.
    myfunc "$i" &
    pid=$!
    wait $pid
    CleanUp
done

QUIT=1

   When you hit Ctrl-C while myfunc is in the middle of a run, PreTrap prints its message and
   sets the QUIT flag, but myfunc continues running and CleanUp doesn't commence until the
   current myfunc run has finished.

   Note that my version of CleanUp resets the QUIT flag. This prevents CleanUp from running
   twice.

   This version removes the CleanUp call from the main loop and puts it inside the PreTrap
   function. It uses wait with no ID argument in PreTrap, which means we don't need to bother
   saving the PID of each child process. This should be ok since if we're in the trap we do
   want to wait for all child processes to complete before proceeding.
#!/bin/bash

# Yet another Trap demo...

myfunc()
{
    echo -n "Starting $1 :"
    for i in {1..5}
    do
        echo -n " $i"
        sleep 1
    done
    echo ". Finished $1"
}

PreTrap() { echo -n " in trap "; wait; CleanUp; }

CleanUp() {
    [[ -n $CLEAN ]] && { echo bye; exit; }

    echo "Cleaning up"
    sleep 1
    echo "... done!"
    CLEAN=1

    exit
}

trap PreTrap SIGINT SIGTERM SIGTSTP
trap "echo exittrap; CleanUp" EXIT

for i in {a..c}
do
    #Run myfunc in background but wait until it completes.
    myfunc "$i" &  wait $!
done

   We don't really need to do myfunc "$i" & wait $! in this script, it could be simplified
   even further to myfunc "$i" & wait. But generally it's better to wait for a specific PID
   just in case there's some other process running in the background that we don't want to
   wait for.

   Note that pressing Ctrl-C while CleanUp itself is running will interrupt the current
   foreground process (probably sleep in this demo).
***
   Thanks a lot. Are there a solution for a script with many commands that do not shall
   interrupt? Do I have to use the 3 lines for every command? And why do you think it is
   necessary to unset the QUIT variable? –  [60]UsersUser Nov 9 '14 at 21:31
***
   @UsersUser: Those 3 lines can be written as one line: myfunc "$i" & pid=$!; wait $pid. But
   I'll add a simpler version of my script to my answer. As for your last question, if I don't
   reset QUIT then cleanup runs twice; at least, it does on my system. –  [61]PM 2Ring Nov 10
***
   I´ve tried your solution but it doesn´t work like I expect. If I execute your script and
   press CTRL-C into one loop I get: ./testloop.sh Starting a : 1 2 3^C in trap Cleaning up
   ... done! It seams so that by pressing SIGINT it will go to PreTrap but also interrupt the
   running command. –  [62]UsersUser Nov 12 '14 at 8:13
***
   An another point: If I delete your QUIT=1 at the end it doesn´t execute CleanUp function,
   but it should execute CleanUp in line 39. ./testloop.sh Starting a : 1 2 3 4 5 6 7.
   Finished a Starting b : 1 2 3 4 5 6 7. Finished b Starting c : 1 2 3 4 5 6 7. Finished c
   Starting d : 1 2 3 4 5 6 7. Finished d Starting e : 1 2 3 4 5 6 7. Finished e My Bash
   version is 4.3.30(1)-release –  [63]UsersUser Nov 12 '14 at 8:16
***
   For your second example: I can´t find the declaration of $CLEAN which do you use in
   CleanUp. –  [64]UsersUser Nov 12 '14 at 8:17
***



---
http://unix.stackexchange.com/questions/79648/how-to-trigger-error-using-trap-command

[25]How to trigger error using Trap command

   I am using Ubuntu 12.04.2. I am trying to use "trap" command to capture abnormal or error
   in my shell script but I am also trying to manually trigger "Error" exit.

   I have tried exit 1, but it won't trigger "Error" signal.
#!/bin/bash

func()
{
    exit 1
}

trap "echo hi" INT TERM ERR
func

   Not sure how to manually trigger "Error" exit signal?
   [27]bash [28]shell [29]error [30]trap
   [31]share|[32]improve this question
   [33]edited Jun 17 '13 at 4:30
   [34]Anthon
   28.5k113372
   asked Jun 17 '13 at 4:21
   [35]forestclown
   514
   add a comment |

2 Answers 2

   the ERR trap is not to run code when the shell itself exits with a non-zero error code, but
   when any command run by that shell that is not part of a condition (like in if cmd..., or
   cmd || ......) exits with a non-zero exit status (the same conditions as what causes set -e
   to exit the shell).

   If you want to run code upon exit of the shell with non-zero exit status, you should add a
   trap on EXIT instead and check $? there:
trap '[ "$?" -eq 0 ] || echo hi' EXIT

   Note however that upon a trapped signal, both the signal trap and the EXIT trap would be
   run, so you may want to do it like:
trap killed_by=INT INT
trap killed_by=TERM TERM
trap '
  ret=$?
  if [ -n "$killed_by" ]; then
    echo >&2 "Ouch! Killed by $killed_by"
    exit 1
  elif [ "$ret" -ne 0 ]; then
    echo >&2 "Died with error code $ret"
  fi' EXIT

   Or to use exit status like $((signum + 128)) upon signals:
for sig in INT TERM HUP; do
  trap "exit $((128 + $(kill -l "$sig")))" "$sig"
done
trap '
  ret=$?
  [ "$ret" -eq 0 ] || echo >&2 "Bye: $ret"' EXIT

   If you want the ERR trap to fire, just run a command with a non-zero exit status like false
   or test.
***
   Use return, not exit, to set the status on exit from a function (if the function
   falls-through without a return, the status is that of the last statement executed.) If you
   substitute return for exit in the question's example, it will work as I think you intended:
   the trap will be triggered on the ERR pseudo-signal and 'hi' will be printed. For
   additional considerations, try this:
#!/bin/bash

func()
{
    echo 'in func'
    return 99
    echo 'still in func'
}

trap 'echo "done"' EXIT
trap 'status=$?; echo "error status is $status"; trap - EXIT; exit $status' ERR
func
echo 'returned from func'

   You can try various modifications, such as returning 0, commenting out the ERR trap, not
   canceling the EXIT trap within the ERR handler, not exiting from the ERR handler, or
   removing the return and putting false as the last statement in func.
***



---
http://www.alittlemadness.com/2012/06/25/bash-tip-reliable-clean-up-with-trap/

Bash Tip: Reliable Clean Up With Trap

   Wow, it has been over 6 years since my last [9]bash tip. Bash scripts are still my go-to
   for automating the mundane and repetitive — it might not be beautiful but bash is feature
   rich and installed everywhere. Although a lot of my scripts are throw-away, others make it
   into the permanent tool kit. For scripts in the latter category, it’s worth the extra bit
   of effort to make them more robust.

   A key part of a robust script is detecting and sensibly reporting errors. Related to this
   is proper clean up of work in progress when the script encounters a fatal error. Such clean
   up is often overlooked, as it is difficult to get right in a naive fashion. Thankfully,
   bash has a built-in mechanism that makes it simple: trap.

   Setting a trap instructs bash to run a command when the shell process receives a specified
   signal. Further, bash defines pseudo-signals ERR and EXIT that can be used to trap any
   error or exit of the shell. I usually pair an exit trap with a clean up function to ensure
   my scripts don’t leave a mess. If the script runs successfully, I reset the trap (by
   specifying – as the command to run) and call the clean up function directly (if required).
   For example:
#! /usr/bin/env bash

set -e

# Defines a working area on the file system.
SCRATCH=/tmp/$$.scratch

function cleanUp() {
    if [[ -d "$SCRATCH" ]]
    then
        rm -r "$SCRATCH"
    fi
}

trap cleanUp EXIT
mkdir "$SCRATCH"

# Actual work here, all temp files created under $SCRATCH.

# We succeeded, reset trap and clean up normally.
trap - EXIT
cleanUp
exit 0

   Note that the EXIT signal pairs well with [10]set -e: if the script exits on error your
   EXIT trap is executed. You may also consider applying the trap to interrupts (signal INT)
   and kills (signal TERM) of your script. Multiple signals can be specified in one trap
   statement:
trap cleanUp EXIT INT TERM

   If you’re used to programming with exceptions, you can think of a trap as a “finally”
   clause for your whole script. It’s certainly a whole lot easier and less error-prone that
   trying to figure out all the ways the script might exit and adding calls to clean up
   manually.

   —-
   Want Continuous Integration without the Needless Duplication? Try [11]pulse.



---
http://unix.stackexchange.com/questions/125607/proper-usage-of-exit-err-traps-in-bash-scripts

[24]Proper usage of EXIT & ERR traps in bash scripts [closed]

   I'm working on a bash script and as I've been going I've learned about traps, signals,
   function return codes and other such features I've not previously used.

   I may be thinking about things incorrectly - I'm looking for some advice.

   I am setting the following options:
set -o errexit
set -o nounset
set -o noclobber

   I've got the following exit and err traps in my bash script:
# Error handler. This function is called anytime an ERR signal is received.
# This function should never be explictly called.
function _trap_error () {
    if [ ! -v _VERBOSE ]; then
        echo "An error has occurred. Exiting."
    else
        _name="$0"                # name of the script
        _lastline="$1"            # argument 1: last line of error occurence
        _lasterr="$2"             # argument 2: error code of last command
        echo "${_name}: line ${_lastline}: exit status of last command: ${_lasterr}"
        exit 1
    fi
}
trap '_trap_error ${LINENO} ${$?}' ERR

# Exit handler. This function is called anytime an EXIT signal is received.
# This function should never be explicitly called.
function _trap_exit () {
    [ -v _POPD ] && popd &> /dev/null
}
trap _trap_exit EXIT

   They work much as I'd expect. Rather than inserting error checking into all my functions,
   I'm attempting to leverage the traps to handle this for me, for example when checking for
   the existence of a file. If the specified module can't be loaded, I'd like to catch it as
   an error, display an error message, and exit.
function _module_path () {
    echo "mod.d/$2s/$1/__init__.sh"
}

function _module_exists () {
    [ -f $(_module_path $1 $2) ] && return 0 || return 1
}

function _module_push () {
    _module_exists $1 $2 && _MODULES+=$( _module_path $1 $2 ) || msg "Module $1 does not exist."
}

   However, setting the return code to 0 in conjunction with errexit triggers an EXIT signal,
   which is caught by my exit trap instead. I started trying to figure out if I can manually
   emit an ERR signal instead, but haven't found an answer and started to wonder if I'm going
   about this correctly.
***
   Please clarify your specific problem or add additional details to highlight exactly what
   you need. As it's currently written, it’s hard to tell exactly what you're asking. See the
   [40]How to Ask page for help clarifying this question. If this question can be reworded to
   fit the rules in the [41]help center, please [42]edit the question.

   Please look at the following answer, especially if you're using [ -v ]. I think its the
   best answer I've ever written. Also, what is ${$?} ? I suspect it's your problem. That
   should be an invalid substitution as far as I can tell.
***

   From info bash: The ERR trap is not executed if the failed command is part of the command
   list immediately following a while or until keyword, part of the test in an if statement,
   part of a command executed in a && or || list, or if the command's return value is being
   inverted via !. –  [45]devnull Apr 20 '14 at 2:55
***
   @devnull That's true too - traps are triggered for otherwise unhandled exceptions. A while
   or until wouldn't trigger as they are explicit tests. While loops don't return a failure
   code just because their defined parameters run out. But if you want an error code all you
   have to do is ${unset_var?this is written to stderr} or just false –  [46]mikeserv Apr 20
***

   @mikeserv "$?" is the error code of the last executed command. –  [47]nfarrar Apr 20 '14 at
***

   Im well aware of that. I just checked and it seems to work, but it is strange. For
   instance, echo ${$?} works, but n=$? ; echo ${$n} returns a bad substitution error. See
   what i mean? Don't know why youre putting ${} around it. Please see that other post - it
   discusses all kinds of ways of generating, handling errors. –  [48]mikeserv Apr 20 '14 at
***
