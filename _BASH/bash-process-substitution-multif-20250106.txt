filename: bash_process-substitution_20241219.txt
https://sysxplore.com/process-substitution-in-bash/

Process Substitution in Bash
Mar 4

On this page
   Process substitution is a handy feature in Bash that lets you redirect the input and output of a
   process as if it were a file. This opens up some neat possibilities for chaining programs together in
   creative ways.

   This article aims to provide a comprehensive understanding of process substitution in Bash, along
   with some practical examples.

Process Substitution Syntax
   There are two forms of process substitution in Bash:
     * <(command) feeds the output of the process into another command.
     * >(command) takes the output of a command and feeds it as input to a process.

   So, <() treats a process as file input, while >() treats it as file output. The operator >(...) is
   not as commonly used as <(...).

Using Process Substitution in Bash
   Let's take a look at a few examples to illustrate how process substitution can be used.

Comparing Files
   Process substitution can simplify complex pipelines by eliminating the need for unnecessary temporary
   files. Instead of creating intermediate temporary files, process substitution manages redirection via
   automatic temporary files, which are cleaned automatically after the command finishes.

   For instance, if you want to compare two files sorted line by line, you would typically do this
   without process substitution:
$> sort data.txt > sorted-data.txt
$> sort backup-data.txt > sorted-backup-data.txt
$> diff sorted-data.txt sorted-backup-data.txt

   With process substitution, this can be done in one line:
$> diff <(sort data.txt) <(sort backup-data.txt)

Comparing Command Outputs
   Suppose you've changed a directory structure and want to compare the file listings before and after
   the changes to ensure accuracy:
$> diff <(ls /data) <(ls /data-backup)

   This command compares the output of the ls command for two different directories (/data and
   /data-backup). The process substitution syntax <(command) treats the ls output as if it were a file,
   allowing diff to compare the "files" directly.

Searching through Command Output
   Suppose you want to search for a specific error message or pattern across multiple log files' output.
   You would run:
$> grep 'error' <(cat /var/log/syslog /var/log/apache2/error.log)

   In this example, process substitution treats the combined output of cat /var/log/syslog and cat
   /var/log/apache2/error.log as a single file. The grep command then searches for the pattern 'error'
   across this combined output stream.

   This is equivalent to:
$> cat /var/log/syslog /var/log/apache2/error.log | grep 'error'

Sorting and Saving Command Output
   The following example sorts the output of the ps aux command and saves the sorted output to a file
   for further analysis or processing:
$> sort <(ps aux) > processes.sorted

   Here, the ps aux command's output (which lists running processes) is treated as a file and piped into
   the sort command. The sorted output is then redirected to a file named processes.sorted.

Opening Multiple Files
   Process substitution can be handy if you want to open multiple text files in a text editor like vim,
   without having to manually concatenate them first.
$> vim <(cat data.txt new.txt)

   This command combines the contents of data.txt and new.txt into a single stream, which is then
   treated as a file and opened in the vim text editor.

Transferring Compressed Files
   Often, you need to transfer and extract files or directories between different servers for backup,
   deployment, or maintenance purposes. Instead of creating a local archive, transferring it over SSH,
   and then extracting it on the remote server (which involves multiple steps and temporary files), you
   can streamline the process using process substitution.
$> tar -cf >(ssh remote_server tar xf -)

   The above command allows you to create a tar archive of the current directory and directly pipe it
   over an SSH connection to the remote server, where it is extracted in a single step.

Advantages of Process Substitution
   Some key advantages of process substitution include:
     * Avoiding Temporary Files: Process substitution eliminates the need to create temporary files on
       disk, which can save disk space and improve efficiency, especially when dealing with large
       amounts of data
     * Streamlined Pipelines: By treating the output of one command as the input file for another
       command, process substitution allows you to create more streamlined and concise command
       pipelines, making your scripts and workflows more readable and maintainable.

Conclusion
   This article provided a concise overview of process substitution in Bash, a handy feature that allows
   you to treat the input and output of processes as if they were files. Through several practical
   examples, you learned how process substitution can simplify complex pipelines, enable efficient file
   comparisons, filter command output, transfer compressed data, and open multiple files simultaneously.
   Though the article was short, it showed many useful process substitution methods. This technique can
   help make command-line tasks easier and faster.


---
https://medium.com/factualopinions/process-substitution-in-bash-739096a2f66d

Process Substitution in Bash

A nifty trick to use in bash

   In lamest terms, process substitution allows you to turn a command into a temporary file that
   banishes after it finishes.

   Let me give you an example:
cat <(echo hey there) # this outputs: hey there
echo <(echo hey there) # this outputs: /dev/fd/63

   The first command converts the output of the command echo hey there into a file with the contents hey
   there

   The second command echoes the name of the temporary file being used.

   This may not seem very useful in this example but consider the following example where you want to
   compre the contents of two directories, you could do the following:
$> ls /bin/ > bindir
$> ls /usr/bin/ > usrbindir
$> diff bindir usrbindir

   Or you could do this instead with process substitution:
$> diff <(ls /bin) <(ls /usr/bin)

   Another less commonly use of process substitution takes the standard input from another command like
   so:
$> ls > >(grep file)

   This will send the contents of ls to the command substitution on the right and they will be processed
   within the file substitution.

   I couldn’t find many practical uses of this (yet) myself at work but I found this excellent blog
   on the same topic that offers some examples.

   Additional info can be found here:

Process Substitution
Piping the stdout of a command into the stdin of another is a powerful technique. But, what if you need to
pipe the ...

Process substitution
Process substitution is a form of redirection where the input or output of a process (some sequence of
commands) appear ...


---
https://medium.com/@joewalnes/handy-bash-feature-process-substitution-8eb6dce68133

Handy Bash feature: Process Substitution
Feb 28, 2015

   Pretty much everything useful I ever learned about UNIX shells was not from reading books or manuals,
   but by peering over someone’s shoulder and seeing something I’d never seen before. “Ooooh, what was
   that you just did?”

   It was a few years ago I was working with my friend Jordan Samuels, when we wanted to compare two
   versions of a file at a particular URL. I knew what to do…
$> curl http://somesite/file1 > file1
$> curl http://somesite/file2 > file2
$> diff file1 file2

   Simple right? Download file1, download file2, and diff them. 3 steps.

   But before I could type it, Jordan grabbed the keyboard and typed some crazy voodoo I’d never seen
   before…
$> diff <(curl http://somesite/file1) <(curl http://somesite/file2)

   Ooooh, what was that weird syntax? And why did it appear to run twice as fast as what I was
   expecting?

Process substitution!
   Process substitution gives you similar capabilities to piping. Except piping only allows you to pipe
   the output from a single command into another. In the diff scenario, we need to pipe the output from
   multiple commands into another. And that’s what process substitution allows us to do.

   The syntax for using process substitution is this:
$> some-command <(another-command)

   Where some-command accepts a filename (or multiple filenames) as arguments, and another-command
   writes output to stdout.

   Wait a minute ... how does that work? There are no filenames anywhere? Well, behind the scenes, when
   Bash sees the process substitution <(…), it’ll create a temporary file descriptor which it uses as
   the filename and pipe output from the other process into it.

When to use process substitution
   If a regular old pipe will do, just do that. But there are a few scenarios when pipes won’t cut it…
	 * If you need to feed multiple outputs into a single program (like the diff example above)
	 * If you need to feed output from a program into a program that expects input files, but cannot
	   read from stdin
	 * If you find yourself using temporary files

Parallelization!
   Apart from simplicity, another advantage of using process substitution is Bash will automatically
   parallelize your tasks. Returning to our first example…
$> diff <(curl http://somesite/file1) <(curl http://somesite/file2)

   ... Bash will run both those curl commands in parallel. Sweet huh?

   Ok, that’s it. Have a nice day.

Diving deeper
   If you want to get into the nitty gritty details about how this stuff works, here’s some more
   reading.

Process Substitution
Piping the stdout of a command into the stdin of another is a powerful technique. But, what if you need to
pipe the ...

Process substitution
In computing, process substitution is a form of inter-process communication that allows the input or output
of a ...

Named pipe
In computing, a named pipe (also known as a for its behavior) is an extension to the traditional pipe
concept on Unix…



---
https://www.unix.com/shell-programming-and-scripting/93407-difference-between-command-substitution-process-substitution.html

Difference between "Command substitution" and "Process substitution"
10:45 AM 12-15-2008

   Hi,
   What is the actual difference between these two? Why the following code works for process
   substitution and fails for command substitution?
   Code:
$> while IFS= read -r line; do	echo $line; done < <(cat file)

   Code:

$> while IFS= read -r line; do echo $line; done < <(cat file)
   executes successfully and display the contents of the file

   But,
   Code:
$> while IFS='\n' read -r line; do	echo $line; done < $(cat file)

   Code:
$> while IFS='\n' read -r line; do echo $line; done < $(cat file)

   gives error as: bash: $(cat file): ambiguous redirect (same results for backticks syntax instead of
   "$()")

   Also, please clarify to me whether 'IFS' is really required in this while loop as it seems to be
   redundant because by default read command will fetches the entire line if only one argument is
   supplied and no delimiter is needed here to print every line???

   Is there any use case(s) available that the IFS presence is mandatory to print each and every line of
   a file?

***
   I don't understand what you mean by command and process substitution. I see no point in using IFS in
   this example as you said yourself.
   Also I would go by
   Code:
while read -r line; do
	echo $line
done < file

   Code:
while read -r line; do echo $line done < file

   Cat'ting the file is not needed.

***
while IFS='\n' read -r line; do  echo $line; done <<< $(cat file)

   Code:
   while IFS='\n' read -r line; do echo $line; done <<< $(cat file)
   <<< is here-string

***
   Hi,
   $(...) means execute the command ... and print the output
   to the command line.
   <(...) and =(...) create a temporary file of the output and
   redirect the output of this to the command line.
   To understand the difference try:
   Code:
diff $(ls) $(ls)

   and
   Code:
diff <(ls) <(ls)

   The first will fail as diff expects input from a file.



---
https://stackoverflow.com/questions/51293767/what-is-the-difference-between-using-process-substitution-vs-a-pipe

What is the difference between using process substitution vs. a pipe?

   I came across an example for the using tee utility in the tee info page:
$> wget -O - http://example.com/dvd.iso | tee >(sha1sum > dvd.sha1) > dvd.iso

   I looked up the >(...) syntax and found something called "process substitution". From what I
   understand, it makes a process look like a file that another process could write/append its output
   to. (Please correct me if I'm wrong on that point.)

   How is this different from a pipe? (|) I see a pipe is being used in the above example—is it just a
   precedence issue? or is there some other difference?
     * bash
     * pipe
     * process-substitution

***
   There's no benefit here, as the line could equally well have been written like this:
$> wget -O - http://example.com/dvd.iso | tee dvd.iso | sha1sum > dvd.sha1

   The differences start to appear when you need to pipe to/from multiple programs, because these can't
   be expressed purely with |. Feel free to try:
# Calculate 2+ checksums while also writing the file
$> wget -O - http://example.com/dvd.iso | tee >(sha1sum > dvd.sha1) >(md5sum > dvd.md5) > dvd.iso

# Accept input from two 'sort' processes at the same time
$> comm -12 <(sort file1) <(sort file2)

   They're also useful in certain cases where you for any reason can't or don't want to use pipelines:
# Start logging all error messages to file as well as disk
# Pipes don't work because bash doesn't support it in this context
$> exec 2> >(tee log.txt)
$> ls doesntexist

# Sum a column of numbers
# Pipes don't work because they create a subshell
$> sum=0
$> while IFS= read -r num; do (( sum+=num )); done < <(curl http://example.com/list.txt)
$> echo "$sum"

# apt-get something with a generated config file
# Pipes don't work because we want stdin available for user input
$> apt-get install -c <(sed -e "s/%USER%/$USER/g" template.conf) mysql-server

***
   One major difference is the propagation of return values / exit codes (I'll use simpler commands to
   illustrate):

   Pipe:
$> ls -l /notthere | tee listing.txt
ls: cannot access '/notthere': No such file or directory
$> echo $?
0

   -> exit code of tee is propagated

   Process substitution:
$> ls -l /notthere > >(tee listing.txt)
ls: cannot access '/notthere': No such file or directory
$> echo $?
2

   -> exit code of ls is propagated

   There are of course several methods to work around this (e.g. set -o pipefail, variable PIPESTATUS),
   but I think it's worth mentioning since this is the default behavior.

   Yet another rather subtle, yet potentially annoying difference lies in subprocess termination (best
   illustrated using commands that produce lots of output):

   Pipe:
#!/usr/bin/env bash
$> tar --create --file /tmp/etc-backup.tar --verbose --directory /etc . 2>&1 | tee /tmp/etc-backup.log
retval=${PIPESTATUS[0]}
(( ${retval} == 0 )) && echo -e "\n*** SUCCESS ***\n" || echo -e "\n*** FAILURE (EXIT CODE: ${retval}) ***\n"

   -> after the line containing the pipe construct, all commands of the pipe have already terminated
   (otherwise PIPESTATUS could not contain their respective exit codes)

   Process substitution:
#!/usr/bin/env bash
tar --create --file /tmp/etc-backup.tar --verbose --directory /etc . &> >(tee /tmp/etc-backup.log)
retval=$?
(( ${retval} == 0 )) && echo -e "\n*** SUCCESS ***\n" || echo -e "\n*** FAILURE (EXIT CODE: ${retval}) ***\n"

   -> after the line containing the process substitution, the command within >(...), i.e. tee in this
   example, may still be running, potentially causing desynchronized console output (SUCCESS / FAILURE
   message gets mixed in with still flowing tar output) [*]


---
https://unix.stackexchange.com/questions/17107/process-substitution-and-pipe

Process substitution and pipe

   I was wondering how to understand the following:

	 Piping the stdout of a command into the stdin of another is a powerful technique. But, what if you
	 need to pipe the stdout of multiple commands? This is where process substitution comes in.

   In other words, can process substitution do whatever pipe can do?

   What can process substitution do, but pipe cannot?
     * shell
     * io-redirection
     * pipe
     * process-substitution

***
   A good way to grok the difference between them is to do a little experimenting on the command line.
   In spite of the visual similarity in use of the < character, it does something very different than a
   redirect or pipe.

   Let's use the date command for testing.
$> date | cat
Thu Jul 21 12:39:18 EEST 2011

   This is a pointless example but it shows that cat accepted the output of date on STDIN and spit it
   back out. The same results can be achieved by process substitution:
$> cat <(date)
Thu Jul 21 12:40:53 EEST 2011

   However what just happened behind the scenes was different. Instead of being given a STDIN stream,
   cat was actually passed the name of a file that it needed to go open and read. You can see this step
   by using echo instead of cat.
$> echo <(date)
/proc/self/fd/11

   When cat received the file name, it read the file's content for us. On the other hand, echo just
   showed us the file's name that it was passed. This difference becomes more obvious if you add more
   substitutions:
$> cat <(date) <(date) <(date)
Thu Jul 21 12:44:45 EEST 2011
Thu Jul 21 12:44:45 EEST 2011
Thu Jul 21 12:44:45 EEST 2011

$> echo <(date) <(date) <(date)
/proc/self/fd/11 /proc/self/fd/12 /proc/self/fd/13

   It is possible to combine process substitution (which generates a file) and input redirection (which
   connects a file to STDIN):
$> cat < <(date)
Thu Jul 21 12:46:22 EEST 2011

   It looks pretty much the same but this time cat was passed STDIN stream instead of a file name. You
   can see this by trying it with echo:
$> echo < <(date)
<blank>

   Since echo doesn't read STDIN and no argument was passed, we get nothing.

   Pipes and input redirects shove content onto the STDIN stream. Process substitution runs the
   commands, saves their output to a special temporary file and then passes that file name in place of
   the command. Whatever command you are using treats it as a file name. Note that the file created is
   not a regular file but a named pipe that gets removed automatically once it is no longer needed.

***
Multiple process inputs

$> diff <(cd /foo/bar/; ls) <(cd /foo/baz; ls)

   There simply is no way to do this with pipes.

Preserving STDIN

   Say you have the following:
$> curl -o - http://example.com/script.sh

#!/bin/bash
read LINE
echo "You said ${LINE}!"

   And you want to run it directly. The following fails miserably. Bash is already using STDIN to read
   the script, so other input is impossible.
$> curl -o - http://example.com/script.sh | bash

   But this way works perfectly.
$> bash <(curl -o - http://example.com/script.sh)

Outbound process substitution
   Also note that process substitution works the other way too. So you can do something like this:
(ls /proc/*/exe >/dev/null) 2> >(sed -n \
  '/Permission denied/ s/.*\(\/proc.*\):.*/\1/p' > denied.txt )

   That's a bit of a convoluted example, but it sends stdout to /dev/null, while piping stderr to a sed
   script to extract the names of the files for which a "Permission denied" error was displayed, and
   then sends THOSE results to a file.

   Note that the first command and the stdout redirection is in parentheses (subshell) so that only the
   result of THAT command gets sent to /dev/null and it doesn't mess with the rest of the line.

***
   I should suppose you are talking about bash or some other advanced shell, because the posix shell
   does not have process substitution.

   bash manual page reports:
     Process Substitution
     Process substitution is supported on systems that support named pipes (FIFOs) or the /dev/fd
     method of naming open files. It takes the form of <(list) or >(list). The process list is run with
     its input or output connected to a FIFO or some file in /dev/fd. The name of this file is passed
     as an argument to the current command as the result of the expansion. If the >(list) form is used,
     writing to the file will provide input for list. If the <(list) form is used, the file passed as
     an argument should be read to obtain the output of list.
     When available, process substitution is performed simultaneously with parameter and variable
     expansion, command substitution, and arithmetic expansion.

   In other words, and from a practical point of view, you can use an expression like the following
<(commands)

   as a file name for other commands requiring a file as a parameter. Or you can use redirection for
   such a file:
while read line; do something; done < <(commands)

   Turning back to your question, it seems to me that process substitution and pipes have not much in
   common.

   If you want to pipe in sequence the output of multiple commands, you can use one of the following
   forms:
(command1; command2) | command3
{ command1; command2; } | command3

   but you can also use redirection on process substitution
command3 < <(command1; command2)

   finally, if command3 accepts a file parameter (in substitution of stdin)
command3 <(command1; command2)

***
   If a command takes a list of files as arguments and processes those files as input (or output, but
   not commonly), each of those files can be a named pipe or /dev/fd pseudo-file provided transparently
   by process subsitution:
$> sort -m <(command1) <(command2) <(command3)

   This will "pipe" the output of the three commands to sort, as sort can take a list of input files on
   the command line.

***
   It should be noted that process substitution is not limited to the form <(command), which uses the
   output of command as a file. It can be in the form >(command) which feeds a file as the input to
   command as well. This is also mentioned in the quote of bash manual in @enzotib's answer.

   For the date | cat example above, a command that uses the process substitution of the form >(command)
   to achieve the same effect would be,
$> date > >(cat)

   Note that the > before >(cat) is necessary. This can again be clearly illustrated by echo as in
   @Caleb's answer.
$> echo >(cat)
/dev/fd/63

   So, without the extra >, date >(cat) would be the same as date /dev/fd/63 which will print a message
   to stderr.

   Suppose you have a program that only takes filenames as parameters and does not process stdin or
   stdout. I will use the oversimplified script psub.sh to illustrate this. The content of psub.sh is
#!/bin/bash
[ -e "$1" ] && [ -e "$2" ] && awk '{print $1}' < "$1" > "$2"

   Basically, it tests that both of its arguments are files (not necessarily regular files) and if this
   is the case, write the first field of each line of "$1" to "$2" using awk. Then, a command that
   combines all that mentioned so far is,
./psub.sh <(printf "a a\nc c\nb b") >(sort)

   This will print
a
b
c

   and is equivalent to
$> printf "a a\nc c\nb b" | awk '{print $1}' | sort

   but the following will not work, and we have to use process substitution here,
$> printf "a a\nc c\nb b" | ./psub.sh | sort

   or its equivalent form
$> printf "a a\nc c\nb b" | ./psub.sh /dev/stdin /dev/stdout | sort

   If ./psub.sh also reads stdin besides what is mentioned above, then such an equivalent form does not
   exist, and in that case there are nothing we can use instead of the process substitution (of course
   you can also use a named pipe or temp file, but that's another story).

***
   I feel pipeline is good at gradually processing data step by step by sequence the commands one by
   one; process substitution is good at getting outputs from many command sequences or provide inputs to
   many command sequences by files; combine them appropriately could be some powerful tools.

   Pipeline use a pipe to link two file descriptors, typically standard output file descriptor of a
   command, and standard input file descriptor of the next command, thus the output of a command can be
   accessed by the command next to it. You can sequence infinite commands in this way to gradually
   process the data.
$> ls | head -3 | tail -1

   The output of ls is used as the input of head; the output of head is used as the input of tail.

   Process Substitution creates a file by which other commands can access the output of a command
   sequence or provide input to it.
$> paste <(echo hello) <(echo world) | tee >(cat) >(cat)

   <(echo hello) and <(echo world) created two files as the input of paste, one file includes 'hello',
   one includes 'world', the output of the echo commands;

   tee reads the output ('hello world') of paste through the pipe;

   the two >(cat) commands also create two files as the input of the two cat commands, two files all
   include 'hello world' which is written by the command tee;

   then the two cat commands output the content of the files they get as their input.

   The output is as below:
# paste <(echo hello) <(echo world) | tee >(cat) >(cat)
hello    world
hello    world
hello    world

   First 'hello world' is output of the paste command; The two after it is output of the two cat
   commands.

   The file is created by <() includes output of the command sequence as its content; but the file
   created by >() is empty, you must write something to it explicitly.
$> echo hello >(cat)
hello /proc/self/fd/12

$> echo hello > >(cat)
hello

   Above, first time the 'hello' is produced by the echo command; because the file created by >(cat) is
   empty, so the name of the file is produced by the shell.

   Second time, the 'hello' is redirected to the file created by >(cat), then the file is taken as the
   input of the cat command which produces the 'hello'.

   More examples:
$> comm -23 <(set -o posix; set | sort) <(env | sort)

   Comparing the difference between shell variables and environmental variables.


---
https://askubuntu.com/questions/678915/whats-the-difference-between-and-in-bash

What's the difference between <<, <<< and < < in bash?

   What's the difference between <<, <<< and < < in bash?

***
   Here document

   << is known as here-document structure. You let the program know what will be the ending text, and
   whenever that delimiter is seen, the program will read all the stuff you've given to the program as
   input and perform a task upon it.

   Here's what I mean:
$> wc << EOF
> one two three
> four five
> EOF
 2  5  24

   In this example we tell wc program to wait for EOF string, then type in five words, and then type in
   EOF to signal that we're done giving input. In effect, it's similar to running wc by itself, typing
   in words, then pressing CtrlD

   In bash these are implemented via temp files, usually in the form /tmp/sh-thd.<random string>, while
   in dash they are implemented as anonymous pipes. This can be observed via tracing system calls with
   strace command. Replace bash with sh to see how /bin/sh performs this redirection.
$> strace -e open,dup2,pipe,write -f bash -c 'cat <<EOF
> test
> EOF'

   Here string
   <<< is known as here-string. Instead of typing in text, you give a pre-made string of text to a
   program. For example, with such program as bc we can do bc <<< 5*4 to just get output for that
   specific case, no need to run bc interactively. Think of it as the equivalent of echo '5*4' | bc.

   Here-strings in bash are implemented via temporary files, usually in the format /tmp/sh-thd.<random
   string>, which are later unlinked, thus making them occupy some memory space temporarily but not show
   up in the list of /tmp directory entries, and effectively exist as anonymous files, which may still
   be referenced via file descriptor by the shell itself, and that file descriptor being inherited by
   the command and later duplicated onto file descriptor 0 (stdin) via dup2() function. This can be
   observed via
$> ls -l /proc/self/fd/ <<< "TEST"
total 0
lr-x------ 1 user1 user1 64 Aug 20 13:43 0 -> /tmp/sh-thd.761Lj9 (deleted)
lrwx------ 1 user1 user1 64 Aug 20 13:43 1 -> /dev/pts/4
lrwx------ 1 user1 user1 64 Aug 20 13:43 2 -> /dev/pts/4
lr-x------ 1 user1 user1 64 Aug 20 13:43 3 -> /proc/10068/fd

   And via tracing syscalls (output shortened for readability; notice how temp file is opened as fd 3,
   data written to it, then it is re-opened with O_RDONLY flag as fd 4 and later unlinked, then dup2()
   onto fd 0, which is inherited by cat later ):
$> strace -f -e open,read,write,dup2,unlink,execve bash -c 'cat <<< "TEST"'
execve("/bin/bash", ["bash", "-c", "cat <<< \"TEST\""], [/* 47 vars */]) = 0
...
strace: Process 10229 attached
[pid 10229] open("/tmp/sh-thd.uhpSrD", O_RDWR|O_CREAT|O_EXCL, 0600) = 3
[pid 10229] write(3, "TEST", 4)          = 4
[pid 10229] write(3, "\n", 1)            = 1
[pid 10229] open("/tmp/sh-thd.uhpSrD", O_RDONLY) = 4
[pid 10229] unlink("/tmp/sh-thd.uhpSrD") = 0
[pid 10229] dup2(4, 0)                   = 0
[pid 10229] execve("/bin/cat", ["cat"], [/* 47 vars */]) = 0
...
[pid 10229] read(0, "TEST\n", 131072)    = 5
[pid 10229] write(1, "TEST\n", 5TEST
)        = 5
[pid 10229] read(0, "", 131072)          = 0
[pid 10229] +++ exited with 0 +++
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=10229, si_uid=1000, si_status=0, si_utime=0, si_stim
e=0} ---
+++ exited with 0 +++

   Opinion: potentially because here strings make use of temporary text files, it is the possible reason
   why here-strings always insert a trailing newline, since text file by POSIX definition has to
   have lines that end in newline character.

   Process Substitution
	 Process substitution feeds the output of a process (or processes) into the stdin of another
	 process.

   So in effect this is similar to piping stdout of one command to the other , e.g. echo foobar
   barfoo | wc . But notice: in the bash manpage you will see that it is denoted as <(list). So
   basically you can redirect output of multiple (!) commands.

   Note: technically when you say < < you aren't referring to one thing, but two redirection with single
   < and process redirection of output from <( . . .).

   Now what happens if we do just process substitution?
$> echo <(echo bar)
/dev/fd/63

   As you can see, the shell creates temporary file descriptor /dev/fd/63 where the output goes (which
   according to Gilles's answer, is an anonymous pipe). That means < redirects that file descriptor
   as input into a command.

   So very simple example would be to make process substitution of output from two echo commands into
   wc:
$> wc < <(echo bar;echo foo)
      2          2          8

   So here we make shell create a file descriptor for all the output that happens in the parenthesis and
   redirect that as input to wc .As expected, wc receives that stream from two echo commands, which by
   itself would output two lines, each having a word, and appropriately we have 2 words, 2 lines, and 6
   characters plus two newlines counted.

   How is process substitution implemented ? We can find out using the trace below (output shortened for
   brevity)
$> strace -e clone,execve,pipe,dup2 -f bash -c 'cat <(/bin/true) <(/bin/false) <(/bin/echo)'
execve("/bin/bash", ["bash", "-c", "cat <(/bin/true) <(/bin/false) <"...], 0x7ffcb96004f8 /* 50 vars */) = 0
pipe([3, 4])                            = 0
dup2(3, 63)                             = 63
clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f6c12569a10) =
8954
strace: Process 8954 attached
[pid  8953] pipe([3, 4])                = 0
[pid  8953] dup2(3, 62)                 = 62
[pid  8953] clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f6c
12569a10) = 8955
strace: Process 8955 attached
[pid  8953] pipe([3, 4])                = 0
[pid  8953] dup2(3, 61)                 = 61
[pid  8953] clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f6c
12569a10) = 8956
[pid  8953] execve("/bin/cat", ["cat", "/dev/fd/63", "/dev/fd/62", "/dev/fd/61"], 0x55ab7566e8f0 /* 50 vars */) = 0

   The above trace on Ubuntu (which also implies on Linux in general) suggests that process substitution
   is implemented by repeatedly forking multiple subprocesses (so process 8953 forks multiple child
   processes 8954,8955,8956,etc). Then all these subprocesses communicate back via their stdout , but
   that is duplicated (that is copied) onto the stack of next available file descriptors starting at 63
   downwards. Why start at 63 ? That may be a good question for the developers. It is known for a fact
   that bash can use fd 255 for saving file descriptors for the "main" command/pipeline when its
   streams are redirected.

   Side Note: Process substitution may be referred to as a bashism (a command or structure usable in
   advanced shells like bash, but not specified by POSIX), but it was implemented in ksh before bash's
   existence as ksh man page and this answer suggest. Shells like tcsh and mksh however do not
   have process substitution. So how could we go around redirecting output of multiple commands into
   another command without process substitution? Grouping plus piping!
$> (echo foo;echo bar) | wc
      2          2          8

   Effectively this is the same as above example, However, this is different under the hood from process
   substitution, since we make stdout of the whole subshell and stdin of wc linked with the pipe. On
   the other hand, process substitution makes a command read a temporary file descriptor.

   So if we can do grouping with piping, why do we need process substitution? Because sometimes we
   cannot use piping. Consider the example below - comparing outputs of two commands with diff (which
   needs two files, and in this case we are giving it two file descriptors)
diff <(ls /bin) <(ls /usr/bin)

***
   < < is a syntax error:
$> cat < <
bash: syntax error near unexpected token `<'

   < <() is process substitution (<()) combined with redirection (<):

   A contrived example:
$> wc -l < <(grep ntfs /etc/fstab)
4
$> wc -l <(grep ntfs /etc/fstab)
4 /dev/fd/63

   With process substitution, the path to the file descriptor is used like a filename. In case you don't
   want to (or can't) use a filename directly, you combine process substitution with redirection.

   To be clear, there is no < < operator.

***
   < < is a syntax error, you probably mean command1 < <( command2 ) which is a simple input redirection
   followed by a process substitution and is very similar but not equivalent to :
command2 | command1

   The difference assuming you are running bash is command1 is run in a subshell in the second case
   while it is run in the current shell in the first one. That means variables set in command1 would not
   be lost with the process substitution variant.

***
   < < will give an syntax error. Proper use is as follows:

   Explaining with the help of examples:

   Example for < <():
while read line; do
	echo $line
done< <(ls)

   In the above example, the input to the while loop will come from the ls command which can be read
   line by line and echoed in the loop.

   <() is used for process substitution. More information and example for <() can be found at this link:


---

