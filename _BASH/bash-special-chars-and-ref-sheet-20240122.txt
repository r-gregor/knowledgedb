filename: bash_special-chars-and-ref-sheet_20240122.txt
https://tldp.org/LDP/abs/html/special-chars.html

Advanced Bash-Scripting Guide:
Chapter 3. Special Characters

What makes a character special? If it has a meaning beyond its literal meaning, a meta-meaning, then we
refer to it as a special character. Along with commands and keywords, special characters are building
blocks of Bash scripts.

Special Characters Found In Scripts and Elsewhere

#
    Comments. Lines beginning with a # (with the exception of #!) are comments and will not be executed.
    # This line is a comment.

    Comments may also occur following the end of a command.

    echo "A comment will follow." # Comment here.
    #                ^ Note whitespace before #

    Comments may also follow whitespace at the beginning of a line.
     # A tab precedes this comment.

    Comments may even be embedded within a pipe.
    initial=( `cat "$startfile" | sed -e '/#/d' | tr -d '\n' |\
    # Delete lines containing '#' comment character.
           sed -e 's/\./\. /g' -e 's/_/_ /g'` )
    # Excerpted from life.sh script

    Caution
    A command may not follow a comment on the same line. There is no method of terminating the comment,
    in order for "live code" to begin on the same line. Use a new line for the next command.

    Note
    Of course, a quoted or an escaped # in an echo statement does not begin a comment. Likewise, a #
    appears in certain parameter-substitution constructs and in numerical constant expressions.

    echo "The # here does not begin a comment."
    echo 'The # here does not begin a comment.'
    echo The \# here does not begin a comment.
    echo The # here begins a comment.

    echo ${PATH#*:}	  # Parameter substitution, not a comment.
    echo $(( 2#101011 ))  # Base conversion, not a comment.

    # Thanks, S.C.

    The standard quoting and escape characters (" ' \) escape the #.

    Certain pattern matching operations also use the #.
;
    Command separator [semicolon]. Permits putting two or more commands on the same line.
    echo hello; echo there


    if [ -x "$filename" ]; then    #  Note the space after the semicolon.
    #+                   ^^
      echo "File $filename exists."; cp $filename $filename.bak
    else   #                       ^^
      echo "File $filename not found."; touch $filename
    fi; echo "File test complete."

    Note that the ";" sometimes needs to be escaped.

;;
    Terminator in a case option [double semicolon].

	case "$variable" in
		abc)  echo "\$variable = abc" ;;
		xyz)  echo "\$variable = xyz" ;;
	esac

;;&, ;&
    Terminators in a case option (version 4+ of Bash).

.
    "dot" command [period]. Equivalent to source (see Example 15-22). This is a bash builtin.

.
    "dot", as a component of a filename. When working with filenames, a leading dot is the prefix of a
    "hidden" file, a file that an ls will not normally show.

    bash$ touch .hidden-file
    bash$ ls -l
    total 10
     -rw-r--r--    1 bozo      4034 Jul 18 22:04 data1.addressbook
     -rw-r--r--    1 bozo      4602 May 25 13:58 data1.addressbook.bak
     -rw-r--r--    1 bozo	877 Dec 17  2000 employment.addressbook


    bash$ ls -al
    total 14
     drwxrwxr-x    2 bozo  bozo      1024 Aug 29 20:54 ./
     drwx------   52 bozo  bozo      3072 Aug 29 20:51 ../
     -rw-r--r--    1 bozo  bozo      4034 Jul 18 22:04 data1.addressbook
     -rw-r--r--    1 bozo  bozo      4602 May 25 13:58 data1.addressbook.bak
     -rw-r--r--    1 bozo  bozo       877 Dec 17  2000 employment.addressbook
     -rw-rw-r--    1 bozo  bozo		0 Aug 29 20:54 .hidden-file


    When considering directory names, a single dot represents the current working directory, and two
    dots denote the parent directory.

    bash$ pwd
    /home/bozo/projects

    bash$ cd .
    bash$ pwd
    /home/bozo/projects

    bash$ cd ..
    bash$ pwd
    /home/bozo/


    The dot often appears as the destination (directory) of a file movement command, in this context
    meaning current directory.

    bash$ cp /home/bozo/current_work/junk/* .

    Copy all the "junk" files to $PWD.

.
    "dot" character match. When matching characters, as part of a regular expression, a "dot" matches
    a single character.

"
    partial quoting [double quote]. "STRING" preserves (from interpretation) most of the special characters
    within STRING. See Chapter 5.

'
    full quoting [single quote]. 'STRING' preserves all special characters within STRING. This is a
    stronger form of quoting than "STRING". See Chapter 5.

,
    comma operator. The comma operator [1] links together a series of arithmetic operations. All are
    evaluated, but only the last one is returned.

    let "t2 = ((a = 9, 15 / 3))"
    # Set "a = 9" and "t2 = 15 / 3"

    The comma operator can also concatenate strings.

    for file in /{,usr/}bin/*calc
    #             ^    Find all executable files ending in "calc"
    #+                 in /bin and /usr/bin directories.
    do
        if [ -x "$file" ]
        then
          echo $file
        fi
    done

    # /bin/ipcalc
    # /usr/bin/kcalc
    # /usr/bin/oidcalc
    # /usr/bin/oocalc

    # Thank you, Rory Winston, for pointing this out.

,, ,
    Lowercase conversion in parameter substitution (added in version 4 of Bash).

\
    escape [backslash]. A quoting mechanism for single characters.

    \X escapes the character X. This has the effect of "quoting" X, equivalent to 'X'. The \ may be used
    to quote " and ', so they are expressed literally.


    See Chapter 5 for an in-depth explanation of escaped characters.
/
    Filename path separator [forward slash]. Separates the components of a filename (as in
    /home/bozo/projects/Makefile).

    This is also the division arithmetic operator.

`
    command substitution. The `command` construct makes available the output of command for assignment
    to a variable. This is also known as backquotes or backticks.

:
    null command [colon]. This is the shell equivalent of a "NOP" (no op, a do-nothing operation). It
    may be considered a synonym for the shell builtin true. The ":" command is itself a Bash builtin,
    and its exit status is true (0).

    :
    echo $?   # 0

    Endless loop:

    while :
    do
       operation-1
       operation-2
       ...
       operation-n
    done

    # Same as:
    #     while true
    #     do
    #       ...
    #     done

    Placeholder in if/then test:

    if condition
    then :   # Do nothing and branch ahead
    else     # Or else ...
       take-some-action
    fi

    Provide a placeholder where a binary operation is expected, see Example 8-2 and default parameters.

    : ${username=`whoami`}
    # ${username=`whoami`}   Gives an error without the leading :
    #                 unless "username" is a command or builtin...

    : ${1?"Usage: $0 ARGUMENT"}     # From "usage-message.sh example script.

    Provide a placeholder where a command is expected in a here document. See Example 19-10.

    Evaluate string of variables using parameter substitution (as in Example 10-7).

    : ${HOSTNAME?} ${USER?} ${MAIL?}
    #  Prints error message
    #+ if one or more of essential environmental variables not set.

    Variable expansion / substring replacement.

    In combination with the > redirection operator, truncates a file to zero length, without changing
    its permissions. If the file did not previously exist, creates it.

    : > data.xxx   # File "data.xxx" now empty.

    # Same effect as   cat /dev/null >data.xxx
    # However, this does not fork a new process, since ":" is a builtin.

    See also Example 16-15.

    In combination with the >> redirection operator, has no effect on a pre-existing target file (: >>
    target_file). If the file did not previously exist, creates it.

    Note

    This applies to regular files, not pipes, symlinks, and certain special files.

    May be used to begin a comment line, although this is not recommended. Using # for a comment turns off
    error checking for the remainder of that line, so almost anything may appear in a comment. However,
    this is not the case with :.

    : This is a comment that generates an error, ( if [ $x -eq 3] ).

    The ":" serves as a field separator, in /etc/passwd, and in the $PATH variable.

    bash$ echo $PATH
    /usr/local/bin:/bin:/usr/bin:/usr/X11R6/bin:/sbin:/usr/sbin:/usr/games

    A colon is acceptable as a function name.

    :()
    {
      echo "The name of this function is "$FUNCNAME" "
      # Why use a colon as a function name?
      # It's a way of obfuscating your code.
    }

    :
    # The name of this function is :

    This is not portable behavior, and therefore not a recommended practice. In fact, more recent releases
    of Bash do not permit this usage. An underscore _ works, though.

    A colon can serve as a placeholder in an otherwise empty function.

    not_empty ()
    {
      :
    } # Contains a : (null command), and so is not empty.

!
    reverse (or negate) the sense of a test or exit status [bang]. The ! operator inverts the exit
    status of the command to which it is applied (see Example 6-2). It also inverts the meaning of a test
    operator. This can, for example, change the sense of equal ( = ) to not-equal ( != ). The ! operator
    is a Bash keyword.

    In a different context, the ! also appears in indirect variable references.

    In yet another context, from the command line, the ! invokes the Bash history mechanism (see Appendix L).

    Note that within a script, the history mechanism is disabled.
*
    wild card [asterisk]. The * character serves as a "wild card" for filename expansion in globbing. By
    itself, it matches every filename in a given directory.

    bash$ echo *
    abs-book.sgml add-drive.sh agram.sh alias.sh

    The * also represents any number (or zero) characters in a regular expression.

*
    arithmetic operator. In the context of arithmetic operations, the * denotes multiplication.

    ** A double asterisk can represent the exponentiation operator or extended file-match globbing.

?
    test operator. Within certain expressions, the ? indicates a test for a condition.

    In a double-parentheses construct, the ? can serve as an element of a C-style trinary operator. [2]

    condition?result-if-true:result-if-false

    (( var0 = var1<98?9:21 ))
    #                ^ ^

    # if [ "$var1" -lt 98 ]
    # then
    #    var0=9
    # else
    #    var0=21
    # fi

    In a parameter substitution expression, the ? tests whether a variable has been set.

?
    wild card. The ? character serves as a single-character "wild card" for filename expansion in globbing,
    as well as representing one character in an extended regular expression.

$
    Variable substitution (contents of a variable).

    var1=5
    var2=23skidoo

    echo $var1       # 5
    echo $var2       # 23skidoo

    A $ prefixing a variable name indicates the value the variable holds.

$
    end-of-line. In a regular expression, a "$" addresses the end of a line of text.

${}
    Parameter substitution.

$' ... '
    Quoted string expansion. This construct expands single or multiple escaped octal or hex values into
    ASCII [3] or Unicode characters.

$*, $@
    positional parameters.

$?
    exit status variable. The $? variable holds the exit status of a command, a function, or of the
    script itself.

$$
    process ID variable. The $$ variable holds the process ID [4] of the script in which it appears.

()
    command group.

    (a=hello; echo $a)

    Important
    A listing of commands within parentheses starts a subshell.

    Variables inside parentheses, within the subshell, are not visible to the rest of the script. The
    parent process, the script, cannot read variables created in the child process, the subshell.

    a=123
    ( a=321; )

    echo "a = $a"   # a = 123
    # "a" within parentheses acts like a local variable.

    array initialization.
    Array=(element1 element2 element3)

{xxx,yyy,zzz,...}
    Brace expansion.

    echo \"{These,words,are,quoted}\"	# " prefix and suffix
    # "These" "words" "are" "quoted"

    cat {file1,file2,file3} > combined_file
    # Concatenates the files file1, file2, and file3 into combined_file.

    cp file22.{txt,backup}
    # Copies "file22.txt" to "file22.backup"

    A command may act upon a comma-separated list of file specs within braces. [5] Filename expansion
    (globbing) applies to the file specs between the braces.

    Caution
    No spaces allowed within the braces unless the spaces are quoted or escaped.

    echo {file1,file2}\ :{\ A," B",' C'}

    file1 : A file1 : B file1 : C file2 : A file2 : B file2 : C

{a..z}
    Extended Brace expansion.

    echo {a..z} # a b c d e f g h i j k l m n o p q r s t u v w x y z
    # Echoes characters between a and z.

    echo {0..3} # 0 1 2 3
    # Echoes characters between 0 and 3.

    base64_charset=( {A..Z} {a..z} {0..9} + / = )
    # Initializing an array, using extended brace expansion.
    # From vladz's "base64.sh" example script.

    The {a..z} extended brace expansion construction is a feature introduced in version 3 of Bash.

{}
    Block of code [curly brackets]. Also referred to as an inline group, this construct, in effect,
    creates an anonymous function (a function without a name). However, unlike in a "standard" function,
    the variables inside a code block remain visible to the remainder of the script.

    bash$ { local a;
          a=123; }
    bash: local: can only be used in a
    function


    a=123
    { a=321; }
    echo "a = $a"   # a = 321	(value inside code block)

    # Thanks, S.C.

    The code block enclosed in braces may have I/O redirected to and from it.

    Example 3-1. Code blocks and I/O redirection

#!/bin/bash
# Reading lines in /etc/fstab.

File=/etc/fstab

{
	read line1
	read line2
} < $File

echo "First line in $File is:"
echo "$line1"
echo
echo "Second line in $File is:"
echo "$line2"

exit 0

# Now, how do you parse the separate fields of each line?
# Hint: use awk, or . . .
# . . . Hans-Joerg Diers suggests using the "set" Bash builtin.

    Example 3-2. Saving the output of a code block to a file

#!/bin/bash
# rpm-check.sh

#  Queries an rpm file for description, listing,
#+ and whether it can be installed.
#  Saves output to a file.
#
#  This script illustrates using a code block.

SUCCESS=0
E_NOARGS=65

if [ -z "$1" ]
then
	echo "Usage: `basename $0` rpm-file"
	exit $E_NOARGS
fi

{ # Begin code block.
	echo
	echo "Archive Description:"
	rpm -qpi $1	# Query description.
	echo
	echo "Archive Listing:"
	rpm -qpl $1	# Query listing.
	echo
	rpm -i --test $1	# Query whether rpm file can be installed.
	if [ "$?" -eq $SUCCESS ]
	then
		echo "$1 can be installed."
	else
		echo "$1 cannot be installed."
	fi
	echo		# End code block.
} > "$1.test"	# Redirects output of everything in block to file.

echo "Results of rpm test in file $1.test"

# See rpm man page for explanation of options.

exit 0
    Note
    Unlike a command group within (parentheses), as above, a code block enclosed by {braces} will not
    normally launch a subshell. [6]

    It is possible to iterate a code block using a non-standard for-loop.

{}
    placeholder for text. Used after xargs -i (replace strings option). The {} double curly brackets
    are a placeholder for output text.

    ls . | xargs -i -t cp ./{} $1
    #            ^^         ^^

    # From "ex42.sh" (copydir.sh) example.

{} \;
    pathname. Mostly used in find constructs. This is not a shell builtin.

    Definition: A pathname is a filename that includes the complete path. As an example,
    /home/bozo/Notes/Thursday/schedule.txt. This is sometimes referred to as the absolute path.

    Note
    The ";" ends the -exec option of a find command sequence. It needs to be escaped to protect it from
    interpretation by the shell.

[ ]
    test.

    Test expression between [ ]. Note that [ is part of the shell builtin test (and a synonym for it),
    not a link to the external command /usr/bin/test.

[[ ]]
    test.

    Test expression between [[ ]]. More flexible than the single-bracket [ ] test, this is a shell keyword.

    See the discussion on the [[ ... ]] construct.

[ ]
    array element.

    In the context of an array, brackets set off the numbering of each element of that array.

    Array[1]=slot_1
    echo ${Array[1]}

[ ]
    range of characters.

    As part of a regular expression, brackets delineate a range of characters to match.

$[ ... ]
    integer expansion.

    Evaluate integer expression between $[ ].

    a=3
    b=7

    echo $[$a+$b]   # 10
    echo $[$a*$b]   # 21

    Note that this usage is deprecated, and has been replaced by the (( ... )) construct.

(( ))
    integer expansion.

    Expand and evaluate integer expression between (( )).

    See the discussion on the (( ... )) construct.

> &> >& >> < <>
    redirection.

    scriptname >filename redirects the output of scriptname to file filename. Overwrite filename if it
    already exists.

    command &>filename redirects both the stdout and the stderr of command to filename.

    Note
    This is useful for suppressing output when testing for a condition. For example, let us test whether
    a certain command exists.

    bash$ type bogus_command &>/dev/null

    bash$ echo $?
    1

    Or in a script:

    command_test () { type "$1" &>/dev/null; }
    #                                      ^

    cmd=rmdir         # Legitimate command.
    command_test $cmd; echo $?     # 0


    cmd=bogus_command     # Illegitimate command
    command_test $cmd; echo $?     # 1

    command >&2 redirects stdout of command to stderr.

    scriptname >>filename appends the output of scriptname to file filename. If filename does not already
    exist, it is created.

    [i]<>filename opens file filename for reading and writing, and assigns file descriptor i to it. If
    filename does not exist, it is created.

process substitution.

    (command)>

    <(command)

    In a different context, the "<" and ">" characters act as string comparison operators.

    In yet another context, the "<" and ">" characters act as integer comparison operators. See also
    Example 16-9.

<<
    redirection used in a here document.

<<<
    redirection used in a here string.

<, >
    ASCII comparison.

    veg1=carrots
    veg2=tomatoes

	if [[ "$veg1" < "$veg2" ]]
	then
		echo "Although $veg1 precede $veg2 in the dictionary,"
		echo -n "this does not necessarily imply anything "
		echo "about my culinary preferences."
	else
		echo "What kind of dictionary are you using, anyhow?"
	fi

\<, \>
    word boundary in a regular expression.

    bash$ grep '\<the\>' textfile

|
    pipe. Passes the output (stdout) of a previous command to the input (stdin) of the next one, or to
    the shell. This is a method of chaining commands together.

    echo ls -l | sh
    #  Passes the output of "echo ls -l" to the shell,
    #+ with the same result as a simple "ls -l".


    cat *.lst | sort | uniq
    # Merges and sorts all ".lst" files, then deletes duplicate lines.

    A pipe, as a classic method of interprocess communication, sends the stdout of one process to the
    stdin of another. In a typical case, a command, such as cat or echo, pipes a stream of data to a
    filter, a command that transforms its input for processing. [7]

    cat $filename1 $filename2 | grep $search_word

    For an interesting note on the complexity of using UNIX pipes, see the UNIX FAQ, Part 3.

    The output of a command or commands may be piped to a script.

    #!/bin/bash
    # uppercase.sh : Changes input to uppercase.

    tr 'a-z' 'A-Z'
    #  Letter ranges must be quoted
    #+ to prevent filename generation from single-letter filenames.

    exit 0

    Now, let us pipe the output of ls -l to this script.

    bash$ ls -l | ./uppercase.sh
    -RW-RW-R--    1 BOZO  BOZO       109 APR  7 19:49 1.TXT
    -RW-RW-R--    1 BOZO  BOZO       109 APR 14 16:48 2.TXT
    -RW-R--R--    1 BOZO  BOZO       725 APR 20 20:56 DATA-FILE

    Note
    The stdout of each process in a pipe must be read as the stdin of the next. If this is not the case,
    the data stream will block, and the pipe will not behave as expected.

    cat file1 file2 | ls -l | sort
    # The output from "cat file1 file2" disappears.

    A pipe runs as a child process, and therefore cannot alter script variables.

    variable="initial_value"
    echo "new_value" | read variable
    echo "variable = $variable"     # variable = initial_value

    If one of the commands in the pipe aborts, this prematurely terminates execution of the pipe. Called
    a broken pipe, this condition sends a SIGPIPE signal.

>|
    force redirection (even if the noclobber option is set). This will forcibly overwrite an existing file.

||
    OR logical operator. In a test construct, the || operator causes a return of 0 (success) if either
    of the linked test conditions is true.

&
    Run job in background. A command followed by an & will run in the background.

    bash$ sleep 10 &
    [1] 850
    [1]+  Done              sleep 10

    Within a script, commands and even loops may run in the background.

    Example 3-3. Running a loop in the background

#!/bin/bash
# background-loop.sh

for i in 1 2 3 4 5 6 7 8 9 10         # First loop.
do
	echo -n "$i "
done & # Run this loop in background.
# Will sometimes execute after second loop.

echo   # This 'echo' sometimes will not display.

for i in 11 12 13 14 15 16 17 18 19 20   # Second loop.
do
	echo -n "$i "
done

echo   # This 'echo' sometimes will not display.

# ======================================================

# The expected output from the script:
# 1 2 3 4 5 6 7 8 9 10
# 11 12 13 14 15 16 17 18 19 20

# Sometimes, though, you get:
# 11 12 13 14 15 16 17 18 19 20
# 1 2 3 4 5 6 7 8 9 10 bozo $
# (The second 'echo' doesn't execute. Why?)

# Occasionally also:
# 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
# (The first 'echo' doesn't execute. Why?)

# Very rarely something like:
# 11 12 13 1 2 3 4 5 6 7 8 9 10 14 15 16 17 18 19 20
# The foreground loop preempts the background one.

exit 0

#  Nasimuddin Ansari suggests adding    sleep 1
#+ after the   echo -n "$i"   in lines 6 and 14,
#+ for some real fun.

    Caution
    A command run in the background within a script may cause the script to hang, waiting for a
    keystroke. Fortunately, there is a remedy for this.

&&
    AND logical operator. In a test construct, the && operator causes a return of 0 (success) only if
    both the linked test conditions are true.

-
    option, prefix. Option flag for a command or filter. Prefix for an operator. Prefix for a default
    parameter in parameter substitution.

    COMMAND -[Option1][Option2][...]

    ls -al

    sort -dfu $filename

if [ $file1 -ot $file2 ]
then #      ^
	echo "File $file1 is older than $file2."
fi

if [ "$a" -eq "$b" ]
then #    ^
	echo "$a is equal to $b."
fi

if [ "$c" -eq 24 -a "$d" -eq 47 ]
then #    ^              ^
	echo "$c equals 24 and $d equals 47."
fi


    param2=${param1:-$DEFAULTVAL}
    #               ^

    --

    The double-dash -- prefixes long (verbatim) options to commands.

    sort --ignore-leading-blanks

    Used with a Bash builtin, it means the end of options to that particular command.

    Tip

    This provides a handy means of removing files whose names begin with a dash.

    bash$ ls -l
    -rw-r--r-- 1 bozo bozo 0 Nov 25 12:29 -badname


    bash$ rm -- -badname

    bash$ ls -l
    total 0

    The double-dash is also used in conjunction with set.

    set -- $variable (as in Example 15-18)

-
    redirection from/to stdin or stdout [dash].

    bash$ cat -
    abc
    abc

    ...

    Ctl-D

    As expected, cat - echoes stdin, in this case keyboarded user input, to stdout. But, does I/O
    redirection using - have real-world applications?

    (cd /source/directory && tar cf - . ) | (cd /dest/directory && tar xpvf -)
    # Move entire file tree from one directory to another
    # [courtesy Alan Cox <a.cox@swansea.ac.uk>, with a minor change]

    # 1) cd /source/directory
    #     Source directory, where the files to be moved are.
    # 2) &&
    #    "And-list": if the 'cd' operation successful,
    #     then execute the next command.
    # 3) tar cf - .
    #     The 'c' option 'tar' archiving command creates a new archive,
    #     the 'f' (file) option, followed by '-' designates the target file
    #     as stdout, and do it in current directory tree ('.').
    # 4) |
    #     Piped to ...
    # 5) ( ... )
    #     a subshell
    # 6) cd /dest/directory
    #     Change to the destination directory.
    # 7) &&
    #    "And-list", as above
    # 8) tar xpvf -
    #     Unarchive ('x'), preserve ownership and file permissions ('p'),
    #     and send verbose messages to stdout ('v'),
    #     reading data from stdin ('f' followed by '-').
    #
    #     Note that 'x' is a command, and 'p', 'v', 'f' are options.
    #
    # Whew!


    # More elegant than, but equivalent to:
    #    cd source/directory
    #    tar cf - . | (cd ../dest/directory; tar xpvf -)
    #
    #      Also having same effect:
    # cp -a /source/directory/* /dest/directory
    #      Or:
    # cp -a /source/directory/* /source/directory/.[^.]* /dest/directory
    #      If there are hidden files in /source/directory.

    bunzip2 -c linux-2.6.16.tar.bz2 | tar xvf -
    #  --uncompress tar file--	    | --then pass it to "tar"--
    #  If "tar" has not been patched to handle "bunzip2",
    #+ this needs to be done in two discrete steps, using a pipe.
    #  The purpose of the exercise is to unarchive "bzipped" kernel source.

    Note that in this context the "-" is not itself a Bash operator, but rather an option recognized by
    certain UNIX utilities that write to stdout, such as tar, cat, etc.

    bash$ echo "whatever" | cat -
    whatever

    Where a filename is expected, - redirects output to stdout (sometimes seen with tar cf), or accepts
    input from stdin, rather than from a file. This is a method of using a file-oriented utility as a
    filter in a pipe.

    bash$ file
    Usage: file [-bciknvzL] [-f namefile] [-m magicfiles] file...

    By itself on the command-line, file fails with an error message.

    Add a "-" for a more useful result. This causes the shell to await user input.

    bash$ file -
    abc
    standard input:         ASCII text



    bash$ file -
    #!/bin/bash
    standard input:         Bourne-Again shell script text executable

    Now the command accepts input from stdin and analyzes it.

    The "-" can be used to pipe stdout to other commands. This permits such stunts as prepending lines
    to a file.

    Using diff to compare a file with a section of another:

    grep Linux file1 | diff file2 -

    Finally, a real-world example using - with tar.

    Example 3-4. Backup of all files changed in last day

#!/bin/bash

#  Backs up all files in current directory modified within last 24 hours
#+ in a "tarball" (tarred and gzipped file).

BACKUPFILE=backup-$(date +%m-%d-%Y)
#	Embeds date in backup filename.
#	Thanks, Joshua Tschida, for the idea.
archive=${1:-$BACKUPFILE}
#  If no backup-archive filename specified on command-line,
#+ it will default to "backup-MM-DD-YYYY.tar.gz."

tar cvf - `find . -mtime -1 -type f -print` > $archive.tar
gzip $archive.tar
echo "Directory $PWD backed up in archive file \"$archive.tar.gz\"."


#  Stephane Chazelas points out that the above code will fail
#+ if there are too many files found
#+ or if any filenames contain blank characters.

# He suggests the following alternatives:
# -------------------------------------------------------------------
#	find . -mtime -1 -type f -print0 | xargs -0 tar rvf "$archive.tar"
#	using the GNU version of "find".


#	find . -mtime -1 -type f -exec tar rvf "$archive.tar" '{}' \;
#	portable to other UNIX flavors, but much slower.
# -------------------------------------------------------------------

	exit 0

    Caution
    Filenames beginning with "-" may cause problems when coupled with the "-" redirection operator. A
    script should check for this and add an appropriate prefix to such filenames, for example ./-FILENAME,
    $PWD/-FILENAME, or $PATHNAME/-FILENAME.

    If the value of a variable begins with a -, this may likewise create problems.

    var="-n"
    echo $var
    # Has the effect of "echo -n", and outputs nothing.

-
    previous working directory. A cd - command changes to the previous working directory. This uses the
    $OLDPWD environmental variable.

    Caution
    Do not confuse the "-" used in this sense with the "-" redirection operator just discussed. The
    interpretation of the "-" depends on the context in which it appears.

-
    Minus. Minus sign in an arithmetic operation.

=
    Equals. Assignment operator

    a=28
    echo $a   # 28

    In a different context, the "=" is a string comparison operator.

+
    Plus. Addition arithmetic operator.

    In a different context, the + is a Regular Expression operator.

+
    Option. Option flag for a command or filter.

    Certain commands and builtins use the + to enable certain options and the - to disable them. In
    parameter substitution, the + prefixes an alternate value that a variable expands to.

%
    modulo. Modulo (remainder of a division) arithmetic operation.

    let "z = 5 % 3"
    echo $z  # 2

    In a different context, the % is a pattern matching operator.

~
    home directory [tilde]. This corresponds to the $HOME internal variable. ~bozo is bozo's home directory,
    and ls ~bozo lists the contents of it. ~/ is the current user's home directory, and ls ~/ lists the
    contents of it.

    bash$ echo ~bozo
    /home/bozo

    bash$ echo ~
    /home/bozo

    bash$ echo ~/
    /home/bozo/

    bash$ echo ~:
    /home/bozo:

    bash$ echo ~nonexistent-user
    ~nonexistent-user

~+
    current working directory. This corresponds to the $PWD internal variable.

~-
    previous working directory. This corresponds to the $OLDPWD internal variable.

=~
    regular expression match. This operator was introduced with version 3 of Bash.

^
    beginning-of-line. In a regular expression, a "^" addresses the beginning of a line of text.

^, ^^
    Uppercase conversion in parameter substitution (added in version 4 of Bash).

Control Characters
    change the behavior of the terminal or text display. A control character is a CONTROL + key combination
    (pressed simultaneously). A control character may also be written in octal or hexadecimal notation,
    following an escape.

    Control characters are not normally useful inside a script.

	Ctl-A
	Moves cursor to beginning of line of text (on the command-line).

	Ctl-B
	Backspace (nondestructive).

	Ctl-C
	Break. Terminate a foreground job.

	Ctl-D
	Log out from a shell (similar to exit).

	EOF (end-of-file). This also terminates input from stdin.
	When typing text on the console or in an xterm window, Ctl-D erases the character under the
	cursor. When there are no characters present, Ctl-D logs out of the session, as expected. In an
	xterm window, this has the effect of closing the window.

	Ctl-E
	Moves cursor to end of line of text (on the command-line).

	Ctl-F
	Moves cursor forward one character position (on the command-line).

	Ctl-G
	BEL. On some old-time teletype terminals, this would actually ring a bell. In an xterm it might beep.

	Ctl-H
	Rubout (destructive backspace). Erases characters the cursor backs over while backspacing.

	#!/bin/bash
	# Embedding Ctl-H in a string.
	a="^H^H"    # Two Ctl-H's -- backspaces
	            # ctl-V ctl-H, using vi/vim
	echo "abcdef"        # abcdef
	echo
	echo -n "abcdef$a "    # abcd f
	#  Space at end  ^           ^  Backspaces twice.
	echo
	echo -n "abcdef$a"    # abcdef
	#  No space at end           ^ Doesn't backspace (why?).
	            # Results may not be quite as expected.
	echo; echo

	# Constantin Hagemeier suggests trying:
	# a=$'\010\010'
	# a=$'\b\b'
	# a=$'\x08\x08'
	# But, this does not change the results.

	########################################

	# Now, try this.

    rubout="^H^H^H^H^H"      # 5 x Ctl-H.

	echo -n "12345678"
	sleep 2
	echo -n "$rubout"
	sleep 2

	Ctl-I
	Horizontal tab.

	Ctl-J
	Newline (line feed). In a script, may also be expressed in octal notation -- '\012' or in
	hexadecimal -- '\x0a'.

	Ctl-K
	Vertical tab.

	When typing text on the console or in an xterm window, Ctl-K erases from the character under the
	cursor to end of line. Within a script, Ctl-K may behave differently, as in Lee Lee Maschmeyer's
	example, below.

	Ctl-L
	Formfeed (clear the terminal screen). In a terminal, this has the same effect as the clear
	command. When sent to a printer, a Ctl-L causes an advance to end of the paper sheet.

	Ctl-M
	Carriage return.

	#!/bin/bash
	# Thank you, Lee Maschmeyer, for this example.

	read -n 1 -s -p \
	$'Control-M leaves cursor at beginning of this line. Press Enter. \x0d'
		# Of course, '0d' is the hex equivalent of Control-M.
	echo >&2   #  The '-s' makes anything typed silent,
		#+ so it is necessary to go to new line explicitly.

	read -n 1 -s -p $'Control-J leaves cursor on next line. \x0a'
		#  '0a' is the hex equivalent of Control-J, linefeed.
	echo >&2

	###
	read -n 1 -s -p $'And Control-K\x0bgoes straight down.'
	echo >&2   #  Control-K is vertical tab.

	# A better example of the effect of a vertical tab is:

	var=$'\x0aThis is the bottom line\x0bThis is the top line\x0a'
	echo "$var"

	#  This works the same way as the above example. However:
	echo "$var" | col

	#  This causes the right end of the line to be higher than the left end.
	#  It also explains why we started and ended with a line feed --
	#+ to avoid a garbled screen.

	# As Lee Maschmeyer explains:
	# --------------------------
	#  In the [first vertical tab example] . . . the vertical tab
	#+ makes the printing go straight down without a carriage return.
	#  This is true only on devices, such as the Linux console,
	#+ that can't go "backward."
	#  The real purpose of VT is to go straight UP, not down.
	#  It can be used to print superscripts on a printer.
	#  The col utility can be used to emulate the proper behavior of VT.

	exit 0

	Ctl-N
	Erases a line of text recalled from history buffer [8] (on the command-line).

	Ctl-O
	Issues a newline (on the command-line).

	Ctl-P
	Recalls last command from history buffer (on the command-line).

	Ctl-Q
	Resume (XON).

	This resumes stdin in a terminal.

	Ctl-R
	Backwards search for text in history buffer (on the command-line).

	Ctl-S
	Suspend (XOFF).

	This freezes stdin in a terminal. (Use Ctl-Q to restore input.)

	Ctl-T
	Reverses the position of the character the cursor is on with the previous character (on the
	command-line).

	Ctl-U
	Erase a line of input, from the cursor backward to beginning of line. In some settings, Ctl-U
	erases the entire line of input, regardless of cursor position.

	Ctl-V
	When inputting text, Ctl-V permits inserting control characters. For example, the following two
	are equivalent:

	echo -e '\x0a'
	echo <Ctl-V><Ctl-J>

	Ctl-V is primarily useful from within a text editor.

	Ctl-W
	When typing text on the console or in an xterm window, Ctl-W erases from the character under the
	cursor backwards to the first instance of whitespace. In some settings, Ctl-W erases backwards
	to first non-alphanumeric character.

	Ctl-X
	In certain word processing programs, Cuts highlighted text and copies to clipboard.

	Ctl-Y
	Pastes back text previously erased (with Ctl-U or Ctl-W).

	Ctl-Z
	Pauses a foreground job.

	Substitute operation in certain word processing applications.

	EOF (end-of-file) character in the MSDOS filesystem.

Whitespace
    functions as a separator between commands and/or variables. Whitespace consists of either spaces,
    tabs, blank lines, or any combination thereof. [9] In some contexts, such as variable assignment,
    whitespace is not permitted, and results in a syntax error.

    Blank lines have no effect on the action of a script, and are therefore useful for visually separating
    functional sections.

    $IFS, the special variable separating fields of input to certain commands. It defaults to whitespace.

    Definition: A field is a discrete chunk of data expressed as a string of consecutive
    characters. Separating each field from adjacent fields is either whitespace or some other designated
    character (often determined by the $IFS). In some contexts, a field may be called a record.

    To preserve whitespace within a string or in a variable, use quoting.

    UNIX filters can target and operate on whitespace using the POSIX character class [:space:].

Notes
[1]

An operator is an agent that carries out an operation. Some examples are the common arithmetic operators,
+ - * /. In Bash, there is some overlap between the concepts of operator and keyword.

[2]
This is more commonly known as the ternary operator. Unfortunately, ternary is an ugly word. It doesn't
roll off the tongue, and it doesn't elucidate. It obfuscates. Trinary is by far the more elegant usage.

[3]
American Standard Code for Information Interchange. This is a system for encoding text characters
(alphabetic, numeric, and a limited set of symbols) as 7-bit numbers that can be stored and manipulated
by computers. Many of the ASCII characters are represented on a standard keyboard.

[4]
A PID, or process ID, is a number assigned to a running process. The PIDs of running processes may be
viewed with a ps command.

Definition: A process is a currently executing command (or program), sometimes referred to as a job.

[5]
The shell does the brace expansion. The command itself acts upon the result of the expansion.

[6]
Exception: a code block in braces as part of a pipe may run as a subshell.

ls | { read firstline; read secondline; }
#  Error. The code block in braces runs as a subshell,
#+ so the output of "ls" cannot be passed to variables within the block.
echo "First line is $firstline; second line is $secondline"  # Won't work.

# Thanks, S.C.

[7]
Even as in olden times a philtre denoted a potion alleged to have magical transformative powers, so
does a UNIX filter transform its target in (roughly) analogous fashion. (The coder who comes up with a
"love philtre" that runs on a Linux machine will likely win accolades and honors.)

[8]
Bash stores a list of commands previously issued from the command-line in a buffer, or memory space,
for recall with the builtin history commands.

[9]
A linefeed (newline) is also a whitespace character. This explains why a blank line, consisting only of
a linefeed, is considered whitespace.


---
https://mywiki.wooledge.org/BashSheet

Bash Reference Sheet

   Contents
    1. Bash Reference Sheet
    2. Syntax
    3. Basic Structures
         1. Compound Commands
              1. Command Lists
              2. Expressions
              3. Loops
         2. Builtins
              1. Dummies
              2. Declarative
              3. Input
              4. Output
              5. Execution
              6. Jobs/Processes
              7. Conditionals And Loops
              8. Script Arguments
    4. Streams
         1. File Descriptors
         2. Redirection
         3. Piping
         4. Expansions
         5. Common Combinations
    5. Tests
         1. Exit Codes
              1. Testing The Exit Code
         2. Patterns
              1. Glob Syntax
         3. Testing
    6. Parameters
         1. Special Parameters
         2. Parameter Operations
         3. Arrays
              1. Creating Arrays
              2. Using Arrays
    7. Examples: Basic Structures
         1. Compound Commands
              1. Command Lists
              2. Expressions
              3. Loops
         2. Builtins
              1. Dummies
              2. Declarative
              3. Input
              4. Output
              5. Execution

Syntax
     * [word] [space] [word]
          + Spaces separate words. In bash, a word is a group of characters that belongs together.
            Examples are command names and arguments to commands. To put spaces inside an argument (or
            word), quote the argument with single or double quotes (see next two points).
     * ' [Single quoted string] '
          + Disables syntactical meaning of all characters inside the string. Whenever you want literal
            strings in your code, it's good practice to wrap them in single quotes so you don't run the
            risk of accidentally using a character that also has a syntactical meaning to Bash.
     * " [Double quoted string] "
          + Disables syntactical meaning of all characters except expansions inside the string. Use this
            form instead of single quotes if you need to expand a parameter or command substitution into
            your string.
          + Remember: It's important to always wrap your expansions ("$var" or "$(command)") in double
            quotes. This will, in turn, safely disable meaning of syntactical characters that may occur
            inside the expanded result.
     * [command] ; [command] [newline]
          + Semi-colons and newlines separate synchronous commands from each other. Use a semi-colon or
            a new line to end a command and begin a new one. The first command will be executed
            synchronously, which means that Bash will wait for it to end before running the next
            command.
     * [command] & [command]
          + A single ampersand terminates an asynchronous command. An ampersand does the same thing as a
            semicolon or newline in that it indicates the end of a command, but it causes Bash to
            execute the command asynchronously. That means Bash will run it in the background and run
            the next command immediately after, without waiting for the former to end. Only the command
            before the & is executed asynchronously and you must not put a ; after the &, the & replaces
            the ;.
     * [command] | [command]
          + A vertical line or pipe-symbol connects the output of one command to the input of the next.
            Any characters streamed by the first command on stdout will be readable by the second
            command on stdin.
     * [command] && [command]
          + An AND conditional causes the second command to be executed only if the first command ends
            and exits successfully.
     * [command] || [command]
          + An OR conditional causes the second command to be executed only if the first command ends
            and exits with a failure exit code (any non-zero exit code).

Basic Structures

Compound Commands
   Compound commands are statements that can execute several commands but are considered as a sort of
   command group by Bash.

Command Lists
     * { [command list]; }
          + Execute the list of commands in the current shell as though they were one command.
          + Command grouping on its own isn't very useful. However, it comes into play wherever Bash
            syntax accepts only one command while you need to execute multiple. For example, you may
            want to pass output of multiple commands via a pipe to another command's input:
          + { cmd1; cmd2; } | cmd3
          + Or you may want to execute multiple commands after a || operator:
          + rm file || { echo "Removal failed, aborting."; exit 1; }
          + It is also used for function bodies. Technically, this can also be used for loop bodies
            though this is undocumented, not portable and we normally prefer do ...; done for this):
          + for digit in 1 9 7; { echo "$digit"; }       # non-portable, undocumented, unsupported
          + for digit in 1 9 7; do echo "$digit"; done   # preferred
          + Note: You need a ; before the closing } (or it must be on a new line).
     * ( [command list] )
          + Execute the list of commands in a subshell.
          + This is exactly the same thing as the command grouping above, only, the commands are
            executed in a subshell. Any code that affects the environment such as variable assignments,
            cd, export, etc. do not affect the main script's environment but are scoped within the
            brackets.
          + Note: You do not need a ; before the closing ).

Expressions
     * (( [arithmetic expression] ))
          + Evaluates the given expression in an arithmetic context.
          + That means, strings are considered names of integer variables, all operators are considered
            arithmetic operators (such as ++, ==, >, <=, etc..) You should always use this for
            performing tests on numbers!
     * $(( [arithmetic expression] ))
          + Expands the result of the given expression in an arithmetic context.
          + This syntax is similar to the previous, but expands into the result of the expansion. We use
            it inside other commands when we want the result of the arithmetic expression to become part
            of another command.
     * [[ [test expression] ]]
          + Evaluates the given expression as a test-compatible expression.
          + All test operators are supported but you can also perform Glob pattern matching and several
            other more advanced tests. It is good to note that word splitting will not take place on
            unquoted parameter expansions here. You should always use this for performing tests on
            strings and filenames!

Loops
   If you're new to loops or are looking for more details, explanation and/or examples of their usage,
   go read [69]the BashGuide's section on Conditional Loops.
     * do [command list]; done
          + This constitutes the actual loop that is used by the next few commands.
            The list of commands between the do and done are the commands that will be executed in every
            iteration of the loop.
     * for [name] in [words]
          + The next loop will iterate over each WORD after the in keyword.
            The loop's commands will be executed with the value of the variable denoted by name set to
            the word.
     * for (( [arithmetic expression]; [arithmetic expression]; [arithmetic expression] ))
          + The next loop will run as long as the second arithmetic expression remains true
            .
            The first arithmetic expression will be run before the loop starts. The third arithmetic
            expression will be run after the last command in each iteration has been executed.
     * while [command list]
          + The next loop will be repeated for as long as the last command ran in the command list exits
            successfully.
     * until [command list]
          + The next loop will be repeated for as long as the last command ran in the command list exits
            unsuccessfully ("fails").
     * select [name] in [words]
          + The next loop will repeat forever, letting the user choose between the given words.
               o
                 The iteration's commands are executed with the variable denoted by name's value set to
                 the word chosen by the user. Naturally, you can use break to end this loop.

Builtins
   Builtins are commands that perform a certain function that has been compiled into Bash.
   Understandably, they are also the only types of commands (other than those above) that can modify the
   Bash shell's environment.

Dummies
     * true (or :): These commands do nothing at all.
          + They are NOPs that always return successfully.
     * false: The same as above, except that the command always "fails".
          + It returns an exit code of 1 indicating failure.

Declarative
     * alias: Sets up a Bash alias, or print the bash alias with the given name.
          + Aliasses replace a word in the beginning of a command by something else. They only work in
            interactive shells (not scripts).
     * declare (or typeset): Assign a value to a variable.
          + Each argument is a new variable assignment. Each argument's part before the equal sign is
            the name of the variable, and after comes the data of the variable. Options to declare can
            be used to toggle special variable flags (like read-only/export/integer/array).
     * export: Export the given variable to the environment so that child processes inherit it.
          + This is the same as declare -x. Remember that for the child process, the variable is not the
            same as the one you exported. It just holds the same data. Which means, you can't change the
            variable data and expect it to change in the parent process, too.
     * local: Declare a variable to have a scope limited to the current function.
          + As soon as the function exits, the variable disappears. Assigning to it in a function also
            doesn't change a global variable with the same name, should one exist. The same options as
            taken by declare can be passed to local.
     * type: Show the type of the command name specified as argument.
          + The type can be either: alias, keyword, function, builtin, or file.

Input
     * read: Read a line (unless the -d option is used to change the delimiter from newline to something
       else) and put it in the variables denoted by the arguments given to read.
          + If more than one variable name is given, split the line up using the characters in [70]IFS
            as delimiters. If less variable names are given than there are split chunks in the line, the
            last variable gets all data left unsplit.

Output
     * echo: Output each argument given to echo on one line, separated by a single space.
          + The first arguments can be options that toggle special behaviour (like no newline at
            end/evaluate escape sequences).
     * printf: Use the first argument as a format specifier of how to output the other arguments.
          + See help printf.
     * pwd: Output the absolute pathname of the current working directory.
          + You can use the -P option to make pwd resolve any symlinks in the pathname.

Execution
     * cd: Changes the current directory to the given path.
          + If the path doesn't start with a slash, it is relative to the current directory.
     * command: Run the first argument as a command.
          + This tells Bash to skip looking for an alias, function or keyword by that name; and instead
            assume the command name is a builtin, or a program in PATH.
     * coproc: Run a command or compound command as a co-process.
          + Runs in bg, setting up pipes for communication. See
            [71]http://wiki.bash-hackers.org/syntax/keywords/coproc for details.
     * . or source: Makes Bash read the filename given as first argument and execute its contents in the
       current shell.
          + This is kind of like include in other languages. If more arguments are given than just a
            filename to source, those arguments are set as the positional parameters during the
            execution of the sourced code. If the filename to source has no slash in it, PATH is
            searched for it.
     * exec: Run the command given as first argument and replace the current shell with it.
          + Other arguments are passed to the command as its arguments. If no arguments are given to
            exec but you do specify Redirections on the exec command, the redirections will be applied
            to the current shell.
     * exit: End the execution of the current script.
          + If an argument is given, it is the exit status of the current script (an integer between 0
            and 255).
     * logout: End the execution of a login shell.
     * return: End the execution of the current function.
          + An exit status may be specified just like with the exit builtin.
     * ulimit: Modify resource limitations of the current shell's process.
          + These limits are inherited by child processes.

Jobs/Processes
     * jobs: List the current shell's active jobs.
     * bg: Send the previous job (or job denoted by the given argument) to run in the background.
          + The shell continues to run while the job is running. The shell's input is handled by itself,
            not the job.
     * fg: Send the previous job (or job denoted by the given argument) to run in the foreground.
          + The shell waits for the job to end and the job can receive the input from the shell.
     * kill: Send a signal(3) to a process or job.
          + As argument, give the process ID of the process or the jobspec of the job you want to send
            the signal to.
     * trap: Handle a signal(3) sent to the current shell.
          + The code that is in the first argument is executed whenever a signal is received denoted by
            any of the other arguments to trap.
     * suspend: Stops the execution of the current shell until it receives a SIGCONT signal.
          + This is much like what happens when the shell receives a SIGSTOP signal.
     * wait: Stops the execution of the current shell until active jobs have finished.
          + In arguments, you can specify which jobs (by jobspec) or processes (by PID) to wait for.

Conditionals And Loops
     * break: Break out of the current loop.
          + When more than one loop is active, break out the last one declared. When a number is given
            as argument to break, break out of number loops, starting with the last one declared.
     * continue: Skip the code that is left in the current loop and start a new iteration of that loop.
          + Just like with break, a number may be given to skip out more loops.

Script Arguments
     * set: The set command normally sets various Shell options, but can also set Positional parameters.
          + Shell options are options that can be passed to the shell, such as bash -x or bash -e. set
            toggles shell options like this: set -x, set +x, set -e, ... Positional parameters are
            parameters that hold arguments that were passed to the script or shell, such as
            bash myscript -foo /bar. set assigns positional parameters like this: set -- -foo /bar.
     * shift: Moves all positional parameters' values one parameter back.
          + This way, values that were in $1 are discarted, values from $2 go into $1, values from $3 go
            into $2, and so on. You can specify an argument to shift which is an integer that specifies
            how many times to repeat this shift.
     * getopts: Puts an option specified in the arguments in a variable.
          + getopts Uses the first argument as a specification for which options to look for in the
            arguments. It then takes the first option in the arguments that is mentioned in this option
            specification (or next option, if getopts has been ran before), and puts this option in the
            variable denoted by the name in the second argument to getopts. This command is pretty much
            always used in a loop:

	while getopts abc opt
	do
	case $opt in
		a) ...;;
		b) ...;;
		c) ...;;
	esac
	done
            This way all options in the arguments are parsed and when they are either -a, -b or -c, the
            respective code in the case statement is executed. Following short style is also valid for
            specifying multiple options in the arguments that getopts parses: -ac.

Streams
   If you're new to handling input and output in bash or are looking for more examples, details and/or
   explanations, go read [72]BashGuide/InputAndOutput.

   Bash is an excellent tool for managing streams of data between processes. Thanks to its excellent
   operators for connecting file descriptors, we take data from almost anywhere and send it to almost
   anywhere. Understanding streams and how you manipulate them in Bash is key to the vastness of Bash's
   power.

File Descriptors
   A file descriptor is like a road between a file and a process. It's used by the process to send data
   to the file or read data from the file. A process can have a great many file descriptors, but by
   default, there are three that are used for standard tasks.
     * 0: Standard Input
          + This is where processes normally read information from. Eg. the process may ask you for your
            name, after you type it in, the information is read over FD 0.
     * 1: Standard Output
          + This is where processes normally write all their output to. Eg. the process may explain what
            it's doing or output the result of an operation.
     * 2: Standard Error
          + This is where processes normally write their error messages to. Eg. the process may complain
            about invalid input or invalid arguments.

Redirection
     * [command] > [file], [command] [n]> [file], [command] 2> [file]
          + File Redirection: The > operator redirects the command's Standard Output (or FD n) to a
            given file.
          + This means all standard output generated by the command will be written to the file.
          + You can optionally specify a number in front of the > operator. If not specified, the number
            defaults to 1. The number indicates which file descriptor of the process to redirect output
            from.
          + Note: The file will be truncated (emptied) before the command is started!
     * [command] >&[fd], [command] [fd]>&[fd], [command] 2>&1
          + Duplicating File Descriptors: The x>&y operator copies FD y's target to FD x.
          + For the last example, FD 1 (the command's stdout)'s current target is copied to FD 2 (the
            command's stderr).
          + As a result, when the command writes to its stderr, the bytes will end up in the same place
            as they would have if they had been written to the command's stdout.
     * [command] >> [file], [command] [n]>> [file]
          + File Redirection: The >> operator redirects the command's Standard Output to a given file,
            appending to it.
          + This means all standard output generated by the command will be added to the end of the
            file.
          + Note: The file is not truncated. Output is just added to the end of it.
     * [command] < [file], [command] [n]< [file]
          + File Redirection: The < operator redirects the given file to the command's Standard Input.
          + You can optionally specify a number in front of the < operator. If not specified, the number
            defaults to 0. The number indicates which file descriptor of the process to redirect input
            into.
     * [command] &> [file]
          + File Redirection: The &> operator redirects the command's Standard Output and Standard Error
            to a given file.
          + This means all standard output and errors generated by the command will be written to the
            file.
     * [command] &>> [file] (Bash 4+)
          + File Redirection: The &>> operator redirects the command's Standard Output and Standard
            Error to a given file, appending to it.
          + This means all standard output and errors generated by the command will be added to the end
            of the file.
     * [command] <<< "[line of data]"
          + Here-String: Redirects the single string of data to the command's Standard Input.
          + This is a good way to send a single line of text to a command's input. Note that since the
            string is quoted, you can also put newlines in it safely, and turn it into multiple lines of
            data.
     * [command] <<[WORD]
       [lines of data]
       [WORD]
          + Here-Document: Redirects the lines of data to the command's Standard Input.
          + This is a good way of sending multiple lines of text to a command's input.
          + Note: The word after << must be exactly the same as the word after the last line of data,
            and when you repeat that word after the last line of data, it must be in the beginning of
            the line, and there must be nothing else on that line.
          + Note: You can 'quote' the word after the <<. If you do so, anything in the lines of data
            that looks like expansions will not be expanded by bash.
          + Note: If a hyphen (-) is appended after << (<<-[WORD]), then all the leading tab characters
            are ignored in each line.

Piping
     * [command] | [othercommand]
          + Pipe: The | operator connects the first command's Standard Output to the second command's
            Standard Input.
          + As a result, the second command will read its data from the first command's output.
     * [command] |& [othercommand] (Bash 4+)
          + Pipe: The |& operator connects the first command's Standard Output and Standard Error to the
            second command's Standard Input.
          + As a result, the second command will read its data from the first command's output and
            errors combined.

Expansions
     * [command] "$( [command list] )", [command] "` [command list] `"
          + Command Substitution: captures the output of a command and expands it inline.
          + We only use command substitution inside other commands when we want the output of one
            command to become part of another statement. An ancient and ill-advised alternative syntax
            for command substitution is the back-quote: `command`. This syntax has the same result, but
            it does not nest well and it's too easily confused with quotes (back-quotes have nothing to
            do with quoting!). Avoid this syntax and replace it with $(command) when you find it.
          + It's like running the second command, taking its output, and pasting it in the first command
            where you would put $(...).
     * [command] <([command list])
          + Process substitution: The <(...) operator expands into a new file created by bash that
            contains the other command's output.
          + The file provides whomever reads from it with the output from the second command.
          + It's like redirecting the output of the second command to a file called foo, and then
            running the first command and giving it foo as argument. Only, in a single statement, and
            foo gets created and cleaned up automatically afterwards.
          + NOTE: DO NOT CONFUSE THIS WITH FILE REDIRECTION. The < here does not mean File Redirection.
            It is just a symbol that's part of the <(...) operator! This operator does not do any
            redirection. It merely expands into a path to a file.
     * [command] >([command list])
          + Process substitution: The >(...) operator expands into a new file created by bash that sends
            data you write to it to a second command's Standard Input.
          + When the first command writes something to the file, that data is given to the second
            command as input.
          + It's like redirecting a file called foo to the input of the second command, and then running
            the first command, giving it foo as argument. Only, in a single statement, and foo gets
            created and cleaned up automatically afterwards

Common Combinations
     * [command] < <([command list])
          + File Redirection and Process Substitution: The <(...) is replaced by a file created by bash,
            and the < operator takes that new file and redirects it to the command's Standard Input.
          + This is almost the same thing as piping the second command to the first
            (secondcommand | firstcommand), but the first command is not sub-shelled like it is in a
            pipe. It is mostly used when we need the first command to modify the shell's environment
            (which is impossible if it is subshelled). For example, reading into a variable:
            read var < <(grep foo file). This wouldn't work: grep foo file | read var, because the var
            will be assigned only in its tiny subshell, and will disappear as soon as the pipe is done.
          + Note: Do not forget the whitespace between the < operator and the <(...) operator. If you
            forget that space and turn it into <<(...), that will give errors!
          + Note: This creates (and cleans up) a temporary implementation-specific file (usually, a
            FIFO) that channels output from the second command to the first.
     * [command] <<< "$([command list])"
          + Here-String and Command Substitution: The $(...) is replaced by the output of the second
            command, and the <<< operator sends that string to the first command's Standard Input.
          + This is pretty much the same thing as the command above, with the small side-effect that $()
            strips all trailing newlines from the output and <<< adds one back to it.
          + Note: This first reads all output from the second command, storing it in memory. When the
            second command is complete, the first is invoked with the output. Depending on the amount of
            output, this can be more memory-consuming.

Tests
   If you're new to bash, don't fully understand what commands and exit codes are or want some details,
   explanation and/or examples on testing commands, strings or files, go read [73]the BashGuide's
   section on Tests and Conditionals.

Exit Codes
   An Exit Code or Exit Status is an unsigned 8-bit integer returned by a command that indicates how its
   execution went. It is agreed that an Exit Code of 0 indicates the command was successful at what it
   was supposed to do. Any other Exit Code indicates that something went wrong. Applications can choose
   for themselves what number indicates what went wrong; so refer to the manual of the application to
   find out what the application's Exit Code means.

Testing The Exit Code
     * if [command list]; then [command list]; elif [command list]; then [command list]; else [command
       list]; fi
          + The if command tests whether the last command in the first command list had an exit code of
            0.
            If so, it executes the command list that follows the then. If not, the next elif is tried in
            the same manner. If no elifs are present, the command list following else is executed,
            unless there is no else statement. To summarize, if executes a list of *command*s. It tests
            the exit code. On success, the then commands are executed. elif and else parts are optional.
            The fi part ends the entire if block (don't forget it!).
     * while [command list], and until [command list]
          + Execute the next iteration depending on the exit code of the last command in the command
            list.
            We've discussed these before, but it's worth repeating them in this section, as they
            actually do the same thing as the if statement; except that they execute a loop for as long
            as the tested exit code is respectively 0 or non-0.

Patterns
   Bash knows two types of patterns. Glob Patterns is the most important, most used and best readable
   one. Later versions of Bash also support the "trendy" Regular Expressions. However, it is ill-advised
   to use regular expressions in scripts unless you have absolutely no other choice or the advantages of
   using them are far greater than when using globs. Generally speaking, if you need a regular
   expression, you'll be using awk(1), sed(1), or grep(1) instead of Bash.

Glob Syntax
     * ?: A question mark matches any character.
          + That is one single character.
     * *: A star matches any amount of any characters.
          + That is zero or more of whatever characters.
     * [...]: This matches *one of* any of the characters inside the braces.
          + That is one character that is mentioned inside the braces.
               o [abc]: Matches either a, b, or c but not the string abc.
               o [a-c]: The dash tells Bash to use a range.
                    # Matches any character between (inclusive) a and c. So this is the same thing as
                      the example just above.
               o [!a-c] or [^a-c]: The ! or ^ in the beginning tells Bash to invert the match.
                    # Matches any character that is *not* a, b or c. That means any other letter, but
                      *also* a number, a period, a comma, or any other character you can think of.
               o [[:digit:]]: The [:class:] syntax tells Bash to use a character class.
                    # Character classes are groups of characters that are predefined and named for
                      convenience. You can use the following classes:
                      alnum, alpha, ascii, blank, cntrl, digit, graph, lower, print, punct, space,
                      upper, word, xdigit

Testing
     * case [string] in [glob pattern]) [command list];; [glob pattern]) [command list];; esac:
          + Using case is handy if you want to test a certain string that could match either of several
            different glob patterns.
            The command list that follows the *first* glob pattern that matched your string will be
            executed. You can specify as many glob pattern and command lists combos as you need.
     * [[ [string] = "[string]" ]], [[ [string] = [glob pattern] ]], or [[ [string] =~ [regular
       expression] ]]:
          + Test whether the left-hand STRING matches the right-hand STRING (if quoted), GLOB (if
            unquoted and using =) or REGEX (if unquoted and using =~).
            [ and test are commands you often see in sh scripts to perform these tests. [[ can do all
            these things (but better and safer) and it also provides you with pattern matching.
            Do NOT use [ or test in bash code. Always use [[ instead. It has many benefits and no
            downsides.
            Do NOT use [[ for performing tests on commands or on numeric operations. For the first, use
            if and for the second use ((.
            [[ can do a bunch of other tests, such as on files. See help test for all the types of tests
            it can do for you.
     * (( [arithmetic expression] )):
          + This keyword is specialized in performing numeric tests and operations.
            See [75]ArithmeticExpression

Parameters
   Parameters are what Bash uses to store your script data in. There are Special Parameters and
   Variables.

   Any parameters you create will be variables, since special parameters are read-only parameters
   managed by Bash. It is recommended you use lower-case names for your own parameters so as not to
   confuse them with the all-uppercase variable names used by Bash internal variables and environment
   variables. It is also recommended you use clear and transparent names for your variables. Avoid x, i,
   t, tmp, foo, etc. Instead, use the variable name to describe the kind of data the variable is
   supposed to hold.

   It is also important that you understand the need for quoting. Generally speaking, whenever you use a
   parameter, you should quote it: echo "The file is in: $filePath". If you don't, bash will tear the
   contents of your parameter to bits, delete all the whitespace from it, and feed the bits as arguments
   to the command. Yes, Bash mutilates your parameter expansions by default - it's called Word Splitting
   - so use quotes to prevent this.
   The exception is keywords and assignment. After myvar= and inside [[, case, etc, you don't need the
   quotes, but they won't do any harm either - so if you're unsure: quote!

   Last but not least: Remember that parameters are the data structures of bash. They hold your
   application data. They should NOT be used to hold your application logic. So while many ill-written
   scripts out there may use things like GREP=/usr/bin/grep, or command='mplayer -vo x11 -ao alsa', you
   should NOT do this. The main reason is because you cannot possibly do it completely right and safe
   and readable/maintainable.
   If you want to avoid retyping the same command multiple times, or make a single place to manage the
   command's command line, use a function instead. Not parameters.

Special Parameters
     * 1, 2, ...: Positional Parameters are the arguments that were passed to your script or your
       function.
          + When your script is started with ./script foo bar, "$1" will become "foo" and "$2" will
            become "bar". A script ran as ./script "foo bar" hubble will expand "$1" as "foo bar" and
            "$2" as "hubble".
     * *: When expanded, it equals the single string that concatenates all positional parameters using
       the first character of [77]IFS to separate them (- by default, that's a space).
          + In short, "$*" is the same as "$1x$2x$3x$4x..." where x is the first character of IFS.
            With a default IFS, that will become a simple "$1 $2 $3 $4 ...".
     * @: This will expand into multiple arguments: Each positional parameter that is set will be
       expanded as a single argument.
          + So basically, "$@" is the same as "$1" "$2" "$3" ..., all quoted separately.
            NOTE: You should always use "$@" before "$*", because "$@" preserves the fact that each
            argument is its separate entity. With "$*", you lose this data! "$*" is really only useful
            if you want to separate your arguments by something that's not a space; for instance, a
            comma: (IFS=,; echo "You ran the script with the arguments: $*") -- output all your
            arguments, separating them by commas.
     * #: This parameter expands into a number that represents how many positional parameters are set.
          + A script executed with 5 arguments, will have "$#" expand to 5. This is mostly only useful
            to test whether any arguments were set:
            if (( ! $# )); then echo "No arguments were passed." >&2; exit 1; fi
     * ?: Expands into the exit code of the previously completed foreground command.
          + We use $? mostly if we want to use the exit code of a command in multiple places; or to test
            it against many possible values in a case statement.
     * -: The dash parameter expands into the option flags that are currently set on the Bash process.
          + See set for an explanation of what option flags are, which exist, and what they mean.
     * $: The dollar parameter expands into the Process ID of the Bash process.
          + Handy mostly for creating a PID file for your bash process (echo "$$" > /var/run/foo.pid);
            so you can easily terminate it from another bash process, for example.
     * !: Expands into the Process ID of the most recently backgrounded command.
          + Use this for managing backgrounded commands from your Bash script:
            foo ./bar & pid=$!; sleep 10; kill "$pid"; wait "$pid"
     * _: Expanding the underscore argument gives you the last argument of the last command you
       executed.
          + This one's used mostly in interactive shells to shorten typing a little:
            mkdir -p /foo/bar && mv myfile "$_".

Parameter Operations
     * "$var", "${var}"
          + Expand the value contained within the parameter var. The parameter expansion syntax is
            replaced by the contents of the variable.
     * "${var:-Default Expanded Value}"
          + Expand the value contained within the parameter var or the string Default Expanded Value if
            var is empty. Use this to expand a default value in case the value of the parameter is empty
            (unset or contains no characters).
     * "${var:=Default Expanded And Assigned Value}"
          + Expand the value contained within the parameter var but first assign
            Default Expanded And Assigned Value to the parameter if it is empty. This syntax is often
            used with the colon command (:): : "${name:=$USER}", but a regular assignment with the above
            will do as well: name="${name:-$USER}".
     * "${var:?Error Message If Unset}", "${name:?Error: name is required.}"
          + Expand the value contained within the parameter name or show an error message if it's empty.
            The script (or function, if in an interactive shell) is aborted.
     * ${name:+Replacement Value}, ${name:+--name "$name"}
          + Expand the given string if the parameter name is not empty. This expansion is used mainly
            for expanding the parameter along with some context. The example expands two arguments:
            notice how, unlike all other examples, the main expansion is unquoted, allowing word
            splitting of the inside string. Remember to quote the parameter in the inside string,
            though!
     * "${line:5}", "${line:5:10}", "${line:offset:length}"
          + Expand a substring of the value contained within the parameter line. The substring begins at
            character number 5 (or the number contained within parameter offset, in the second example)
            and has a length of 10 characters (or the number contained within parameter length). The
            offset is 0-based. If the length is omitted, the substring reaches til the end of the
            parameter's value.
     * "${@:5}", "${@:2:4}", "${array:start:count}"
          + Expand elements from an array starting from a start index and expanding all or a given count
            of elements. All elements are expanded as separate arguments because of the quotes. If you
            use @ as the parameter name, the elements are taken from positional parameters (the
            arguments to your script - the second example becomes: "$2" "$3" "$4" "$5").
     * "${!var}"
          + Expand the value of the parameter named by the value of the parameter var. This is bad
            practice! This expansion makes your code highly non-transparent and unpredictable in the
            future. You probably want an associative array instead.
     * "${#var}", "${#myarray[@]}"
          + Expand into the length of the value of the parameter var. The second example expands into
            the number of elements contained in the array named myarray.
     * "${var#A Prefix}", "${PWD#*/}", "${PWD##*/}"
          + Expand the value contained within the parameter var after removing the string A Prefix from
            the beginning of it. If the value doesn't have the given prefix, it is expanded as is. The
            prefix can also be a glob pattern, in which case the string that matches the pattern is
            removed from the front. You can double the # mark to make the pattern match greedy.
     * "${var%A Suffix}", "${PWD%/*}", "${PWD%%/*}"
          + Expand the value contained within the parameter var after removing the string A Suffix from
            the end of it. Works just like the prefix trimming operation, only takes away from the end.
     * "${var/pattern/replacement}", "${HOME/$USER/bob}", "${PATH//:/ }"
          + Expand the value contained within the parameter var after replacing the given pattern with
            the given replacement string. The pattern is a glob used to search for the string to replace
            within var's value. The first match is replaced with the replacement string. You can double
            the first / to replace all matches: The third example replaces all colons in PATH's value by
            spaces.
     * "${var^}", "${var^^}", "${var^^[ac]}"
          + Expand the value contained within the parameter var after upper-casing all characters
            matching the pattern. The pattern must be match a single character and the pattern ? (any
            character) is used if it is omitted. The first example upper-cases the first character from
            var's value, the second upper-cases all characters. The third upper-cases all characters
            that are either a or c.
     * "${var,}", "${var,,}", "${var,,[AC]}"
          + Expand the value contained within the parameter var after lower-casing all characters
            matching the pattern. Works just like the upper-casing operation, only lower cases matching
            characters.

Arrays
   Arrays are variables that contain multiple strings. Whenever you need to store multiple items in a
   variable, use an array and NOT a string variable. Arrays allow you to keep the elements nicely
   separated and allow you to cleanly expand the elements into separate arguments. This is impossible to
   do if you mash your items together in a string!

   If you're new to bash or don't fully grasp what arrays are and why one would use them in favor of
   normal variables, or you're looking for more explanation and/or examples on arrays, go read [80]the
   BashGuide's section on Arrays and [81]BashFAQ/005

Creating Arrays
     * myarray=( foo bar quux )
          + Create an array myarray that contains three elements. Arrays are created using the x=(y)
            syntax and array elements are separated from each other by whitespace.
     * myarray=( "foo bar" quux )
          + Create an array myarray that contains two elements. To put elements in an array that contain
            whitespace, wrap quotes around them to indicate to bash that the quoted text belongs
            together in a single array element.
     * myfiles=( *.txt )
          + Create an array myfiles that contains all the filenames of the files in the current
            directory that end with .txt. We can use any type of expansion inside the array assignment
            syntax. The example use pathname expansion to replace a glob pattern by all the filenames it
            matches. Once replaced, array assignment happens like in the first two examples.
     * myfiles+=( *.html )
          + Add all HTML files from the current directory to the myfiles array. The x+=(y) syntax can be
            used the same way as the normal array assignment syntax, but append elements to the end of
            the array.
     * names[5]="Big John", names[n + 1]="Long John"
          + Assign a string to a specific index in the array. Using this syntax, you explicitly tell
            Bash at what index in your array you want to store the string value. The index is actually
            interpreted as an arithmetic expression, so you can easily do math there.
     * read -ra myarray
          + Chop a line into fields and store the fields in an array myarray. The read commands reads a
            line from stdin and uses each character in the [82]IFS variable as a delimiter to split that
            line into fields.
     * IFS=, read -ra names <<< "John,Lucas,Smith,Yolanda"
          + Chop a line into fields using , as the delimiter and store the fields in the array named
            names. We use the <<< syntax to feed a string to the read command's stdin. IFS is set to ,
            for the duration of the read command, causing it to split the input line into fields
            separated by a comma. Each field is stored as an element in the names array.
     * IFS=$'\n' read -d '' -ra lines
          + Read all lines from stdin into elements of the array named lines. We use read's -d '' switch
            to tell it not to stop reading after the first line, causing it to read in all of stdin. We
            then set IFS to a newline character, causing read to chop the input up into fields whenever
            a new line begins.
     * files=(); while IFS= read -d '' -r file; do files+=("$file"); done < <(find . -name '*.txt' -print0)
          + Safely read all TXT files contained recursively in the current directory into the array
            named files.
            We begin by creating an empty array named files. We then start a while loop which runs a
            read statement to read in a filename from stdin, and then appends that filename (contained
            in the variable file) to the files array. For the read statement we set IFS to empty,
            avoiding read's behavior of trimming leading whitespace from the input and we set -d '' to
            tell read to continue reading until it sees a NUL byte (filenames CAN span multiple lines,
            so we don't want read to stop reading the filename after one line!). For the input, we
            attach the find command to while's stdin. The find command uses -print0 to output its
            filenames by separating them with NUL bytes (see the -d '' on read). NOTE: This is the only
            truly safe way of building an array of filenames from a command's output! You must delimit
            your filenames with NUL bytes, because it is the only byte that can't actually appear inside
            a filename! NEVER use ls to enumerate filenames! First try using the glob examples above,
            they are just as safe (no need to parse an external command), much simpler and faster.
     * declare -A homedirs=( ["Peter"]=~pete ["Johan"]=~jo ["Robert"]=~rob )
          + Create an associative array, mapping names to user home directories. Unlike normal arrays,
            associative arrays indices are strings (just like the values). Note: you must use declare -A
            when creating an associative array to indicate to bash that this array's indices are strings
            and not integers.
     * homedirs["John"]=~john
          + Add an element to an associative array, keyed at "John", mapped to john's home directory.

Using Arrays
     * echo "${names[5]}", echo "${names[n + 1]}"
          + Expand a single element from an array, referenced by its index. This syntax allows you to
            retrieve an element's value given the index of the element. The index is actually
            interpreted as an arithmetic expression, so you can easily do math there.
     * echo "${names[@]}"
          + Expand each array element as a separate argument. This is the preferred way of expanding
            arrays. Each element in the array is expanded as if passed as a new argument, properly
            quoted.
     * cp "${myfiles[@]}" /destinationdir/
          + Copy all files referenced by the filenames within the myfiles array into /destinationdir/.
            Expanding an array happens using the syntax "${array[@]}". It effectively replaces that
            expansion syntax by a list of all the elements contained within the array, properly quoted
            as separate arguments.
     * rm "./${myfiles[@]}"
          + Remove all files referenced by the filenames within the myfiles array. It's generally a bad
            idea to attach strings to an array expansion syntax. What happens is: the string is only
            prefixed to the first element expanded from the array (or suffixed to the last if you
            attached the string to the end of the array expansion syntax). If myfiles contained the
            elements -foo.txt and bar-.html, this command would expand into:
            rm "./-foo.txt" "bar-.html". Notice only the first element is prefixed with ./. In this
            particular instance, this is handy because rm fails if the first filename begins with a
            dash. Now it begins with a dot.
     * (IFS=,; echo "${names[*]}")
          + Expand the array names into a single string containing all elements in the array, merging
            them by separating them with a comma (,). The "${array[*]}" syntax is only very rarely
            useful. Generally, when you see it in scripts, it is a bug. The one use it has is to merge
            all elements of an array into a single string for displaying to the user. Notice we
            surrounded the statement with (brackets), causing a subshell: This will scope the [83]IFS
            assignment, resetting it after the subshell ends.
     * for file in "${myfiles[@]}"; do read -p "Delete $file? " && [[ $REPLY = y ]] && rm "$file"; done
          + Iterate over all elements of the myfiles array after expanding them into the for statement.
            Then, for each file, ask the user whether he wants to delete it.
     * for index in "${!myfiles[@]}"; do echo "File number $index is ${myfiles[index]}"; done
          + Iterate over all keys of the myfiles array after expanding them into the for statement. The
            syntax "${!array[@]}" (notice the !) gets expanded into a list of array keys, not values.
            Keys of normal arrays are numbers starting at 0. The syntax for getting to a particular
            element within an array is "${array[index]}", where index is the key of the element you want
            to get at.
     * names=(John Pete Robert); echo "${names[@]/#/Long }"
          + Perform a parameter expansion operation on every element of the names array. When adding a
            parameter expansion operation to an array expansion, the operation is applied to every
            single array element as it is expanded.
     * names=(John Pete Robert); echo "${names[@]:start:length}"; echo "${names[@]:1:2}"
          + Expand length array elements, starting at index start. Similar to the simple "${names[@]}"
            but expands a sub-section of the array. If length is omitted, the rest of the array elements
            are expanded.
     * printf '%s\n' "${names[@]}"
          + Output each array element on a new line. This printf statement is a very handy technique for
            outputting array elements in a common way (in this case, appending a newline to each). The
            format string given to printf is applied to each element (unless multiple %s's appear in it,
            of course).
     * for name in "${!homedirs[@]}"; do echo "$name lives in ${homedirs[$name]}"; done
          + Iterate over all keys of the homedirs array after expanding them into the for statement. The
            syntax for getting to the keys of associative arrays is the same as that for normal arrays.
            Instead of numbers beginning at 0, we now get the keys for which we mapped our associative
            array's values. We can later use these keys to look up values within the array, just like
            normal arrays.
     * printf '%s\n' "${#names[@]}"
          + Output the number of elements in the array. In this printf statement, the expansion expands
            to only one argument, regardless of the amount of elements in the array. The expanded
            argument is a number that indicates the amount of elements in the names array.

Examples: Basic Structures

Compound Commands

Command Lists
     * [[ $1 ]] || { echo "You need to specify an argument!" >&2; exit 1; }
          + We use a command group here because the || operator takes just one command.
            We want both the echo and exit commands to run if $1 is empty.
     * (IFS=','; echo "The array contains these elements: ${array[*]}")
          + We use parenthesis to trigger a subshell here.
            When we set the [84]IFS variable, it will only change in the subshell and not in our main
            script. That avoids us having to reset it to it's default after the expansion in the echo
            statement (which otherwise we would have to do in order to avoid unexpected behaviour later
            on).
     * (cd "$1" && tar -cvjpf archive.tbz2 .)
          + Here we use the subshell to temporarily change the current directory to what's in $1.
            After the tar operation (when the subshell ends), we're back to where we were before the cd
            command because the current directory of the main script never changed.

Expressions
     * ((completion = current * 100 / total))
          + Note that arithmetic context follows completely different parsing rules than normal bash
            statements.
     * [[ $foo = /* ]] && echo "foo contains an absolute pathname."
          + We can use the [[ command to perform all tests that test(1) can do.
            But as shown in the example it can do far more than test(1); such as glob pattern matching,
            regular expression matching, test grouping, etc.

Loops
     * for file in *.mp3; do openssl md5 "$file"; done > mysongs.md5
          + For loops iterate over all arguments after the in keyword.
            One by one, each argument is put in the variable name file and the loop's body is executed.
            DO NOT PASS A COMMAND'S OUTPUT TO for BLINDLY!
            for will iterate over the WORDS in the command's output; which is almost NEVER what you
            really want!
     * for file; do cp "$file" /backup/; done
          + This concise version of the for loop iterates the positional parameters.
            It's basically the equivalent of for file in "$@".
     * for (( i = 0; i < 50; i++ )); do printf "%02d," "$i"; done
          + Generates a comma-separated list of numbers zero-padded to two digits.
            (The last character will be a comma, yes, if you really want to get rid of it; you can - but
            it defeats the simplicity of this example)
     * while read _ line; do echo "$line"; done < file
          + This while loop continues so long as the read command is successful.
            (Meaning, so long as lines can be read from the file). The example basically just throws out
            the first column of data from a file and prints the rest.
     * until myserver; do echo "My Server crashed with exit code: $?; restarting it in 2 seconds .."; sl
       eep 2; done
          + This loop restarts myserver each time it exits with a non-successful exit code.
            It assumes that when myserver exits with a non-successful exit code; it crashed and needs to
            restart; and if it exist with a successful exit code; you ordered it to shut down and it
            needn't be restarted.
     * select fruit in Apple Pear Grape Banana Strawberry; do (( credit -= 2, health += 5 )); echo "You
       purchased some $fruit.  Enjoy!"; done
          + A simple program which converts credits into health.
            Amazing.

Builtins

Dummies
     * while ! ssh lhunath@lyndir.com; do :; done
          + Reconnect on failure.

Declarative
     * alias l='ls -al'
          + Make an alias called l which is replaced by ls -al.
            Handy for quickly viewing a directory's detailed contents.
     * declare -i myNumber=5
          + Declare an integer called myNumber initialized to the value 5.
     * export AUTOSSH_PORT=0
          + Export a variable on the bash process environment called AUTOSSH_PORT which will be
            inherited by any process this bash process invokes.
     * foo() { local bar=fooBar; echo "Inside foo(), bar is $bar"; }; echo "Setting bar to 'normalBar'";
        bar=normalBar; foo; echo "Outside foo(), bar is $bar"
          + An exercise in variable scopes.
     * if ! type -P ssh >/dev/null; then echo "Please install OpenSSH." >&2; exit 1; fi
          + Check to see if ssh is available.
            Suggest the user install OpenSSH if it is not, and exit.

Input
     * read firstName lastName phoneNumber address
          + Read data from a single line with four fields into the four named variables.

Output
     * echo "I really don't like $nick.  He can be such a prick."
          + Output a simple string on standard output.
     * printf "I really don't like %s.  He can be such a prick." "$nick"
          + Same thing using printf instead of echo, nicely separating the text from the data.

Execution
     * cd ~lhunath
          + Change the current directory to lhunath's home directory.
     * cd() { builtin cd "$@" && echo "$PWD"; }
          + Inside the function, execute the builtin cd command, not the function (which would cause
            infinite recursion) and if it succeeds, echo out the new current working directory.
     * source bashlib; source ./.foorc
          + Run all the bash code in a file called bashlib which exists somewhere in PATH; then do the
            same for the file .foorc in the current directory.
     * exec 2>/var/log/foo.log
          + Send all output to standard error from now on to a log file.
     * echo "Fatal error occurred!  Terminating!"; exit 1
          + Show an error message and exit the script.


---

