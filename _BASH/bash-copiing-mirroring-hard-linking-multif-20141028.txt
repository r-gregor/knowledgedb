filename: bash_copiing-mirroring-hard-linking-multif_20141028.txt
http://stackoverflow.com/questions/1240636/symlink-copying-a-directory-hierarchy

symlink-copying a directory hierarchy

   What's the simplest way on Linux to "copy" a directory hierarchy so that a new hierarchy of
   directories are created while all "files" are just symlinks pointing back to the actual
   files on the source hierarchy?
   'cp -s' does not work recursively.
   Thanks!

7 Answers 7

   I googled around a little bit and found a command called [41]lns, available from [42]here.
***
   This tool works great for me. Thanks for pointing it out! -  [46]Max Spring Aug 10 '09 at
***
   I just did a quick test on a linux box and cp -sR /orig /dest does exactly what you
   described: creates a directory hierarchy with symlinks for non-directories back to the
   original.
***
   It only works on the first directory level. For every file in subdirectories I get
   "xyz-file: can make relative symbolic links only in current directory". (On Ubuntu 8.10, cp
   version 6.10) -  [50]Max Spring Aug 10 '09 at 3:48
***
   The reason you get "xyz-file: can make relative symbolic links only in current directory"
   is because for the source directory, you specified a relative path. It'll work as you want
   it if you specify an absolute path for the source, like so: "cp -sR
   /root/absolute/path/name dest". -  [51]redstreet Sep 3 '11 at 0:34

   In case you need/want to make all the symlinks relative you can use [52]symlinks like this:
   cp -sR /orig /dest && symlinks -rc /dest -  [53]Nathan S. Watson-Haigh Feb 4 at 2:38
   1
   Does not work on all systems. On Mac/PowerPC, I get: cp: illegal option -- s, so if you
   need to make a portable script, you'll need a different approach. -  [54]PacMan-- Oct 9 at
   6:39
***
cp -as /root/absolute/path/name dest_dir

   will do what you want. Note that the source name must be an absolute path, it cannot be
   relative. Else, you'll get this error: "xyz-file: can make relative symbolic links only in
   current directory."

   Also, be careful as to what you're copying: if dest_dir already exists, you'll have to do
   something like:
cp -as /root/absolute/path/name/* dest_dir/
cp -as /root/absolute/path/name/.* dest_dir/
***
   Starting from above the original & new directories, I think this pair of find(1) commands
   will do what you need:
find original -type d -exec mkdir new/{} \;
find original -type f -exec ln -s {} new/{} \;

   The first instance sets up the directory structure by finding only directories in the
   original tree and recreating them in the new tree. The second creates the symlinks to the
   original files in the new tree.
***
   This works very nicely for me (as written above, cp -as or -Rs won't work on Mac OS X). It
   might be a good idea to (cd origParentDir; find origDir .. ; find origDir ..) in order to
   get the relative path as parameter for both mkdir and ln -s. Use parantheses to start a
   (subshell) because running cd in a subshell will only temporary set CWD; CWD is restored
   when the subshell exits. Eg. if you're 'cloning' /src/binutils-2.24 to ${HOME}/source then
   you do not want the 'src' folder to be created. -  [61]PacMan-- Oct 10 at 1:46
***
   There's also the "lndir" utility (from X) which does such a thing; I found it mentioned
   here: [62]Debian Bug report #301030: can we move lndir to coreutils or debianutils? , and
   I'm now happily using it.
***
   I had the exact problem as the original questioner, and after starting to code a shell
   script, found this answer and discovered lndir already installed. Works exactly as I need
   it. -  [66]shmuelp Oct 6 '09 at 19:02
***
   If you feel like getting your hands dirty Here is a trick that will automatically create
   the destination folder, subfolders and symlink all files recursively.

   In the folder where the files you want to symlink and sub folders are:
    1. create a file shell.sh:
       nano shell.sh
    2. copy and paste this charmer:

   #!/bin/bash
export DESTINATION=/your/destination/folder/
export TARGET=/your/target/folder/

find . -type d -print0 | xargs -0 bash -c 'for DIR in "$@";
do
  echo "${DESTINATION}${DIR}"
  mkdir -p "${DESTINATION}${DIR}"
  done' -


find . -type f -print0 |  xargs -0 bash -c 'for file in "$@";
do
  ln -s  "${TARGET}${file}"  "${DESTINATION}${file}"
   done' -

    1. save the file ctrl+O
    2. close the file ctrl+X
    3. Make your script executable chmod 777 shell.sh
    4. Run your script ./shell.sh

   Happy hacking!
***



---
http://stackoverflow.com/questions/9622883/recursive-copy-of-specific-files-in-unix-linux

Recursive copy of specific files in Unix/Linux? [closed]

   I need to copy all *.jar files from directory and all its subdirectories. How can I do it
   in UNIX/Linux terminal? Command cp -r *.jar /destination_dir doesn't work.
***
   does the destination directory need to maintain the folder structure of the source
   directory? -  [42]Alex Mar 8 '12 at 18:45
   add a comment |

7 Answers 7

   rsync is useful for local file copying as well as between machines. This will do what you
   want:

   rsync -avm --include='*.jar' -f 'hide,! */' . /destination_dir

   The entire directory structure from . is copied to /destination_dir, but only the .jar
   files are copied. The -a ensures all permissions and times on files are unchanged. The -m
   will omit empty directories. -v is for verbose output.

   For a dry run add a -n, it will tell you what it would do but not actually copy anything.
***
   Would you mind explaining me this part: -f 'hide,! */' ? Thanks in advance for your help!
***
   Sure. The -f means it is a filter rule (short for --filter). The rule says hide all
   non-directories, ie files. The '*/' pattern matches a directory, then the ! negates it to
   mean anything that is not a directory (so, a file). The '--include=*.jar' has precedence
   over the filter so .jar files (only) are included. -  [51]Sean Sep 30 '13 at 8:10

   That was very useful, thks!Just to make sure I got it, you are filtering the command by
   saying to match everything that is not a directory, which means all the files. And the
   --include takes care of making sure that only .m files are considered. A last question,
   what if I were interested in copying only the files in that directory, without copying the
   entire directory structure? -  [52]Matteo Sep 30 '13 at 16:32

   Yes, match all files and hide them, except for .jar files. Not sure I understand your last
   question: do you mean flattening the tree structure? If so see:
   [53]stackoverflow.com/questions/9800989/... Or do you mean copy the .jar files from
   directory A to dir B? Plain old 'cp' will do that for you, or 'rsync *.jar
   /path/to/new/dir' -  [54]Sean Sep 30 '13 at 18:12

   Cool, thks again for your explanation. I mean copy all (and only) the .jar files in a
   directory A to a directory B, without going in the sub-directories of A. -  [55]Matteo Sep
***
   If you don't need the directory structure only the jar files, you can use:
shopt -s globstar
cp **/*.jar destination_dir

   If you want the directory structure you can check cp's --parent option.
***
   +1 for shopt globstar, I didn't know about either of those things, useful. -  [59]Sean Mar
   9 '12 at 10:22

   Thanks for pointing out the --parents option. It does something slightly different to the
   posters requirement: It creates the directory structure as far as needed for the files to
   copy, not the whole directory structure. - Was exactly what I needed! :-) -  [60]halloleo
***
   If your find has an -exec switch, and cp an -t option:
find . -name "*.jar" -exec cp -t /destination_dir {} +

   If you find doesn't provide the "+" for parallel invocation, you can use ";" but then you
   can omit the -t:
find . -name "*.jar" -exec cp {} /destination_dir ";"
***
   If the user's not using GNU find, there will be -exec but not with the + command
   terminator. -  [65]glenn jackman Mar 8 '12 at 19:57

   Thanks, @glennjackman. Added a plusless solution. -  [66]user unknown Mar 8 '12 at 20:09

   @glennjackman -1. The + command terminator is defined by POSIX.
   [67]pubs.opengroup.org/onlinepubs/009604599/utilities/find.html -  [68]jordanm Mar 8 '12 at
***
   @jordanm, hmm. On a Solaris 8 box at work, the first find in my path is GNU find 4.1, which
   doesn't have +. Guess I shouldn't take a 10 year old program as gospel. -  [69]glenn
***
   @glennjackman :) 10 years old? But mine is only 4.4.2 - doesn't look so dramatically. -
***
tar -cf - `find . -name "*.jar" -print` | ( cd /destination_dir && tar xBf - )
***
   Why do you use the B flag for the destination tar? The man page says only "reblock as we
   read". I haven't ever run across obvious issues without it in similar settings, but I'm
   curious. -  [76]Eduardo Ivanec Mar 8 '12 at 23:01

   @EduardoIvanec Reblock will make sure that the copy has happened correctly.
   [77]linuxdevcenter.com/pub/a/linux/lpt/18_16.html. Also, from tar GNU docs, If
   --read-full-records (-B) is used, tar will not panic if an attempt to read a record from
   the archive does not return a full record. Instead, tar will keep reading until it has
   obtained a full record But as you observed, it should run fine in most of the cases. -
   [78]Pavan Manjunath Mar 9 '12 at 4:46

   That's great, thank you! -  [79]Eduardo Ivanec Mar 9 '12 at 12:50
***
cp --parents `find -name \*.jar` destination/

   from man cp:
--parents
       use full source file name under DIRECTORY
***
   The OP tagged this "unix", not Linux. AFAIK, the --parents option to cp is Linux-only. -
   [83]ghoti Mar 8 '12 at 19:23
   1
   You mean "GNU-only" -  [84]glenn jackman Mar 8 '12 at 19:58
***
   If you want to maintain the same directory hierarchy under the destination, you could use
(cd SOURCE && find . -type f -name \*.jar -exec tar cf - {} +) \
  | (cd DESTINATION && tar xf -)

   This way of doing it, instead of expanding the output of find within back-ticks, has the
   advantage of being able to handle any number of files.
***
find . -name \*.jar | xargs cp -t /destination_dir

   Assuming your jar filenames do not contain spaces, and your cp has the "-t" option. If cp
   can't do "-t"
find . -name \*.jar | xargs -I FILE cp FILE /destination_dir
***



---
http://stackoverflow.com/questions/22645498/make-hard-links-from-all-subfolders-to-all-subfolders-in-linux

Make hard links from all subfolders to all subfolders in Linux?

   I have two folders, let's call them A and B. Both folders have a folder structure under
   them, that is identical. Say A has folders 1, 2, 3, 4 and 5. B has folders 1, 2, 3, 4 and
   5. All of the subfolders of A have various files in them (e.g /A/1/file.txt
   /A/2/anotherfile.txt.). Same goes for subfolders of the subfolders, so the tree is quite
   deep.

   Now, can I make hard links in all B:s folders and subfolders? So that both tree structures
   look the same and all folders and subfolders have the same files in them. Well, hard links
   that is.

   cp -l all files in A into B

2 Answers 2

   In bash 4, you could write a simple loop like
cd A
shopt -s globstar
for d in **/; do
    mkdir -p "B/$d"
    for f in "$d"; do
        [[ -f $f ]] && cp -l "$f" "B/$f"
    done
done

***
   Even though my solution is brief and elegant, the way --link-dest is confusingly explained
   in the man page makes it a headache to use so I'd probably rather use a loop myself unless
   I remember how to use rsync for this scenario off the top of my head, so have an upvote. -
   [42]Adrian Fruehwirth Mar 25 at 21:18

   I was going to add an rsync answer as well, but I was similarly confused about whether it
   would work :) -  [43]chepner Mar 25 at 22:17

   I admit I did have to play around for a few minutes, I never remember how --link-dest works
   but it certainly is handy :) -  [44]Adrian Fruehwirth Mar 25 at 22:24
   add a comment |
   up vote 1 down vote

   This can be easily done using rsync:
$ rsync -a --link-dest=../A A/ B

   Example:
# Optionally, get rid of your destination
$ rm -rf B

$ find
.
./A
./A/2
./A/2/foo
./A/1
./A/1/foo

# If the argument to --link-dest is relative, it is relative
# to the target directory which is B in this case, hence the ../A
$ rsync -a --link-dest=../A A/ B

$ find
.
./B
./B/2
./B/2/foo
./B/1
./B/1/foo
./A
./A/2
./A/2/foo
./A/1
./A/1/foo

# Notice the identical inodes
$ ls -1i {A,B}/{1,2}/foo
349408 A/1/foo
349409 A/2/foo
349408 B/1/foo
349409 B/2/foo

***
   +1 Nicely explained, as well. -  [49]chepner Mar 25 at 22:19
***
   How about cp -al A/* B/ -  [50]Paolo Mar 26 at 8:02
***
   That, uh, seems to work. D'oh. Note that this is not portable though, but in your case it
   probably doesn't matter. -  [51]Adrian Fruehwirth Mar 26 at 8:45
***
   What does "not portable" mean in this case? -  [52]Paolo Mar 26 at 12:30
***
   That -a and -l are not POSIX so you cannot rely on a cp implementation having those...but
   neither can you rely on having rsync available so it doesn't really matter...I just felt it
   should be mentioned. For example, Apple's cp (darwin) doesn't seem to come with -l
   according to the [53]man page. -  [54]Adrian Fruehwirth Mar 26 at 12:56



---
http://unix.stackexchange.com/questions/61907/how-do-i-create-a-directory-in-all-subdirectories

How do I create a directory in all subdirectories?

   Suppose I have a directory structure like this:
$ [~/practice] ls
a/ b/ c/ d/

   Now I want to create a directory tmp1 in all sub directories of practice and I do this:
$ [~/practice] mkdir */tmp1
mkdir: cannot create directory `*/tmp1': No such file or directory

   Then I try the -p switch and I endup with a directory named * with a sub directory tmp1
$ [~/practice] mkdir -p */tmp1

$ [~/practice] ls
*/ a/ b/ c/ d/

   I know the use of -p switch is to create multiple nonexistent directories. I just thought
   it might help.

   How do I create tmp1 in all subdirectories at once?

   If this can be done, how do I extend it to create \tmp1, \tmp2, \tmp3 in \a, \b and \c at
   once?

   Edit: I missed mentioning that the directories don't have to be simple and in order, like
   a, b, c etc., and the directory to be created is not necessarily like tmp1, tmp2.
$ [~/practice] ls
dog/ cat/ rat/

   In them, I would like to have something like
$ [~/practice] ls *
dog:
red/ blue/

cat:
red/ blue/

rat:
red/ blue/

***
   Given [35]Christopher's answer, you should clarify whether "create \tmp1, \tmp2, \tmp3 in
   \a, \b and \c" should result a total of 3 or 9 subdirectories. -  [36]manatwork Jan 20 '13
   at 15:24
***
   @manatwork: That's a good point. It should create 9 subdirectories. -  [37]Nanda Jan 20 '13
***

7 Answers 7

   With [41]globs :
for dir in */; do mkdir -- "$dir/tmp1"; done

NOTE

     * I treat only dirs (including symlinks to dirs) with the little hack of using */ as a
       glob
     * If you want to create multiple subdirs at once :
       for dir in */; do mkdir -- "$dir"/{tmp1,foo,bar,qux}; done
***
   Could I do for i in */; do mkdir "$i/itemone" "$i/itemtwo"; done for multiple, not-in-order
   directory names? -  [46]Nanda Jan 20 '13 at 15:36
***
   I tested this and it is very much possible. Thanks. -  [47]Nanda Jan 20 '13 at 15:39
***
   See my edited post -  [48]sputnick Jan 20 '13 at 15:42
   1
   Brace expansion is not performed in quoted string. -  [49]manatwork Jan 20 '13 at 16:13
***
   Yes, thanks, post edited by Stephane Chazelas accordingly... -  [50]sputnick Jan 20 '13 at
***
     [...] how do I extend it to create \tmp1, \tmp2, \tmp3 in \a, \b and \c at once?

 mkdir {a,b,c}/tmp{1,2,3}
***
   With GNU or BSD* find:
find -mindepth 1 -maxdepth 1 -type d -exec mkdir {}/newdir \;

   or using parameter expansion:
dirs=(*/)
mkdir -- "${dirs[@]/%/newdir}"
***
   With standard find syntax: find . -name . -o -prune -type d -exec sh -c 'exec mkdir
   "$1/newdir"' sh {} \; -  [58]Stephane Chazelas Jan 20 '13 at 22:04

   Also note the differences between the two solutions: the first one includes hidden
   directories, the second one will add a newdir in the directories linked by any symlink in
   the current directory. -  [59]Stephane Chazelas Jan 20 '13 at 22:06
***
   Off topic since you're mentioning bash, but for the record, with zsh, you'd do:
dirs=(*(/))
mkdir -- $^dirs/tmp1

   $^var turns on brace-like expansion for the expansion of the array. It's reminiscent of
   rc's ^ operator and in rc (or its derivative es), you'd write it:
dirs=(*/)
mkdir -- $dirs^tmp1

   However note (and the same applies to the bash solutions given here) that in the rc
   solution dirs would also contain symbolic links to directories. In the zsh solution, change
   *(/) to *(-/) if you want to include symlinks to directories.
***
   +1 for your point about symlinks! This behavior may be desired, but mkdir's complaint about
   creating a duplicate directory can be suppressed with the -p flag. -  [65]kojiro Jan 20 '13
***
   Portably, loop over the parent directories:
for d in */; do mkdir "$d/red" "$d/blue"; done

   Add -- after mkdir if you may have directories whose name starts with -.

   In zsh, you can do it in a single command with the e [66]glob qualifier:
mkdir *(/e\''REPLY=($REPLY/{red,blue})'\')

   but it's quicker to type this as two commands:
d=(*(/)); mkdir $^d/{red,blue}
***
   On a site that is meant to be a reference, I'd rather say "mkdir -- whatever, and omit --
   if you intend for the expansion of whatever to be possibly taken as options to the mkdir
   command.". There's no point in omiting -- here. It may not be a problem in the OP's case,
   but it is one in the general case. I think we have a duty to teach the correct and safe
   syntax here. -  [70]Stephane Chazelas Jan 21 '13 at 10:35

   @StephaneChazelas In a scripting context, I always put all necessary -- and quotes and big
   fat warnings when newlines aren't supported. In a command line context, I prefer to show
   the quick version that works in practice first, and the bulletproof version as a
   complement. -  [71]Gilles Jan 21 '13 at 11:06
***
   You can do that like that:
mkdir {a,b,c,d}/tmp1
***
   What if he has 100 directories? -  [75]Bernhard Jan 20 '13 at 20:13
***
   Variation on sputnick's answer which avoids non-directory files:
for x in *; do if [ -d "$x" ]; then mkdir "$x/tmp1"; fi; done
***
   I treat only dirs, that"s all the magic... -  [81]sputnick Jan 20 '13 at 15:40
***
   cool, got it ;) -  [82]goldilocks Jan 20 '13 at 15:44
***
   Shouldn't that be if [ -d "$x" ];...? -  [83]kojiro Jan 20 '13 at 21:43
***
   Yes. I practically never have spaces in filenames and tend to forget that stuff... -
***



---
http://www.linuxquestions.org/questions/linux-newbie-8/script-to-create-folders-and-subfolders-656168/

   Script to create folders and subfolders

   I need to create a lot of folders and subfolders and was wondering how I might write a
   script to do this. I need to have a top level folder, 'images' and under that, subfolders
   numbered sequentially, '100', 101', 102', etc. Within those subfolders I need three
   additional folders, '192x128', '384x256', and '768x512'. The second level folders (the
   sequential ones) will number anywhere from ten to 100 folders. Any thoughts on how I can do
   this?
   I am using ImageMagick to resize images in one set of folder and I need to move them over
   to this new set and unfortunately the folder structure is not the same as where I am
   getting the images.
   Thanks,
   Todd
***
   please do man mkdir
***
   There's more

   As an aside, you are more likely to get help by starting this process, and then asking for
   help.
   First, create the script file name using a text editor. Depending what shell you want it to
   run -- bash -- make sure the first line is #!/bin/bash. On Red Hat systems #!/bin/sh links
   to /bin/bash, but that is not guaranteed on other distros.
   Don't forget to protect the file chmod 775 <script_file_name>, and invoke it (run it) using
   ./ in front of the script name.
   Then, look through man bash and/or try this link to find out about for loops
   [58]http://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO-7.html
   You could probably put all your resolution directories in one of those for loops and then
   use mkdir within the loop.
   3) It also helps for you and those answering you to know your distribution.
***
   man mkdir is one of the first places that I looked. I feel that my needs are a bit more
   involved than what I can get out of simply the mkdir command. I would imagine that I will
   need to do some scripting that is a bit more involved than what I am familiar with.
   Thanks,
   Todd
***
   Quote:
   Originally Posted by leupi [74]View Post
   I feel that my needs are a bit more involved than what I can get out of simply the mkdir
   command.
   Not really...
   Code:
mkdir -p images/{100..110}/192x128
mkdir -p images/{100..110}/384x256
mkdir -p images/{100..110}/768x512

   in bash the {N..M} syntax produces a sequence of integers from N to M. You should start to
   read a good bash programming guide for future reference. You can accomplish a lot of tasks
   in a bunch of seconds using parameter substitution, loops, and so on.
***
   Thanks for the info. I will work on this later when I get home. Seems like I need to set up
   a 'while' statement to create the first level directories and set up a counter and keep
   creating directories till the counter increments to a set number. Then I'll need to figure
   out a way to populate each one of those new directories with three more subdirectories,
   '192x128', '384x256', and '768x512'. Does that sound like I am on the right track?
   Thanks,
   Todd
***
   calucix,
   Thanks, that sounds like what I need! I just bought 'Learning the Bash Shell' by O'Reilly
   so I'm sure that that will be a big help. I appreciate the insight. I will be doing a lot
   of this and this script will be a big time saver for me.
   Thanks,
   Todd
***
   As colucix pointed out, the {n..m} expansion works. You can also use {a,b,c} which will
   expand to "a" and b" and "c". Combining them, you can quickly make a long list of strings.
   For example:
   Code:
% echo {1..3}{a,b}
1a 1b 2a 2b 3a 3b

   instead of passing this list of strings to echo, you can pass their straight to mkdir:
   Code:
mkdir -p images/{100..110}/{192x128,384x256,768x512}

   The -p option makes it possible makes multi-level sub-directories without a problem.
   Without it, you have to create "images" before you can create "images/100" and so on.
***
   Matt,
   That worked beautifully, that did exactly what I needed, and it was so simple. Now I just
   need to play with ImageMagick and get the resized files in the appropriate places and I am
   set. I think that I am going to have to get more familiar with bash, this can be quite the
   time saver. Thanks so much for everything!
   Todd
***
   Yeah, shell scripting can be a really boost to productivity. It's not always pretty, but
   for things like this, you can often spend 2 minutes doing what would take 2 hours with GUI
   tools.
***
   I completed my project (thanks to you guys) and all went rather well. It went so well in
   fact that I was handed another one (gotta love working for a nonprofit...). This one is
   very similar with a bit of a twist. I will have a directory with subdirectories which
   include images. The subdirectories could be one or more levels deep. I need to convert all
   of the images to thumbnails and maintain the existing directory structure.
   I was looking for a script that would recursively drill down into the directories and
   convert and images to thumbnails. I found this script and am trying to decipher it:
   Code:
new=order-thumb
mkdir /d1/$new
for i in $(find /photo1 -name "*jpg"); do
    img=$(basename $i);dir=$(dirname $i)
    if [ ! -d $new/$dir ]; then mkdir -p $new/$dir; fi
    convert -size 500x500 -geometry 500x500 $i $new/$dir/$img
done

   I have my 'Learning the bash Shell' book that I am flipping through trying to translate,
   but if anyone could offer their expertise that would be greatly appreciated.
   Thanks again for everyone's previous help,
   Todd
***
   Code:
#This sets a variable
new=order-thumb
#This creates the directord /dl/order-thumb
mkdir /d1/$new

#This uses the output of the find command
#and assigns it to the variable 'i'
for i in $(find /photo1 -name "*jpg");
     do

#For each element found above, assign the image filename
#to the 'img' variable and the path to 'dir'.
         img=$(basename $i);
         dir=$(dirname $i);

#Here we are checking for the directory order-thumb
         if [ ! -d $new/$dir ];
            then
                #If the above directory doesn't exist, create it.
                mkdir -p $new/$dir;
         fi
            #Convert the images and place them into their new directory.
            convert -size 500x500 -geometry 500x500 $i $new/$dir/$img
     done

***
   If you put
   Code:
set -vx

   on the line after the #!/bin/bash line in your script, each statement will be printed after
   it is read from the file, and also after doing expansion of the command (like putting in
   the values of variables and so on).
   With long scripts, this will often create so much output that you get swamped, but for
   small fragments it can be very helpful to understand what is going on. for example:
   Code:
#!/bin/bash
set -vx
cd $HOME/tmp/test
ls -l *.txt
for f in *.txt; do
  echo "oh hai $f"
done

   That will produce this output:
   Code:
cd $HOME/tmp/test
+ cd /home/matthew/tmp/test
ls -l *.txt
+ ls -l one.txt three.txt two.txt
-rw-r--r-- 1 matthew matthew 0 2008-07-18 16:18 one.txt
-rw-r--r-- 1 matthew matthew 0 2008-07-18 16:19 three.txt
-rw-r--r-- 1 matthew matthew 0 2008-07-18 16:18 two.txt
for f in *.txt; do
  echo "oh hai $f"
done
+ for f in '*.txt'
+ echo 'oh hai one.txt'
oh hai one.txt
+ for f in '*.txt'
+ echo 'oh hai three.txt'
oh hai three.txt
+ for f in '*.txt'
+ echo 'oh hai two.txt'
oh hai two.txt

   ...which I hope is useful.
   I would like to point out that you might run into problems when there are files with spaces
   in the file name. Whenever you are iterating over a list of strings, it is prudent to use
   "double quotes" when taking the value of the iterator variable ($i in this case).
   Consider this example:
   Code:
touch "file1.txt" "file 2.txt"
for f in *.txt; do
    ls -l $f
done

   Here you will have a problem with "file 2.txt" because the ls line will look like this to
   the shell:
   Code:
ls -l file 2.txt

   ...which it interprets as a request to list two files: "file" and "2.txt".
   To correct it, you should add double quotes when using the iterator operator:
   Code:
for f in *.txt; do
    ls -l "$f"
done

   This is a very a common mistake and can often be difficult to debug if files with spaces in
   the name are only created some time after the script is written and tested. For this
   reason, I think it's a good idea to get into the habit of using double quotes when taking
   the value of variables, even when it is not strictly necessary... just to set that pattern
   of using the quotes so that you won't fail to do so when it is necessary.
   In the case where you are calling find like this, it is worse:
   Code:
for i in $(find /photo1 -name "*jpg"); do
    ...
done

   Here, the bit inside the $(...) is executed as a shell command, and then the result is
   split up with IFS being used as a delimiter. In this case, there is no way for the shell to
   know if there is a space within a file name.
   A better construct is like this:
   Code:
find /photo1 -name "*.jpg" | while read i; do
    ...
done

   There the output of the find command is read line-by-line and each line is read into the i
   variable. This method will cope with spaces in file names. You still need to remember quote
   the $i when you use it.
   This still does not cope with the case where there is a new line character in a file name,
   but it's probably safe to assume that you won't encounter that very often.



---
http://www.thegeekstuff.com/2010/10/linux-ln-command-examples/ [5+]

The Ultimate Linux Soft and Hard Link Guide (10 Ln Command Examples)

   There are two types of links available in Linux -- Soft Link and Hard Link.

   Linux ln command is used to create either soft or hard links.

   This article explains how to create soft link, how to create hard link, and various link
   tips and tricks with 10 practical examples.
$ ls -l
total 4
lrwxrwxrwx 1 chris chris 10 2010-09-17 23:40 file1 -> sample.txt
-rw-r--r-- 1 chris chris 22 2010-09-17 23:36 sample.txt

   The 1st character in each and every line of the [11]ls command output indicates one of the
   following file types. If the 1st character is l (lower case L), then it is a link file.
     * - regular file
     * l link file
     * d directory
     * p pipe
     * c character special device
     * b block special device

1. What is Soft Link and Hard Link?

Soft Link

   Linux OS recognizes the data part of this special file as a reference to another file path.
   The data in the original file can be accessed through the special file, which is called as
   Soft Link.

   To create a soft link, do the following (ln command with -s option):
$ ln -s /full/path/of/original/file /full/path/of/soft/link/file

Hard Link

   With Hard Link, more than one file name reference the same inode number. Once you create a
   directory, you would see the hidden directories "." and ".." . In this, "." directory is
   hard linked to the current directory and the ".." is hard linked to the parent directory.

   When you use link files, it helps us to reduce the disk space by having single copy of the
   original file and ease the administration tasks as the modification in original file
   reflects in other places.

   To create a hard link, do the following (ln command with no option):
$ ln /full/path/of/original/file /full/path/of/hard/link/file

2. Create Symbolic Link for File or Directory

Create a symbolic link for a File

   The following examples creates a symbolic link library.so under /home/chris/lib, based on
   the library.so located under /home/chris/src/ directory.
$ cd /home/chris/lib

$ ln -s /home/chris/src/library.so library.so

$ ls -l library.so
lrwxrwxrwx  1 chris chris       21 2010-09-18 07:23 library.so -> /home/chris/src/library.so

Create a symbolic link for a Directory

   Just like file, you can create symbolic link for directories as shown below.
$ mkdir /home/chris/obj

$ cd tmp

$ ln -s /home/chris/obj objects

$ ls -l objects
lrwxrwxrwx 1 chris chris       6 2010-09-19 16:48 objects -> /home/chris/obj

   Note: The inode of the original file/directory and the soft link should not be identical.

3. Create Hard Link for Files

   The inode number for the hard linked files would be same. The hard link for files can be
   created as follows,
$ ln src_original.txt dst_link.txt

$ ls -i dst_link.txt
253564 dst_link.txt

$ ls -i src_original.txt
253564 src_original.txt

   Note: Unix / Linux will not allow any user (even root) to create hard link for a directory.

4. Create Links Across Different Partitions

   When you want to create the link across partitions, you are allowed to create only the
   symbolic links. Creating hard link across partitions is not allowed, as Unix can't
   create/maintain same inode numbers across partitions.

   You would see the "Invalid cross-device link" error when you are trying to create a hard
   link file across partitions.
# mount /dev/sda5 /mnt

# cd /mnt

# ls
main.c Makefile

# ln Makefile /tmp/Makefile
ln: creating hard link `/tmp/Makefile' to `Makefile': Invalid cross-device link

   And the symbolic link can be created in the same way as we did in the above.

5. Backup the Target Files If it Already Exists

   When you create a new link (if another file exist already with the same name as the new
   link name), you can instruct ln command to take a backup of the original file before
   creating the new link using the -backup option as shown below.
$ ls
ex1.c  ex2.c

$ ln --backup -s ex1.c ex2.c

$ ls -lrt
total 8
-rw-r--r-- 1 chris chris 20 2010-09-19 16:57 ex1.c
-rw-r--r-- 1 chris chris 20 2010-09-19 16:57 ex2.c~
lrwxrwxrwx 1 chris chris  5 2010-09-19 17:02 ex2.c -> ex1.c

   Note: If you don't want the backup and overwrite the existing file then use -f option.

6. Create Link Using "No-Deference" ln Command Option

   While creating a new soft link, normally OS would de-reference the destination path before
   it creates the new soft link.

   Sometimes you might not want ln command to create the new link, if the destination path is
   already a symbolic link that is pointing to a directory.

   Following examples shows a normal way of creating soft link inside a directory.
$ cd ~

$ mkdir example

$ ln -s /etc/passwd example

$ cd example/

$ ls -l
total 0
lrwxrwxrwx 1 root root 16 2010-09-19 17:24 passwd -> /etc/passwd

   In case the "example" directory in the above code-snippet is a symbolic link pointing to
   some other directory (for example second-dir), the ln command shown will still create the
   link under second-dir. If you don't want that to happen, use ln -n option as shown below.
$ cd ~

$ rm -rf example

$ mkdir second-dir

$ ln -s second-dir example

$ ln -n -s /etc/passwd example
ln: creating symbolic link `example': File exists

   Note: In the above example, if you don't use the -n option, the link will be created under
   ~/second-dir directory.

7. Create Link for Multiple Files at the Same Time

   In the following example, there are two directories -- first-dir and second-dir. The
   directory first-dir contains couple of C program files. If you want to create soft links
   for these files in second-dir, you'll typically do it one by one. Instead, you can create
   soft list for multiple files together using -t option as shown below.
$ ls
first-dir second-dir

$ ls first-dir
ex1.c  ex2.c

$ cd second-dir

$ ln -s ../first-dir/*.c -t .

$ ls -l
total 0
lrwxrwxrwx 1 chris chris 14 2010-09-19 15:20 ex1.c -> ../first-dir/ex1.c
lrwxrwxrwx 1 chris chris 14 2010-09-19 15:20 ex2.c -> ../first-dir/ex2.c

   Keep in mind that whenever you are creating link files with -t option, it is better to go
   into target directory and perform the link creation process. Otherwise, you would face the
   broken link files as shown below.
$ cd first-dir

$ ln -s *.c /home/chris/second-dir

$ cd /home/chris/second-dir
$ ls -l
total 0
lrwxrwxrwx 1 chris chris 5 2010-09-19 15:26 ex1.c -> ex1.c
lrwxrwxrwx 1 chris chris 5 2010-09-19 15:26 ex2.c -> ex2.c

   Instead, you might also use actual path for source files to create the link properly.

8. Removing the Original File When a Soft Link is pointing to it

   When the original file referred by a soft-link is deleted, the soft link will be broken as
   shown below.
$ ln -s file.txt /tmp/link

$ ls -l /tmp/link
lrwxrwxrwx 1 chris chris 9 2010-09-19 15:38 /tmp/link -> file1.txt

$ rm file.txt

$ ls -l /tmp/link
lrwxrwxrwx 1 chris chris 9 2010-09-19 15:38 /tmp/link -> file1.txt

9. Links Help You to Increase the Partition Size Virtually

   Let us assume that you have two partitions - 5GB and 20GB. The first partition does not
   have too much free space available in it. If a program located on the first partition needs
   more space (For example, for it's log file), you can use some of the space from the second
   partition by creating a link for the log files as shown below.

   Consider that partition1 is mounted on /, and partition2 is mounted to /mnt/. Let us assume
   that the logs that are located on partition1 is running out of space, and you've decided to
   move them to partition2. You can achieve this as shown below.
$ mkdir /mnt/logs

$ cd /logs

$ mv * /mnt/logs

$ cd /; rmdir logs

$ ln -s /mnt/logs logs

10. Removing the Hard Linked Files

   When you delete a file that is hard linked, you would be still able to access the content
   of the file until you have the last file which is hard linked to it, as shown in the
   example below.

   Create a sample file.
$ vim src_original.txt
Created this file to test the hard link.

   Create a hard link to the sample file.
$ ln src_original.txt dst_link.txt

   Delete the original file.
$ rm src_original.txt

   You can still access the original file content by using the hard link you created.
$ cat dst_link.txt
Created this file to test the hard link.



---
http://superuser.com/questions/81164/why-create-a-link-like-this-ln-nsf

Why create a link like this: ln -nsf?

   What does this do?
ln -nsf

   I know ln -s creates a symbolic link, not a hard link which means you can delete it and it
   won't delete the think that it's linking to. But what do the other things mean? (-nf)

   Update: okay...so I remembered you can find this stuff out from the command line. Here's
   what I found out from typing ln --help:
-f, --force                 remove existing destination files
-n, --no-dereference        treat destination that is a symlink to a
                            directory as if it were a normal file

   But this still isn't very clear to me what the implications of this are. Why would I want
   to create a soft/sym link like this?
***
   Even if you don't use -s you can delete the link without deleting the original file. Hard
   links increase the link count of the file so it won't be deleted when you delete only one
   of the links to it. -  [34]Amuck Dec 10 '09 at 2:08

   That's not quite the difference between a hard link and a symbolic link. A hard link points
   to the same bytes (inode) on disk. A soft link points to another file by filename. -
   [35]Greg Hewgill Dec 10 '09 at 2:10

   There are also man pages. i.e. run man ln. Or man man, to learn about that help system. You
   can get man pages online, too... -  [36]Peter Cordes Dec 10 '09 at 2:40

5 Answers 5

   -f says that if the target of your command is an existing file, it should be removed and
   replaced by the new link. (Note that in Unix-influenced systems, "file" can include
   directories, links, pipes, etc.)

   -n modifies -f, saying that if the target you specify is an existing symbolic link, it
   should not be removed.
***
   Your description of -n is wrong. -f by itself will not replace a symlink to a directory.
   When replacing a symlink to a directory, -n is needed to treat the existing symlink like a
   normal file instead of a directory. -  [43]Brian Mar 24 '11 at 18:12
***
   From the BSD man page:
 -f    If the target file already exists, then unlink it so that the link
           may occur.  (The -f option overrides any previous -i options.)

 -n    If the target_file or target_dir is a symbolic link, do not follow
           it.  This is most useful with the -f option, to replace a symlink
           which may point to a directory.
***
   You can type "man ln" to find such things:
   -f, --force
          remove existing destination files

   -n, --no-dereference
          treat destination that is a symlink to a directory as if it were
          a normal file
***
   i still don't exactly understand what that means -  [50]Andrew Dec 10 '09 at 2:14
***
   Here are all the options to ln. You'll find -n and -f in here.

     -F If the target file already exists and is a directory, then remove it so that the link
     may occur. The -F option should be used with either -f or -i options. If none is
     specified, -f is implied. The -F option is a no-op unless -s option is specified.
 -h    If the target_file or target_dir is a symbolic link, do not

     follow it. This is most useful with the -f option, to replace a symlink which may point
     to a directory.
 -f    If the target file already exists, then unlink it so that the

     link may occur. (The -f option overrides any previous -i options.)
 -i    Cause ln to write a prompt to standard error if the target file

     exists. If the response from the standard input begins with the character y' or Y', then
     unlink the target file so that the link may occur. Otherwise, do not attempt the link.
     (The -i option overrides any previous -f options.)
 -n    Same as -h, for compatibility with other ln

     implementations.
 -s    Create a symbolic link.

 -v    Cause ln to be verbose, showing files as they are processed.
***
   -f, --force remove existing destination files

   -n, --no-dereference treat destination that is a symlink to a directory as if it were a
   normal file



---
http://superuser.com/questions/516635/hard-linking-directory-structure-somewhere-else

Hard linking directory structure somewhere else

   I have one directory where files appear in. I want to run a script regulary that finds all
   files in that directory that have only one link to them, and hard link them in another
   directory. However, I want the directory structure in the second directory to be created to
   match the first.

     find /srcdir/ -links 1 -exec ln {} /dstdir/ \;

   Does hardlink all files, but does not create the directories I need.

   If a directory contains only files that have already multiple links, that directory does
   not need to be created in the destination.

   Your question states that you have "one directory where files appear in". I take it what
   you mean is you have one directory with various subdirectories that files appear in? -
 ***
   Yes, indeed. Files can also appear in that directory directly, but there can also be new
   subdirectories where files appear in. -  [34]Tom Ribbens Dec 8 '12 at 15:32

2 Answers 2

   If I have understood your question correctly and you have one directory (sourcedir) with
   various sub directories and the linked files can be either in /sourcedir/ or in
   /sourcedir/foo or /sourcedir/bar etc, then this should do what you need:
find /sourcedir/ -links 1  | sed 's/.sourcedir.//' | while read n; do \
  mkdir -p /destdir/`dirname "$n"`; ln /sourcedir/"$n" /destdir/"$n"; \
done

   It uses dirname to get the sub directory of each file and mkdir -p to create the directory
   structure in the destination directory.
***
   Since hard links are rather cheap, you might make them like : (this will make hard link of
   all files, and create directory's as in the source)
cp -al source dest

   Then you can remove the hardlinks that are in some other location on your file system. (if
   double hard links are a issue) Using the slightly adapted find command you posted.



---
http://superuser.com/questions/269435/bash-mirroring-of-multiple-directories-hard-linking

bash, mirroring of multiple directories (hard linking)

   I have 5 FTP users that upload files (and subdirectories) in their home directory, i need
   to mirror theese directories beetween them and with a "master" directory (accessible from a
   6th user). Files can contain spaces or others special caracters. All the files are in the
   same filesystem, and i want to use hard link because i don't want to waste 5 time the space
   of a single file.

   I tried with find but i cannot handle spaces in it.
 ***
   Re "I tried with find but i cannot handle spaces in it.": You were doing it the wrong way,
   then. Post the command that you tried. -  [34]grawity Apr 11 '11 at 18:05

1 Answer 1

   Hardlink the directory
 ln [OPTION]... TARGET... DIRECTORY     (3rd form)

   Spaces should be processed using "name with space" or name\ with\ space I guess.
***
   Directories cannot be hardlinked on any modern filesystem without resorting to black magic.
***
   In my system it's not possible to hard-link one directory... Directories can only be
   soft-linked. -  [42]Aleritty Apr 13 '11 at 7:08



---
http://www.cyberciti.biz/faq/unix-linux-bsdosx-copying-directory-structures-trees-rsync/

Linux: rsync Copy Directories Structures Tree Only

   I am looking for to only sync directories structures only. How do I copy directory
   structure tree without copying any files under Linux or UNIX operating system to remove
   server or local directory?
***
   You need to use the rsync command. The rsync remote-update protocol allows rsync to
   transfer just

   the differences between two sets of files across the network connection, using an efficient
   checksum-search algorithm. Make sure it is installed on all servers for remote copy. The
   syntax is as follows to copy directories tree only:

rsync -av -f"+ */" -f"- *" /path/to/src /path/to/dest/
rsync -av -f"+ */" -f"- *" /path/to/apache/logs/ root@www433.nixcraft.net.in:/path/to/apache/logs/

   If you are using an older rsync version, try:

rsync -av --include='*/' --exclude='*' /path/to/src /path/to/dest/
rsync -av --include='*/' --exclude='*' /path/to/apache/logs/ root@www433.nixcraft.net.in:/path/to/ap
ache/logs/

rsync Command For Directory Structures / Tree Only

   Consider the following layout in /var/logs/apache/ for each domain:
cricketnow.in/
cyberciti.biz/
hexindia.net/
io9.in/
nixcraft.com/
theos.in/

   You can sync just directories by excluding everything else. Open a command-line terminal
   (select Applications > Accessories > Terminal), and then type the following commands or
   login using ssh to the remote server. You want to copy all dirs i.e. exclude everything
   that is not a directory, enter:
   # cd /var/log/apache/
   # rsync -av -f"+ */" -f"- *" . root@server2.nixcraft.com:/var/log/apache/
   Sample outputs:
building file list ... done
./
cricketnow.in/
cyberciti.biz/
hexindia.net/
io9.in/
nixcraft.com/
theos.in/
sent 388 bytes  received 98 bytes  972.00 bytes/sec
total size is 0  speedup is 0.00

   You can also make local copies as follows:
   # cd /var/log/apache/
   # rsync -av -f"+ */" -f"- *" . /jailfs/apache/httpd_root/var/log/apache/

See also:

   If you need assistance with Linux / UNIX rsync command-line options, turn to the man page
   first. It will give you detailed information, parameters and switches for rsync command:
   $ man rsync
***
          Excellent. Rsyncing the directory structure only was exactly what I needed!
***
          You can use a find command for this if you want the whole directory tree, not just
          the top level. Of course when pushing a structure remotely its better to manipulate
          locally then push:

          find -type d -exec mkdir -p /{} \;

          This will copy the directory structure of to under the dir.

          Isn't the find command wonderful?!



---
http://www.unix.com/shell-programming-and-scripting/210193-compare-copy-directories-bash-script-help.html

   Compare & Copy Directories : Bash Script Help

   I have been looking for a solution to a backup problem. I need to compare Directory 1 to
   Directory 2 and copy all modified or new files/directories from Directory 1 to Directory 3.
   I need the directory and file structure to be mirrored on Directory 3. Another way of
   thinking about the logic is: Dir1 - Dir2 = Dir3. I want Dir3 to be portable between
   users/machines so I don't think an incremental backup with hardlinks will work. Seems like
   it should be easy right?

   I found a scripts that seems like it could do the trick. However, I'm having some trouble
   getting it to work properly. It compares Dir1 to Dir2 and copies all new or modified files
   into Dir3 but it does NOT recreate the directory structure on the target. Instead all files
   end up in a flat folder.
   From Statckoverflow . com
   Code:
#!/bin/bash
#
# setup folders for our different stages
#
Dir1=/Users/username/source1
Dir2=/Users/username/source2
Dir3=/Users/username/target
#
cd $Dir1
for f in *f
do
# Diff the files - ignore the output...
    diff $f $Dir2 > /dev/null 2>&1
# ...but get the status
    status=$?
    if [ $status -eq 0 ] ; then
# Files are identical - don't copy the file
        echo $f unchanged
    elif [ $status -eq 1 ] ; then
# Files differ - copy new file
        echo $f changed
        cp $f $diff
    elif [ $status -eq 2 ] ; then
# Old file doesn't exist - copy new file
        echo old $f does not exist
        cp $f $diff
    fi
done

    I started my reading with rsync. I've used it for back up - locally and over ssh between
   NAS servers. It should be able to do the job, right? I just couldn't find examples to guide
   me and I don't know enough and / or have enough time to do it unaided. Researching it I got
          side tracked by diff which I didn't know much about but it looked promising.
             My preference is to do this with a bash script. Anyone have any ideas?
                                             Thanks!
***
   Rod, here is a crude script that I wrote in bash. It uses cksum to check if the file in
   DIR_1 is modified. I have commented most of the steps. This one is just to give you an idea
   of using a different approach other than diff , I hope it helps.
   Code:
#!/bin/bash

for file_1 in $( find DIR_1/* -type f | sed 's/\.\.\///g' )             # For each file in DIR_1
do
        file_2=$( echo $file_1 | sed 's/DIR_1/DIR_2/g' )                # Getting file path in DIR_2
        dir_2=$( dirname $file_2 )

        if [ ! -d $dir_2 ]                                              # Checking if sub-dir exists
 in DIR_2
        then
                echo -e "Dir: $dir_2 does not exist. Creating...\c"
                mkdir -p $dir_2                                         # Creating if sub-dir missin
g
                echo "Done"
        fi

        if [ -f $file_2 ]                                               # Checking if file exists in
 DIR_2
        then
                cksum_file_1=$( cksum $file_1 | cut -f 1 -d " " )       # Get cksum of file in DIR_1
                cksum_file_2=$( cksum $file_2 | cut -f 1 -d " " )       # Get cksum of file in DIR_2

                if [ $cksum_file_1 -ne $cksum_file_2 ]                  # Check if cksum matches
                then
                        echo -e "File: $file_1 is modified. Copying..\c"
                        cp $file_1 $file_2                              # Copy if cksum mismatch
                        echo "Done"
                fi
        else
                echo -e "File: $file_2 does not exist. Copying...\c"
                cp $file_1 $file_2                                      # Copy if file does not exis
t.
                echo "Done"
        fi
done

           BTW I am using only 2 directory structures in this script: DIR_1 & DIR_2 .
***
   Hi Rod
   You can make a script in order to get all the differences between Dir1 and Dir2 with the
   rsync parameter --dry-run, after that, you only need to do a copy of this files/folders
   from Dir1 to Dir3, something like that in csh:
   Code:
#!/bin/csh
setenv Dir1 "path1"
setenv Dir2 "path2"
setenv Dir3 "path3"
rsync -Havx --dry-run "$Dir1" "$Dir2" > /tmp/differences
foreach "element" ( 'cat /tmp/differences' )
            cp -rpf "$element" "$Dir3"
end
exit

     This script, or something like that, will copy any file or folder from the Dir1 to Dir3
                                    with the same structure.
 