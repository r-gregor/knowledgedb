filename: bash_iterate-over-all-hdds-check-their-smart-status_20190919.txt
https://dwaves.org/2019/09/08/linux-bash-script-iterate-over-all-harddisks-in-the-system-and-check-their-smart-status/

linux bash script - iterate over all harddisks in the system and check their smart status
08.Sep.2019
 
# tested on:
hostnamectl
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 5.X
      Architecture: x86-64

vim /scripts/harddisk_iteration.sh
# fill with:

#!/bin/bash

echo "=== iterate over all harddisks in the system: ==="
for x in {a..z}
do
if test $(ls /dev |grep sd$x |wc -l) != 0; then
        echo "/dev/sd$sd$x";
        /usr/sbin/smartctl -H /dev/sd$sd$x;
fi
done

echo "=== print nice overview over all harddisks and filesystems: ==="
lsblk -o "NAME,MAJ:MIN,RM,SIZE,RO,FSTYPE,MOUNTPOINT,UUID"


example output:

   software raid1 with two SATA disks using ext4:
=== iterate over all harddisks in the system: ===
/dev/sda
smartctl 6.5 2016-05-07 r4318 [x86_64-linux-5.2.1] (local build)
Copyright (C) 2002-16, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF READ SMART DATA SECTION ===
SMART overall-health self-assessment test result: PASSED

/dev/sdb
smartctl 6.5 2016-05-07 r4318 [x86_64-linux-5.2.1] (local build)
Copyright (C) 2002-16, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF READ SMART DATA SECTION ===
SMART overall-health self-assessment test result: PASSED

=== print nice overview over all harddisks and filesystems: ===
NAME    MAJ:MIN RM    SIZE RO FSTYPE            MOUNTPOINT UUID
sdb       8:16   0    2.7T  0
+-sdb4    8:20   0    1.7T  0 linux_raid_member            d2c6c88a-8420-f0a0-5f9b-7d1aa0d19152
| +-md3   9:3    0    1.7T  0 ext4              /home      3efaf082-6484-48ee-ae61-c4a2f50f5688
+-sdb2    8:18   0    512M  0 linux_raid_member            ae11003b-ae85-1ec7-6bba-b8f063bda310
| +-md1   9:1    0  511.4M  0 ext3              /boot      49960289-524f-4f22-b69a-9a448884edf6
+-sdb5    8:21   0      1M  0
+-sdb3    8:19   0      1T  0 linux_raid_member            7243e6cb-b0b4-c802-853a-ef9b5b12027d
| +-md2   9:2    0 1023.9G  0 ext4              /          e1edb56d-5fe0-4328-b987-70aca94b6cdf
+-sdb1    8:17   0      8G  0 linux_raid_member            79ca7eed-4918-b281-6dc9-eca8ac59ab2e
  +-md0   9:0    0      8G  0 swap              [SWAP]     7dbf269b-3274-4d65-8d5f-d0a378929a87
sda       8:0    0    2.7T  0
+-sda4    8:4    0    1.7T  0 linux_raid_member            d2c6c88a-8420-f0a0-5f9b-7d1aa0d19152
| +-md3   9:3    0    1.7T  0 ext4              /home      3efaf082-6484-48ee-ae61-c4a2f50f5688
+-sda2    8:2    0    512M  0 linux_raid_member            ae11003b-ae85-1ec7-6bba-b8f063bda310
| +-md1   9:1    0  511.4M  0 ext3              /boot      49960289-524f-4f22-b69a-9a448884edf6
+-sda5    8:5    0      1M  0
+-sda3    8:3    0      1T  0 linux_raid_member            7243e6cb-b0b4-c802-853a-ef9b5b12027d
| +-md2   9:2    0 1023.9G  0 ext4              /          e1edb56d-5fe0-4328-b987-70aca94b6cdf
+-sda1    8:1    0      8G  0 linux_raid_member            79ca7eed-4918-b281-6dc9-eca8ac59ab2e
  +-md0   9:0    0      8G  0 swap              [SWAP]     7dbf269b-3274-4d65-8d5f-d0a378929a87


---
