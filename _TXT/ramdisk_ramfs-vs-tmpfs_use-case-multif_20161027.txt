filename: /c/Users/gregor.redelonghi/Dropbox/ODPRTO/_TXT/ramdisk_ramfs-vs-tmpfs_use-case-multif_20161027.txt
https://www.jamescoyle.net/knowledge/951-the-difference-between-a-tmpfs-and-ramfs-ram-disk

The difference between tmpfs and ramfs ramdisk

There are two file system types built into most modern Linux distributions which allow you to
create a RAM based storage area which can be mounted and used link a normal folder.

Before using this type of file system you must understand the benefits and problems of memory file system in
general, as well as the two different types. The two types of RAM disk file systems are tmpfs and ramfs and
each type has it?s own strengths and weaknesses.

See my other post for details on how to create a RAM disk in Linux.

What is a memory based file system (RAM disk)?

A memory based file system is something which creates a storage area directly in a computers RAM as if it
were a partition on a disk drive. As RAM is a volatile type of memory which means when the system is
restarted or crashes the file system is lost along with all it?s data.

The major benefit to memory based file systems is that they are very fast ? 10s of times faster than modern
SSDs. Read and write performance is massively increased for all workload types. These types of fast storage
areas are ideally suited for applications which need repetitively small data areas for caching or using as
temporary space. As the data is lost when the machine reboots the data must not be  precious as even
scheduling backups cannot guarantee that all the data will be replicated in the even of a system crash.

tmpfs vs. ramfs
The two main RAM based file system types in Linux are tmpfs and ramfs. ramfs is the older file system type
and is largely replaced in most scenarios by tmpfs.

ramfs
ramfs creates an in memory file system which uses the same mechanism and storage space as Linux file system
cache. Running the command free in Linux will show you the amount of RAM you have on your system, including
the amount of file system cache in use. The below is an example of a 31GB of ram in a production server.
	1 free -g
	2        total used free shared buffers cached
	3 Mem:   31    29   2    0      0       8
	4 -/+ buffers/cache: 20 11
	5 Swap:  13    6    7

Currently 8GB of file system cache is in use on the system. This memory is generally used by Linux to cache
recently accessed files so that the next time they are requested then can be fetched from RAM very quickly.
ramfs uses this same memory and exactly the same mechanism which causes Linux to cache files with the
exception that it is not removed when the memory used exceeds threshold set by the system.

ramfs file systems cannot be limited in size like a disk base file system which is limited by it?s capacity.
ramfs will continue using memory storage until the system runs out of RAM and likely crashes or becomes
unresponsive. This is a problem if the application writing to the file system cannot be limited in total
size. Another issue is you cannot see the size of the file system in df and it can only be estimated by
looking at the cached entry in free.

tmpfs
tmpfs is a more recent RAM file system which overcomes many of the drawbacks with ramfs. You can specify a
size limit in tmpfs which will give a ?disk full? error when the limit is reached. This behaviour is exactly
the same as a partition of a physical disk.

The size and used amount of space on  a tmpfs partition is also displayed in df. The below example shows an
empty 512MB RAM disk.
	1 df -h /mnt/ramdisk
	2 Filesystem Size Used Avail Use% Mounted on
	3 tmpfs      512M 0    512M  0%   /mnt/ramdisk

These two differences between ramfs and tmpfs make tmpfs much more manageable  however this is one major
drawback; tmpfs may use SWAP space. If your system runs out of physical RAM, files in your tmpfs partitions
may be written to disk based SWAP partitions and will have to be read from disk when the file is next
accessed. In some environments this can be seen as a benefit as you are less likely to get out of memory
exceptions as you could with ramfs because more ?memory? is available to use.

**************************************************************************************************************************************

**************************************************************************************************************************************


---
https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux

Create a RAM disk in Linux

Linux penguinThere are many reasons for creating a memory based file system in Linux, not least of which is
to provide a near zero latency and extremely fast area to story files. A prime use of a RAM disk is for
application caching directories or work areas.

There are two main types of RAM disk which can be used in Linux and each have their own benefits and
weaknesses:
  * ramfs
  * tmpfs

See my other post for the differences between ramfs and tmpfs.

Check the amount of free RAM you have left on your machine before creating a RAM disk. Use the Linux command 
free to see the unused RAM. The below is an example of a 31GB of ram in a production server.
	1 free -g
	2        total used free shared buffers cached
	3 Mem:   31    29   2    0      0       8
	4 -/+ buffers/cache: 20 11
	5 Swap:  13    6    7

The free command shows the amount of RAM availale on your system in addition to the amount of memory used,
free and used for caching. SWAP space is also displayed and shows if your system is writing memory to disk.

Create a folder to use as a mount point for your RAM disk.

1 mkdir /mnt/ramdisk

Then use the mount command to create a RAM disk.
	mount -t [TYPE] -o size=[SIZE] [FSTYPE] [MOUNTPOINT]

Substitute the following attirbutes for your own values:
  * [TYPE] is the type of RAM disk to use; either tmpfs or ramfs.
  * [SIZE] is the size to use for the file system. Remember that ramfs does not have a physical limit and is
    specified as a starting size.
  * [FSTYPE] is the type of RAM disk to use; either tmpfs, ramfs, ext4, etc.

Example:
	mount -t tmpfs -o size=512m tmpfs /mnt/ramdisk

You can add the mount entry into /etc/fstab to make the RAM disk persist over reboots. Remember however, that
the data will disappear each time the machine is restarted.
	vi /etc/fstab
	tmpfs       /mnt/ramdisk tmpfs   nodev,nosuid,noexec,nodiratime,size=1024M   0 0
**************************************************************************************************************************************

**************************************************************************************************************************************
---
http://askubuntu.com/questions/173094/how-can-i-use-ram-storage-for-the-tmp-directory-and-how-to-set-a-maximum-amount

How can I use RAM storage for the /tmp directory and how to set a maximum amount of RAM usage for it?

                After seeing the comment by Anonymous on the question How is the /tmp directory cleaned up?,
                I found that it would be a great idea to implement on my system, since I have 16GB of RAM and
                I never used all of it.

                    My temporary files never get written to the disk. They get written to a RAM disk. I did
                    put tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0 in /etc/fstab.

                My question is:
                Can I set a maximum value for RAM Usage for /tmp? And in that case, what would happen if the
                maximum amount got exceeded, would it write into the hard-disk drive?

                I have read this solution which states:
			mkdir -p /tmp/ram
			sudo mount -t tmpfs -o size=512M tmpfs /tmp/ram/

		But in my understanding, this won't be a permanent solution. If I need it to be permanent, it
                has to be added to the /etc/fstab configuration file.

                If this is the correct solution, how can I transform that mount command into a line in /etc/
                fstab?


                this is also a good idea if you have and SSD as you will not 'consume' it with not
                useful writings ... ? Postadelmaga Apr 2 '14 at 10:47

                add a comment |   

***
            You are absolutely right. The according fstab entry would look like this:
		tmpfs /tmp tmpfs defaults,noatime,nosuid,nodev,noexec,mode=1777,size=512M 0 0

            Please note:
            As tmpfs gets filled up, it will behave as any physical harddrive by giving an "not enough space"
            error. While rebooting (and thus emptying the cache) will fix this, you may run into trouble when
            a single operation consumes more space to begin with than there's space on tmpfs. In this case
            your computer will start to swap from ram to disk, which will make your system crawl to a halt,
            given you've got a swap partition to begin with, of course.

            Considering this, a size of 512MB might be far too less nowadays, since much more ram is in
            existence in modern machines and it has become much cheaper. Since you've already got 16GB of
            ram, using the default value of half your ram for tmpfs should more than suffice for almost all
            scenarios. To use the default value, simply leave out the size=512M entry in your /etc/fstab
            file.

            Another note:
	    You can quite as easily mount other system folders into ramdisk as well, such as
		    /var/cache
		    /var/games
		    /var/log/apt (use only defaults,noatime without mode= or nosuid)

            But beware: the same rules apply as above, running out of space might cause major trouble. E.g.
            imagine running out of space for /var/log/apt will render you unable to install any programs!
            Furthermore, loading /var/log folders into ramdisk will delete all your log files upon reboot, so
            you won't be able to debug your system if anything unexpected happens. So use these settings at
            your own risk!

            Editorial note: I removed the /run in tmpfs mount option since this folder and its subfolders are
            already mounted in tmpfs by default.

***
            4   If i'm not wrong, /var/tmp/ is for keeping files after reboot. Thats the main difference
                between this and /tmp/ , so YOU should not move /var/tmp to ram. ? user285767 May 27 '14 at
                13:20
            3   If Ubuntu runs out of 4GB tmpfs, will it use my 20GB SWAP partition? ? loostro Jun 24 '14 at
                16:30
            2   Yes, I'll need to add this, too. As soon as tmpfs exeeeds its limits, it'll extend to swap
                partition (give there is one). ? FuzzyQ Jun 24 '14 at 19:10
            2   Does allocating half your RAM to this mean that half your RAM is reserved for the RAMDISK, or
                is it only a cap to what the RAMDISK may consume, and whatever is not in use is free RAM that
                gets assigned to whatever program needs RAM?? ? matt Jan 19 '15 at 15:01
            2   @matt It's only a cap. ? FuzzyQ Jan 19 '15 at 16:04

***
             On systems using systemd, you have the option of using a systemd unit file instead of fstab to
             accomplish the goal of using tmpfs to mount tmp. On my Ubuntu 16.04 system, I ran:
		     sudo cp /usr/share/systemd/tmp.mount /etc/systemd/system/tmp.mount
		     sudo systemctl start tmp.mount
	
             The file /usr/share/systemd/tmp.mount looks like:
		     #  This file is part of systemd.
		     #
		     #  systemd is free software; you can redistribute it and/or modify it
		     #  under the terms of the GNU Lesser General Public License as published by
		     #  the Free Software Foundation; either version 2.1 of the License, or
		     #  (at your option) any later version.
		     [Unit]
		     Description=Temporary Directory
		     Documentation=man:hier(7)
		     Documentation=http://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
		     ConditionPathIsSymbolicLink=!/tmp
		     DefaultDependencies=no
		     Conflicts=umount.target
		     Before=local-fs.target umount.target
		     After=swap.target

		     [Mount]
		     What=tmpfs
		     Where=/tmp
		     Type=tmpfs
		     Options=mode=1777,strictatime

		     [Install]
		     WantedBy=local-fs.target

             Using FuzzyQ's fstab approach, systemd translates your fstab entries into mount units
             dynamically. I don't think either approach is better.

***	     
	     This looks interesting! I will try this when I'm next to my laptop ? Dan Aug 13 at 19:15
             You will need systemctl enable tmp.mount after cp else systemctl will fail with message
             "Failed to start tmp.mount: Unit tmp.mount not found." ? vimdude Oct 8 at 18:17


---
http://askubuntu.com/questions/152868/how-do-i-make-a-ram-disk

How do I make a RAM disk?

           I want to make a partition that is made of ram ...
           Example
           In windows 7 you can make a partition that is made of ram

	   Is there any good Alternative in Ubuntu ?

***	   
                Ubuntu comes with tmpfs. You need not create a RAMDISK. ? mixdev Mar 30 '14 at 4:03

                Depending on your intended use case you may not need a ramdisk for Ubuntu (or most Linux
                distros). The operating system caches reads and write activity to RAM while it is working
                with regular disks. If you read a small file several times, it will only be fetched from disk
                once, then retrieved from the RAM cache on the following times. If you have plenty of RAM,
                everything you do will get cached in this way so you get very little repeat disk activity. If
                you want non-persistent fast memory use instead of files, you need a RAMDISK still. See
                linuxatemyram.com for more details. ? TafT Oct 6 at 14:11

***		
                    This will show you how to make a RAMDISK super fast and easily. With a RAMDISK you can
                    use your memory for temporary space and it?s also a lot quicker than your hard drive.

                    Now lets start by using the next 2 commands to make your RAMDISK.

                    Put whatever you want your RAMDISK to be called where I wrote ?nameme?.
			    mkdir -p /media/nameme
			    mount -t tmpfs -o size=2048M tmpfs /media/nameme/

		    The above commands would use 2GB of my RAM for the RAMDISK. If you don?t have as much ram
                    as I do I would use 512MB or 1GB. So next were going to create a command for Terminal
                    that will automatically create the RAMDISK for you.

***		    
            The tmpfs filesystem is a RAMDISK. The following will create a 2G RAMDISK that will always be
            available.
		    sudo mkdir -p /media/ramdisk
		    sudo mount -t tmpfs -o size=2048M tmpfs /media/ramdisk

            The ramdisk folder is owned by root as it is to be available on reboot. The ramdisk permissions
            should be writeable by everyone. The tmpfs default permissions (chmod 1777) are correct.
		drwxrwxrwt 2 root root 180 Apr 23 07:34 /media/ramdisk

            To make the ramdisk permanently available, add it to /etc/fstab.
		grep /media/ramdisk /etc/mtab | sudo tee -a /etc/fstab

            You will see the line moved from mtab to fstab. It will look something like this.
		tmpfs /media/ramdisk tmpfs rw,size=2048M 0 0

            The RAMDISK won't consume memory until you use it. Double check your memory requirements during
	    maximum system load. If the RAMDISK is too large, your system will consume swap storage to make
	    up the difference.

            To adjust the size of the RAMDISK, edit /etc/fstab and verify by remounting the ramdisk (you will
            lose your current RAMDISK content as you will on reboot). The following will change the size of
            the ramdisk to 512M
		    # Check the existing ramdisk size.
		    df /media/ramdisk
		    # change size=512M for a 512 megabyte ram drive.
		    sudo vi /etc/fstab
		    # Remount the ramdisk, you will lose any existing content.
		    sudo mount -a /media/ramdisk
		    # Verify the new ramdisk size.
		    df /media/ramdisk


---
http://www.vanemery.com/Linux/Ramdisk/ramdisk.html

Linux Ramdisk mini-HOWTO

Introduction
What is a RAM disk? A RAM disk is a portion of RAM which is being used as if it were a disk drive. RAM disks
have fixed sizes, and act like regular disk partitions. Access time is much faster for a RAM disk than for a
real, physical disk. However, any data stored on a RAM disk is lost when the system is shut down or powered
off. RAM disks can be a great place to store temporary data.

The Linux kernel version 2.4 has built-in support for ramdisks. Ramdisks are useful for a number of things,
including:
  * Working with the unencrypted data from encrypted documents
  * Serving certain types of web content
  * Mounting Loopback file systems (such as run-from-floppy/CD distributions)

Why did I write this document? Because I needed to setup a 16 MB ramdisk for viewing and creating encrypted
documents. I did not want the unencrypted documents to be written to any physical media on my workstation. I
also found it amazing that I could easily create a "virtual disk" in RAM that is larger than my first hard
drive, a 20 MB Winchester disk. At the time, that disk was so large that I never even considered filling it
up, and I never did!

This document should take you step-by-step through the process of creating and using RAM disks.

Assumptions/Setup
I was using Red Hat 9 for this test, but it should work with other GNU/Linux distributions running 2.4.x
kernels. I am also assuming that the distribution you are using already has ramdisk support compiled into the
kernel. My test machine was a Pentium 4 and had 256 MB of RAM. The exact version of the kernel that I used
was: 2.4.20-20.9

-------------------------------------------------------------------------------------------------------------

Step 1: Take a look at what has already been created by your system
Red Hat creates 16 ramdisks by default, although they are not "active" or using any RAM. It lists devices
ram0 - ram 19, but only ram0 - ram15 are usable by default. To check these block devices out, use the
following command:
	[root]# ls -l /dev/ram*
	lrwxrwxrwx    1 root     root            4 Jun 12 00:31 /dev/ram -> ram1
	brw-rw----    1 root     disk       1,   0 Jan 30  2003 /dev/ram0
	brw-rw----    1 root     disk       1,   1 Jan 30  2003 /dev/ram1
	brw-rw----    1 root     disk       1,  10 Jan 30  2003 /dev/ram10
	brw-rw----    1 root     disk       1,  11 Jan 30  2003 /dev/ram11
	brw-rw----    1 root     disk       1,  12 Jan 30  2003 /dev/ram12
	brw-rw----    1 root     disk       1,  13 Jan 30  2003 /dev/ram13
	brw-rw----    1 root     disk       1,  14 Jan 30  2003 /dev/ram14
	brw-rw----    1 root     disk       1,  15 Jan 30  2003 /dev/ram15
	brw-rw----    1 root     disk       1,  16 Jan 30  2003 /dev/ram16
	brw-rw----    1 root     disk       1,  17 Jan 30  2003 /dev/ram17
	brw-rw----    1 root     disk       1,  18 Jan 30  2003 /dev/ram18
	brw-rw----    1 root     disk       1,  19 Jan 30  2003 /dev/ram19
	brw-rw----    1 root     disk       1,   2 Jan 30  2003 /dev/ram2
	brw-rw----    1 root     disk       1,   3 Jan 30  2003 /dev/ram3
	brw-rw----    1 root     disk       1,   4 Jan 30  2003 /dev/ram4
	brw-rw----    1 root     disk       1,   5 Jan 30  2003 /dev/ram5
	brw-rw----    1 root     disk       1,   6 Jan 30  2003 /dev/ram6
	brw-rw----    1 root     disk       1,   7 Jan 30  2003 /dev/ram7
	brw-rw----    1 root     disk       1,   8 Jan 30  2003 /dev/ram8
	brw-rw----    1 root     disk       1,   9 Jan 30  2003 /dev/ram9
	lrwxrwxrwx    1 root     root            4 Jun 12 00:31 /dev/ramdisk -> ram0

Now, grep through dmesg output to find out what size the ramdisks are:
	[root]# dmesg | grep RAMDISK
	RAMDISK driver initialized: 16 RAM disks of 4096K size 1024 blocksize
	RAMDISK: Compressed image found at block 0

As you can see, the default ramdisk size is 4 MB. I want a 16 MB ramdisk, so the next step will be to
configure Linux to use a larger ramdisk size during boot.

Step 2: Increase ramdisk size
Ramdisk size is controlled by a command-line option that is passed to the kernel during boot. Since GRUB is
the default bootloader for Red Hat 9, I will modify /etc/grub.conf with the new kernel option. The kernel
option for ramdisk size is:  ramdisk_size=xxxxx, where xxxxx is the size expressed in 1024-byte blocks. Here
is what I will add to /etc/grub.conf to configure 16 MB ramdisks:
	# grub.conf generated by anaconda
	#
	# Note that you do not have to rerun grub after making changes to this file
	# NOTICE:  You have a /boot partition.  This means that
	#          all kernel and initrd paths are relative to /boot/, eg.
	#          root (hd0,0)
	#          kernel /vmlinuz-version ro root=/dev/hda5
	#          initrd /initrd-version.img
	#boot=/dev/hda
	default=0
	timeout=10
	splashimage=(hd0,0)/grub/splash.xpm.gz
	title Red Hat Linux (2.4.20-20.9)
		root (hd0,0)
		kernel /vmlinuz-2.4.20-20.9 ro root=LABEL=/ hdc=ide-scsi ramdisk_size=16000
		initrd /initrd-2.4.20-20.9.img

Once you save the file, you will need to reboot your system. After the reboot, a look at the dmesg output
should confirm the change has taken effect:
	[root]# dmesg | grep RAMDISK
	RAMDISK driver initialized: 16 RAM disks of 16000K size 1024 blocksize
	RAMDISK: Compressed image found at block 0

Step 3: Format the ramdisk
There is no need to format the ramdisk as a journaling file system, so we will simply use the ubiquitous ext2
file system. I only want to use one ramdisk, so I will only format /dev/ram0:
	[root]# mke2fs -m 0 /dev/ram0
	mke2fs 1.32 (09-Nov-2002)
	Filesystem label=
	OS type: Linux
	Block size=1024 (log=0)
	Fragment size=1024 (log=0)
	4000 inodes, 16000 blocks
	0 blocks (0.00%) reserved for the super user
	First data block=1
	2 block groups
	8192 blocks per group, 8192 fragments per group
	2000 inodes per group
	Superblock backups stored on blocks:
		8193

	Writing inode tables: done
	Writing superblocks and filesystem accounting information: done

	This filesystem will be automatically checked every 22 mounts or
	180 days, whichever comes first.  Use tune2fs -c or -i to override.

The -m 0 option keeps mke2fs from reserving any space on the file system for the root user, which is the
default behavior. I want all of the ramdisk space available to a regular user for working with encrypted
files.

Step 4: Create a mount point and mount the ramdisk
Now that you have formatted the ramdisk, you must create a mount point for it. Then you can mount your
ramdisk and use it. We will use the directory /mnt/rd for this operation.
	[root]# mkdir /mnt/rd
	[root]# mount /dev/ram0 /mnt/rd

Now verify the new ramdisk mount:
	[root]# mount | grep ram0
	/dev/ram0 on /mnt/rd type ext2 (rw)
	[root]# df -h | grep ram0
	/dev/ram0              16M   13K   16M   1% /mnt/rd

You can even take a detailed look at the new ramdisk with the tune2fs command:
	[root]# tune2fs -l /dev/ram0
	tune2fs 1.32 (09-Nov-2002)
	Filesystem volume name:   none
	Last mounted on:          not available
	Filesystem UUID:          fbb80e9a-8e7c-4bd4-b3d9-37c29813a5f5
	Filesystem magic number:  0xEF53
	Filesystem revision #:    1 (dynamic)
	Filesystem features:      filetype sparse_super
	Default mount options:    (none)
	Filesystem state:         not clean
	Errors behavior:          Continue
	Filesystem OS type:       Linux
	Inode count:              4000
	Block count:              16000
	Reserved block count:     0
	Free blocks:              15478
	Free inodes:              3989
	First block:              1
	Block size:               1024
	Fragment size:            1024
	Blocks per group:         8192
	Fragments per group:      8192
	Inodes per group:         2000
	Inode blocks per group:   250
	Filesystem created:       Mon Dec  8 14:33:57 2003
	Last mount time:          Mon Dec  8 14:35:39 2003
	Last write time:          Mon Dec  8 14:35:39 2003
	Mount count:              1
	Maximum mount count:      22
	Last checked:             Mon Dec  8 14:33:57 2003
	Check interval:           15552000 (6 months)
	Next check after:         Sat Jun  5 14:33:57 2004
	Reserved blocks uid:      0 (user root)
	Reserved blocks gid:      0 (group root)
	First inode:              11
	Inode size:               128

In my case, I need the user "van" to be able to read and write to the ramdisk, so I must change the ownership
and permissions of the /mnt/rd directory:
	[root]# chown van:root /mnt/rd
	[root]# chmod 0770 /mnt/rd
	[root]# ls -ald /mnt/rd
	drwxrwx---    2 van     root         4096 Dec  8 11:09 /mnt/rd

The ownership and permissions on the ramdisk filesystem/directory should be tailored to your particular
needs.

Step 5: Use the ramdisk
Now that it has been created, you can copy, move, delete, edit, and list files on the ramdisk exactly as if
they were on a physical disk partiton. This is a great place to view decrypted GPG or OpenSSL files, as well
as a good place to create files that will be encrypted. After your host is powered down, all traces of files
created on the ramdisk are gone.

To unmount the ramdisk, simply enter the following:
	[root]# umount -v /mnt/rd
	/dev/ram0 umounted

Note:  If you remount the ramdisk, your data will still be there. Once memory has been allocated to the
ramdisk, it is flagged so that the kernel will not try to reuse the memory later. Therefore, you cannot
"reclaim" the RAM after you are done with using the ramdisk. For this reason, you will want to be careful not
to allocate more memory to the ramdisk than is absolutely necessary. In my case, I am allocating < 10% of the
physical RAM. You will have to tailor the ramdisk size to your needs. Of course, you can always free up the
space with a reboot!

-------------------------------------------------------------------------------------------------------------

Automating Ramdisk Creation
If you need to create and mount a ramdisk every time your system boots, you can automate the process by
adding some commands to your /etc/rc.local init script. Here are the lines that I added:
	# Formats, mounts, and sets permissions on my 16MB ramdisk
	/sbin/mke2fs -q -m 0 /dev/ram0
	/bin/mount /dev/ram0 /mnt/rd
	/bin/chown van:root /mnt/rd
	/bin/chmod 0750 /mnt/rd

-------------------------------------------------------------------------------------------------------------

Conclusion
You have now seen how to setup and use a ramdisk on your GNU/Linux system. Hopefully, you will find this
information to be interesting and useful!

-------------------------------------------------------------------------------------------------------------

Resources

  * /usr/src/linux-2.4/Documentation/ramdisk.txt
  * /usr/src/linux-2.4/drivers/block/rd.c
  * man mke2fs
  * Ramdisk article by Mark Nielsen for Red Hat 6.0

  

---
http://www.thegeekstuff.com/2008/11/overview-of-ramfs-and-tmpfs-on-linux/

Overview of RAMFS and TMPFS on Linux

[Linux Ramfs and Tmpfs]Using ramfs or tmpfs you can allocate part of the physical memory to be used as a
partition. You can mount this partition and start writing and reading files like a hard disk partition. Since
you?ll be reading and writing to the RAM, it will be faster.

When a vital process becomes drastically slow because of disk writes, you can choose either ramfs or tmpfs
file systems for writing files to the RAM.

Both tmpfs and ramfs mount will give you the power of fast reading and writing files from and to the primary
memory. When you test this on a small file, you may not see a huge difference. You?ll notice the difference
only when you write large amount of data to a file with some other processing overhead such as network.

1. How to mount Tmpfs
	# mkdir -p /mnt/tmp
	# mount -t tmpfs -o size=20m tmpfs /mnt/tmp

The last line in the following df -k shows the above mounted /mnt/tmp tmpfs file system.
	# df -k
	Filesystem      1K-blocks  Used     Available Use%  Mounted on
	/dev/sda2       32705400   5002488  26041576  17%   /
	/dev/sda1       194442     18567    165836    11%   /boot
	tmpfs           517320     0        517320    0%    /dev/shm
	tmpfs           20480      0        20480     0%    /mnt/tmp

2. How to mount Ramfs
	# mkdir -p /mnt/ram
	# mount -t ramfs -o size=20m ramfs /mnt/ram
	
The last line in the following mount command shows the above mounted /mnt/ram ramfs file system.
	# mount
	/dev/sda2 on / type ext3 (rw)
	proc on /proc type proc (rw)
	sysfs on /sys type sysfs (rw)
	devpts on /dev/pts type devpts (rw,gid=5,mode=620)
	/dev/sda1 on /boot type ext3 (rw)
	tmpfs on /dev/shm type tmpfs (rw)
	none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
	sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)
	fusectl on /sys/fs/fuse/connections type fusectl (rw)
	tmpfs on /mnt/tmp type tmpfs (rw,size=20m)
	ramfs on /mnt/ram type ramfs (rw,size=20m)

You can mount ramfs and tmpfs during boot time by adding an entry to the /etc/fstab.

3. Ramfs vs Tmpfs
Primarily both ramfs and tmpfs does the same thing with few minor differences.

  * Ramfs will grow dynamically.   So, you need control the process that writes the data to make sure ramfs
    doesn?t go above the available RAM size in the system. Let us say you have 2GB of RAM on your system and
    created a 1 GB ramfs and mounted as /tmp/ram. When the total size of the /tmp/ram crosses 1GB, you can
    still write data to it.   System will not stop you from writing data more than 1GB. However, when it goes
    above total RAM size of 2GB, the system may hang, as there is no place in the RAM to keep the data.
  * Tmpfs will not grow dynamically. It would not allow you to write more than the size you?ve specified
    while mounting the tmpfs. So, you don?t need to worry about controlling the process that writes the data
    to make sure tmpfs doesn?t go above the specified limit. It may give errors similar to ?No space left on
    device?.
  * Tmpfs uses swap.
  * Ramfs does not use swap.

4. Disadvantages of Ramfs and Tmpfs
Since both ramfs and tmpfs is writing to the system RAM, it would get deleted once the system gets rebooted,
or crashed. So, you should write a process to pick up the data from ramfs/tmpfs to disk in periodic
intervals. You can also write a process to write down the data from ramfs/tmpfs to disk while the system is
shutting down. But, this will not help you in the time of system crash.

                       Table: Comparison of ramfs and tmpfs
+--------------------------------------------------------------------------------+
|            Experimentation            |      Tmpfs       |        Ramfs        |
|---------------------------------------+------------------+---------------------|
|Fill maximum space and continue writing|Will display error|Will continue writing|
|---------------------------------------+------------------+---------------------|
|Fixed Size                             |Yes               |No                   |
|---------------------------------------+------------------+---------------------|
|Uses Swap                              |Yes               |No                   |
|---------------------------------------+------------------+---------------------|
|Volatile Storage                       |Yes               |Yes                  |
+--------------------------------------------------------------------------------+

If you want your process to write faster, opting for tmpfs is a better choice with precautions about the
system crash.

This article was written by SathiyaMoorthy. He is working at bksystems, interested in writing articles and  
contribute to open source in his leisure time. The Geek Stuff welcomes your tips and guest articles.



---
http://unix.stackexchange.com/questions/66329/creating-a-ram-disk-on-linux

Creating a ram disk on Linux

               I have a machine with 62GB of RAM, and a trunk that's only 7GB, so I thought I would create a
               RAM disk and compile there. I am not a Linux expert. I found instructions on the internet to
               create the RAM disk:
		mkfs -q /dev/ram1 8192

               but I changed the 8192 to 16777216 in an attempt to allocate 16GB of ram disk.

               I got the following error:
		       mkfs.ext2: Filesystem larger than apparent device size.
		       Proceed anyway? (y,n)

               At which point I got spooked and bailed.
			sudo dmidecode --type 17 | grep Size

	       shows
			8x8192MB + 2048MB = 67584 MB

               but du on /dev gives 804K.
               Is that the problem? Can I overcome that /dev size?

***
               12    Did you try tmpfs? It is a filesystem in RAM, no need for ext2. mount -o size=16G -t
                     tmpfs none /mnt/tmpfs ? t-8ch Feb 27 '13 at 18:17
                     That worked! Thanks! But so far, not much speed-up: I think the tools I'm using to build
                     are still using the regular disk. I'll put more stuff on the ram disk. ? Frank Feb 27 '13
                     at 18:24
               2     Putting the tools themselves on the ramdisk shouldn't make much difference as the kernel
                     will cache them anyways in ram. ? t-8ch Feb 27 '13 at 18:28
               1     @goldilocks It's anecdotal evidence, but when compiling our Java projects with Maven,
                     there is a significant speedup when using a ramdisk. I would guess though that this is
                     more because of seek time than read time. ? SpellingD Feb 27 '13 at 18:54
               1     /dev/shm, actually /run/shm, can be used; it's almost always there. ? Camille Goudeseune 
                     Feb 17 '14 at 22:06

***		     
          The best way to create a ram disk on linux is tmpfs. It's a filesystem living in ram, so there is
          no need for ext2. You can create a tmpfs of 16Gb size with:
		mount -o size=16G -t tmpfs none /mnt/tmpfs

***		
              on my system, with nothing at all in /mnt, it says: ls: cannot access /mnt/tmpfs: No such file
          2   or directory mount: mount point /mnt/tmpfs does not exist. Is that something to worry about? If
              I simply mkdir /mnt/tmpfs, does that defeat the purpose (by creating tmpfs on the regular disk
              - please no flames, I'm a beginner here). ? Frank Feb 27 '13 at 19:23
              You need a mountpoint (directory) as target, so after you created this directory (you can use
          9   any directory, existing contents are shadowed) you can mount it with the command from the
              answer. ? t-8ch Feb 27 '13 at 19:26

***	      
        Linux is very efficient in using RAM. There is little surprise that you see little if any speedup
        with tmpfs. The largest pieces to read into memory (and thus able to slow the process down) are the
        tools (compiler, assembler, linker), and in a longish make they will be loaded into memory at startup
        and never leave it. What is left is reading in source (the writing out of the results won't slow you
        down, unless severely memory constrained). Again, comon header files will stay around, only the
        user's source will require reading. And that is unlikely to be more than a few megabytes. Creating a
	large RAMdisk (or even much use of tmpfs) can very well slow things down (by making the build memory
	constrained, the files on RAMdisk or on tmpfs can not be used directly from there).

***
              What! How can they not be used directly from there? ? Kazark Feb 28 '13 at 16:08

              They are in RAM, but not in a format that is directly usable. ? vonbrand Feb 28 '13 at 16:09

        1     Really! How so? (Pardon my slowness.) ? Kazark Feb 28 '13 at 16:34

              @Kazark, to handle executables in memory special data structures are used. As RAMdisks and tmpfs
        6     aren't in common use to store executables (RAMdisks are a remnant from the good old days of
              excruciatingly slow floppy disks and such, tmpfs is for stricty temporary data), nobody has
              considered it important enough to add the required ugly hacks. ? vonbrand Feb 28 '13 at 16:39
              I have tried running my rails code from a tmpfs (RAM) filesystem, and I did not see any
        5     difference at all. I was really hoping for a noticeable difference but I was disappointed by how
              awesome linux is. ? Khaja Minhajuddin Mar 4 '13 at 19:25

***	      
        The problem is that the maximum size of a ramdisk, more specifically of size of memory that can be
        accessed via the ramdisk driver is configured at compiletime, can be overwritten at boottime, but
        remains fixed once the kernel is loaded into memory. The default value is probably measured in
        Megabytes. If I recall correctly the memory for a ramdisk is reserved right when the driver is
        loaded, all ramdisks are the same size and there is are some 16 ramdisks by default. So not even you
        want a ramdisk size of 16G :-)

	As stated in the other answer, tmpfs is what you want to use. Further, you won't win a lot by having
	your entire OS in a ramdisk/tmpfs. Just copy your builddir to a tmpfs and do your compiling then. You
	may have to ensure that all temporary results are written to a location thats in the tmpfs as well.

***	
              They don't actually use any memory until you write things to them. The boot time limit is just
              the limit. Even after filling one you can free the memory back up with blockdev --flushbufs. ? 
              psusi Feb 28 '13 at 13:57
              @psusi: can you give us more information on that? I can only find statements mentioning that
              once claimed by the ramdisk memory is never reclaimed, e.g. in Documentation/blockdev/
              ramdisk.txt in the kernel sources. And on my answer: that file also says the ramdisk grows as
              memory is consumed so it is not all allocated at once. ? Bananguin Mar 1 '13 at 14:46
              What sort of information? You run the command and it frees the ram, assuming you don't still
              have it mounted anyhow. ? psusi Mar 1 '13 at 15:13
              How do you know that the command does what you say it does? Its man page doesn't confirm that
              and the documentation in the kernel source tree can be understood to contradict your
              information. ? Bananguin Mar 1 '13 at 20:40
        4     I read the source code, and verified it by trying it. ? psusi Mar 1 '13 at 20:50

***	
             To make a large ram disk after boot, with no messing around with kernel parameters, this seems
             to work. Use tmpfs, make a file, mount it via loop, and mount that via a filesystem:
		     mount -t tmpfs -o size=200M tmpfs temp/
		     cd temp/
		     dd if=/dev/zero of=disk.img bs=1M count=199
		     losetup /dev/loop0 disk.img
		     mkfs.ext4 /dev/loop0
		     mount /dev/loop0 temp2/

             Probably a bit of performance penalty going through multiple different layers... but at least it
             works.

***
                 OP the amount of RAM is expressed in MB. So all you need to enter there is 16384. And then
                 voila you'd be in business.


---
http://superuser.com/questions/45342/when-should-i-use-dev-shm-and-when-should-i-use-tmp

When should I use /dev/shm/ and when should I use /tmp?

                        When should I use /dev/shm/ and when should I use /tmp? Can I always rely on them
                        both being there on Unices?

***			
           /dev/shm is a temporary file storage filesystem, i.e., tmpfs, that uses RAM for the backing
           store.  It can function as a shared memory implementation that facilitates IPC.

           From Wikipedia:
               Recent 2.6 Linux kernel builds have started to offer /dev/shm as shared memory in the form of
               a ramdisk, more specifically as a world-writable directory that is stored in memory with a
               defined limit in /etc/default/tmpfs.  /dev/shm support is completely optional within the
               kernel config file.  It is included by default in both Fedora and Ubuntu distributions, where
               it is most extensively used by the Pulseaudio application. ????????????^(Emphasis added.)

           /tmp is the location for temporary files as defined in the Filesystem Hierarchy Standard, which is
           followed by almost all Unix and Linux distributions.

	   Since RAM is significantly faster than disk storage, you can use /dev/shm instead of /tmp for the
	   performance boost, if your process is I/O intensive and extensively uses temporary files.

           To answer your questions: No, you cannot always rely on /dev/shm being present, certainly not on
           machines strapped for memory. You should use /tmp unless you have a very good reason for using /
           dev/shm.

           Remember that /tmp can be part of the / filesystem instead of a separate mount, and hence can grow
           as required. The size of /dev/shm is limited by excess RAM on the system, and hence you're more
           likely to run out of space on this filesystem.

***	   
                 I will be using it to redirect output from a commands' standard error output to a file. Then
                 I will read this file and process it. I will be doing this several thousand times (it's part
                 of the condition of a loop construct). I thought memory would be nice in this case. But I
                 also want it to be portable. I guess I'll check if /dev/shm exists, use it if it does, or
                 fallback to /tmp. Does that sound good? ? Deleted Sep 23 '09 at 16:04
           1     I'd also add a check for the minimum size and current usage level of /dev/shm to guard
                 against inadvertently filling it up. ? nagul Sep 23 '09 at 21:01
                 Under Linux 2.6 and later the /dev/shm is required to be mounted for the POSIX shared memory
           3     system calls like shm_open() to work. In other words some programs will break if its not
                 mounted - so it should be. It is not just a RAM disk. So you should make sure some of /dev/
                 shm is free. ? EdH Nov 30 '12 at 21:07
                 There is no performance boost by using /dev/shm. /dev/shm is memory (tmpfs) backed by the
           2     disk (swap). /var/tmp is memory (disk cache) backed by the disk (on-disk filesystem). In
                 practice, performance is about the same (tmpfs has a slight edge but not enough to matter). /
                 tmp may be tmpfs or not depending on how the administrator configured it. There is no good
                 reason to use /dev/shm in your scripts. ? Gilles Jun 18 '13 at 7:13
                 @GaretClaborn There's plenty of good reasons to use memory backed by swap, but that's called
                 normal process memory. If you're using a file, it's called a filesystem, and all filesystems
                 are memory (cache), which is backed by swap if the filesystem is something like tmpfs.
           2     Allocating disk space between swap and other storage areas is typically in the real of the
                 administrator. If an application wants files that tend to remain in RAM, /tmp is the normal
                 location (with $TMPDIR to override). The choice to make /tmp backed by swap, other disk space
                 or nothing is the administrator's. ? Gilles Jun 5 '14 at 14:09

***		 
        Okay, here's the reality.

        Both tmpfs and a normal filesystem are a memory cache over disk.

        The tmpfs uses memory and swapspace as it's backing store a filesystem uses a specific area of disk,
        neither is limited in the size the filesystem can be, it is quite possible to have a 200GB tmpfs on a
        machine with less than a GB of ram if you have enough swapspace.

        The difference is in when data is written to the disk. For a tmpfs the data is written ONLY when
        memory gets too full or the data unlikely to be used soon. OTOH most normal Linux filesystems are
        designed to always have a more or less consistent set of data on the disk so if the user pulls the
        plug they don't lose everything.

        Personally, I'm used to having operating systems that don't crash and UPS systems (eg: laptop
        batteries) so I think the ext2/3 filesystems are too paranoid with their 5-10 second checkpoint
        interval. The ext4 filesystem is better with a 10 minute checkpoint, except it treats user data as
	second class and doesn't protect it. (ext3 is the same but you don't notice it because of the 5
	second checkpoint)

        This frequent checkpointing means that unnecessary data is being continually written to disk, even
        for /tmp.

        So the result is you need to create swap space as big as you need your /tmp to be (even if you have
        to create a swapfile) and use that space to mount a tmpfs of the required size onto /tmp.

        NEVER use /dev/shm.

        Unless, you're using it for very small (probably mmap'd) IPC files and you are sure that it exists
        (it's not a standard) and the machine has more than enough memory + swap available.

***	
            Agreed, except for the conclusion, "NEVER use /dev/shm". You want to use /dev/shm in cases where
            you don't want a file to be written to the disk at all, and you want to minimize disk i/o. For
            example, I need to download very large zip files from an FTP server, unzip them, and then import
        9   them into a database. I unzip to /dev/shm so that for both the unzip and the import operations
            the HDD only needs to perform half the operation, rather than moving back and forth between
            source and destination. It speeds up the process immensely. That's one example of many, but I
            agree that it's a niche tool. ? Nathan Stretch Dec 11 '14 at 23:13

***	    
       In descending order of tmpfs likelyhood:

       +++++++++++++++++++++++++++++++++++++++++++++
       + /dev/shm  + always tmpfs + Linux specific +
       +++++++++++++++++++++++++++++++++++++++++++++
       + /tmp      + can be tmpfs + FHS 1.0        +
       +++++++++++++++++++++++++++++++++++++++++++++
       + /var/tmp  + never tmpfs  + FHS 1.0        +
       +++++++++++++++++++++++++++++++++++++++++++++

       Since you are asking about a Linux specific tmpfs mountpoint versus a portably defined directory that
       may be tmpfs (depending on your sysadmin and what's default for your distro), your question has two
       aspects, which other answers have emphasized differently:
		1. When to use these directories, based on good practice
		2. When it is appropriate to use tmpfs

       ------------------------------------------------------------------------------------------------------
       
       Good practices
       Conservative edition (mixture of conventions from FHS and common use):
		 * When in doubt, use /tmp.
		 * Use /var/tmp for large data that may not easily fit in ram.
		 * Use /var/tmp for data that is beneficial to keep across reboots (like a cache).
		 * Use /dev/shm as a side-effect of calling shm_open(). The intended audience is data buffers of
		   bounded size that are overwritten frequently and endlessly.
		 * If still in doubt, provide a way for the user to override. For example, the mktemp program 
		   honors the TMPDIR environment variable.

       Pragmatic edition:
       Use /dev/shm when it is important to use tmpfs, /var/tmp when it is important not to, else /tmp.

       Where tmpfs excels
       fsync is a no-op on tmpfs. This syscall is the number one enemy of (IO) performance (and flash
       longevity, if you care about that), though if you find yourself using tmpfs (or eatmydata) just to
       defeat fsync, then you (or some other developer in the chain) are doing something wrong. It means that
       the transactions toward the storage device are unnecessarily fine grained for your purpose ? you are
       clearly willing to skip some savepoints for performance, as you have now gone to the extreme of
       sabotaging them all ? seldom the best compromise. Also, it is here in transaction performance land
       where some of the greatest benefits of having an SSD are ? any decent SSD is going to perform
       out-of-this-world compared to what a spinning disk can possibly take (7200 rpm = 120 Hz, if notihing
       else is accessing it), not to mention flash memory cards, which vary widely on this metric (not least
       because it is a tradeoff with sequential performance, which is what they are rated by, e.g. SD card
       class rating). So beware, developers with blazing fast SSDs, not to force your users into this use
       case!

       Wanna hear a ridiculous story? My first fsync lesson: I had a job that involved routinely "upgrading"
       a bunch of Sqlite databases (kept as testcases) to an ever-changing current format. The "upgrade"
       framework would run a bunch of scripts, making at least one transaction each, to upgrade one database.
       Of course, I upgraded my databases in parallel (8 in parallel, since I was blessed with a mighty 8
       core CPU). But as I found out, there was no parallelization speedup whatsoever (rather a slight hit)
       because the process was entirely IO bound. Hilariously, wrapping the upgrade framework in a script
       that copied each database to /dev/shm, upgraded it there, and copied it back to disk was like 100
       times faster (still with 8 in parallel). As a bonus, the PC was usable too, while upgrading databases.

       Where tmpfs is appropriate
       The appropriate use of tmpfs is to avoid unnecessary writing of volatile data. Effectively disabling
       writeback, like setting /proc/sys/vm/dirty_writeback_centisecs to infinity on a regular filesystem.

       This has very little to do with performance, and failing this is a much smaller concern than abusing
       fsync: The writeback timeout determines how lazily the disk content is updated after the pagecache
       content, and the default of 5 seconds is a long time for a computer ? an application can overwrite a
       file as frequently as it wants, in pagecache, but the content on disk is only updated about once every
       5 seconds. Unless the application forces it through with fsync, that is. Think about how many times an
       application can output a small file in this time, and you see why fsyncing every single one would be a
       much bigger problem.

       What tmpfs can not help you with
         * Read performance. If your data is hot (which it better be if you consider keeping it in tmpfs),
           you will hit the pagecache anyway. The difference is when not hitting the pagecache; if this is
           the case, go to "Where tmpfs sux", below.
         * Short lived files. These can live their entire lives in the pagecache (as dirty pages) before ever
           being written out. Unless you force it with fsync of course.

       Where tmpfs sux
       Keeping cold data. You might be tempted to think that serving files out of swap is just as efficient
       as a normal filesystem, but there are a couple of reasons why it isn't:

         * The simplest reason: There is nothing that contemporary storage devices (be it harddisk or flash
           based) loves more than reading fairly sequential files neatly organized by a proper filesystem;
           swapping in 4KiB blocks is unlikely to improve on that.
         * More significantly, the cost of swapping out: Tmpfs pages are dirty ? they need to be written
           somewhere (to swap) to be evicted from pagecache, as opposed to file backed clean pages that can
           be dropped instantly. This extra write penalty is felt by whoever else needed that memory, which
           is hard to know, but deserves to be part of your performance evaluation.

***	   
        Use /tmp/ for temporary files. Use /dev/shm/ when you want shared memory (ie, interprocess
        communication through files).

        You can rely on /tmp/ being there, but /dev/shm/ is a relatively recent Linux only thing.

***	
             Isn't there a performance aspect as well? As /dev/shm is most often mounted as a tmpfs volume
             and essentially a RAM-disk? ? Deleted Sep 23 '09 at 9:37
             You can also mount /tmp as a tmpfs filesystem, I do so on my netbook to speed some things up by
             reducing writes to the (slow) SSD. There are disadvantages to doing so, of course (mainly the
             RAM use, but my netbook has far more RAM than it generally needs anyway). ? David Spillett Sep
             23 '09 at 10:55
             For my specific case I would use it for a sort of process communication. I capture the output of
             standard error from an application and act on the contents (and I still need the standard output
             untouched, so I can't do any 1>/dev/null 2>&1. I would do this several thousand times so a tmpfs
             would be nice. However if I release the script I can't rely on tmpfs being used for /tmp as I
             think it's not that common. If it's more common for /dev/shm then that's better for me. But I'm
             looking for guidelines regarding portability etc. ? Deleted Sep 23 '09 at 16:00

***	     
           /dev/shm is used for shared virtual memory system specific device drivers and programs.

           If you are creating a program that requires a virtual memory heap that should be mapped to virtual
           memory. This goes double so if you need multiple processes or threads to be able to safely access
           that memory.

           The fact is that just because the driver uses a special version of tmpfs for it, doesn't mean you
	   should use it as a generic tmpfs partition. Instead, you should just create another tmpfs
	   partition if you want one for your temporary directory.

***	   
         In PERL, having 8GB minimum on any machine (all running Linux Mint), I am of what I think is a good
         habit of doing DB_File-based (data structure in a file) complex algorithms with millions of reads
         and writes using /dev/shm

         In other languages, not having gigether everywhere, to avoid the starts and stops in network
         transfer (working locally on a file that is located on a server in a client-server atmosphere),
         using a batch file of some type, I will copy the whole (300-900MB) file at once to /dev/shm, run the
         program with output to /dev/shm, write the results back to the server, and delete from /dev/shm

	 Naturally, if I had less RAM, I would not be doing this. Ordinarily, the in-memory file system of /
	 dev/shm reads as a size being one half of your available RAM. However, ordinary use of RAM is
         constant. So you really couldn't do this on a device with 2GB or less. To turn paraphrase to
         hyperbole, there is often things in RAM that even the system doesn't report well.

***	 
              (I think this is in the spirit of what was originally asked.) What I mean basically is that I'm
              comfortable using /dev/shm as a RAM disk as long as I have sufficient memory. If it is
              inefficient to do so somehow, that should not dissuade you from doing so, but should trigger a
              question like "How can I have a ram disk on linux?". The answer is /dev/shm ? David Grove Sep
              27 '15 at 21:44



---
https://forums.plex.tv/discussion/80100/plex-transcoding-on-ramdisk

Plex Transcoding on RAMDisk

Hey all,
I just recently stumbled on an article that made me feel like I was back in 1994 again and it was about
RAMDisk's and how much faster they are than SSD's.  I decided to try it out and indeed the RAMDisk I made
benchmarked at over 5 GB/s read and 6 GB/s write speeds (my SSD's get 250+ MB/s).  It got me thinking, I have
this home media server with an abundance of extra RAM (32 GB total) and I'd like to find a way to utilize
that.  Then I was wondering what exactly I'd do with a RAMDisk and I was considering if this would be a
viable transcoding drive for Plex.  I've Googled it, but haven't found much information especially as it
pertains to Plex.

Currently, I don't have many issues with Plex and network speed isn't one of them, so I'm not looking to
"speed" things up necessarily.  What I'm more interested in is whether or not this could solve the issue that
no matter what I do, I can't watch videos streamed by Plex and continue downloading and processing data in
the background.  I'm almost positive that the reason the video freezes on me when this happens is because I'm
running SATA drives and if I had SAS drives that would allow simultaneous read/write, I don't think this
would be an issue.  But, instead of purchasing a SAS controller card at a few hundred bucks and then spending
hundreds more on SAS drives, what if I just used all this extra RAM I have and make a RAMDisk?

I'd be very interested in hearing if anybody is currently using this, how well it works, etc.  I'd also like
to know how transcoding with Plex is done, more specifically, does it do a frame at a time and then push it
to the device?  How big would the RAMDisk need to be for it to be efficient?

I appreciate any input in this matter!

***
    It depends what transcoding you're wanting to speed up. Many transcoding operations are very CPU-limited,
    meaning the CPU is the bottleneck, not any other part of the system. Granted, this is more true for video
    than it is for music, but for the most part you could probably speed up your storage system and find it
    wouldn't matter one bit.

    It also might not make any sense to speed up the transcoding, if Plex's on the fly transcoding we're
    talking about. For example, if your server can transcode video at 2x realtime (say), it can already keep
    up with the demands of any single media player. Being able to transcode a single stream at 4x real time
    makes no difference whatsoever.

    Sequential transfer rates sound really impressive for RAM disks, but again they're pointless for this
    sort of application. The bitrate of a raw CD stream is 1440 kbits/sec, or 180KB/sec. Any compressed
    2-channel, 16-bit 44kHz audio will by definition be less than that. Your SSD can stream that data at
    least a million times faster than that; what's the point of a RAM disk at that point?

    Bluray's maximum bitrate is something in the region of 60Mbit/sec, or call it 7.5MB/sec. That's a paltry
    data rate for a modern computer to keep up with, and again by definition any compressed media will have a
    lower rate. A cheap software RAID array of mechanical disks can easily outdo that by a factor of 10 or
    more and your SSD is 33 times faster. For transcoding, there's no point in being able to shovel the data
    at the CPU any faster as it simply can't keep up.

    RAM disks are a pain in the bum, to be honest. They excel as temporary scratch space for working on data
    with next to no access time hit, but they're hopeless otherwise. As soon as you shut the machine down,
    the RAM disk's contents are lost, and have to be repopulated the next time the system starts up.

    IMHO, if you wanted to make use of the extra RAM on your home server, a better approach might be to get
    into virtualisation.

    I have a Vsphere whitebox at home ("whitebox" is the term given to a server that's built from
    comparatively cheap commodity hardware rather than anything that's expensive and on VMware's hardware
    compatibility lists). It's quad-core Ivy bridge (i5-3470) system with 16GB of RAM, a boot/datastore SSD
    and a handful of 3TB drives; it runs the free version of Vsphere 5.1 (register with VMware and they give
    you a key to turn the trial version into something permanent), but it could quite easily be built on top
    of Microsoft's Hyper-V or something open-source like Xen. I chose Vsphere as that's what I wanted to
    learn at the time.

    On there I run an instance of FreeNAS (with the onboard SATA controller handed over to that VM), several
    instances of Ubuntu 12.04 for various purposes (including one that runs Plex server), an instance of
    WinXP for a couple of bits and bobs I'm playing with that are Windows-only and a small cluster of virtual
    machines for work.

    Doing things this way means I've been free to pick and choose between functions. I like ZFS as a
    filesystem, so something BSD-based made a lot of sense and FreeNAS was simple to get up and running.
    However, a lot of other software runs on Linux; if I'd dedicated the entire machine to FreeNAS, I would
    have been out of luck in running any of that.

    Another nice side-effect is the segregation between functions. For example, nothing I do to the VM
    running Plex can affect my FreeNAS install; I can't bork my data just because I much up something in
    Ubuntu. Similarly, I can feel free to fire up new VMs for work or whatever that I can trash if I make a
    complete mess of them, and it affects nothing else.

    The hardware cost no more than a pre-built Atom NAS box, consumes about the same amount of idle power
    (Ivy Bridge idles at single-digit Watts; it's damn impressive) and offers far more flexibility in what I
    can do with the system. Instead of hoping everything plays nicely with one another under a single OS, I
    have over a dozen servers up and running that all do their own thing. The main cost over a NAS is my
    time; I had to spend the time to set everything up and so forth.

    The reason RAM is important is that every instance of a VM incurs some overhead. I'm running many
    instances of different (and sometimes the same) operating system, which isn't free. However, RAM is
    cheap, and ~100MB or so per instance of (say) Ubuntu server is something I'd planned for by building with
    16GB.

    The problem with virtualisation is it really has to be planned from the beginning. It's hard to take a
    machine that already has data on it and turn it into a VM factory (where does the data go in the
    meantime?). It's also hard to take just any old machine and turn it into a Vsphere system; there are
    certain hardware features that are very desirable for running Vsphere, and not all processors, chipsets
    and motherboards support them.

    Like I said, it cost me some time to set up, but it's opened up a world of possibilities that I wouldn't
    otherwise have.

***
    So I read your topic and decided to try it out. Just set the transcoder temporary directory to the
    mounted tmpfs and it's working smoothly.

    If  you're not familiar with ramfs / tmpfs here's a good read:
	http://www.thegeekstuff.com/2008/11/overview-of-ramfs-and-tmpfs-on-linux/#more-251

    I'd recommend a tmpfs.

    The transcoder, it seems, stores many .ts files in different directories for each show being watched. I
    believe it cleans up after itself after the video finishes. I of course made my initial tmpfs 1024m so
    it's taking the better part of a movie to see what happens when it reaches the limit. 

    I read tmpfs will pour over into swap once it's full, I really hope plex will just cleanup watched ts
    files out as the tmpfs fills up.

    @Smegheid - your post was an interesting read, the reason I'd continue to use a ram disk for transcoding
    is to remove unnecessary read and writes on my SSD.

    EDIT:
    well finally played to the 1GB mark, plex clears the tmp dir and my 1GB tmpfs is empty again, the
    transcoder kicks off and hangs as the player was still buffering & w/ cpu utilization but nothing written
    to the tmp dir.

    Some purge logic needs to be introduced to manage the transcoder's temp directory if we want to have a
    limited directory size.

    TBH it would be nice to not have to write the transcoded data back to disk if we don't have to. For
    multi-user setups that come under concurrent load this could prove to be quite useful.

***
    Thanks for the responses and very solid info!

    @Smegheid - I really don't have any need to speed things up per se.  I guess what I'm trying to say is my
    primary issue isn't speed at all, but instead it's doing too much disk access at one time or at least I
    think that's the problem :).  Here's my setup:  i7-3770k overclocked to 4.2Ghz, MSI Z77A-GD65 mobo, 32 GB
    of RAM, PowerColor 7870 Myst Edition, Corsair SATA III 128 GB SSD's (for the OS which includes my
    installed programs) and my video drive is a 3 TB USB 3.0 external Seagate 7200 rpm drive.  When I'm
    downloading something and I'm watching a video at the same time, it's fine until the download gets
    processed and is being extracted.  When that happens, my video that I'm transcoding freezes and won't
    recover unless I restart the video from scratch after the entire process is over.  So what I was
    wondering is if I use a RAMdisk as the transcoding destination, would this eliminate the freezing?
     Currently my transcoding drive is setup to transcode to the external 3 TB drive (which again is what I'm
    playing the video from as well as where the downloaded data is being written) although I've also had it
    transcoding on the SSD and there was no difference on the freezing.  I suppose this could also be an
    issue with the processor, but that just seems so unlikely considering I've ran this thing through
    seemingly much higher loads in benchmarking and it hasn't hiccuped or done anything weird.  It just seems
    like a disk access issue and so I was wondering if a RAMdisk would offload that stress on these drives.
     I do have a bunch of other hard drives, none RAIDed, just random old drives that I've thrown in here and
    I haven't tried putting the transcoder on any of those either to see if it would help.  I suppose I could
    do that to test it as well.  I just figured that since I overdid it on the RAM with 32 GB and I've maybe
    used at most, 10 GB of that at any given time that I could utilize that extra RAM with the RAMdisk and
    save some money instead of buying commercial-grade SAS equipment.  I definitely am interested in
    transcoding to multiple devices simultaneously at some point in the future as well.

    @Vulcanworlds - I never really thought about it from the perspective of conserving read/writes on the SSD
    to prolong longevity, but that's a good point. :)  I have a trial edition of Dataram's RAMdisk and it's a
    great program, but only allows for a max of 4 GB to a single disk.  I was wondering whether or not if
    you're transcoding a 13 GB MKV file if that would mean that I'd at least need a 13 GB RAMdisk to
    effectively transcode or if I'd need more RAM allocated for that.  I'm totally willing to purchase the
    software because it would only be $20 and I like the fact that you can have Windows mount the drive on
    startup, yet you can still throw away the data after each reboot and not commit it to the saved image
    file.  When you say some "purge logic needs to be introduced" I believe you're saying that it doesn't
    automatically purge the transcode directory, correct?  I noticed a while back when the transcoding was
    still setup on my SSD that WinDirStat showed a huge amount of data being eaten up by the transcoding
    directory, so I suppose that would be the case.  With this program, it'll theoretically throw away that
    data every reboot, but that doesn't help if the thing never reboots, which is the goal...  Maybe there's
    some Windows scripting that could be done on this to automate clearing the directory out?

    Again, thanks for the helpful info!  Whenever I get a plan figured out and have more time, I'd be happy
    to post my findings on here as well.

***
    RandomTask83RandomTask83 Posts: 81Members, Plex Pass Plex Pass
    September 2013
    I've done it in Archlinux and it doesn't really is worthy because the bottleneck would not be your HD , I
    think SATA III is 3 gbps IIRC so split it in a half, so 1,5 per up and down . Still enough. As plex uses
    ffmpeg for all things, and it relies on your CPU speed , that is the bottleneck, do a test, encode a file
    manually with ffmpeg with x264 and mp3 or AAC and that is exactly what plex does to transcode. What I'm
    frying to argue is that a bluray movie is 40 Mbps < 1,5 gbps so the drive wouldn't be a bottleneck issue
    AFAIK.

    If you want to preserve read/write cycles in SSD to prevent isolation then is a good choice but you need
    at least 16-32 Gb of ram, because tmpfs uses only half of your ram at most, so if plex is transcoding and
    tmpfs wants out of space then your transcoding session aka your movie and your joy will end suddenly.

***    
    @jvillanova - I wouldn't even call this a bottleneck issue really.  I have no speed concerns for wanting
    to do this.  It's a matter of figuring out if my HDD/SSD are under too much stress from read/writes and
    whether or not a RAMdisk will solve that and preserving read/write cycles would be an added benefit.  I
    understand that the CPU is what does the heavy lifting on the transcoding process :)  Also SATA III is 6
    Gbps theoretical.  On my SSD I see real-world speeds around 250 Mb/s (2 Gbps) sequential and 150 Mb/s
    (1.2 Gbps) random.

    Maybe I should just forget about it and build a 21 Tb SuperNAS like Linus did... 

***
    I'd think your bottleneck is the USB 3.0 drive, put one of your spare hdd's in the box and set that as
    the transcoding directory. With it being the only I/O for that disk, you should be better off than having
    the transcoding write to the external hdd. Or, use a spare hdd as the download destination or extract
    destination. It'd be better to have 1 disk be read from while writing to another rather than your current
    setup which is attempting to read 2 different files (the archive and the file to transcode) while
    attempting to write 2 different files (the transcoded data & the extracted data) all over the same USB
    port. Sounds like a good recipe for some I/O blockage.

    It sounds like you're running windows, have you watched your drive I/O at all? Task Manager > Performance
    Tab > Resource Monitor

    In my experience, my 3770k @ 4.5 seems to handle transcoding 2 different 1080p movies simultaneously to
    the same 1 TB wd black sata III drive haven't really tried anything past that, though cpu utilization
    wise it seems like maybe 3 is all I'd manage.

    Technically you're correct about the ramdisk size. I'm thinking plex doesn't clear the transcoding
    directory until the file finishes playing or (a guess) you navigate back to the library. So, if you had
    enough space in your ramdisk for the entire transcoded file it should work without freezing & crashing
    PMS. If you want, try it out with a 20gb ramdisk and leave the other 12gb for windows. As long as you've
    got a single user or multiple users aren't all watching movies you may be okay.

    The purge logic I mentioned is something that the plex developers should / would need to implement such
    that the transcoded directory only holds on to the previous few minutes you just watched rather than from
    the beginning of the file.

***
    @Vulcanworlds - I offloaded the transcoding directory for Plex to a spare drive that I just got.  It's a
    2 TB drive with a bunch of reallocated sectors, so if it fails, no big loss.  I'll have to see how this
    goes, but I'm a bit skeptical of whether or not this will help.  The logistics of how data flows in from
    my downloads and then becomes available in the Plex library might be impossible to solve.  I don't see
    how I can get the data downloaded, uncompressed, moved to the library, but yet play from that same
    library simultaneously without encountering issues.

    For instance, say you're using Sickbeard/Couchpotato/Sabnzbd and you have them all installed on your
    local disk C:.  By default they download to a directory on C:, but you can of course change that download
    destination to a different drive like V:\.  Now on V:\ you want Plex to read that as your library so you
    set it to the directory there.  Now say you have another drive that you set as your transcoding drive T:
    \.  Now you have something downloading and you watch something at the same time so it's downloading to V:
    \ and you're watching a transcoded file, it's still accessing the V:\ drive for your video and then
    trasncoding it to T:\ right?  Eventually the download gets done and it needs to extract and process, so
    it's doubling the reads and writing to V: as well, correct?  Even if you left Sab to download to your C:
    \, you'd still need to eventually move it at some point to the V:\ drive to make it available to the Plex
    library, which would still be causing stress on the disk if you're trying to watch something at the same
    time.  After the download completes, Sab needs to process the file and extract it, potentially repair it
    with parity, etc. or am I missing something?

    It just seems like there's no way to get around the disk that houses the library on it from being
    accessed by multiple sources both reading and writing simultaneously, which is why I was considering
    going with SAS drives for that, but of course those are so crazy expensive.  I thought potentially using
    the RAMdisk would at least eliminate the stress caused to the disk by transcoding, but I think the bigger
    issue is simultaneous read/writes...

    Ugh my head is spinning...

    EDIT:  What about RAID'ing the drive that the Plex library resides on?  If I put those in a RAID that
    would increase the bandwidth and cut the read/writes in half correct?

***
    A couple of things:

    1) Raid'ing your drives won't necessarily increase the available bandwidth to your media. It really
    depends on how it's setup.

    2) Unless I miss understood, it seems like your media and your download path are on your external hard
    drive. Is that correct?

    If so, you mentioned your external media drive is USB3, but is it plugged in to a USB3?

    If it is on an external hard drive, that could be your bottle neck/ From my experience with external
    drives (which is not much), transfers over USB usually deteriorate if multiple read/write are occuring on
    the same drive. 

    What I would suggest is that you download your media to your SSD and then manually transfer them to your
    external later, which is a hassle, but could be done automatically with a script.

***
    Running Plex Media Server from a machine with fairly intensive operations on the filesystem I really like
    running transcoder reads/writes on a tmpfs. I've been doing this for a little while now. It all runs
    smoothly, but I do need to restart playback if the tmpfs fills up. So that's for anything where the
    quality after transcoding is still fairly high and the file is lengthy. (say, a 1080p 3 hour movie gets
    transcoded to a high bitrate 720p)

    I see no reason why Plex would hang on to older parts of the transcoding session. It doesn't seem to
    influence seeking much. Can't really think of another reason they would be kept in the first place. Would
    love to hear more reasons if there are any, though.

    So yes, I think it would be great if space would get purged/recycled. Alternatively it would also be
    great to simply have a configurable space limit per transcoding session. (Or a collective limit for all
    sessions, but that seems more error-prone.)

***
    @thejixn0r - if it's setup in a RAID-0, then it's just striped across all drives, right?  That should
    theoretically increase the bandwidth unless I'm mistaken.  Guess it really doesn't matter since my
    largest media storage drives are external and I'd need to rip them out of the enclosures.  Also, yes it's
    on a 3 TB Seagate 7200 RPM USB 3.0 drive.  The drive typically sees sequential read/writes around 145 MB/
    s when transferring to/from my SSD.  Not sure about how multiple connections degrade it, but it
    definitely is degraded.  As soon as something decompresses in SAB, whatever I'm watching, whether
    transcoding or not freezes up.  I've even tried just watching something in VLC and that freezes as soon
    as something is unpacking in Sab.  After the unpacking is over, the video is still frozen and I have to
    exit out of VLC and restart the video, but then it's fine until it happens again.

    @pzt - it seems as if Plex doesn't remove transcoding data from the transcode directory and if that fills
    up, then I can see how it would cause problems.  It would need more intensive purge logic than just a
    flush though because if you only had the last few minutes as Vulcanworlds suggested, then wouldn't that
    eliminate the ability to effectively search/fast-forward/rewind?  Granted, that feature doesn't seem to
    work too keen for me right now anyways, especially if I'm streaming to a 360, but just throwing out
    questions.

    I haven't had the free time lately that I wish I'd have to really dig into this stuff, test, and post
    results.  I'm also out of money to buy any other equipment to benchmark against.

***
    Vulcanworlds, that's an interesting idea. I hadn't considered that plex would generate intermediate files
    in the process of transcoding; I figured it would just be a plain old stream that didn't actually land
    anywhere.

    In that case, tmpfs is perfect. It's pretty much designed for this sort of thing, for data that is
    short-lived and not permanent.

    One word of warning to anyone else reading that has a passing familiarity with Unix/Linux is that /tmp is
    no longer a RAM disk on a bunch of Linux distributions. Ubuntu (and a bunch of its derivatives) now leave
    /tmp on the root filesystem, which  can be a surprise. Even the server version of Ubuntu (certainly
    12.04) does this these days.

***
    I've been trying to cleanup the transcode dir with a cron task:
find /ramdisk/plex-transcode-* -type f \( -iname 'media-0*.ts' ! -iname "*.tmp" \) -mmin 0.33 -exec rm {} \;
find /ramdisk/plex-transcode-* -type f \( -iname 'chunk-0*' ! -iname "*.tmp" \) -mmin 0.33 -exec rm {} \;
     
    Which seems to delete the old files, but  somehow it's not a 100% stable fix

***    
    1st of all.
    Sorry for necroing this thread. :(

    2nd.
    I can not get Plex Media Server to run on a RamDisk. I am Using 32Gb Corsair Vengeance Pro 2400 DDR3 and
    DimmDrive.

    If I run Plex Media Server, from the RamDisk, the client can not connect to the server despite all manual
    workarounds.

    Running Plex Media Server, off of my HDD and Plex connects to my tablet without a hitch.

    I figured I did not have enough to post to create another thread.



---
http://www.linuxfocus.org/English/November1999/article124.html

[ !!! OLD !!! ]
How to use a Ramdisk for Linux

Introduction to RamDisk
This is a brief article about how to setup a RamDisk on a RedHat 6.0 system. It should be very similar for
other Linux distributions.

What is a RamDisk? A RamDisk is a portion of memory that you allocate to use as a partition. Or, in other
words, you are taking memory, pretending to treat it as a hard drive, and you are saving your files to it.
Why would you want to use a RamDisk? Well, if you know that certain files you have are constantly going to be
used, putting the files into memory will increase the performance of your computer since your memory is
faster than your hard drive. Things like web servers with lots of data can be sped up this way. Or, if you
are insane, and you have a PII 550 Mhz computer with 1 gig of memory and an old 500 meg hard drive, you can
use it just to increase your hard drive space. Then again, if you want an almost diskless machine, it might
not be that crazy afterall.

Here are some more resources to help you.
 1. http://metalab.unc.edu/LDP/HOWTO/Kernel-HOWTO.html
 2. http://metalab.unc.edu/LDP/HOWTO/mini/LILO.html
 3. /usr/src/linux/Documentation/ramdisk.txt

How to use RamDisk
Well, it is very easy to use a ramdisk. First of all, the default installation of RedHat 6.0 comes with
ramdisk support. All you have to do is format a ramdisk and then mount it to a directory. To find out all the
ramdisks you have available, do a "ls -al /dev/ram*". This gives you the preset ramdisks available to your
liking. These ramdisks don't actually grab memory until you use them somehow (like formatting them). Here is
a very simple example of how to use a ramdisk.
	# create a mount point:
	mkdir /tmp/ramdisk0
	# create a filesystem:
	mke2fs /dev/ram0
	# mount the ramdisk:
	mount /dev/ram0 /tmp/ramdisk0

Those three commands will make a directory for the ramdisk , format the ramdisk (create a filesystem), and
mount the ramdisk to the directory "/tmp/ramdisk0". Now you can treat that directory as a pretend partition!
Go ahead and use it like any other directory or as any other partition.
If the formatting of the ramdisk faild then you might have no support for ramdisk compiled into the Kernel.
The Kernel configuration option for ramdisk is CONFIG_BLK_DEV_RAM .

The default size of the ramdisk is 4Mb=4096 blocks. You saw what ramdisk size you got while you were running
mke2fs. mke2fs /dev/ram0 should have produced a message like this:
	mke2fs 1.14, 9-Jan-1999 for EXT2 FS 0.5b, 95/08/09
	Linux ext2 filesystem format
	Filesystem label=
	1024 inodes, 4096 blocks
	204 blocks (4.98%) reserved for the super user
	First data block=1
	Block size=1024 (log=0)
	Fragment size=1024 (log=0)
	1 block group
	8192 blocks per group, 8192 fragments per group
	1024 inodes per group

Running df -k /dev/ram0 tells you how much of that you can really use (The filesystem takes also some space):
	>df -k /dev/ram0
	Filesystem  1k-blocks  Used Available Use% Mounted on
	/dev/ram0        3963    13      3746   0% /tmp/ramdisk0

What are some catches? Well, when the computer reboots, it gets wiped. Don't put any data there that isn't
copied somewhere else. If you make changes to that directory, and you need to keep the changes, figure out
some way to back them up.    

Changing the size of the ramdisks
To use a ram disk you either need to have ramdisk support compiled into the Kernel or you need to compile it
as loadable module. The Kernel configuration option is CONFIG_BLK_DEV_RAM . Compiling the ramdisk a loadable
module has the advantage that you can decide at load time what the size of your ramdisks should be.

Okay, first the hard way. Add this line to your lilo.conf file:
	ramdisk_size=10000 (or ramdisk=10000 for old kernels)
and it will make the default ramdisks 10 megs after you type the "lilo" command and reboot the computer. Here
is an example of my /etc/lilo.conf file.
	boot=/dev/hda
	map=/boot/map
	install=/boot/boot.b
	prompt
	timeout=50
	image=/boot/vmlinuz
		label=linux
		root=/dev/hda2
		read-only
		ramdisk_size=10000

Actually, I got a little over 9 megs of usable space as the filesystem takes also a little space.

When you compile ramdisk support as loadable module then you can decide at load time what the size should be.
This is done either with an option line in the /etc/conf.modules file:
	options rd rd_size=10000

or as a command line parameter to ismod:
	insmod rd rd_size=10000

Here is an example which shows how to use the module:
 1. Unmount the ramdisk mounted in the previous chapter, umount /tmp/ramdisk0 .
 2. Unload the module (it was automatically loaded in the previous chapter), rmmod rd
 3. Load the ramdisk module and set the size to 20Mb, insmod rd rd_size=20000
 4. create a file system, mke2fs /dev/ram0
 5. mount the ramdisk, mount /dev/ram0 /tmp/ramdisk0

Example of how to use a RamDisk for a webserver.
Okay, here is an example of how to use 3 ramdisks for a webserver. Let us say you are 99% confident that your
default installation of Apache for RedHat 6.0 won't use more than 9 megs for its cgi-scripts, html, and
icons. Here is how to install one.
First, issue this command to move the real copy of the document root directory of your webserver to a
different place. Also, make the directories to mount the ramdisks .
	mv /home/httpd/ /home/httpd_real
	mkdir /home/httpd
	mkdir /home/httpd/cgi-bin
	mkdir /home/httpd/html
	mkdir /home/httpd/icons

Then, add these commands to the start procedure in your /etc/rc.d/init.d/httpd.init (or where ever the httpd
gets started on your system):
### Make the ramdisk partitions
	/sbin/mkfs -t ext2 /dev/ram0
	/sbin/mkfs -t ext2 /dev/ram1
	/sbin/mkfs -t ext2 /dev/ram2

### Mount the ramdisks to their appropriate places
	mount /dev/ram0 /home/httpd/cgi-bin
	mount /dev/ram1 /home/httpd/icons
	mount /dev/ram2 /home/httpd/html

### Copying real directory to ramdisks (the
### data on the ramdisks is lost after a reboot)
	tar -C /home/httpd_real -c . | tar -C /home/httpd -x

### After this you can start the web-server.

-------------------------------------------------------------------------------------------------------------
                              Webpages maintained by the LinuxFocus Editor team
                                              (C) Mark Nielsen
                                               LinuxFocus 1999
1999-11-01, generated by lfparser version 0.8
[ !!! OLD !!! ]