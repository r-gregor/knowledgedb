filename: howto_create-linux-ram-disk-filesystem_multif_20151202.txt
http://www.cyberciti.biz/faq/howto-create-linux-ram-disk-filesystem/

Software RAM disks use the normal RAM in main memory as if it were a partition on a hard drive rather than
actually accessing the data bus normally used for secondary storage such as hard disk. How do I create
and store a web cache on a RAM disk to improve the speed of loading pages under Linux operating systems?

You can create the ram disk as follows (8192 = 8M, no need to format the ramdisk as a journaling file
system) :
# mkfs -q /dev/ram1 8192
# mkdir -p /ramcache
# mount /dev/ram1 /ramcache
# df -H | grep ramcache

Sample outputs:
/dev/ram1              8.2M   1.1M   6.7M  15% /ramcache
Next you copy images or caching objects to /ramcache
# cp /var/www/html/images/*.jpg /ramcache

Now you can edit Apache or squid reverse proxy to use /ramcache to map to images.example.com:

<VirtualHost 1.2.3.4:80>
     ServerAdmin admin@example.com
     ServerName images.example.com
     DocumentRoot /ramcache
     #ErrorLog /var/logs/httpd/images.example.com_error.log
     #CustomLog /var/logs/httpd/images.example.com_access.log combined
</VirtualHost>

Reload httpd:
# service httpd reload

Now all hits to images.example.com will be served from the ram. This can improve the speed of loading
pages or images. However, if server rebooted all data will be lost. So you may want to write /etc/init.d/
script to copy back files to /ramcache. Create a script called initramcache.sh:

#!/bin/sh
mkfs -t ext2 -q /dev/ram1 8192
[ ! -d /ramcache ] && mkdir -p /ramcache
mount /dev/ram1 /ramcache
/bin/cp /var/www/html/images/*.jpg /ramcache

Call it from /etc/rc.local or create softlink in /etc/rc3.d/
# chmod +x /path/to/initramcache.sh
# echo '/path/to/initramcache.sh' >> /etc/rc.local

A Note About tmpfs
tmpfs is supported by the Linux kernel from version 2.4+. tmpfs (also known as shmfs) is a little different
from the Linux ramdisk. It allocate memory dynamically and by allowing less-used pages to be moved onto
swap space. ramfs, in contrast, does not make use of swap which can be an advantage or disadvantage in
many cases. See how to use tmpfs under Linux.



---
http://www.cyberciti.biz/tips/what-is-devshm-and-its-practical-usage.html

/dev/shm is nothing but implementation of traditional shared memory concept. It is an efficient means
of passing data between programs. One program will create a memory portion, which other processes (if
permitted) can access. This will result into speeding up things on Linux.

shm / shmfs is also known as tmpfs, which is a common name for a temporary file storage facility on
many Unix-like operating systems. It is intended to appear as a mounted file system, but one which uses
virtual memory instead of a persistent storage device.

If you type the mount command you will see /dev/shm as a tempfs file system. Therefore, it is a file
system, which keeps all files in virtual memory. Everything in tmpfs is temporary in the sense that no
files will be created on your hard drive. If you unmount a tmpfs instance, everything stored therein is
lost. By default almost all Linux distros configured to use /dev/shm:
$ df -h

Sample outputs:

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/wks01-root
                      444G   70G  351G  17% /
tmpfs                 3.9G     0  3.9G   0% /lib/init/rw
udev                  3.9G  332K  3.9G   1% /dev
tmpfs                 3.9G  168K  3.9G   1% /dev/shm
/dev/sda1             228M   32M  184M  15% /boot
Nevertheless, where can I use /dev/shm?

You can use /dev/shm to improve the performance of application software such as Oracle or overall
Linux system performance. On heavily loaded system, it can make tons of difference. For example VMware
workstation/server can be optimized to improve your Linux host's performance (i.e. improve the performance
of your virtual machines).

In this example, remount /dev/shm with 8G size as follows:
# mount -o remount,size=8G /dev/shm

To be frank, if you have more than 2GB RAM + multiple Virtual machines, this hack always improves
performance. In this example, you will give you tmpfs instance on /disk2/tmpfs which can allocate 5GB
RAM/SWAP in 5K inodes and it is only accessible by root:
# mount -t tmpfs -o size=5G,nr_inodes=5k,mode=700 tmpfs /disk2/tmpfs

Where,
-o opt1,opt2 : Pass various options with a -o flag followed by a comma separated string of options. In
this examples, I used the following options:
remount : Attempt to remount an already-mounted filesystem. In this example, remount the system and
increase its size.
size=8G or size=5G : Override default maximum size of the /dev/shm filesystem. he size is given in bytes,
and rounded up to entire pages. The default is half of the memory. The size parameter also accepts a
suffix % to limit this tmpfs instance to that percentage of your pysical RAM: the default, when neither
size nor nr_blocks is specified, is size=50%. In this example it is set to 8GiB or 5GiB. The tmpfs
mount options for sizing ( size, nr_blocks, and nr_inodes) accept a suffix k, m or g for Ki, Mi, Gi
(binary kilo, mega and giga) and can be changed on remount.
nr_inodes=5k : The maximum number of inodes for this instance. The default is half of the number of your
physical RAM pages, or (on a machine with highmem) the number of lowmem RAM pages, whichever is the lower.
mode=700 : Set initial permissions of the root directory.
tmpfs : Tmpfs is a file system which keeps all files in virtual memory.

How do I restrict or modify size of /dev/shm permanently?
You need to add or modify entry in /etc/fstab file so that system can read it after the reboot. Edit,
/etc/fstab as a root user, enter:
# vi /etc/fstab

Append or modify /dev/shm entry as follows to set size to 8G

none      /dev/shm        tmpfs   defaults,size=8G        0 0
Save and close the file. For the changes to take effect immediately remount /dev/shm:
# mount -o remount /dev/shm

Verify the same:
# df -h

Recommend readings:
See man pages of mount regarding tmpfs options.
Details regarding tmpfs is available in /usr/share/doc/kernel-doc-/Documentation/filesystems/tmpfs.txt file.


---
http://www.vanemery.com/Linux/Ramdisk/ramdisk.html

Linux Ramdisk mini-HOWTO

RAM Disk

Introduction
What is a RAM disk? A RAM disk is a portion of RAM which is being used as if it were a disk drive. RAM
disks have fixed sizes, and act like regular disk partitions. Access time is much faster for a RAM disk
than for a real, physical disk. However, any data stored on a RAM disk is lost when the system is shut
down or powered off. RAM disks can be a great place to store temporary data.

The Linux kernel version 2.4 has built-in support for ramdisks. Ramdisks are useful for a number of
things, including:

Working with the unencrypted data from encrypted documents
Serving certain types of web content
Mounting Loopback file systems (such as run-from-floppy/CD distributions)
Why did I write this document? Because I needed to setup a 16 MB ramdisk for viewing and creating
encrypted documents. I did not want the unencrypted documents to be written to any physical media on my
workstation. I also found it amazing that I could easily create a "virtual disk" in RAM that is larger
than my first hard drive, a 20 MB Winchester disk. At the time, that disk was so large that I never even
considered filling it up, and I never did!

This document should take you step-by-step through the process of creating and using RAM disks.

Assumptions/Setup
I was using Red Hat 9 for this test, but it should work with other GNU/Linux distributions running 2.4.x
kernels. I am also assuming that the distribution you are using already has ramdisk support compiled
into the kernel. My test machine was a Pentium 4 and had 256 MB of RAM. The exact version of the kernel
that I used was: 2.4.20-20.9

Step 1: Take a look at what has already been created by your system
Red Hat creates 16 ramdisks by default, although they are not "active" or using any RAM. It lists
devices ram0 - ram 19, but only ram0 - ram15 are usable by default. To check these block devices out,
use the following command:

[root]# ls -l /dev/ram*
lrwxrwxrwx    1 root     root            4 Jun 12 00:31 /dev/ram -> ram1
brw-rw----    1 root     disk       1,   0 Jan 30  2003 /dev/ram0
brw-rw----    1 root     disk       1,   1 Jan 30  2003 /dev/ram1
brw-rw----    1 root     disk       1,  10 Jan 30  2003 /dev/ram10
brw-rw----    1 root     disk       1,  11 Jan 30  2003 /dev/ram11
brw-rw----    1 root     disk       1,  12 Jan 30  2003 /dev/ram12
brw-rw----    1 root     disk       1,  13 Jan 30  2003 /dev/ram13
brw-rw----    1 root     disk       1,  14 Jan 30  2003 /dev/ram14
brw-rw----    1 root     disk       1,  15 Jan 30  2003 /dev/ram15
brw-rw----    1 root     disk       1,  16 Jan 30  2003 /dev/ram16
brw-rw----    1 root     disk       1,  17 Jan 30  2003 /dev/ram17
brw-rw----    1 root     disk       1,  18 Jan 30  2003 /dev/ram18
brw-rw----    1 root     disk       1,  19 Jan 30  2003 /dev/ram19
brw-rw----    1 root     disk       1,   2 Jan 30  2003 /dev/ram2
brw-rw----    1 root     disk       1,   3 Jan 30  2003 /dev/ram3
brw-rw----    1 root     disk       1,   4 Jan 30  2003 /dev/ram4
brw-rw----    1 root     disk       1,   5 Jan 30  2003 /dev/ram5
brw-rw----    1 root     disk       1,   6 Jan 30  2003 /dev/ram6
brw-rw----    1 root     disk       1,   7 Jan 30  2003 /dev/ram7
brw-rw----    1 root     disk       1,   8 Jan 30  2003 /dev/ram8
brw-rw----    1 root     disk       1,   9 Jan 30  2003 /dev/ram9
lrwxrwxrwx    1 root     root            4 Jun 12 00:31 /dev/ramdisk -> ram0

Now, grep through dmesg output to find out what size the ramdisks are:

[root]# dmesg | grep RAMDISK
RAMDISK driver initialized: 16 RAM disks of 4096K size 1024 blocksize
RAMDISK: Compressed image found at block 0

As you can see, the default ramdisk size is 4 MB. I want a 16 MB ramdisk, so the next step will be to
configure Linux to use a larger ramdisk size during boot.

Step 2: Increase ramdisk size
Ramdisk size is controlled by a command-line option that is passed to the kernel during boot. Since GRUB
is the default bootloader for Red Hat 9, I will modify /etc/grub.conf with the new kernel option. The
kernel option for ramdisk size is:  ramdisk_size=xxxxx, where xxxxx is the size expressed in 1024-byte
blocks. Here is what I will add to /etc/grub.conf to configure 16 MB ramdisks:

# grub.conf generated by anaconda
#
# Note that you do not have to rerun grub after making changes to this file
# NOTICE:  You have a /boot partition.  This means that
#          all kernel and initrd paths are relative to /boot/, eg.
#          root (hd0,0)
#          kernel /vmlinuz-version ro root=/dev/hda5
#          initrd /initrd-version.img
#boot=/dev/hda
default=0
timeout=10
splashimage=(hd0,0)/grub/splash.xpm.gz
title Red Hat Linux (2.4.20-20.9)
        root (hd0,0)
        kernel /vmlinuz-2.4.20-20.9 ro root=LABEL=/ hdc=ide-scsi ramdisk_size=16000
        initrd /initrd-2.4.20-20.9.img
	
Once you save the file, you will need to reboot your system. After the reboot, a look at the dmesg output
should confirm the change has taken effect:

[root]# dmesg | grep RAMDISK
RAMDISK driver initialized: 16 RAM disks of 16000K size 1024 blocksize
RAMDISK: Compressed image found at block 0

Step 3: Format the ramdisk
There is no need to format the ramdisk as a journaling file system, so we will simply use the ubiquitous
ext2 file system. I only want to use one ramdisk, so I will only format /dev/ram0:

[root]# mke2fs -m 0 /dev/ram0
mke2fs 1.32 (09-Nov-2002)
Filesystem label=
OS type: Linux
Block size=1024 (log=0)
Fragment size=1024 (log=0)
4000 inodes, 16000 blocks
0 blocks (0.00%) reserved for the super user
First data block=1
2 block groups
8192 blocks per group, 8192 fragments per group
2000 inodes per group
Superblock backups stored on blocks:
        8193

Writing inode tables: done
Writing superblocks and filesystem accounting information: done

This filesystem will be automatically checked every 22 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.

The -m 0 option keeps mke2fs from reserving any space on the file system for the root user, which is
the default behavior. I want all of the ramdisk space available to a regular user for working with
encrypted files.

Step 4: Create a mount point and mount the ramdisk
Now that you have formatted the ramdisk, you must create a mount point for it. Then you can mount your
ramdisk and use it. We will use the directory /mnt/rd for this operation.

[root]# mkdir /mnt/rd
[root]# mount /dev/ram0 /mnt/rd
Now verify the new ramdisk mount:

[root]# mount | grep ram0
/dev/ram0 on /mnt/rd type ext2 (rw)
[root]# df -h | grep ram0
/dev/ram0              16M   13K   16M   1% /mnt/rd

You can even take a detailed look at the new ramdisk with the tune2fs command:

[root]# tune2fs -l /dev/ram0
tune2fs 1.32 (09-Nov-2002)
Filesystem volume name:   none
Last mounted on:          not available
Filesystem UUID:          fbb80e9a-8e7c-4bd4-b3d9-37c29813a5f5
Filesystem magic number:  0xEF53
Filesystem revision #:    1 (dynamic)
Filesystem features:      filetype sparse_super
Default mount options:    (none)
Filesystem state:         not clean
Errors behavior:          Continue
Filesystem OS type:       Linux
Inode count:              4000
Block count:              16000
Reserved block count:     0
Free blocks:              15478
Free inodes:              3989
First block:              1
Block size:               1024
Fragment size:            1024
Blocks per group:         8192
Fragments per group:      8192
Inodes per group:         2000
Inode blocks per group:   250
Filesystem created:       Mon Dec  8 14:33:57 2003
Last mount time:          Mon Dec  8 14:35:39 2003
Last write time:          Mon Dec  8 14:35:39 2003
Mount count:              1
Maximum mount count:      22
Last checked:             Mon Dec  8 14:33:57 2003
Check interval:           15552000 (6 months)
Next check after:         Sat Jun  5 14:33:57 2004
Reserved blocks uid:      0 (user root)
Reserved blocks gid:      0 (group root)
First inode:              11
Inode size:               128

In my case, I need the user "van" to be able to read and write to the ramdisk, so I must change the
ownership and permissions of the /mnt/rd directory:

[root]# chown van:root /mnt/rd
[root]# chmod 0770 /mnt/rd
[root]# ls -ald /mnt/rd
drwxrwx---    2 van     root         4096 Dec  8 11:09 /mnt/rd

The ownership and permissions on the ramdisk filesystem/directory should be tailored to your particular
needs.

Step 5: Use the ramdisk
Now that it has been created, you can copy, move, delete, edit, and list files on the ramdisk exactly as
if they were on a physical disk partiton. This is a great place to view decrypted GPG or OpenSSL files,
as well as a good place to create files that will be encrypted. After your host is powered down, all
traces of files created on the ramdisk are gone.

To unmount the ramdisk, simply enter the following:

[root]# umount -v /mnt/rd
/dev/ram0 umounted

Note:  If you remount the ramdisk, your data will still be there. Once memory has been allocated to the
ramdisk, it is flagged so that the kernel will not try to reuse the memory later. Therefore, you cannot
"reclaim" the RAM after you are done with using the ramdisk. For this reason, you will want to be careful
not to allocate more memory to the ramdisk than is absolutely necessary. In my case, I am allocating <
10% of the physical RAM. You will have to tailor the ramdisk size to your needs. Of course, you can
always free up the space with a reboot!

Automating Ramdisk Creation
If you need to create and mount a ramdisk every time your system boots, you can automate the process by
adding some commands to your /etc/rc.local init script. Here are the lines that I added:

# Formats, mounts, and sets permissions on my 16MB ramdisk
/sbin/mke2fs -q -m 0 /dev/ram0
/bin/mount /dev/ram0 /mnt/rd
/bin/chown van:root /mnt/rd
/bin/chmod 0750 /mnt/rd


Conclusion
You have now seen how to setup and use a ramdisk on your GNU/Linux system. Hopefully, you will find this
information to be interesting and useful!



---
http://www.linuxfocus.org/English/November1999/article124.html

Introduction to RamDisk
How to use RamDisk
Changing the size of the ramdisks
Example of how to use a RamDisk for a webserver.
Comments
How to use a Ramdisk for Linux

Introduction to RamDisk
This is a brief article about how to setup a RamDisk on a RedHat 6.0 system. It should be very similar
for other Linux distributions.
What is a RamDisk? A RamDisk is a portion of memory that you allocate to use as a partition. Or, in other
words, you are taking memory, pretending to treat it as a hard drive, and you are saving your files to
it. Why would you want to use a RamDisk? Well, if you know that certain files you have are constantly
going to be used, putting the files into memory will increase the performance of your computer since
your memory is faster than your hard drive. Things like web servers with lots of data can be sped up
this way. Or, if you are insane, and you have a PII 550 Mhz computer with 1 gig of memory and an old
500 meg hard drive, you can use it just to increase your hard drive space. Then again, if you want an
almost diskless machine, it might not be that crazy afterall.

Here are some more resources to help you.
http://metalab.unc.edu/LDP/HOWTO/Kernel-HOWTO.html
http://metalab.unc.edu/LDP/HOWTO/mini/LILO.html
/usr/src/linux/Documentation/ramdisk.txt

How to use RamDisk
Well, it is very easy to use a ramdisk. First of all, the default installation of RedHat 6.0 comes with
ramdisk support. All you have to do is format a ramdisk and then mount it to a directory. To find out all
the ramdisks you have available, do a "ls -al /dev/ram*". This gives you the preset ramdisks available
to your liking. These ramdisks don't actually grab memory until you use them somehow (like formatting
them). Here is a very simple example of how to use a ramdisk.
# create a mount point:
mkdir /tmp/ramdisk0
# create a filesystem:
mke2fs /dev/ram0
# mount the ramdisk:
mount /dev/ram0 /tmp/ramdisk0

Those three commands will make a directory for the ramdisk , format the ramdisk (create a filesystem),
and mount the ramdisk to the directory "/tmp/ramdisk0". Now you can treat that directory as a pretend
partition! Go ahead and use it like any other directory or as any other partition.
If the formatting of the ramdisk faild then you might have no support for ramdisk compiled into the
Kernel. The Kernel configuration option for ramdisk is CONFIG_BLK_DEV_RAM .
The default size of the ramdisk is 4Mb=4096 blocks. You saw what ramdisk size you got while you were
running mke2fs. mke2fs /dev/ram0 should have produced a message like this:

mke2fs 1.14, 9-Jan-1999 for EXT2 FS 0.5b, 95/08/09
Linux ext2 filesystem format
Filesystem label=
1024 inodes, 4096 blocks
204 blocks (4.98%) reserved for the super user
First data block=1
Block size=1024 (log=0)
Fragment size=1024 (log=0)
1 block group
8192 blocks per group, 8192 fragments per group
1024 inodes per group

Running df -k /dev/ram0 tells you how much of that you can really use (The filesystem takes also some space):
>df -k /dev/ram0
Filesystem  1k-blocks  Used Available Use% Mounted on
/dev/ram0        3963    13      3746   0% /tmp/ramdisk0

What are some catches? Well, when the computer reboots, it gets wiped. Don't put any data there that
isn't copied somewhere else. If you make changes to that directory, and you need to keep the changes,
figure out some way to back them up.

Changing the size of the ramdisks
To use a ram disk you either need to have ramdisk support compiled into the Kernel or you need to compile
it as loadable module. The Kernel configuration option is CONFIG_BLK_DEV_RAM . Compiling the ramdisk a
loadable module has the advantage that you can decide at load time what the size of your ramdisks should be.
Okay, first the hard way. Add this line to your lilo.conf file:
   ramdisk_size=10000 (or ramdisk=10000 for old kernels)
   
and it will make the default ramdisks 10 megs after you type the "lilo" command and reboot the computer. Here
is an example of my /etc/lilo.conf file.

boot=/dev/hda
map=/boot/map
install=/boot/boot.b
prompt
timeout=50
image=/boot/vmlinuz
	label=linux
	root=/dev/hda2
	read-only
	ramdisk_size=10000
	
Actually, I got a little over 9 megs of usable space as the filesystem takes also a little space.
When you compile ramdisk support as loadable module then you can decide at load time what the size should
be. This is done either with an option line in the /etc/conf.modules file:

options rd rd_size=10000
or as a command line parameter to ismod:
insmod rd rd_size=10000
Here is an example which shows how to use the module:
Unmount the ramdisk mounted in the previous chapter, umount /tmp/ramdisk0 .
Unload the module (it was automatically loaded in the previous chapter), rmmod rd
Load the ramdisk module and set the size to 20Mb, insmod rd rd_size=20000
create a file system, mke2fs /dev/ram0
mount the ramdisk, mount /dev/ram0 /tmp/ramdisk0

Example of how to use a RamDisk for a webserver.
Okay, here is an example of how to use 3 ramdisks for a webserver. Let us say you are 99% confident that
your default installation of Apache for RedHat 6.0 won't use more than 9 megs for its cgi-scripts, html,
and icons. Here is how to install one.
First, issue this command to move the real copy of the document root directory of your webserver to a
different place. Also, make the directories to mount the ramdisks .
mv /home/httpd/ /home/httpd_real
mkdir /home/httpd
mkdir /home/httpd/cgi-bin
mkdir /home/httpd/html
mkdir /home/httpd/icons

Then, add these commands to the start procedure in your /etc/rc.d/init.d/httpd.init (or where ever the
httpd gets started on your system):

	### Make the ramdisk partitions
/sbin/mkfs -t ext2 /dev/ram0
/sbin/mkfs -t ext2 /dev/ram1
/sbin/mkfs -t ext2 /dev/ram2

	### Mount the ramdisks to their appropriate places

mount /dev/ram0 /home/httpd/cgi-bin
mount /dev/ram1 /home/httpd/icons
mount /dev/ram2 /home/httpd/html

	### Copying real directory to ramdisks (the
  ### data on the ramdisks is lost after a reboot)
tar -C /home/httpd_real -c . | tar -C /home/httpd -x

  ### After this you can start the web-server.

Comments
Please remember one thing, BACKUP YOUR DATA if you change it and you need it. When the computer reboots,
any changes are lost.

A cron job should do it. Have it check every 10 minutes and see if any files have changed and backup
any changes. Another thing you could do is make your changes to the real directory, and then copy over
the changes to the ramdisks. That is much safer.
A cool use of this would be to have a computer with 1 gig of memory and then use 256 megs for "/tmp". If
you have lots of processes that use "/tmp", it should help speed up your system. Also, anything in /tmp
would get lost when the computer reboots, which can be a good thing.
Linux uses all the memory that is not in use by programs as a unified disk-cache but my experience is
that ramdisks give you despite that still some speed increase.
Webpages maintained by the LinuxFocus Editor team
© Mark Nielsen
LinuxFocus 1999



---
http://www.jamescoyle.net/knowledge/951-the-difference-between-a-tmpfs-and-ramfs-ram-disk

THE DIFFERENCE BETWEEN A TMPFS AND RAMFS RAM DISK

Linux penguinThere are two file system types built into most modern Linux distributions which allow you
to create a RAM based storage area which can be mounted and used link a normal folder.

Before using this type of file system you must understand the benefits and problems of memory file system
in general, as well as the two different types. The two types of RAM disk file systems are tmpfs and
ramfs and each type has it’s own strengths and weaknesses.

See my other post for details on how to create a RAM disk in Linux.

What is a memory based file system (RAM disk)?
A memory based file system is something which creates a storage area directly in a computers RAM as if
it were a partition on a disk drive. As RAM is a volatile type of memory which means when the system is
restarted or crashes the file system is lost along with all it’s data.

The major benefit to memory based file systems is that they are very fast – 10s of times faster than
modern SSDs. Read and write performance is massively increased for all workload types. These types of fast
storage areas are ideally suited for applications which need repetitively small data areas for caching or
using as temporary space. As the data is lost when the machine reboots the data must not be  precious as
even scheduling backups cannot guarantee that all the data will be replicated in the even of a system crash.

tmpfs vs. ramfs
The two main RAM based file system types in Linux are tmpfs and ramfs. ramfs is the older file system
type and is largely replaced in most scenarios by tmpfs.

ramfs
ramfs creates an in memory file system which uses the same mechanism and storage space as Linux file system
cache. Running the command free in Linux will show you the amount of RAM you have on your system, including
the amount of file system cache in use. The below is an example of a 31GB of ram in a production server.

free -g
       total used free shared buffers cached
Mem:   31    29   2    0      0       8
-/+ buffers/cache: 20 11
Swap:  13    6	  7

Currently 8GB of file system cache is in use on the system. This memory is generally used by Linux to
cache recently accessed files so that the next time they are requested then can be fetched from RAM very
quickly. ramfs uses this same memory and exactly the same mechanism which causes Linux to cache files
with the exception that it is not removed when the memory used exceeds threshold set by the system.

ramfs file systems cannot be limited in size like a disk base file system which is limited by it’s
capacity. ramfs will continue using memory storage until the system runs out of RAM and likely crashes or
becomes unresponsive. This is a problem if the application writing to the file system cannot be limited
in total size. Another issue is you cannot see the size of the file system in df and it can only be
estimated by looking at the cached entry in free.

tmpfs
tmpfs is a more recent RAM file system which overcomes many of the drawbacks with ramfs. You can specify
a size limit in tmpfs which will give a ‘disk full’ error when the limit is reached. This behaviour
is exactly the same as a partition of a physical disk.

The size and used amount of space on  a tmpfs partition is also displayed in df. The below example shows
an empty 512MB RAM disk.

df -h /mnt/ramdisk
Filesystem Size Used Avail Use% Mounted on
tmpfs	   512M 0    512M  0%	/mnt/ramdisk

These two differences between ramfs and tmpfs make tmpfs much more manageable  however this is one
major drawback; tmpfs may use SWAP space. If your system runs out of physical RAM, files in your tmpfs
partitions may be written to disk based SWAP partitions and will have to be read from disk when the file
is next accessed. In some environments this can be seen as a benefit as you are less likely to get out
of memory exceptions as you could with ramfs because more ‘memory’ is available to use.

See my other post for details on how to create a RAM disk in Linux.



---
http://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux

CREATE A RAM DISK IN LINUX

Linux penguinThere are many reasons for creating a memory based file system in Linux, not least of which
is to provide a near zero latency and extremely fast area to story files. A prime use of a RAM disk is
for application caching directories or work areas.

There are two main types of RAM disk which can be used in Linux and each have their own benefits and
weaknesses:

ramfs
tmpfs

See my other post for the differences between ramfs and tmpfs.

Check the amount of free RAM you have left on your machine before creating a RAM disk. Use the Linux
command free to see the unused RAM. The below is an example of a 31GB of ram in a production server.

free -g
       total used free shared buffers cached
Mem:   31    29   2    0      0       8
-/+ buffers/cache: 20 11
Swap:  13    6	  7

The free command shows the amount of RAM availale on your system in addition to the amount of memory used,
free and used for caching. SWAP space is also displayed and shows if your system is writing memory to disk.

Create a folder to use as a mount point for your RAM disk.

mkdir /mnt/ramdisk

Then use the mount command to create a RAM disk.

mount -t [TYPE] -o size=[SIZE] [FSTYPE] [MOUNTPOINT]

Substitute the following attirbutes for your own values:
[TYPE] is the type of RAM disk to use; either tmpfs or ramfs.
[SIZE] is the size to use for the file system. Remember that ramfs does not have a physical limit and
is specified as a starting size.
[FSTYPE] is the type of RAM disk to use; either tmpfs, ramfs, ext4, etc.

Example:
mount -t tmpfs -o size=512m tmpfs /mnt/ramdisk

You can add the mount entry into /etc/fstab to make the RAM disk persist over reboots. Remember however,
that the data will disappear each time the machine is restarted.

vi /etc/fstab

tmpfs	    /mnt/ramdisk tmpfs	 nodev,nosuid,noexec,nodiratime,size=1024M   0 0


---
filename: howto_ramdisk-usage-linux_multif_20151203.txt
http://minecraft.gamepedia.com/Tutorials/Ramdisk_enabled_server

Tutorials/Ramdisk enabled server

This tutorial is intended to give you a basic understanding of what a ramdisk is, what use it is for
Minecraft and how to make a Minecraft server use a ramdisk.

Contents  [hide]
1 Ramdisk Introduction
2 Advantages and Disadvantages
2.1 Advantages
2.2 Disadvantages
3 Why it makes sense for Minecraft servers
4 Basic Minecraft and ramdisk setup
4.1 GNU/Linux (Easy Way)
4.2 GNU/Linux (alternative)

Ramdisk Introduction
Conventionally, files and directories are stored on hard disk drives which, by today's standards, offer
a lot of space at mediocre data transfer rates (between 80MB/s and 200MB/s). Ramdisks are virtual file
systems (unlike HDDs which are hardware) that live completely inside the computer's RAM. They offer
significantly higher data transfer rates (between 3,000MB/s and 15,000MB/s) at the cost of volatility
(data will be lost after restarting the computer) and space (limited by the amount of RAM installed on
the system, including swap space). Many utilities however make it possible to backup Ramdisk data at
set intervals, and before the system is shut down, then load the last data when the system starts up.

Advantages and Disadvantages
Advantages
Very high transfer speed (data to application)
Very low seek time (searching between and in files)

Disadvantages
Ramdisks will be cleared when a system restarts
Unfeasible if the world size exceeds the available RAM
Why it makes sense for Minecraft servers

In a Minecraft server, one of the strongest bottlenecks are disk I/O related operations (e.g. chunk
management). By moving the data into the RAM, access times will be near instant and data transfer rates will
be significantly faster, making chunk loading and saving much faster operations. Since a Minecraft world
currently consists of very many chunk files, seek time is equally, if not more, important for overall speed.

Basic Minecraft and ramdisk setup
Make sure to back up your files before starting!

GNU/Linux (Easy Way)
A simple way to load a minecraft server into a ramdisk was posted on the Aimless Bits blog [1] on March
12, 2011. It involves modifying the server startup script available on the wiki and making some minor
changes to fstab. This guide fleshes out the process and makes some minor changes to Aimless Bits' script.

This quick guide assumes you have a user for loading minecraft, a minecraft directory and a server
running. It also helps to be familiar with the /etc/init.d/minecraft startup script.

Firstly, start by creating a directory for the ramdisk in your home directory,
i.e. "/home/username/minecraft_ramdisk".
To mount it as a ramdisk, simply edit your /etc/fstab/ file:
sudo nano /etc/fstab

Then add this line, making sure that the path is correct (username, dir name etc.)
tmpfs  /home/username/minecraft_ramdisk tmpfs  defaults,size=512m      0       0

The size of the ramdisk MUST be larger than the minecraft directory world. Make sure that you give
yourself some overhead.

Restart your computer. The ramdisk will now be loaded every time you restart. If you wish to load
immediately, type
mount -t tmpfs none /home/username/minecraft_ramdisk -o size=512m

It's now a matter of simply running a modified script that loads the files on the drive onto the server,
copies them back on a timely basis to prevent data loss, and does backups. Again, this is a modified
version of the script found at Aimless Bits.

If you have /etc/init.d/minecraft, delete it or overwrite it with this script. If you don't, make a new
text file, call it minecraft, and copy this script into it.

#!/bin/bash
# /etc/init.d/minecraft
# version 0.6 2012-02-25 (YYYY-MM-DD)

### BEGIN INIT INFO
# Provides:   minecraft
# Required-Start: $local_fs $remote_fs
# Required-Stop:  $local_fs $remote_fs
# Should-Start:   $network
# Should-Stop:    $network
# Default-Start:  2 3 4 5
# Default-Stop:   0 1 6
# Short-Description:    Minecraft server
# Description:    Starts the minecraft server
### END INIT INFO

#Settings
JARFILE='craftbukkit-beta_1.4.6-R0.3.jar'
USERNAME="minecraft"
MCSTORE="/home/$USERNAME/minecraft"
MCPATH="/home/$USERNAME/minecraft_ramdisk"
CPU_COUNT=1
INVOCATION="java -Xmx2048M -Xms2048M -server -jar $JARFILE -o false"
BACKUPPATH="/home/$USERNAME/minecraft_backups/"
WORLD=Asgarde


as_user() {
  if [ "`whoami`" == "$USERNAME" ] ; then
    bash -c "$1"
  else
    su - $USERNAME -c "$1"
  fi
}

mc_status() {
  ps aux |grep -F -v grep|grep -F -v SCREEN|grep -F --quiet $JARFILE
  return $?
}

mc_start() {
  if mc_status; then
    echo "Tried to start but $JARFILE was already running!"
  else
    echo "$JARFILE was not running... starting."
    if [ -d $MCSTORE/$WORLD.bak ]; then
      echo "last $WORLD.bak still exist, crashed warning! manual check required!!!"
      exit 1
    fi
    cd $MCPATH
    if [ ! -f "$MCPATH/$JARFILE" ]; then
      echo "Ram drive empty...  prepping."
      as_user "cp -R $MCSTORE/* $MCPATH/"
    fi
    as_user "cd $MCPATH && screen -dmS minecraft $INVOCATION"
    sleep 7
    if mc_status; then
      echo "$JARFILE is now running."
    else
      echo "Could not start $JARFILE."
    fi
  fi
}

mc_saveoff() {
  if mc_status; then
    echo "$JARFILE is running... suspending saves"
    TO_SCREEN="screen -p 0 -S minecraft -X eval 'stuff "
    as_user "$TO_SCREEN \"say SERVER BACKUP STARTING. Server going readonly...\"\015'"
    as_user "$TO_SCREEN \"save-off\"\015'"
    as_user "$TO_SCREEN \"save-all\"\015'"
    sync
    sleep 10
  else
    echo "$JARFILE was not running. Not suspending saves."
  fi
}

mc_saveon() {
  if mc_status; then
    echo "$JARFILE is running... re-enabling saves"
    TO_SCREEN="screen -p 0 -S minecraft -X eval 'stuff "
    as_user "$TO_SCREEN \"save-on\"\015'"
    as_user "$TO_SCREEN \"say SERVER BACKUP ENDED. Server going read-write...\"\015'"
  else
    echo "$JARFILE was not running. Not resuming saves."
  fi
}

mc_stop() {
  if mc_status; then
    echo "$JARFILE is running... stopping."
    TO_SCREEN="screen -p 0 -S minecraft -X eval 'stuff "
    as_user "$TO_SCREEN \"say SERVER SHUTTING DOWN IN 5 SECONDS. Saving map...\"\015'"
    as_user "$TO_SCREEN \"save-all\"\015'"
    sleep 5
    as_user "$TO_SCREEN \"stop\"\015'"
    sleep 5
  else
    echo "$JARFILE was not running."
  fi

  if mc_status; then
    echo "$JARFILE could not be shut down... still running."
  else
    echo "$JARFILE is shut down."
  fi
}


mc_update() {
  if mc_status; then
    echo "$JARFILE is running! Will not start update."
  else
    MC_SERVER_URL=http://minecraft.net/`wget -q -O - http://www.minecraft.net/download.jsp | grep
    minecraft_server.jar\</a\> | cut -d \" -f 2`
    as_user "cd $MCPATH && wget -q -O $MCPATH/minecraft_server.jar.update $MC_SERVER_URL"
    if [ -f $MCPATH/minecraft_server.jar.update ]; then
      if `diff $MCPATH/$JARFILE $MCPATH/minecraft_server.jar.update >/dev/null`
     then
       echo "You are already running the latest version of $JARFILE."
     else
       as_user "mv $MCPATH/minecraft_server.jar.update $MCPATH/$JARFILE"
       echo "Minecraft successfully updated."
      fi
    else
      echo "Minecraft update could not be downloaded."
    fi
  fi
}

mc_backup() {
   echo "Backing up minecraft files"
   as_user "tar zcf $BACKUPPATH/MCBKUP_`date "+%Y.%m.%d-%H"`.tar.gz $MCSTORE"
   echo "Backup complete"
}

mc_disksaverun() {
  if mc_status; then
    echo "Saving ramdrive to disk."
    if [ ! -f $MCPATH/$JARFILE ]; then
      echo "Error.. Minecraft not in ram"
    else
      if [ -d $MCSTORE/$WORLD.bak ]; then
        echo "last $WORLD.bak still exist, crashed warning! manual check required!!!"
        exit 1
      fi
      if [ -d $MCSTORE/$WORLD ]; then
        as_user "mv $MCSTORE/$WORLD $MCSTORE/$WORLD.bak"
      fi

      TO_SCREEN="screen -p 0 -S minecraft -X eval 'stuff "
      as_user "$TO_SCREEN \"save-off\"\015'"
      as_user "$TO_SCREEN \"save-all\"\015'"
      as_user "cp -R $MCPATH/* $MCSTORE/"
      as_user "$TO_SCREEN \"save-on\"\015'"

      if [ -d $MCSTORE/$WORLD.bak ]; then
        as_user "rm -r $MCSTORE/$WORLD.bak"
      fi
    fi
  else
    echo "Service is not running"
 fi

}

mc_disksavehalt() {
   echo "Saving ramdrive to disk."
   if [ ! -f $MCPATH/$JARFILE ]; then
     echo "Error.. Minecraft not in ram"
   else
     if [ -d $MCSTORE/$WORLD.bak ]; then
        echo "last $WORLD.bak still exist, crashed warning! manual check required!!!"
        exit 1
     fi
     if [ -d $MCSTORE/$WORLD ]; then
       as_user "mv $MCSTORE/$WORLD $MCSTORE/$WORLD.bak"
     fi

     echo "Saving, screen session closed"
     as_user "cp -R $MCPATH/* $MCSTORE/"

     if [ -d $MCSTORE/$WORLD.bak ]; then
       as_user "rm -r $MCSTORE/$WORLD.bak"
     fi
   fi
}


#Start-Stop here
case "$1" in
  start)
    mc_start
    ;;
  stop)
    mc_stop
    mc_disksavehalt
    ;;
  restart)
    mc_stop
    mc_disksavehalt
    mc_start
    ;;
  update)
    mc_stop
    mc_backup
    mc_update
    mc_start
    ;;
  backup)
    mc_disksaverun
    mc_saveoff
    mc_backup
    mc_saveon
    ;;
  disksavehalt)
    mc_disksavehalt
    ;;
  disksaverun)
    mc_disksaverun
    ;;
  status)
    if mc_status; then
      echo "$JARFILE is running."
    else
      echo "$JARFILE is not running."
    fi
    ;;
  *)
  echo "Usage: /etc/init.d/minecraft {start|stop|update|backup|status|restart|disksaverun}"
  exit 1
  ;;
esac

Move this script into your /etc/init.d/ directory, and make it executable:
mv /directory/wherefileis/filename /etc/init.d/minecraft
chmod a+x /etc/init.d/minecraft

Note: This script misses the command option that the other minecraft init script has on this website,
http://www.minecraftwiki.net/wiki/Server_startup_script Therefor I rewrote the script with the command code
in it, so ramdisk servers can also use th command thing to sync things without having to get another plugin
to schedule things: http://pastebin.com/4ynwL2js Hope someone can use this, if they need the command option.

You're almost done! This script behaves exactly like the standard startup script, only that it takes
care of loading and maintaining the ramdisk. You can also modify the script to use rsync instead of cp

"rsync -r -t $MCSTORE/ $MCPATH/"
in case you want to do other things, such as remote copying, but performance differences are probably
negligible unless you have very big worlds.

DO NOT SKIP THIS STEP. You need to add a crontab entry to save your world. See below for specific reasons,
but you run the risk of losing data if you don't do this. This script has two disk save functions,
disksavehalt and disksaverun. Disksavehalt assumes the screen session is closing or backing up, and thus
does not disable level saving. Do NOT call this function in crontab. Use disksave run instead. To do this
sudo crontab -e
Then add the line:

*/5 * * * * /etc/init.d/minecraft disksaverun
20 */6 * * * /etc/init.d/minecraft backup

The number represents how often in minutes should you save the world. If you feel like you have a robust
setup, power supply backups and the whole shebang, run this less frequently. Otherwise, stick to 5
minutes at the least!

The other line runs minecraft backup every 6 hours, at :20. Don't skimp on backups! You've been warned!

Hope this helps all those would be admins out there. Good luck!

GNU/Linux (alternative)
On most GNU/Linux distributions there is already a ramdisk set up (usually mounted to /dev/shm (shared
memory)) which defaults to using at most half of your total installed RAM. If there is not one already
set up, resources on how to do it are widely available on the Internet.

It is possible to move anything into the ramdisk, but here I will focus on just moving the map into it
and leaving the server files on the conventional drive.

Given the following basic server directory "minecraft_server/", inside a user's home directory, containing
the world "world" and all other required files

~/minecraft_server/
world/
minecraft_server.jar
server.log
server.properties
...

We will want to move "world/" into the shared memory. Because of the volatility of ramdisks, we will also
want to create a new folder into which an automated script will periodically save the current snapshot
of the world, called (for example) "world_storage" by copying the current world to a new name

$ cd ~/minecraft_server/
$ cp -r world/ world_storage/

Now with the old world in a safe location, we can go ahead and move the world into the ram-disk

$ mkdir /dev/shm/minecraft
$ mv world/ /dev/shm/minecraft

By now, the world is loaded into the RAM, but the Minecraft server doesn't see it in its directory anymore,
causing it to recreate it when started. To stop it from doing that, we have to create a symbolic link
to the world in the ramdisk by running

$ ln -s /dev/shm/minecraft/world/ .

This will create a link to "/dev/shm/minecraft/world/" called "world/" in the server's directory, which
the server will use like the actual world folder, but now inside the RAM.

Now we need to take care of the volatility of the ramdisk, by periodically saving the world from the
RAM into "world_storage/". I'm going to use cron for scheduling and rsync for synching here.

First, we need a script that can be called by cron (it doesn't have to be a script, you could call rsync
directly from the cron command line, but this allows for easy customizing later on)

#!/bin/sh

VOLATILE="/home/$USER/minecraft_server/world/"
PERMANENT="/home/$USER/minecraft_server/world_storage/"

#TODO: Check if both directories actually exist, skipped here for clearness
rsync -r -t -v "$VOLATILE" "$PERMANENT"

And then we need to make this script execute every few minutes (I'll use 5 minutes here, you can test
out what works best for you)

$ crontab -e
You will be put into an editor (more precisely: the editor in your "EDITOR" environment variable) for
editing your user cron table. Add the following line:

*/5 * * * * bash /home/<your_username>/minecraft_server/save_world.sh &>/dev/null

Now if your server restarts you will need to recreate the world folder (/dev/shm/minecraft) then
(/dev/shm/minecraft/world) in the shared memory because the /dev/shm/ empties after restart,. You can
do this by making another similar shell script.

So make a shell script file like before:

exec 1>/tmp/backup_world.log 2>&1 #sends the output to this file
#!/bin/sh
#remake the paths
mkdir /dev/shm/minecraft
mkdir /dev/shm/minecraft/world

VOLATILE="/home/$USER/minecraft_server/world/"
PERMANENT="/home/$USER/minecraft_server/world_storage/"

#TODO: Check if both directories actually exist, skipped here for clearness
#reversed the order
rsync -r -t -v "$PERMANENT" "$VOLATILE"

Everytime you restart you need to run this script to remount the Ramdisk. Do not add this to the
crontab. You can add this to the start up if you figure it out.



---
http://superuser.com/questions/870763/mysql-data-on-ramdisk-partition

MySQL data on ramdisk partition
I'm using Docker with Ubuntu for my CI and development environment. I would like to put the database on
a ramdisk partition to speed up the builds, since I have to reload my fixtures a lot, so data persistence
isn't an issue here.

Is that possible? What steps I should add to my Docker file?

***
Here is excerpt from my post in the DBA StackExchange

RAMDISK_SIZE=32g
service mysql stop
mkdir /var/tmpfs
echo "none   /var/tmpfs  tmpfs  defaults,size=${RAMDISK_SIZE} 1 2" >> /etc/fstab
mount -t tmpfs -o size=${RAMDISK_SIZE} none /var/tmpfs
cp -R /var/lib/mysql/* /var/tmpfs
mv /var/lib/mysql /var/lib/mysql_old
ln -s /var/tmpfs /var/lib/mysql
chown -R mysql:mysql /var/tmpfs
chown -R mysql:mysql /var/lib/mysql
service mysql start
I hope you can apply it to Ubuntu

Give it a Try !!!



---
https://wiki.ubuntu.com/BootToRAM

BootToRAM

Booting Ubuntu To RAM
Unnecessary on 11.04 LiveCD. Casper now includes a functioning toram option, which even works with the
iso-scan/filename= option.

Last update for 9.10 compability.

Latest update for 2.6.31-16 upgrade

Preface
This article aims to document the process of creating a customized Ubuntu that loads an image from the
hard disk to RAM, then boots an entire Ubuntu session out of RAM. It is intended for intermediate to
advanced Ubuntu users who are familiar with the shell, and may have limited experience customizing the
livecd (LiveCDCustomization) and shell scripting. We will customize a LiveCD and copy it to the hard
drive, and make a few modifications to bootup scripts so that it copies to RAM via our good friend tmpfs.

WARNING: The author asserts that this procedure works for him, but cannot guarantee that this procedure
works for anyone else. Although this procedure is meant to be 100% safe, it is feasible that there may be
mistakes, or a chance of misunderstanding the instructions in a manner that causes loss of data. Please
make a backup and do not attempt on mission critical systems. Read through this article thoroughly,
and do not attempt if you do not comprehend or feel comfortable about any of the instructions!

CAUTION: I hope this is intuitively obvious, but I'll humor you and state it bluntly: Changes you make
under the live session are NOT saved and WILL BE LOST when you reboot or shut down. Don't save anything
important to the "home directory" and expect it to still be around! If you want to save data permanently,
mount a permanent medium (such as your hard drive), plug in a thumbdrive, or use some network functionality
built into Ubuntu to save your data to a non-volatile destination.

Use Cases
There are many cases where one would like to boot Ubuntu to RAM:

Performance: The desktop performance is dramatically improved. A 400MB squashed filesystem in RAM, that
holds 1200MB of data, is read back on a 1.6GHz Core Duo in about 3 seconds, including decompression time.
Power, Noise, Durability: Although modern hard disks don't use much power compared to other system
components, this may still be important for some. In laptops, hard disks are often the noisiest components,
so this setup can reduce system noise. With the hard disk spun down, a laptop can potentially withstand
greater shocks without damage.

Abrupt poweroff: Since the hard disk is only momentarily used in read-only mode during boot, then never
touched again, there are few or no negative consequences of an abrupt poweroff. If a system is used where
power is inconsistent, or the system is regularly used in a context where fast shutoffs are required,
this is very handy.

Privacy: Anything you do in this session are lost when you reboot or power off. This is great for kiosks
or other systems where permanent modification are not desired. (Note that by default the livecd user has
full sudo access, so potentially a malicious user can still make permanent changes by mounting the hard
drive and following this HOWTO)

Requirements
The most obvious increased requirement is RAM. For best performance, I recommend having 256MB RAM +
enough RAM to hold a customized image. Stripping Openoffice and some fonts and documentation from a stock
Ubuntu LiveCD results in a 400MB compressed image, which fits in RAM comfortably on a system with 1GB RAM.

Tmpfs can fall back on swap (Ubuntu LiveCD scripts will mount any swap it finds), which is excellent
for a bit of overflow, but if you regularly need to fall back on swap, performance will naturally suffer.

I have not investigated CPU requirements, but squashfs is compressed and decompressing takes some CPU
power, so this is probably not a great idea on systems older than the Pentium III era.

As far as setting this system up, the requirements would be:
Having an Ubuntu LiveCD ISO or CD handy. I used a Ubuntu LiveCD, but I see no reason why Xubuntu,
Kubuntu, etc wouldn't work (they don't have differing casper boot scripts, as far as I know). This
procedure should work on all LiveCD's Dapper and later, with appropriate minor adaptations.
About 2-4GB of free space

A combined 1GB or so of RAM and swap available.

The Process

Unpack LiveCD
First, we need to unpack the LiveCD for customization. For this article, I am going to make the following
assumptions about paths. You can of course reject my choices and substitute your own.

The compressed root image is at /casper/filesystem.squashfs
The kernel is at /casper/vmlinuz
The initramfs is at /casper/initrd.gz
We will make a temporary directory /casper/chroot where we edit this root filesystem.
For the first 3 files are located in /casper on the LiveCD. Please copy these files from the LiveCD to
/casper on your hard disk. You may use the GNOME archive manager (file-roller) as root, bind-mounting,
or a physical CD. I will assume you know how to do this.

Customize Live Environment
This procedure is almost identical to customizing a LiveCD (up to the generation of the .squashfs
image). Please see LiveCDCustomization for detailed instructions on customizing the LiveCD. I will only
be providing a basic rundown on the process.

EXTRACT /CASPER/FILESYSTEM.SQUASHFS TO /CASPER/CHROOT/
sudo mount -o loop -t squashfs /casper/filesystem.squashfs /mnt
sudo mkdir /casper/chroot
sudo rsync -ax /mnt/. /casper/chroot/.
sudo umount /mnt

PATCH BOOT SCRIPTS
The stock casper "toram" functionality is broken in Feisty. In addition, even when it worked, it would
completely decompress the filesystem into RAM, which requires 3-4x more RAM, and is hence undesired. As
a result, we will be providing some nasty hacks on casper to make it copy to RAM the way we want it
to. Casper developers, please look away.

gksu gedit /casper/chroot/usr/share/initramfs-tools/scripts/casper

Around line 35, find:

                export SHOWMOUNTS='Yes' ;;
            persistent)
	    
Between them add extra two lines, so it looks like:

                export SHOWMOUNTS='Yes' ;;
            toram)
                export TORAM='Yes' ;;
            persistent)
	    
Around line 573, find:

    if [ "${TORAM}" ]; then
        live_dest="ram"
    elif [ "${TODISK}" ]; then
    
Between them add some extra lines, like this:

    if [ "${TORAM}" ]; then
        #live_dest="ram"
        echo "Copying CD contents to ram"
        mkdir /store
        #TODO: add a test for amount of ram here
        mount -t tmpfs -o size=1G none /store
        mkdir /store/casper
        cp /cdrom/casper/*.squashfs /store/casper/
        echo "CD-Rom has been unmounted, it's safe to eject!"
        umount /cdrom
        mount -o bind /store /cdrom

    elif [ "${TODISK}" ]; then
    
You need to comment or delete live_dest="ram". Replace "-o size=1G" with a larger (or smaller) size if
your customized image is not 1GB (for example, 2G, 1500M, or 350M). Look at the size of your squashfs
image to determine the required size.

Save this file, and quit the editor.

REGENERATE INITRD.GZ
Since we edited bootup scripts, we need to regenerate the file we know as /casper/initrd.gz to incorporate
these changes:

sudo cp -L /etc/resolv.conf /casper/chroot/etc/
sudo mount -t proc none /casper/chroot/proc
sudo mount -o bind /dev /casper/chroot/dev
sudo chroot /casper/chroot /bin/bash

At this point, you are "in" the live environment's filesystem. We will be doing this a few more times
before the day is over. Remember that our Live environment is at /casper/chroot, not at edit/ (adjust
customization commands accordingly).

Optional: Customize Live Environment Further
It would be a great idea to add or remove some packages, or add some default user settings, etc, to make
the live environment friendlier. The previously linked LiveCD customization article provides full details
on how to do a wide variety of customizations. Follow those instructions, up to: "Putting the CD together"
(don't do that step). Instead, replace it with

Ideas for customizations specific to this howto include:
Removing behemoth packages like OpenOffice.
Adding proprietary 3D video drivers by default (TODO: expand on this idea)
Removing shutdown scripts (TODO: expand)
Customizing user default settings in /etc/skel, including importing a firefox profile, etc. The LiveCD
howto roughly states how to do this. (TODO: expand)
Suppress the eject notice at shutdown.

rm /etc/rc?.d/*casper*

Install something like sshfs so you can easily use SSH-able systems as permanent storage (TODO: Expand)
Upgrade the whole system and regenerate initrd.gz

apt-get update
apt-get dist-upgrade
apt-get autoclean
apt-get autoremove
apt-get clean
mkinitramfs -o /new-initrd.gz 2.6.31-16-generic
exit
umount -l /casper/chroot/dev
umount -l /casper/chroot/proc

The mkinitramfs command may take 30 seconds to a few minutes, depending on your CPU speed. The exit
command will take you back to your original shell, that's not within with live environment. Now we will
move this initrd to the right spot:

sudo mv /casper/chroot/new-initrd.gz /casper/initrd.gz
sudo mksquashfs /casper/chroot /casper/filesystem.squashfs -noappend -always-use-fragments

The always-use-fragments argument allows space to be used more efficiently, at the cost of more
seeking. Since our image is to be loaded into RAM, seeking is costless and not a concern as opposed to
on a mechanical medium.

Make a GRUB Entry
Ok, the last thing we need to do is tell GRUB how to boot this system. Read Making a GRUB bootable
CD-ROM first.

Edit /boot/grub/menu.lst to include an entry like this at the bottom:

title Jaunty RAM Session
kernel /casper/vmlinuz boot=casper toram splash
initrd /casper/initrd.gz

Reboot and Enjoy

Now, it's time to reboot and select Jaunty RAM Session, and see if it works out. If the system does not
boot, then double-check you followed all the instructions properly. It took me about 10 or 11 customization
cycles to get my live system JUST the way I like it, so be patient!

Remember, the possibilities are endless! Enjoy, and share any cool things you do with this HOWTO!

Comments
Why don't you work on bug #25496: toRam or copy2Ram (run ubuntu live from ram), to make this feature in
the default Ubuntu livecd? https://bugs.edge.launchpad.net/ubuntu/+source/casper/+bug/25496

Any idea on how to get this to work with "iso-scan/filename=" option? It loads everything to RAM fine,
but won't let me unmount /isodevice (probably because a loopback device needs to be killed). I can't
seem to find which script creates the loopback nor where to destroy it and unmount the /isodevice folder.

Lucid Updates
For trying this out in Lucid, it's easier to just go into edit mode in grub2 having booted the live
cd/usb and change the options to

kernel /casper/vmlinuz boot=casper toram splash
initrd /casper/initrd.gz

Else you'll need to get grub legacy packages and use that to create the grub install cd stage2_eltorito
can be extracted from http://packages.ubuntu.com/lucid/i386/grub/download

When making the iso use -J option to Generate Joliet directory information so that you can use
usb-creator-gtk (Startup disk creator) and not waste CDs!

mkisofs -R -J -b boot/grub/stage2_eltorito -no-emul-boot \
         -boot-load-size 4 -boot-info-table -o grub.iso iso
	 
Pitfalls:
remember to set permissions on all the files before you create the iso as these will be honored when imaged
Make sure your chroot doesn't end up on the iso
Variations:

loading the squashfs from a cheap usb stick or cd can be slow, so if you do have a hard drive use that
instead e.g.

if [ "${TORAM}" ]; then
#live_dest="ram"
      echo "Copying contents to ram.."
      mkdir /store
      mount -t tmpfs -o size=2G none /store
      mkdir /store/casper
      mkdir /mnt
      
# A use for my old windows recovery partition!
      mount /dev/sda3 /mnt/
      cp /mnt/casper/*.squashfs /store/casper/
      echo "Copy done.. safe to eject boot medium"
      umount /cdrom
      umount /mnt
      mount -o bin /store /cdrom

    elif [ "${TODISK}" ]; then
	BootToRAM

(nazadnje spreminjano 2011-07-18 07:35:36, spreminjal ubuntu-launchpad-bobpaul)



---
http://blog.csdn.net/wang_xya/article/details/43410651

Ubuntu using Ramdisk for better performance and fast response
ubunturamdisk
2015-02-02 16:56 217

Ubuntu using Ramdisk for better performance and fast response
I have written a tutorial about speed up Ubuntu response time by optimizing the usage of swap area, and
that’s avoiding swapping processes out of physical memory for as long as possible. Here’s another
way using ramdisk to get better performance and fast response for Ubuntu.

Ramdisk is part of system memory. Ubuntu by default uses a half of physical memory (RAM) as ramdisk,
and it is mounted onto /dev/shm, it can be used just like normal disk space (create files and folders and
manipulate them with better performance rather if they were stored on the hard disk). If ramdisk uses more
than a half of RAM, data will be moved into the swap space. If ramdisk uses less, the remaining can still do
what RAM’s doing.

Set upper limit of ramdisk
As is said above, ramdisk by default can use a half of RAM. If you want to change the upper limit,
follow the steps below:

1. Edit /etc/fstab by your favourate editor:
gksudo gedit /etc/fstab

2. Find this line and change to make it looks like this(add this line if not exist, and change 512M to
what you like.):
tmpfs /dev/shm tmpfs defaults,size=512M 0 0

3. Reboot or re-mount
/dev/shm
.

Mount /tmp onto ramdisk
To make it easy to use, you can mount a directory into
/dev/shm

by following commands:
mkdir /dev/shm/tmp
chmod 1777 /dev/shm/tmp
mount --bind /dev/shm/tmp /tmp


---
filename: initrd_linux-initial-ram-disk_20170302.txt
https://www.ibm.com/developerworks/library/l-initrd/

Linux initial RAM disk (initrd) overview

What's an initial RAM disk?
   The initial RAM disk (initrd) is an initial root file system that is mounted prior to when the real
   root file system is available. The initrd is bound to the kernel and loaded as part of the kernel
   boot procedure. The kernel then mounts this initrd as part of the two-stage boot process to load the
   modules to make the real file systems available and get at the real root file system.

   The initrd contains a minimal set of directories and executables to achieve this, such as the insmod
   tool to install kernel modules into the kernel.

   In the case of desktop or server Linux systems, the initrd is a transient file system. Its lifetime
   is short, only serving as a bridge to the real root file system. In embedded systems with no mutable
   storage, the initrd is the permanent root file system. This article explores both of these contexts.

Anatomy of the initrd
   The initrd image contains the necessary executables and system files to support the second-stage boot
   of a Linux system.

   Depending on which version of Linux you're running, the method for creating the initial RAM disk can
   vary. Prior to Fedora Core 3, the initrd is constructed using the loop device. The loop device is a
   device driver that allows you to mount a file as a block device and then interpret the file system it
   represents. The loop device may not be present in your kernel, but you can enable it through the
   kernel's configuration tool (make menuconfig) by selecting Device Drivers > Block Devices > Loopback
   Device Support. You can inspect the loop device as follows (your initrd file name will vary):

Listing 1. Inspecting the initrd (prior to FC3)
# mkdir temp ; cd temp
# cp /boot/initrd.img.gz .
# gunzip initrd.img.gz
# mount -t ext -o loop initrd.img /mnt/initrd
# ls -la /mnt/initrd
#

   You can now inspect the /mnt/initrd subdirectory for the contents of the initrd. Note that even if
   your initrd image file does not end with the .gz suffix, it's a compressed file, and you can add the
   .gz suffix to gunzip it.

   Beginning with Fedora Core 3, the default initrd image is a compressed cpio archive file. Instead of
   mounting the file as a compressed image using the loop device, you can use a cpio archive. To inspect
   the contents of a cpio archive, use the following commands:

Listing 2. Inspecting the initrd (FC3 and later)
# mkdir temp ; cd temp
# cp /boot/initrd-2.6.14.2.img initrd-2.6.14.2.img.gz
# gunzip initrd-2.6.14.2.img.gz
# cpio -i --make-directories < initrd-2.6.14.2.img
#

   The result is a small root file system, as shown in Listing 3. The small, but necessary, set of
   applications are present in the ./bin directory, including nash (not a shell, a script interpreter),
   insmod for loading kernel modules, and lvm (logical volume manager tools).

Listing 3. Default Linux initrd directory structure
# ls -la
#
drwxr-xr-x  10 root root    4096 May 7 02:48 .
drwxr-x---  15 root root    4096 May 7 00:54 ..
drwxr-xr-x  2  root root    4096 May 7 02:48 bin
drwxr-xr-x  2  root root    4096 May 7 02:48 dev
drwxr-xr-x  4  root root    4096 May 7 02:48 etc
-rwxr-xr-x  1  root root     812 May 7 02:48 init
-rw-r--r--  1  root root 1723392 May 7 02:45 initrd-2.6.14.2.img
drwxr-xr-x  2  root root    4096 May 7 02:48 lib
drwxr-xr-x  2  root root    4096 May 7 02:48 loopfs
drwxr-xr-x  2  root root    4096 May 7 02:48 proc
lrwxrwxrwx  1  root root       3 May 7 02:48 sbin -> bin
drwxr-xr-x  2  root root    4096 May 7 02:48 sys
drwxr-xr-x  2  root root    4096 May 7 02:48 sysroot
#

   Of interest in Listing 3 is the init file at the root. This file, like the traditional Linux boot
   process, is invoked when the initrd image is decompressed into the RAM disk. We'll explore this later
   in the article.

Tools for creating an initrd
   The cpio command
   Using the cpio command, you can manipulate cpio files. Cpio is also a file format that is simply a
   concatenation of files with headers. The cpio file format permits both ASCII and binary files. For
   portability, use ASCII. For a reduced file size, use the binary version.

   Let's now go back to the beginning to formally understand how the initrd image is constructed in the
   first place. For a traditional Linux system, the initrd image is created during the Linux build
   process. Numerous tools, such as mkinitrd, can be used to automatically build an initrd with the
   necessary libraries and modules for bridging to the real root file system. The mkinitrd utility is
   actually a shell script, so you can see exactly how it achieves its result. There's also the YAIRD
   (Yet Another Mkinitrd) utility, which permits customization of every aspect of the initrd
   construction.

Manually building a custom initial RAM disk
   Because there is no hard drive in many embedded systems based on Linux, the initrd also serves as the
   permanent root file system. Listing 4 shows how to create an initrd image. I'm using a standard Linux
   desktop so you can follow along without an embedded target. Other than cross-compilation, the
   concepts (as they apply to initrd construction) are the same for an embedded target.

Listing 4. Utility (mkird) to create a custom initrd
#!/bin/bash

# Housekeeping...
rm -f /tmp/ramdisk.img
rm -f /tmp/ramdisk.img.gz

# Ramdisk Constants
RDSIZE=4000
BLKSIZE=1024

# Create an empty ramdisk image
dd if=/dev/zero of=/tmp/ramdisk.img bs=$BLKSIZE count=$RDSIZE

# Make it an ext2 mountable file system
/sbin/mke2fs -F -m 0 -b $BLKSIZE /tmp/ramdisk.img $RDSIZE

# Mount it so that we can populate
mount /tmp/ramdisk.img /mnt/initrd -t ext2 -o loop=/dev/loop0

# Populate the filesystem (subdirectories)
mkdir /mnt/initrd/bin
mkdir /mnt/initrd/sys
mkdir /mnt/initrd/dev
mkdir /mnt/initrd/proc

# Grab busybox and create the symbolic links
pushd /mnt/initrd/bin
cp /usr/local/src/busybox-1.1.1/busybox .
ln -s busybox ash
ln -s busybox mount
ln -s busybox echo
ln -s busybox ls
ln -s busybox cat
ln -s busybox ps
ln -s busybox dmesg
ln -s busybox sysctl
popd

# Grab the necessary dev files
cp -a /dev/console /mnt/initrd/dev
cp -a /dev/ramdisk /mnt/initrd/dev
cp -a /dev/ram0 /mnt/initrd/dev
cp -a /dev/null /mnt/initrd/dev
cp -a /dev/tty1 /mnt/initrd/dev
cp -a /dev/tty2 /mnt/initrd/dev

# Equate sbin with bin
pushd /mnt/initrd
ln -s bin sbin
popd

# Create the init file
cat >> /mnt/initrd/linuxrc << EOF
#!/bin/ash
echo
echo "Simple initrd is active"
echo
mount -t proc /proc /proc
mount -t sysfs none /sys
/bin/ash --login
EOF

chmod +x /mnt/initrd/linuxrc

# Finish up...
umount /mnt/initrd
gzip -9 /tmp/ramdisk.img
cp /tmp/ramdisk.img.gz /boot/ramdisk.img.gz

   An initrd Linux distribution
   An interesting open source project that was designed to be a Linux distribution that fits within an
   initrd is Minimax. It's 32MB in size and uses BusyBox and uClibc for its ultra small size. Despite
   its small size, it's a 2.6 Linux kernel with a large array of useful tools.

   To create an initrd, begin by creating an empty file, using /dev/zero (a stream of zeroes) as input
   writing to the ramdisk.img file. The resulting file is 4MB in size (4000 1K blocks). Then use the
   mke2fs command to create an ext2 (second extended) file system using the empty file. Now that this
   file is an ext2 file system, mount the file to /mnt/initrd using the loop device. At the mount point,
   you now have a directory that represents an ext2 file system that you can populate for your initrd.
   Much of the rest of the script provides this functionality.

   The next step is creating the necessary subdirectories that make up your root file system: /bin,
   /sys, /dev, and /proc. Only a handful are needed (for example, no libraries are present), but they
   contain quite a bit of functionality.

   Alternative to the ext2 file system
   While ext2 is a common Linux file system format, there are alternatives that can reduce the size of
   the initrd image and the resulting mounted file systems. Examples include romfs (ROM file system),
   cramfs (compressed ROM file system), and squashfs (highly compressed read-only file system). If you
   need to transiently write data to the file system, ext2 works fine. Finally, the e2compr is an
   extension to the ext2 file system driver that supports online compression.

   To make your root file system useful, use BusyBox. This utility is a single image that contains many
   individual utilities commonly found in Linux systems (such as ash, awk, sed, insmod, and so on). The
   advantage of BusyBox is that it packs many utilities into one while sharing their common elements,
   resulting in a much smaller image. This is ideal for embedded systems. Copy the BusyBox image from
   its source directory into your root in the /bin directory. A number of symbolic links are then
   created that all point to the BusyBox utility. BusyBox figures out which utility was invoked and
   performs that functionality. A small set of links are created in this directory to support your init
   script (with each command link pointing to BusyBox).

   The next step is the creation of a small number of special device files. I copy these directly from
   my current /dev subdirectory, using the -a option (archive) to preserve their attributes.

   The penultimate step is to generate the linuxrc file. After the kernel mounts the RAM disk, it
   searches for an init file to execute. If an init file is not found, the kernel invokes the linuxrc
   file as its startup script. You do the basic setup of the environment in this file, such as mounting
   the /proc file system. In addition to /proc, I also mount the /sys file system and emit a message to
   the console. Finally, I invoke ash (a Bourne Shell clone) so I can interact with the root file
   system. The linuxrc file is then made executable using chmod.

   Finally, your root file system is complete. It's unmounted and then compressed using gzip. The
   resulting file (ramdisk.img.gz) is copied to the /boot subdirectory so it can be loaded via GNU GRUB.

   To build the initial RAM disk, you simply invoke mkird, and the image is automatically created and
   copied to /boot.

Testing the custom initial RAM disk
   Initrd support in the Linux kernel
   For the Linux kernel to support the initial RAM disk, the kernel must be compiled with the
   CONFIG_BLK_DEV_RAM and CONFIG_BLK_DEV_INITRD options.

   Your new initrd image is in /boot, so the next step is to test it with your default kernel. You can
   now restart your Linux system. When GRUB appears, press the C key to enable the command-line utility
   within GRUB. You can now interact with GRUB to define the specific kernel and initrd image to load.
   The kernel command allows you to define the kernel file, and the initrd command allows you to specify
   the particular initrd image file. When these are defined, use the boot command to boot the kernel, as
   shown in Listing 5.

Listing 5. Manually booting the kernel and initrd using GRUB
    GNU GRUB  version 0.95  (638K lower / 97216K upper memory)

[ Minimal BASH-like line editing is supported. For the first word, TAB
  lists possible command completions. Anywhere else TAB lists the possible
  completions of a device/filename. ESC at any time exits.]

grub> kernel /bzImage-2.6.1
   [Linux-bzImage, setup=0x1400, size=0x29672e]

grub> initrd /ramdisk.img.gz
   [Linux-initrd @ 0x5f2a000, 0xb5108 bytes]

grub> boot

Uncompressing Linux... OK, booting the kernel.
   After the kernel starts, it checks to see if an initrd image is available (more on this later), and
   then loads and mounts it as the root file system. You can see the end of this particular Linux
   startup in Listing 6. When started, the ash shell is available to enter commands. In this example, I
   explore the root file system and interrogate a virtual proc file system entry. I also demonstrate
   that you can write to the file system by touching a file (thus creating it). Note here that the first
   process created is linuxrc (commonly init).

Listing 6. Booting a Linux kernel with your simple initrd
...
md: Autodetecting RAID arrays
md: autorun
md: ... autorun DONE.
RAMDISK: Compressed image found at block 0
VFS: Mounted root (ext2 file system).
Freeing unused kernel memory: 208k freed
/ $ ls
bin         etc       linuxrc       proc        sys
dev         lib       lost+found    sbin
/ $ cat /proc/1/cmdline
/bin/ash/linuxrc
/ $ cd bin
/bin $ ls
ash      cat      echo     mount    sysctl
busybox  dmesg    ls       ps
/bin $ touch zfile
/bin $ ls
ash      cat      echo     mount    sysctl
busybox  dmesg    ls       ps       zfile

Booting with an initial RAM disk
   Now that you've seen how to build and use a custom initial RAM disk, this section explores how the
   kernel identifies and mounts the initrd as its root file system. I walk through some of the major
   functions in the boot chain and explain what's happening.

   The boot loader, such as GRUB, identifies the kernel that is to be loaded and copies this kernel
   image and any associated initrd into memory. You can find much of this functionality in the ./init
   subdirectory under your Linux kernel source directory.

   After the kernel and initrd images are decompressed and copied into memory, the kernel is invoked.
   Various initialization is performed and, eventually, you find yourself in init/main.c:init()
   (subdir/file:function). This function performs a large amount of subsystem initialization. A call is
   made here to init/do_mounts.c:prepare_namespace(), which is used to prepare the namespace (mount the
   dev file system, RAID, or md, devices, and, finally, the initrd). Loading the initrd is done through
   a call to init/do_mounts_initrd.c:initrd_load().

   The initrd_load() function calls init/do_mounts_rd.c:rd_load_image(), which determines the RAM disk
   image to load through a call to init/do_mounts_rd.c:identify_ramdisk_image(). This function checks
   the magic number of the image to determine if it's a minux, etc2, romfs, cramfs, or gzip format. Upon
   return to initrd_load_image, a call is made to init/do_mounts_rd:crd_load(). This function allocates
   space for the RAM disk, calculates the cyclic redundancy check (CRC), and then uncompresses and loads
   the RAM disk image into memory. At this point, you have the initrd image in a block device suitable
   for mounting.

   Mounting the block device now as root begins with a call to init/do_mounts.c:mount_root(). The root
   device is created, and then a call is made to init/do_mounts.c:mount_block_root(). From here,
   init/do_mounts.c:do_mount_root() is called, which calls fs/namespace.c:sys_mount() to actually mount
   the root file system and then chdir to it. This is where you see the familiar message shown in
   Listing 6: VFS: Mounted root (ext2 file system).

   Finally, you return to the init function and call init/main.c:run_init_process. This results in a
   call to execve to start the init process (in this case /linuxrc). The linuxrc can be an executable or
   a script (as long as a script interpreter is available for it).

   The hierarchy of functions called is shown in Listing 7. Not all functions that are involved in
   copying and mounting the initial RAM disk are shown here, but this gives you a rough overview of the
   overall flow.

Listing 7. Hierarchy of major functions in initrd loading and mounting
init/main.c:init
  init/do_mounts.c:prepare_namespace
    init/do_mounts_initrd.c:initrd_load
      init/do_mounts_rd.c:rd_load_image
        init/do_mounts_rd.c:identify_ramdisk_image
        init/do_mounts_rd.c:crd_load
          lib/inflate.c:gunzip
    init/do_mounts.c:mount_root
      init/do_mounts.c:mount_block_root
         init/do_mounts.c:do_mount_root
           fs/namespace.c:sys_mount
  init/main.c:run_init_process
    execve

Diskless Boot
   Much like embedded booting scenarios, a local disk (floppy or CD-ROM) isn't necessary to boot a
   kernel and ramdisk root filesystem. The Dynamic Host Configuration Protocol (or DHCP) can be used to
   identify network parameters such as IP address and subnet mask. The Trivial File Transfer Protocol
   (or TFTP) can then be used to transfer the kernel image and the initial ramdisk image to the local
   device. Once transferred, the Linux kernel can be booted and initrd mounted, as is done in a local
   image boot.

Shrinking your initrd
   When you're building an embedded system and want the smallest initrd image possible, there are a few
   tips to consider. The first is to use BusyBox (demonstrated in this article). BusyBox takes several
   megabytes of utilities and shrinks them down to several hundred kilobytes.

   In this example, the BusyBox image is statically linked so that no libraries are required. However,
   if you need the standard C library (for your custom binaries), there are other options beyond the
   massive glibc. The first small library is uClibc, which is a minimized version of the standard C
   library for space-constrained systems. Another library that's ideal for space-constrained
   environments is dietlib. Keep in mind that you'll need to recompile the binaries that you want in
   your embedded system using these libraries, so some additional work is required (but worth it).

Summary
   The initial RAM disk was originally created to support bridging the kernel to the ultimate root file
   system through a transient root file system. The initrd is also useful as a non-persistent root file
   system mounted in a RAM disk for embedded Linux systems.
   
---
filename: ramdisk_howto-use-on-linux-multif_20190828.txt
https://www.techrepublic.com/article/how-to-use-a-ramdisk-on-linux/

How to use a ramdisk on Linux
March 28, 2017

   If you need to boost the speed of data writes to storage on your Linux data center servers, a ramdisk
   might be what you need. Here's how to create one, mount it, and back it up.

   There may be instances where you need to include the fastest possible storage you can find on a
   server. In some cases, the best route to that is by making use of a ramdisk. Effectively, a ramdisk
   takes a portion of your system memory and uses it as a disk drive. This method of storage is
   considerably faster than standard hard disk storage, so it is a great tool for when you need
   blistering speed on a specific app.

   Ramdisks, of course, come with a serious caveat. Should you lose power (or shut down the machine),
   whatever you're working on could be lost. Because of that, it is important to do a regular backup of
   the directory used for your ramdisk (more on that in a bit).

   With that said, let's create a ramdisk. I'll be working with Ubuntu 16.04, but this will work on
   nearly any distribution.

Creating the ramdisk directory
   The first thing you must do is create a folder that will be used to mount the ramdisk. I'll create
   the folder /media/ramdisk. To do that, open up a terminal window and issue the command:
sudo mkdir -p /media/ramdisk

   You can name that folder whatever you like and place it anywhere on the directory structure. I like
   /media because it is the same location other drives will be mounted into by default.

Mounting the ramdisk
   Now we actually mount the newly created directory to a temporary storage area (one that will use RAM
   as opposed to hard drive space). This is accomplished with the following command:
sudo mount -t tmpfs -o size=2048M tmpfs /media/ramdisk

   You can adjust both the size and the mount point to fit your needs. In the above example, I have
   mounted 2GB of RAM to be used as a temporary file system to /media/ramdisk. That mounted directory
   can now be used at your discretion.

   When you're done using the ramdisk, you can unmount it with the command:
sudo umount /media/ramdisk

Automounting the ramdisk
   What if you want to have the ramdisk automatically created at boot? This can be done with the help of
   /etc/fstab. Open up that file and add the following (edit to suit your needs):
none /media/ramdisk tmpfs nodev,nosuid,noexec,nodiratime,size=2048M 0 0

   Save and close that file. You can test the newly modified /etc/fstab file with the command mount -a.
   If you receive no warnings, you're good to go.

Backup that ramdisk data
   Because we're dealing with non-persistent memory, you're going to want to set up a regular backup.
   You could create a very simple bash script with the following contents:
#!/bin/bash
​cp -ru /media/ramdisk /BACKUP/PATH

   Where /BACKUP/PATH is a path to a location to house the backup of /media/ramdisk. Save and close that
   file (we'll name it /root/ramdisk_backup.sh). Give the backup script executable permissions with the
   command chmod u+x ramdisk_backup.sh. Next we must create a crontab entry. Issue the command sudo
   crontab -e and then add the following:
*/15 * * * * /root/ramdisk_backup.sh

   The above crontab entry will backup your ramdisk data every fifteen minutes. Now, should you lose
   power or have to reboot the machine, you won't lose data.

Use it wisely
   How you use your ramdisk is up to you. Make sure to use this type of non-persistent storage wisely.
   The last thing you want is to depend upon it, only to lose precious data, thanks to a black out. If
   used wisely, a ramdisk can be a serious benefit to your data center servers. If used poorly, well,
   I'm sure you know how that story ends.


---
https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux

Create a RAM disk in Linux

   Linux penguin There are many reasons for creating a memory based file system in Linux, not least of
   which is to provide a near zero latency and extremely fast area to story files. A prime use of a RAM
   disk is for application caching directories or work areas.

   There are two main types of RAM disk which can be used in Linux and each have their own benefits and
   weaknesses:
     * ramfs
     * tmpfs

   See my other post for the [***]differences between ramfs and tmpfs.

   Check the amount of free RAM you have left on your machine before creating a RAM disk. Use the Linux
   command free to see the unused RAM. The below is an example of a 31GB of ram in a production server.
free -g
       total used free shared buffers cached
Mem:   31    29   2    0      0       8
-/+ buffers/cache: 20 11
Swap:  13    6    7

   The free command shows the amount of RAM availale on your system in addition to the amount of memory
   used, free and used for caching. SWAP space is also displayed and shows if your system is writing
   memory to disk.

   Create a folder to use as a mount point for your RAM disk.
mkdir /mnt/ramdisk

   Then use the mount command to create a RAM disk.
mount -t [TYPE] -o size=[SIZE] [FSTYPE] [MOUNTPOINT]

   Substitute the following attirbutes for your own values:
     * [TYPE] is the type of RAM disk to use; either tmpfs or ramfs.
     * [SIZE] is the size to use for the file system. Remember that ramfs does not have a physical limit
       and is specified as a starting size.
     * [FSTYPE] is the type of RAM disk to use; either tmpfs, ramfs, ext4, etc.

   Example:
mount -t tmpfs -o size=512m tmpfs /mnt/ramdisk

   You can add the mount entry into /etc/fstab to make the RAM disk persist over reboots. Remember
   however, that the data will disappear each time the machine is restarted.
vi /etc/fstab
tmpfs       /mnt/ramdisk tmpfs   nodev,nosuid,noexec,nodiratime,size=1024M   0 0


---
[***]
https://www.jamescoyle.net/knowledge/951-the-difference-between-a-tmpfs-and-ramfs-ram-disk

The Difference Between a tmpfs and ramfs RAM Disk

   Linux penguin There are two file system types built into most modern Linux distributions which allow
   you to create a RAM based storage area which can be mounted and used link a normal folder.

   Before using this type of file system you must understand the benefits and problems of memory file
   system in general, as well as the two different types. The two types of RAM disk file systems are
   tmpfs and ramfs and each type has it's own strengths and weaknesses.

What is a memory based file system (RAM disk)?
   A memory based file system is something which creates a storage area directly in a computers RAM as
   if it were a partition on a disk drive. As RAM is a volatile type of memory which means when the
   system is restarted or crashes the file system is lost along with all it's data.

   The major benefit to memory based file systems is that they are very fast - 10s of times faster than
   modern SSDs. Read and write performance is massively increased for all workload types. These types of
   fast storage areas are ideally suited for applications which need repetitively small data areas for
   caching or using as temporary space. As the data is lost when the machine reboots the data must not
   be precious as even scheduling backups cannot guarantee that all the data will be replicated in the
   even of a system crash.

tmpfs vs. ramfs
   The two main RAM based file system types in Linux are tmpfs and ramfs. ramfs is the older file system
   type and is largely replaced in most scenarios by tmpfs.

ramfs
   ramfs creates an in memory file system which uses the same mechanism and storage space as Linux file
   system cache. Running the command free in Linux will show you the amount of RAM you have on your
   system, including the amount of file system cache in use. The below is an example of a 31GB of ram in
   a production server.
free -g
       total used free shared buffers cached
Mem:   31    29   2    0      0       8
-/+ buffers/cache: 20 11
Swap:  13    6    7

   Currently 8GB of file system cache is in use on the system. This memory is generally used by Linux to
   cache recently accessed files so that the next time they are requested then can be fetched from RAM
   very quickly. ramfs uses this same memory and exactly the same mechanism which causes Linux to cache
   files with the exception that it is not removed when the memory used exceeds threshold set by the
   system.

   ramfs file systems cannot be limited in size like a disk base file system which is limited by it's
   capacity. ramfs will continue using memory storage until the system runs out of RAM and likely
   crashes or becomes unresponsive. This is a problem if the application writing to the file system
   cannot be limited in total size. Another issue is you cannot see the size of the file system in df
   and it can only be estimated by looking at the cached entry in free.

tmpfs
   tmpfs is a more recent RAM file system which overcomes many of the drawbacks with ramfs. You can
   specify a size limit in tmpfs which will give a 'disk full' error when the limit is reached. This
   behaviour is exactly the same as a partition of a physical disk.

   The size and used amount of space on  a tmpfs partition is also displayed in df. The below example
   shows an empty 512MB RAM disk.
df -h /mnt/ramdisk
Filesystem Size Used Avail Use% Mounted on
tmpfs      512M 0    512M  0%   /mnt/ramdisk

   These two differences between ramfs and tmpfs make tmpfs much more manageable  however this is one
   major drawback; tmpfs may use SWAP space. If your system runs out of physical RAM, files in your
   tmpfs partitions may be written to disk based SWAP partitions and will have to be read from disk when
   the file is next accessed. In some environments this can be seen as a benefit as you are less likely
   to get out of memory exceptions as you could with ramfs because more 'memory' is available to use.


---
https://www.linuxbabe.com/command-line/create-ramdisk-linux

How to Easily Create RAM Disk on Debian, Ubuntu, Linux Mint, CentOS
August 18, 2019

   This tutorial will show you how to quickly create a RAM disk in any Linux distro (Debian, Ubuntu,
   Linux, Fedora, Arch Linux, CentOS, etc). Compared to commercial Windows RAM disk software that costs
   money, Linux can utilize this cool feature 100% free of charge.

What is RAM Disk?
   RAM disk is also known as RAM drive. It's a portion of your RAM that are formated with a file system.
   You can mount it to a directory on your Linux system and use it as a disk partition.

Why use RAM disk?
   RAM is ultra-fast compared to even the fastest solid state drive (SSD). As you may know, the main
   performance bottleneck in today's computer is the speed of hard drive, so moving programs and files
   to the RAM disk yields super fast computing experience.

   Pros of RAM disk:
     * Ultra-fast
     * Can sustain countless reads and writes

   Cons of RAM disk:
     * RAM is volatile which means all data in RAM disk will be lost when the computer shutdowns or
       reboots. However, this can be a pro in some situations, if you use it wisely.
     * RAM is expensive so it has limited capacity. You need to make sure not allocate too much space
       for RAM disk, or the operating system would run out of RAM.

   You can do a lot of interesting things with RAM disk.
     * RAM disk is best suited for temporary data or caching directories, such as Nginx FastCGI
       cache. If you use a SSD and there will be a lot of writes to a particular directory, you can
       mount that directory as a RAM disk to reduce wear out of SSD.
     * I also use RAM disk to temporary store screenshots when writing articles on this blog, so when my
       computer shut down, those screenshots will automatically be deleted on my computer.
     * You may not believe it, but I use RAM disk to run virtual machines inside VirtualBox. My SSD is
       about 250G. I can't run many VMs directly on the SSD and I'm not happy about the speed of my 2TB
       mechanical hard drive (HDD). I can move the VM from HDD to RAM disk before starting the VM, so
       the VM can run much faster.  After shutting down the VM, I move the VM files back to HDD, which
       takes less than 1 minute. This of course requires your computer to have a large capacity RAM.

How to Create a RAM Disk in Any Linux Distro
   First make a directory which can be anywhere in the file system such as
sudo mkdir /tmp/ramdisk

   If you want to let every user on your Linux system use the RAM disk, then change its permission to
   777.
sudo chmod 777 /tmp/ramdisk

   Next, check how much free RAM are left on your system with htop command line utility because we don't
   want to use too much RAM.
htop

   Then all left to do is to specify the file system type, RAM disk size, device name and mount it to
   the above directory. You can see from the screenshot above that I have plenty of free RAM, so I can
   easily allocate 1GB for my RAM disk. This can be done with the following one-liner. It will be using
   tmpfs file system and its size is set to 1024MB. myramdisk is the device name I gave to it.
sudo mount -t tmpfs -o size=1024m myramdisk /tmp/ramdisk

   To allocate 10G for the RAM disk, run this instead.
sudo mount -t tmpfs -o size=10G myramdisk /tmp/ramdisk

   If we issue the following command
mount | tail -n 1

   We can see it's successfully mounted.

   Now if I copy my VirtualBox machines file (5.8G) into the RAM disk, my RAM usage suddenly goes up to
   9.22G.


   If I unmount RAM disk,
sudo umount /tmp/ramdisk/

   Everything in that directory will be lost and RAM usage goes down to original.

   This is how you can test if your RAM disk is working.

Test RAM Disk Speed
   To test write speed of RAM disk, you can use dd utility.
sudo dd if=/dev/zero of=/tmp/ramdisk/zero bs=4k count=100000

   Which gave me 2.8GB/s write speed.


   To test read speed, run:
sudo dd if=/tmp/ramdisk/zero of=/dev/null bs=4k count=100000

   Which gave me 3.1 GB/s read speed.

   I also did a speed test on my SSD. The write speed is 534MB/s and read speed 1.6GB/s.

Auto-mount on System Boot
   Edit /etc/fstab file.
sudo nano /etc/fstab

   Add an entry like this:
myramdisk  /tmp/ramdisk  tmpfs  defaults,size=1G,x-gvfs-show  0  0

   x-gvfs-show will let you see your RAM disk in file manager. Save and close the file. Your Linux
   system will automatically mount the RAM disk when your computer boots up.

   To mount it immediately without reboot, run the following command.
sudo mount -a

How to Run VirtualBox VM on RAM Disk
   Note that this requires a large capacity RAM.

   When you create a brand new virtual machine, you should set the machine folder to the RAM disk
   directory (/tmp/ramdisk/).

   If you have an existing VM, then select the VM in the main VirtualBox Manager window and go to the
   menu bar and select Machine -> Move, or right-click the VM and select Move from the context menu. You
   will be prompted to choose a new folder for the virtual machine. Select /tmp/ramdisk/ as the new
   folder.

   Remember to move your VM back to the original folder before shutting down your computer, or your VM
   will be deleted.

Wrapping Up
   And that's the basics of creating RAM disk in Linux.


---
http://www.linuxfocus.org/English/November1999/article124.html

How to use a Ramdisk for Linux

Introduction to RamDisk
   This is a brief article about how to setup a RamDisk on a RedHat 6.0 system. It should be very
   similar for other Linux distributions.

   What is a RamDisk? A RamDisk is a portion of memory that you allocate to use as a partition. Or, in
   other words, you are taking memory, pretending to treat it as a hard drive, and you are saving your
   files to it. Why would you want to use a RamDisk? Well, if you know that certain files you have are
   constantly going to be used, putting the files into memory will increase the performance of your
   computer since your memory is faster than your hard drive. Things like web servers with lots of data
   can be sped up this way. Or, if you are insane, and you have a PII 550 Mhz computer with 1 gig of
   memory and an old 500 meg hard drive, you can use it just to increase your hard drive space. Then
   again, if you want an almost diskless machine, it might not be that crazy afterall.

   Here are some more resources to help you.
    1. http://metalab.unc.edu/LDP/HOWTO/Kernel-HOWTO.html
    2. http://metalab.unc.edu/LDP/HOWTO/mini/LILO.html
    3. /usr/src/linux/Documentation/ramdisk.txt

How to use RamDisk
   Well, it is very easy to use a ramdisk. First of all, the default installation of RedHat 6.0 comes
   with ramdisk support. All you have to do is format a ramdisk and then mount it to a directory. To
   find out all the ramdisks you have available, do a "ls -al /dev/ram*". This gives you the preset
   ramdisks available to your liking. These ramdisks don't actually grab memory until you use them
   somehow (like formatting them). Here is a very simple example of how to use a ramdisk.
# create a mount point:
mkdir /tmp/ramdisk0
# create a filesystem:
mke2fs /dev/ram0
# mount the ramdisk:
mount /dev/ram0 /tmp/ramdisk0

   Those three commands will make a directory for the ramdisk , format the ramdisk (create a
   filesystem), and mount the ramdisk to the directory "/tmp/ramdisk0". Now you can treat that directory
   as a pretend partition! Go ahead and use it like any other directory or as any other partition.
   If the formatting of the ramdisk faild then you might have no support for ramdisk compiled into the
   Kernel. The Kernel configuration option for ramdisk is CONFIG_BLK_DEV_RAM .

   The default size of the ramdisk is 4Mb=4096 blocks. You saw what ramdisk size you got while you were
   running mke2fs. mke2fs /dev/ram0 should have produced a message like this:
mke2fs 1.14, 9-Jan-1999 for EXT2 FS 0.5b, 95/08/09
Linux ext2 filesystem format
Filesystem label=
1024 inodes, 4096 blocks
204 blocks (4.98%) reserved for the super user
First data block=1
Block size=1024 (log=0)
Fragment size=1024 (log=0)
1 block group
8192 blocks per group, 8192 fragments per group
1024 inodes per group

   Running df -k /dev/ram0 tells you how much of that you can really use (The filesystem takes also some
   space):
>df -k /dev/ram0
Filesystem  1k-blocks  Used Available Use% Mounted on
/dev/ram0        3963    13      3746   0% /tmp/ramdisk0

   What are some catches? Well, when the computer reboots, it gets wiped. Don't put any data there that
   isn't copied somewhere else. If you make changes to that directory, and you need to keep the changes,
   figure out some way to back them up.

Changing the size of the ramdisks
   To use a ram disk you either need to have ramdisk support compiled into the Kernel or you need to
   compile it as loadable module. The Kernel configuration option is CONFIG_BLK_DEV_RAM . Compiling the
   ramdisk a loadable module has the advantage that you can decide at load time what the size of your
   ramdisks should be.

   Okay, first the hard way. Add this line to your lilo.conf file:
      ramdisk_size=10000 (or ramdisk=10000 for old kernels)
   and it will make the default ramdisks 10 megs after you type the "lilo" command and reboot the
   computer. Here is an example of my /etc/lilo.conf file.
boot=/dev/hda
map=/boot/map
install=/boot/boot.b
prompt
timeout=50
image=/boot/vmlinuz
        label=linux
        root=/dev/hda2
        read-only
        ramdisk_size=10000

   Actually, I got a little over 9 megs of usable space as the filesystem takes also a little space.

   When you compile ramdisk support as loadable module then you can decide at load time what the size
   should be. This is done either with an option line in the /etc/conf.modules file:
options rd rd_size=10000

   or as a command line parameter to ismod:
insmod rd rd_size=10000

   Here is an example which shows how to use the module:
    1. Unmount the ramdisk mounted in the previous chapter, umount /tmp/ramdisk0 .
    2. Unload the module (it was automatically loaded in the previous chapter), rmmod rd
    3. Load the ramdisk module and set the size to 20Mb, insmod rd rd_size=20000
    4. create a file system, mke2fs /dev/ram0
    5. mount the ramdisk, mount /dev/ram0 /tmp/ramdisk0

Example of how to use a RamDisk for a webserver.
   Okay, here is an example of how to use 3 ramdisks for a webserver. Let us say you are 99% confident
   that your default installation of Apache for RedHat 6.0 won't use more than 9 megs for its
   cgi-scripts, html, and icons. Here is how to install one.
   First, issue this command to move the real copy of the document root directory of your webserver to a
   different place. Also, make the directories to mount the ramdisks .
mv /home/httpd/ /home/httpd_real
mkdir /home/httpd
mkdir /home/httpd/cgi-bin
mkdir /home/httpd/html
mkdir /home/httpd/icons

   Then, add these commands to the start procedure in your /etc/rc.d/init.d/httpd.init (or where ever
   the httpd gets started on your system):

        ### Make the ramdisk partitions
/sbin/mkfs -t ext2 /dev/ram0
/sbin/mkfs -t ext2 /dev/ram1
/sbin/mkfs -t ext2 /dev/ram2

        ### Mount the ramdisks to their appropriate places

mount /dev/ram0 /home/httpd/cgi-bin
mount /dev/ram1 /home/httpd/icons
mount /dev/ram2 /home/httpd/html

        ### Copying real directory to ramdisks (the
  ### data on the ramdisks is lost after a reboot)
tar -C /home/httpd_real -c . | tar -C /home/httpd -x

  ### After this you can start the web-server.

Comments
    1. Please remember one thing, BACKUP YOUR DATA if you change it and you need it. When the computer
       reboots, any changes are lost.
       A cron job should do it. Have it check every 10 minutes and see if any files have changed and
       backup any changes. Another thing you could do is make your changes to the real directory, and
       then copy over the changes to the ramdisks. That is much safer.
    2. A cool use of this would be to have a computer with 1 gig of memory and then use 256 megs for
       "/tmp". If you have lots of processes that use "/tmp", it should help speed up your system. Also,
       anything in /tmp would get lost when the computer reboots, which can be a good thing.
    3. Linux uses all the memory that is not in use by programs as a unified disk-cache but my
       experience is that ramdisks give you despite that still some speed increase.


---
https://stackoverflow.com/questions/354254/ram-drive-for-compiling-is-there-such-a-thing

RAM drive for compiling - is there such a thing?

   An answer (see below) to one of the questions right here on Stack Overflow gave me an
   idea for a great little piece of software that could be invaluable to coders everywhere.

   I'm imagining RAM drive software, but with one crucial difference - it would mirror a real folder on
   my hard drive. More specifically - the folder which contains the project I'm currently working on.
   This way any builds would be nearly instantaneous (or at least a couple orders of magnitude faster).
   The RAM drive would synchronize its contents with the hard disk drive in background using only idle
   resources.

   A quick Google search revealed nothing, but perhaps I just don't know how to Google. Perhaps someone
   knows of such a software? Preferably free, but reasonable fees might be OK too.

   Added: Some solutions have been suggested which I discarded in the very beginning. They would be (in
   no particular order):
     * Buy a faster hard disk drive (SSD maybe or 10K RPM). I don't want a hardware solution. Not
       only software has the potential to be cheaper (freeware, anyone?), but it can also be used in
       environments where hardware modifications would be unwelcome if not impossible - say, at the
       office.
     * Let OS/HDD do the caching - it knows better how to use your free RAM. The OS/HDD have generic
       cache algorithms that cache everything and try to predict which data will be most needed in the
       future. They have no idea that for me the priority is my project folder. And as we all know quite
       well - they don't really cache it much anyway. ;)
     * There are plenty of RAM drives around; use one of those. Sorry, that would be reckless. I need my
       data to be synchronized back to the HDD whenever there is a bit of free time. In the case of a
       power failure I could bear losing the last five minutes of work, but not everything since my last
       checkin.

   Added 2: An idea that came up - use a normal RAM drive plus a background folder synchronizer (but I
   do mean background). Is there any such thing?

   Added 3: Interesting. I just tried out a simple RAM drive at work. The rebuild time drops from
   ~14 secs to ~7 secs (not bad), but incremental build is still at ~5 secs - just like on the HDD. Any
   ideas why? It uses aspnet_compiler and aspnet_merge. Perhaps they do something with other temp files
   elsewhere?

   Added 4: Oh, nice new set of answers! :) OK, I've got a bit more info for all you naysayers. :)

   One of the main reasons for this idea is not the above-mentioned software (14 secs build time), but
   another one that I didn't have access at the time. This other application has a 100 MB code base, and
   its full build takes about 5 minutes. Ah yes, it's in Delphi 5, so the compiler isn't too
   advanced. :) Putting the source on a RAM drive resulted in a BIG difference. I got it below a minute,
   I think. I haven't measured. So for all those who say that the OS can cache stuff better - I'd beg to
   differ.

   Related Question:
RAM disk for speed up IDE

   Note on first link: The question to which it links has been deleted because it was a duplicate. It
   asked:
What do you do while your code's compiling?

   And the answer by Dmitri Nesteruk to which I linked was:

     I compile almost instantly. Partly due to my projects being small, partly due to the use of RAM
     disks.

***
     * Why is hardware modification impossible in the office? We always have some budget available, if
       the value is there. Also, I've been known to buy hardware with my own money, just to make my work
       experience more pleasant. - Jay Bazuzi Dec 9 '08 at 22:01
     * 2
       In my case the builds take ~15s incremental and ~30s full. Not really something to convice the
       boss with. But it would be nice if it were 1s. :) And I don't want to invest my own money in
       this. Besides - there are many people out there and each has a different story. Many might have
       use of this too. - Vilx- Dec 9 '08 at 22:14
     * 4
       If I was your boss, I'd be interested in ways to get your build time down from 15s/30s to 1s. Any
       perceivable delay is an opportunity for improvement. Developer productivity is directly impacted
       by any delay. - Jay Bazuzi Dec 10 '08 at 0:09
     * 2
       I wish you were my boss. :D - Vilx- Dec 10 '08 at 8:03
     * 3
       @Jay unfortunately in many companies equipment and engineering time are completely different
       costs according to the accounting structure, and it often sadly makes financial sense to go cheap
       on the hardware even with the huge extra expense of the engineering time. Boss may not have
       control over it. - Adam Davis Mar 27 '09 at 15:02

***
   In Linux (you never mentioned which OS you're on, so this could be relevant) you can create block
   devices from RAM and mount them like any other block device (that is, a HDD).

   You can then create scripts that copy to and from that drive on start-up / shutdown, as well as
   periodically.

   For example, you could set it up so you had ~/code and ~/code-real. Your RAM block gets mounted at
   ~/code on startup, and then everything from ~/code-real (which is on your standard hard drive) gets
   copied over. On shutdown everything would be copied (rsync'd would be faster) back from ~/code to
   ~/code-real. You would also probably want that script to run periodically, so you didn't lose much
   work in the event of a power failure, etc.

   I don't do this anymore (I used it for Opera when the 9.5 beta was slow, no need anymore).

***
       +1 - Put the script in cron to rsync every five minutes or so, and nice it so it doesn't kill
       performance. I don't know how this would be accomplished on Windows, but there is a task
       scheduler, and there are rsync tools, so those plus a RAM disk app should work for you if that's
       your platform. - Adam Jaskiewicz Dec 9 '08 at 23:06
     * Yap, I use Windows. Vista Business 32-bit, to be precise. :) But other OS are relevant to the
       topic too. And, yes - the idea to use simple ramdisk+folder sync utility (xcopy in the most
       simple case) has already crossed my mind. See above. - Vilx- Dec 9 '08 at 23:10

***
   I'm surprised at how many people suggest that the OS can do a better job at figuring out your caching
   needs than you can in this specialized case. While I didn't do this for compiling, I did do it for
   similar processes and I ended up using a RAM disk with scripts that automated the synchronization.

   In this case, I think I'd go with a modern source control system. At every compile it would check in
   the source code (along an experimental branch if needed) automatically so that every compile would
   result in the data being saved off.

   To start development, start the RAM disk and pull the current base line. Do the editing, compile,
   edit, compile, etc. - all the while the edits are being saved for you.

   Do the final check in when happy, and you don't even have to involve your regular hard disk drive.

   But there are background synchronizers that will automate things - the issue is that they won't be
   optimized for programming either and may need to do full directory and file scans occasionally to
   catch changes. A source code control system is designed for exactly this purpose, so it would likely
   be lower overhead even though it exists in your build setup.

   Keep in mind that a background sync task, in the case of a power outage, is undefined. You would end
   up having to figure out what was saved and what wasn't saved if things went wrong. With a defined
   save point (at each compile, or forced by hand) you'd have a pretty good idea that it was at least in
   a state where you thought you could compile it. Use a VCS and you can easily compare it to the
   previous code and see what changes you've applied already.

***
     * Keeping the source files on ramdisk is dangerous - better to keep them on disk and have automated
       sync'ing to the ramdisk before builds. +1 for OS not always handling specialized needs perfectly,
       though! - snemarch Mar 27 '09 at 5:43
     * 1
       The source files are used and edited on ramdisk, but I'm suggesting that at every compile they
       are saved off to regular disk or repository. I'm not suggesting using a ramdisk alone with no
       form of non-volatile saving. - Adam Davis Mar 27 '09 at 13:10

***
   Speeding up compiles using RAM drives under Gentoo was the subject of a how-to written many eons ago.
   It provides a concrete example of what has been done. The gist is that all source and build
   intermediate file are redirected to a RAM disk for compile, while final binaries are directed to the
   hard drive for install.

   Also, I recommend exploring maintaining your source on hard drive, but git push your latest source
   changes to a clone respository that resides on the RAM disk. Compile the clone. Use your favorite
   script to copy the binaries created.

   I hope that helps.

***
   Your OS will cache things in memory as it works. A RAM disk might seem faster, but that's because you
   aren't factoring in the "copy to RAMDisk" and "copy from RAMDisk" times. Dedicating RAM to a fixed
   size ramdisk just reduces the memory available for caching. The OS knows better what needs to be in
   RAM.

***
     * 3
       This is true if you're copying the stuff to and from RAM every compile, but the idea is that
       you're copying to ram once, and compiling several times after making minor changes. I've done
       this before for related processes (not compiling) and for huge data sets is makes a really big
       difference. - Adam Davis Mar 27 '09 at 3:54
     * 2
       Don't trust the caching strategy of the OS to give you the same performance as your own caching
       strategy. - Adam Davis Mar 27 '09 at 3:55
     * Shouldn't the contents of recently accessed or modified files, i.e., those touched by the
       compiler, be in the file system cache? - Jay Conrod Mar 27 '09 at 5:34
     * 8
       read-caching is only part of the problem, compiling produces output files - possibly with
       suboptimal write patterns, and often a bunch of temporary files. - snemarch Mar 27 '09 at
       5:35
     * I feel like compiling tools flush files to disk, like permanent databases. So, the file may be
       catched but flushing it nevertheless takes Disk access time and am not sure but tools seem
       waiting until flushing completes. You need to disable durability instead of enabling caching. But
       you seems right in practice. My experiment shows that there is no performance difference besides
       the disk thrashing, which does not affect the performance figures. - Val Mar 19 '15 at 17:20

***
   We used to do this years ago for a 4GL macro-compiler; if you put the macro library and support
   libraries and your code on a RAM disk, compiling an application (on an 80286) would go from 20
   minutes to 30 seconds.

***
     * That's all nice and fine - there are plenty classical RAMDrives around. But I don't want my code
       to live SOLELY on the RamDrive. That's a bit dangerous you know. ;) I would like it to be
       synchronized to HDD whenever there is a bit of free time to do so. - Vilx- Dec 9 '08 at 21:39
     * @Steven A. Lowe - set in Scheduled Tasks to run every minute? Now THAT would kill my PC's
       performance. :P Although I suppose I could make it copy only newer files. Still it's pretty much
       work. However you did give me an idea - maybe some background folder synchronizator? - Vilx-
       Dec 9 '08 at 21:53
     * @Vlix: in our scenario, it took about 2 seconds to copy the files to the RAM disk before
       compiling, and 2 seconds to copy them out after compiling. I think some RAM disk products offer a
       shadow/synch feature - Steven A. Lowe Dec 9 '08 at 21:56


***
   I don't have exactly what you're looking for, but I'm now using a combination of Ramdisk and
   DRAM ramdisk. Since this is Windows, I have a hard 3 GB limit for core memory, meaning I cannot
   use too much memory for a RAM disk. 4 GB extra on the 9010 really rocks it. I let my IDE store all
   its temporary stuff on the solid state RAM disk and also the Maven repository. The DRAM RAM disk
   has a battery backup to the flash card. This sounds like an advertisement, but it really is an
   excellent setup.

   The DRAM disk has double SATA-300 ports and comes out with 0.0 ms average seek on most tests ;)
   Something for the Christmas stocking?

***
     * Sweet, but I don't have that much spare money. Plus, as I said - I want it to be software.
       - Vilx- Dec 9 '08 at 21:51
     * This sounds really cool (though not meeting the posters criteria). Does the backup to flash
       happen automatically whenever the drive is powered down, or what? - erickson Dec 10 '08 at
       0:54
     * Yep. The battery is enough to persist dram to the flash card. And it happens when mains power is
       lost. - krosenvold Dec 10 '08 at 7:35
     * The sad thing about these solutions is that the several GB/s of dram is limited to the SATA-300
       interface speeds :( - snemarch Mar 27 '09 at 5:36
     * At least it's dual SATA-300 interface ;) Strangely enough, I don't feel sad about it....
       - krosenvold Mar 27 '09 at 7:54

***
   Then I wrote these scripts to move directories to and from the RAM disk. Backup is made in a tar
   file before moving into the RAM disk. The benefit of doing it this way is that the path stays the
   same, so all your configuration files don't need to change. When you are done, use uramdir to bring
   back to disk.

   Edit: Added C code that will run any command it is given on an interval in background. I am sending
   it tar with --update to update the archive if any changes.

   I believe this general-purpose solution beats making a unique solution to something very simple. KISS

   Make sure you change path to rdbackupd

ramdir

#!/bin/bash

# May need some error checking for bad input.

# Convert relative path to absolute
# /bin/pwd gets real path without symbolic link on my system and pwd
# keeps symbolic link. You may need to change it to suit your needs.
somedir=$(cd $1; /bin/pwd$(;
somedirparent=$(dirname $somedir$(

# Backup directory
/bin/tar cf $somedir.tar $somedir

# Copy, tried move like https://wiki.archlinux.org/index.php/Ramdisk
# suggests, but I got an error.
mkdir -p /mnt/ramdisk$somedir
/bin/cp -r  $somedir /mnt/ramdisk$somedirparent

# Remove  directory
/bin/rm -r $somedir

# Create symbolic link. It needs to be in parent of given folder.
/bin/ln -s /mnt/ramdisk$somedir $somedirparent

#Run updater
~/bin/rdbackupd "/bin/tar -uf $somedir.tar $somedir" &

uramdir

#!/bin/bash

#Convert relative path to absolute
#somepath would probably make more sense
# pwd and not /bin/pwd so we get a symbolic path.
somedir=$(cd $1; pwd$(;

# Remove symbolic link
rm $somedir

# Copy dir back
/bin/cp -r /mnt/ramdisk$somedir $somedir

# Remove from ramdisk
/bin/rm -r /mnt/ramdisk$somedir

# Stop
killall rdbackupd

   rdbackupd.cpp
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <signal.h>
#include <sys/time.h>

struct itimerval it;
char* command;

void update_archive(int sig)
{
    system(command);
}

int main(int argc, char**argv)
{
    it.it_value.tv_sec     = 1;   // Start right now
    it.it_value.tv_usec    = 0;
    it.it_interval.tv_sec  = 60;  // Run every 60 seconds
    it.it_interval.tv_usec = 0;

    if (argc < 2)
    {
        printf("rdbackupd: Need command to run\n");
        return 1;
    }
    command = argv[1];

    signal(SIGALRM, update_archive);
    setitimer(ITIMER_REAL, &it, NULL); // Start

    while(true);

    return 0;
}

***
     * Correct me if I'm wrong, but this only synchronizes to the HDD when you explicitly tell it to,
       NOT in the background, right? - Vilx- Oct 25 '11 at 23:51
     * Correct add a tar command or script to crond - Joe McGrath Oct 26 '11 at 2:38
     * Also should be able to mount as directory with ntfs on atleast windows nt4 and batch files
       - Joe McGrath Oct 26 '11 at 2:41
     * @Vilx- Added C code that will run in background and update the tar file if there are any changes
       to the files. Can specify interval in C code. Making it take time as a parameter is trivial. Does
       everything you need now. - Joe McGrath Oct 31 '11 at 4:20
     * Will kill all the backup processes when uramdir. Can be addressed. - Joe McGrath Oct 31 '11
       at 5:27

***
    1. Profile. Make sure you do good measurements of each option. You can even buy things you've
       already rejected, measure them, and return them, so you know you're working from good data.
    2. Get a lot of RAM. 2 GB DIMMs are very cheap; 4 GB DIMMs are a little over US$100/ea, but that's
       still not a lot of money compared to what computer parts cost just a few years ago. Whether you
       end up with a RAM disk or just letting the OS do its thing, this will help. If you're running
       32-bit Windows, you'll need to switch to 64-bit to make use of anything over 3 GB or so.
    3. Live Mesh can synchronize from your local RAM drive to the cloud or to another computer, giving
       you an up-to-date backup.
    4. Move just compiler outputs. Keep your source code on the real physical disk, but direct .obj,
       .dll, and .exe files to be created on the RAM drive.
    5. Consider a DVCS. Clone from the real drive to a new repository on the RAM drive. "push" your
       changes back to the parent often, say every time all your tests pass.

***
     * 2. Not true. If your hardware supports PAE the OS can address more than 4G, just each
       application's address space is limited to 4G. - Adam Hawes Mar 27 '09 at 4:19
     * 1
       @Adam> only for server editions of Windows - client editions limit you to 4GB of address space
       (yes, AS, not physical memory! mix of market segmentation and "3rd parties wrote buggy drivers"
       excuse). - snemarch Mar 27 '09 at 5:38

***
   I had the same idea and did some research. I found the following tools that do what you are looking
   for:
     * VSuite RAM disk
     * DiskBoost

   However, the second one I couldn't manage to get working on 64-bit Windows 7 at all, and it doesn't
   seem to be maintained at the moment.

   The VSuite RAM disk on the other hands works very well. Unfortunately I couldn't measure any
   significant performance boost compared to the SSD disc in place.

***
   Yep, I've met the same problem. And after fruitless googling I just wrote a Windows Service for lazy
   backing up the RAM drive (actually - any folder, because RAM drive can be mounted in to, for example,
   the desktop).

   http://bitbucket.org/xkip/transparentbackup You can specify interval for full scan (default 5
   minutes). And an interval for scanning only notified files (default 30 seconds). Scan detects changed
   files using the 'archive' attribute (the OS resets that one specially for archiving purpose). Only
   files modified that way are backed up.

   The service leaves a special marker file to make sure that target backup is exactly a backup of the
   source. If the source is empty and does not contain a marker file, the service performs automatic
   restore from backup. So, you can easily destroy the RAM drive and create it again with automatic data
   restoration. It is better to use a RAM drive that is able to create a partition on system start up to
   make it work transparently.

   Another solution that I've recently detected is SuperSpeed SuperCache.

   This company also has a RAM disk, but that is another software. SuperCache allows you use extra RAM
   for block-level caching (it is very different from file caching), and another option - mirror you
   drive to RAM completely. In any scenario you can specify how often to drop dirty blocks back to the
   hard disk drive, making writes like on the RAM drive, but the mirror scenario also makes reads like
   from the RAM drive. You can create a small partition, for example, 2 GB (using Windows) and map the
   entire partition to RAM.

   One interesting and very useful thing about that solution - you can change caching and mirroring
   options any time just instantly with two clicks. For example, if you want your 2 GB back for gamimg
   or virtual machine - you can just stop mirroring instantly and release memory back. Even opened file
   handles does not break - the partition continues to work, but as a usual drive.

   EDIT: I also highly recommend you move the TEMP folder to te RAM drive, because compilers usually
   make a lot of work with temp. In my case it gave me another 30% of compilation speed.

***
   I wonder if you could build something like a software RAID 1 where you have a physical disk/partition
   as a member, and a chunk of RAM as a member.

   I bet with a bit of tweaking and some really weird configuration one could get Linux to do this. I am
   not convinced that it would be worth the effort though.

***
     There are plenty RAMDrives around, use one of those. Sorry, that would be reckless.

   Only if you work entirely in the RAM disc, which is silly..

   Psuedo-ish shell script, ramMake:
# setup locations
$ramdrive = /Volumes/ramspace
$project = $HOME/code/someproject

# ..create ram drive..

# sync project directory to RAM drive
rsync -av $project $ramdrive

# build
cd $ramdrive
make

#optional, copy the built data to the project directory:
rsync $ramdrive/build $project/build

   That said, your compiler can possibly do this with no additional scripts.. Just change your build
   output location to a RAM disc, for example in Xcode, it's under Preferences, Building, "Place Build
   Products in:" and "Place Intermediate Build Files in:".

***
   What can be super beneficial on even a single-core machine is parallel make. Disk I/O is a
   pretty large factor in the build process. Spawning two compiler instances per CPU core can actually
   increase performance. As one compiler instance blocks on I/O the other one can usually jump into the
   CPU intensive part of compiling.

   You need to make sure you've got the RAM to support this (shouldn't be a problem on a modern
   workstation), otherwise you'll end up swapping and that defeats the purpose.

   On GNU make you can just use -j[n] where [n] is the number of simultaneous processes to spawn.
   Make sure you have your dependency tree right before trying it though or the results can be
   unpredictable.

   Another tool that's really useful (in the parallel make fashion) is distcc. It works a treat
   with GCC (if you can use GCC or something with a similar command line interface). distcc actually
   breaks up the compile task by pretending to be the compiler and spawning tasks on remote servers. You
   call it in the same way as you'd call GCC, and you take advantage of make's -j[n] option to call many
   distcc processes.

   At one of my previous jobs we had a fairly intensive Linux operating system build that was performed
   almost daily for a while. Adding in a couple of dedicated build machines and putting distcc on a few
   workstations to accept compile jobs allowed us to bring build times down from a half a day to under
   60 minutes for a complete OS + userspace build.

   There's a lot of other tools to speed compiles existing. You might want to investigate more than
   creating RAM disks; something which looks like it will have very little gain since the OS is doing
   disk caching with RAM. OS designers spend a lot of time getting caching right for most workloads;
   they are (collectively) smarter than you, so I wouldn't like to try and do better than them.

   If you chew up RAM for RAM disk, the OS has less working RAM to cache data and to run your code ->
   you'll end up with more swapping and worse disk performance than otherwise (note: you should profile
   this option before completely discarding it).

***
   This sounds like disk caching which your operating system and / or your hard drive will handle for
   you automatically (to varying degrees of performance, admittedly).

   My advice is, if you don't like the speed of your drive, buy a high speed drive purely for compiling
   purposes. Less labor on your part and you might have the solution to your compiling woes.

   Since this question was originally asked, spinning hard disks have become miserable tortoises when
   compared to SSDs. They are very close to the originally requested RAM disk in a SKU that you can
   purchase from Newegg or Amazon.

***
     * Unfortunately OS/HDD don't let me tell them "cache this folder at all costs". :) And I was
       looking for a software solution instead of hardware because my office PC has enough RAM but I'm
       not sure my employer would be happy if I started messing with the hardware. Plus, it could be
       free. ;) - Vilx- Dec 9 '08 at 21:24
     * 2
       I do agree. A RAM disk is an order of magnitude faster than a hard disk for certain purposes, and
       I'm tired of getting the same "no need for a RAM disk" answer each time I ask for one :-)
       - Stephan Leclercq Dec 9 '08 at 21:31
     * Er... I meant a CACHED hard disk, of course :-) - Stephan Leclercq Dec 9 '08 at 21:31
     * Okay, let's put it another way: this sounds like an optimization problem. Exactly what speed
       problem are you trying to solve? Compile time to actual disk or compile time to runnable binary?
       - Bob Cross Dec 9 '08 at 22:41
     * Even a 10k rpm raptor/velociraptor drive didn't bring that great compile-time reductions over a
       decent 7200rpm drive for me. - snemarch Mar 27 '09 at 5:06

***
   Some ideas off the top of my head:

   Use Sysinternals' Process Monitor (not Process Explorer) to check what goes on during a
   build - this will let you see if %temp% is used, for instance (keep in mind that response files are
   probably created with FILE_ATTRIBUTE_TEMPORARY which should prevent disk writes if possible, though).
   I've moved my %TEMP% to a RAM disk, and that gives me minor speedups in general.

   Get a RAM disk that supports automatically loading/saving disk images, so you don't have to use boot
   scripts to do this. Sequential read/write of a single disk image is faster than syncing a lot of
   small files.

   Place your often-used/large header files on the RAM disk, and override your compiler standard paths
   to use the RAM drive copies. It will likely not give that much of an improvement after first-time
   builds, though, as the OS caches the standard headers.

   Keep your source files on your harddrive, and sync to the RAM disk - not the other way around. Check
   out MirrorFolder for doing realtime synchronization between folders - it achieves this via a
   filter driver, so only synchronizes what is necessary (and only does changes - a 4 KB write to a 2 GB
   file will only cause a 4 KB write to the target folder). Figure out how to make your IDE build
   from the RAM drive although the source files are on your harddisk... and keep in mind that you'll
   need a large RAM drive for large projects.

***
   The disk slowdown you incur is mainly write, and also possibly due to virus scanners. It can vary
   greatly between OSes too.

   With the idea that writes are slowest, I would be tempted to setup a build where intermediate (for
   example, .o files) and binaries get output to a different location such as a RAM drive.

   You could then link this bin/intermediate folder to faster media (using a symbolic link or

***
   My final solution to the problem is vmtouch: https://hoytech.com/vmtouch/ This tool locks the
   current folder into (ram) cache and vmtouch daemonizes into background.
sudo vmtouch -d -L ./

   Put this in shell rc for fast access:
alias cacheThis = 'sudo vmtouch -d -L ./'

   I searched for a ready made script for quite a while, because I didn't want to waste a lot of time on
   writing my own ramdisk-rsync-script. I'm sure I would have missed some edge cases, which would be
   quite unpleasant if important code was involved. And I never liked the polling approach.

   Vmtouch seems like the perfect solution. In addition it doesn't waste memory like a fixed size
   ramdisk does. I didn't do a benchmark, because 90% of my 1Gig source+build folder were already
   cached, but at least it feels faster ;)

***
   Just as James Curran says, the fact that most programs follow the law of locality of references, the
   frequent code and data page count will be narrowed over time to a manageable size by the OS disk
   cache.

   RAM disks were useful when operating systems were built with limitations such as stupid caches (Win
   3.x, Win 95, DOS). The RAM disk advantage is near zero and if you assign a lot of RAM it will suck
   memory available to the system cache manager, hurting overall system performance. The rule of thumb
   is: let your kernel to do that. This is the same as the "memory defragmentation" or "optimizers"
   programs: they actually force pages out of cache (so you get more RAM eventually), but causing the
   system to do a lot of page-faulting over time when your loaded programs begin to ask for code/data
   that was paged out.

   So for more performance, get a fast disk I/O hardware subsystem, maybe RAID, faster CPU, better
   chipset (no VIA!), more physical RAM, etc.

***
     * RAM disks can still offer substantial advantages. 1) you're 100% guaranteed to be in ram, OS
       cache doesn't guarantee this. 2) FS metadatase journalling... 3) overzealous filesync (firefox
       profile on ramdrive can go a lot faster than on a regular disk - remember backups though :) ).
       - snemarch Mar 27 '09 at 5:41
     * 1) For most applications, data not being 100% at RAM is a good thing, I think, due to (again)
       reference locality 2) This could be true, but for good FS journalling algorithms? [examples?] 3)
       I don't know, I'm sure you are using it to assert that :) - Hernán Mar 27 '09 at 13:17


---
filename: /c/Users/gregor.redelonghi/Dropbox/ODPRTO/_TXT/ramdisk_ramfs-vs-tmpfs_use-case-multif_20161027.txt
https://www.jamescoyle.net/knowledge/951-the-difference-between-a-tmpfs-and-ramfs-ram-disk

The difference between tmpfs and ramfs ramdisk

There are two file system types built into most modern Linux distributions which allow you to
create a RAM based storage area which can be mounted and used link a normal folder.

Before using this type of file system you must understand the benefits and problems of memory file system in
general, as well as the two different types. The two types of RAM disk file systems are tmpfs and ramfs and
each type has it?s own strengths and weaknesses.

See my other post for details on how to create a RAM disk in Linux.

What is a memory based file system (RAM disk)?

A memory based file system is something which creates a storage area directly in a computers RAM as if it
were a partition on a disk drive. As RAM is a volatile type of memory which means when the system is
restarted or crashes the file system is lost along with all it?s data.

The major benefit to memory based file systems is that they are very fast ? 10s of times faster than modern
SSDs. Read and write performance is massively increased for all workload types. These types of fast storage
areas are ideally suited for applications which need repetitively small data areas for caching or using as
temporary space. As the data is lost when the machine reboots the data must not be  precious as even
scheduling backups cannot guarantee that all the data will be replicated in the even of a system crash.

tmpfs vs. ramfs
The two main RAM based file system types in Linux are tmpfs and ramfs. ramfs is the older file system type
and is largely replaced in most scenarios by tmpfs.

ramfs
ramfs creates an in memory file system which uses the same mechanism and storage space as Linux file system
cache. Running the command free in Linux will show you the amount of RAM you have on your system, including
the amount of file system cache in use. The below is an example of a 31GB of ram in a production server.
	1 free -g
	2        total used free shared buffers cached
	3 Mem:   31    29   2    0      0       8
	4 -/+ buffers/cache: 20 11
	5 Swap:  13    6    7

Currently 8GB of file system cache is in use on the system. This memory is generally used by Linux to cache
recently accessed files so that the next time they are requested then can be fetched from RAM very quickly.
ramfs uses this same memory and exactly the same mechanism which causes Linux to cache files with the
exception that it is not removed when the memory used exceeds threshold set by the system.

ramfs file systems cannot be limited in size like a disk base file system which is limited by it?s capacity.
ramfs will continue using memory storage until the system runs out of RAM and likely crashes or becomes
unresponsive. This is a problem if the application writing to the file system cannot be limited in total
size. Another issue is you cannot see the size of the file system in df and it can only be estimated by
looking at the cached entry in free.

tmpfs
tmpfs is a more recent RAM file system which overcomes many of the drawbacks with ramfs. You can specify a
size limit in tmpfs which will give a ?disk full? error when the limit is reached. This behaviour is exactly
the same as a partition of a physical disk.

The size and used amount of space on  a tmpfs partition is also displayed in df. The below example shows an
empty 512MB RAM disk.
	1 df -h /mnt/ramdisk
	2 Filesystem Size Used Avail Use% Mounted on
	3 tmpfs      512M 0    512M  0%   /mnt/ramdisk

These two differences between ramfs and tmpfs make tmpfs much more manageable  however this is one major
drawback; tmpfs may use SWAP space. If your system runs out of physical RAM, files in your tmpfs partitions
may be written to disk based SWAP partitions and will have to be read from disk when the file is next
accessed. In some environments this can be seen as a benefit as you are less likely to get out of memory
exceptions as you could with ramfs because more ?memory? is available to use.

**************************************************************************************************************************************

**************************************************************************************************************************************


---
https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux

Create a RAM disk in Linux

Linux penguinThere are many reasons for creating a memory based file system in Linux, not least of which is
to provide a near zero latency and extremely fast area to story files. A prime use of a RAM disk is for
application caching directories or work areas.

There are two main types of RAM disk which can be used in Linux and each have their own benefits and
weaknesses:
  * ramfs
  * tmpfs

See my other post for the differences between ramfs and tmpfs.

Check the amount of free RAM you have left on your machine before creating a RAM disk. Use the Linux command 
free to see the unused RAM. The below is an example of a 31GB of ram in a production server.
	1 free -g
	2        total used free shared buffers cached
	3 Mem:   31    29   2    0      0       8
	4 -/+ buffers/cache: 20 11
	5 Swap:  13    6    7

The free command shows the amount of RAM availale on your system in addition to the amount of memory used,
free and used for caching. SWAP space is also displayed and shows if your system is writing memory to disk.

Create a folder to use as a mount point for your RAM disk.

1 mkdir /mnt/ramdisk

Then use the mount command to create a RAM disk.
	mount -t [TYPE] -o size=[SIZE] [FSTYPE] [MOUNTPOINT]

Substitute the following attirbutes for your own values:
  * [TYPE] is the type of RAM disk to use; either tmpfs or ramfs.
  * [SIZE] is the size to use for the file system. Remember that ramfs does not have a physical limit and is
    specified as a starting size.
  * [FSTYPE] is the type of RAM disk to use; either tmpfs, ramfs, ext4, etc.

Example:
	mount -t tmpfs -o size=512m tmpfs /mnt/ramdisk

You can add the mount entry into /etc/fstab to make the RAM disk persist over reboots. Remember however, that
the data will disappear each time the machine is restarted.
	vi /etc/fstab
	tmpfs       /mnt/ramdisk tmpfs   nodev,nosuid,noexec,nodiratime,size=1024M   0 0
**************************************************************************************************************************************

**************************************************************************************************************************************
---
http://askubuntu.com/questions/173094/how-can-i-use-ram-storage-for-the-tmp-directory-and-how-to-set-a-maximum-amount

How can I use RAM storage for the /tmp directory and how to set a maximum amount of RAM usage for it?

                After seeing the comment by Anonymous on the question How is the /tmp directory cleaned up?,
                I found that it would be a great idea to implement on my system, since I have 16GB of RAM and
                I never used all of it.

                    My temporary files never get written to the disk. They get written to a RAM disk. I did
                    put tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0 in /etc/fstab.

                My question is:
                Can I set a maximum value for RAM Usage for /tmp? And in that case, what would happen if the
                maximum amount got exceeded, would it write into the hard-disk drive?

                I have read this solution which states:
			mkdir -p /tmp/ram
			sudo mount -t tmpfs -o size=512M tmpfs /tmp/ram/

		But in my understanding, this won't be a permanent solution. If I need it to be permanent, it
                has to be added to the /etc/fstab configuration file.

                If this is the correct solution, how can I transform that mount command into a line in /etc/
                fstab?


                this is also a good idea if you have and SSD as you will not 'consume' it with not
                useful writings ... ? Postadelmaga Apr 2 '14 at 10:47

                add a comment |   

***
            You are absolutely right. The according fstab entry would look like this:
		tmpfs /tmp tmpfs defaults,noatime,nosuid,nodev,noexec,mode=1777,size=512M 0 0

            Please note:
            As tmpfs gets filled up, it will behave as any physical harddrive by giving an "not enough space"
            error. While rebooting (and thus emptying the cache) will fix this, you may run into trouble when
            a single operation consumes more space to begin with than there's space on tmpfs. In this case
            your computer will start to swap from ram to disk, which will make your system crawl to a halt,
            given you've got a swap partition to begin with, of course.

            Considering this, a size of 512MB might be far too less nowadays, since much more ram is in
            existence in modern machines and it has become much cheaper. Since you've already got 16GB of
            ram, using the default value of half your ram for tmpfs should more than suffice for almost all
            scenarios. To use the default value, simply leave out the size=512M entry in your /etc/fstab
            file.

            Another note:
	    You can quite as easily mount other system folders into ramdisk as well, such as
		    /var/cache
		    /var/games
		    /var/log/apt (use only defaults,noatime without mode= or nosuid)

            But beware: the same rules apply as above, running out of space might cause major trouble. E.g.
            imagine running out of space for /var/log/apt will render you unable to install any programs!
            Furthermore, loading /var/log folders into ramdisk will delete all your log files upon reboot, so
            you won't be able to debug your system if anything unexpected happens. So use these settings at
            your own risk!

            Editorial note: I removed the /run in tmpfs mount option since this folder and its subfolders are
            already mounted in tmpfs by default.

***
            4   If i'm not wrong, /var/tmp/ is for keeping files after reboot. Thats the main difference
                between this and /tmp/ , so YOU should not move /var/tmp to ram. ? user285767 May 27 '14 at
                13:20
            3   If Ubuntu runs out of 4GB tmpfs, will it use my 20GB SWAP partition? ? loostro Jun 24 '14 at
                16:30
            2   Yes, I'll need to add this, too. As soon as tmpfs exeeeds its limits, it'll extend to swap
                partition (give there is one). ? FuzzyQ Jun 24 '14 at 19:10
            2   Does allocating half your RAM to this mean that half your RAM is reserved for the RAMDISK, or
                is it only a cap to what the RAMDISK may consume, and whatever is not in use is free RAM that
                gets assigned to whatever program needs RAM?? ? matt Jan 19 '15 at 15:01
            2   @matt It's only a cap. ? FuzzyQ Jan 19 '15 at 16:04

***
             On systems using systemd, you have the option of using a systemd unit file instead of fstab to
             accomplish the goal of using tmpfs to mount tmp. On my Ubuntu 16.04 system, I ran:
		     sudo cp /usr/share/systemd/tmp.mount /etc/systemd/system/tmp.mount
		     sudo systemctl start tmp.mount
	
             The file /usr/share/systemd/tmp.mount looks like:
		     #  This file is part of systemd.
		     #
		     #  systemd is free software; you can redistribute it and/or modify it
		     #  under the terms of the GNU Lesser General Public License as published by
		     #  the Free Software Foundation; either version 2.1 of the License, or
		     #  (at your option) any later version.
		     [Unit]
		     Description=Temporary Directory
		     Documentation=man:hier(7)
		     Documentation=http://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
		     ConditionPathIsSymbolicLink=!/tmp
		     DefaultDependencies=no
		     Conflicts=umount.target
		     Before=local-fs.target umount.target
		     After=swap.target

		     [Mount]
		     What=tmpfs
		     Where=/tmp
		     Type=tmpfs
		     Options=mode=1777,strictatime

		     [Install]
		     WantedBy=local-fs.target

             Using FuzzyQ's fstab approach, systemd translates your fstab entries into mount units
             dynamically. I don't think either approach is better.

***	     
	     This looks interesting! I will try this when I'm next to my laptop ? Dan Aug 13 at 19:15
             You will need systemctl enable tmp.mount after cp else systemctl will fail with message
             "Failed to start tmp.mount: Unit tmp.mount not found." ? vimdude Oct 8 at 18:17


---
http://askubuntu.com/questions/152868/how-do-i-make-a-ram-disk

How do I make a RAM disk?

           I want to make a partition that is made of ram ...
           Example
           In windows 7 you can make a partition that is made of ram

	   Is there any good Alternative in Ubuntu ?

***	   
                Ubuntu comes with tmpfs. You need not create a RAMDISK. ? mixdev Mar 30 '14 at 4:03

                Depending on your intended use case you may not need a ramdisk for Ubuntu (or most Linux
                distros). The operating system caches reads and write activity to RAM while it is working
                with regular disks. If you read a small file several times, it will only be fetched from disk
                once, then retrieved from the RAM cache on the following times. If you have plenty of RAM,
                everything you do will get cached in this way so you get very little repeat disk activity. If
                you want non-persistent fast memory use instead of files, you need a RAMDISK still. See
                linuxatemyram.com for more details. ? TafT Oct 6 at 14:11

***		
                    This will show you how to make a RAMDISK super fast and easily. With a RAMDISK you can
                    use your memory for temporary space and it?s also a lot quicker than your hard drive.

                    Now lets start by using the next 2 commands to make your RAMDISK.

                    Put whatever you want your RAMDISK to be called where I wrote ?nameme?.
			    mkdir -p /media/nameme
			    mount -t tmpfs -o size=2048M tmpfs /media/nameme/

		    The above commands would use 2GB of my RAM for the RAMDISK. If you don?t have as much ram
                    as I do I would use 512MB or 1GB. So next were going to create a command for Terminal
                    that will automatically create the RAMDISK for you.

***		    
            The tmpfs filesystem is a RAMDISK. The following will create a 2G RAMDISK that will always be
            available.
		    sudo mkdir -p /media/ramdisk
		    sudo mount -t tmpfs -o size=2048M tmpfs /media/ramdisk

            The ramdisk folder is owned by root as it is to be available on reboot. The ramdisk permissions
            should be writeable by everyone. The tmpfs default permissions (chmod 1777) are correct.
		drwxrwxrwt 2 root root 180 Apr 23 07:34 /media/ramdisk

            To make the ramdisk permanently available, add it to /etc/fstab.
		grep /media/ramdisk /etc/mtab | sudo tee -a /etc/fstab

            You will see the line moved from mtab to fstab. It will look something like this.
		tmpfs /media/ramdisk tmpfs rw,size=2048M 0 0

            The RAMDISK won't consume memory until you use it. Double check your memory requirements during
	    maximum system load. If the RAMDISK is too large, your system will consume swap storage to make
	    up the difference.

            To adjust the size of the RAMDISK, edit /etc/fstab and verify by remounting the ramdisk (you will
            lose your current RAMDISK content as you will on reboot). The following will change the size of
            the ramdisk to 512M
		    # Check the existing ramdisk size.
		    df /media/ramdisk
		    # change size=512M for a 512 megabyte ram drive.
		    sudo vi /etc/fstab
		    # Remount the ramdisk, you will lose any existing content.
		    sudo mount -a /media/ramdisk
		    # Verify the new ramdisk size.
		    df /media/ramdisk


---
http://www.vanemery.com/Linux/Ramdisk/ramdisk.html

Linux Ramdisk mini-HOWTO

Introduction
What is a RAM disk? A RAM disk is a portion of RAM which is being used as if it were a disk drive. RAM disks
have fixed sizes, and act like regular disk partitions. Access time is much faster for a RAM disk than for a
real, physical disk. However, any data stored on a RAM disk is lost when the system is shut down or powered
off. RAM disks can be a great place to store temporary data.

The Linux kernel version 2.4 has built-in support for ramdisks. Ramdisks are useful for a number of things,
including:
  * Working with the unencrypted data from encrypted documents
  * Serving certain types of web content
  * Mounting Loopback file systems (such as run-from-floppy/CD distributions)

Why did I write this document? Because I needed to setup a 16 MB ramdisk for viewing and creating encrypted
documents. I did not want the unencrypted documents to be written to any physical media on my workstation. I
also found it amazing that I could easily create a "virtual disk" in RAM that is larger than my first hard
drive, a 20 MB Winchester disk. At the time, that disk was so large that I never even considered filling it
up, and I never did!

This document should take you step-by-step through the process of creating and using RAM disks.

Assumptions/Setup
I was using Red Hat 9 for this test, but it should work with other GNU/Linux distributions running 2.4.x
kernels. I am also assuming that the distribution you are using already has ramdisk support compiled into the
kernel. My test machine was a Pentium 4 and had 256 MB of RAM. The exact version of the kernel that I used
was: 2.4.20-20.9

-------------------------------------------------------------------------------------------------------------

Step 1: Take a look at what has already been created by your system
Red Hat creates 16 ramdisks by default, although they are not "active" or using any RAM. It lists devices
ram0 - ram 19, but only ram0 - ram15 are usable by default. To check these block devices out, use the
following command:
	[root]# ls -l /dev/ram*
	lrwxrwxrwx    1 root     root            4 Jun 12 00:31 /dev/ram -> ram1
	brw-rw----    1 root     disk       1,   0 Jan 30  2003 /dev/ram0
	brw-rw----    1 root     disk       1,   1 Jan 30  2003 /dev/ram1
	brw-rw----    1 root     disk       1,  10 Jan 30  2003 /dev/ram10
	brw-rw----    1 root     disk       1,  11 Jan 30  2003 /dev/ram11
	brw-rw----    1 root     disk       1,  12 Jan 30  2003 /dev/ram12
	brw-rw----    1 root     disk       1,  13 Jan 30  2003 /dev/ram13
	brw-rw----    1 root     disk       1,  14 Jan 30  2003 /dev/ram14
	brw-rw----    1 root     disk       1,  15 Jan 30  2003 /dev/ram15
	brw-rw----    1 root     disk       1,  16 Jan 30  2003 /dev/ram16
	brw-rw----    1 root     disk       1,  17 Jan 30  2003 /dev/ram17
	brw-rw----    1 root     disk       1,  18 Jan 30  2003 /dev/ram18
	brw-rw----    1 root     disk       1,  19 Jan 30  2003 /dev/ram19
	brw-rw----    1 root     disk       1,   2 Jan 30  2003 /dev/ram2
	brw-rw----    1 root     disk       1,   3 Jan 30  2003 /dev/ram3
	brw-rw----    1 root     disk       1,   4 Jan 30  2003 /dev/ram4
	brw-rw----    1 root     disk       1,   5 Jan 30  2003 /dev/ram5
	brw-rw----    1 root     disk       1,   6 Jan 30  2003 /dev/ram6
	brw-rw----    1 root     disk       1,   7 Jan 30  2003 /dev/ram7
	brw-rw----    1 root     disk       1,   8 Jan 30  2003 /dev/ram8
	brw-rw----    1 root     disk       1,   9 Jan 30  2003 /dev/ram9
	lrwxrwxrwx    1 root     root            4 Jun 12 00:31 /dev/ramdisk -> ram0

Now, grep through dmesg output to find out what size the ramdisks are:
	[root]# dmesg | grep RAMDISK
	RAMDISK driver initialized: 16 RAM disks of 4096K size 1024 blocksize
	RAMDISK: Compressed image found at block 0

As you can see, the default ramdisk size is 4 MB. I want a 16 MB ramdisk, so the next step will be to
configure Linux to use a larger ramdisk size during boot.

Step 2: Increase ramdisk size
Ramdisk size is controlled by a command-line option that is passed to the kernel during boot. Since GRUB is
the default bootloader for Red Hat 9, I will modify /etc/grub.conf with the new kernel option. The kernel
option for ramdisk size is:  ramdisk_size=xxxxx, where xxxxx is the size expressed in 1024-byte blocks. Here
is what I will add to /etc/grub.conf to configure 16 MB ramdisks:
	# grub.conf generated by anaconda
	#
	# Note that you do not have to rerun grub after making changes to this file
	# NOTICE:  You have a /boot partition.  This means that
	#          all kernel and initrd paths are relative to /boot/, eg.
	#          root (hd0,0)
	#          kernel /vmlinuz-version ro root=/dev/hda5
	#          initrd /initrd-version.img
	#boot=/dev/hda
	default=0
	timeout=10
	splashimage=(hd0,0)/grub/splash.xpm.gz
	title Red Hat Linux (2.4.20-20.9)
		root (hd0,0)
		kernel /vmlinuz-2.4.20-20.9 ro root=LABEL=/ hdc=ide-scsi ramdisk_size=16000
		initrd /initrd-2.4.20-20.9.img

Once you save the file, you will need to reboot your system. After the reboot, a look at the dmesg output
should confirm the change has taken effect:
	[root]# dmesg | grep RAMDISK
	RAMDISK driver initialized: 16 RAM disks of 16000K size 1024 blocksize
	RAMDISK: Compressed image found at block 0

Step 3: Format the ramdisk
There is no need to format the ramdisk as a journaling file system, so we will simply use the ubiquitous ext2
file system. I only want to use one ramdisk, so I will only format /dev/ram0:
	[root]# mke2fs -m 0 /dev/ram0
	mke2fs 1.32 (09-Nov-2002)
	Filesystem label=
	OS type: Linux
	Block size=1024 (log=0)
	Fragment size=1024 (log=0)
	4000 inodes, 16000 blocks
	0 blocks (0.00%) reserved for the super user
	First data block=1
	2 block groups
	8192 blocks per group, 8192 fragments per group
	2000 inodes per group
	Superblock backups stored on blocks:
		8193

	Writing inode tables: done
	Writing superblocks and filesystem accounting information: done

	This filesystem will be automatically checked every 22 mounts or
	180 days, whichever comes first.  Use tune2fs -c or -i to override.

The -m 0 option keeps mke2fs from reserving any space on the file system for the root user, which is the
default behavior. I want all of the ramdisk space available to a regular user for working with encrypted
files.

Step 4: Create a mount point and mount the ramdisk
Now that you have formatted the ramdisk, you must create a mount point for it. Then you can mount your
ramdisk and use it. We will use the directory /mnt/rd for this operation.
	[root]# mkdir /mnt/rd
	[root]# mount /dev/ram0 /mnt/rd

Now verify the new ramdisk mount:
	[root]# mount | grep ram0
	/dev/ram0 on /mnt/rd type ext2 (rw)
	[root]# df -h | grep ram0
	/dev/ram0              16M   13K   16M   1% /mnt/rd

You can even take a detailed look at the new ramdisk with the tune2fs command:
	[root]# tune2fs -l /dev/ram0
	tune2fs 1.32 (09-Nov-2002)
	Filesystem volume name:   none
	Last mounted on:          not available
	Filesystem UUID:          fbb80e9a-8e7c-4bd4-b3d9-37c29813a5f5
	Filesystem magic number:  0xEF53
	Filesystem revision #:    1 (dynamic)
	Filesystem features:      filetype sparse_super
	Default mount options:    (none)
	Filesystem state:         not clean
	Errors behavior:          Continue
	Filesystem OS type:       Linux
	Inode count:              4000
	Block count:              16000
	Reserved block count:     0
	Free blocks:              15478
	Free inodes:              3989
	First block:              1
	Block size:               1024
	Fragment size:            1024
	Blocks per group:         8192
	Fragments per group:      8192
	Inodes per group:         2000
	Inode blocks per group:   250
	Filesystem created:       Mon Dec  8 14:33:57 2003
	Last mount time:          Mon Dec  8 14:35:39 2003
	Last write time:          Mon Dec  8 14:35:39 2003
	Mount count:              1
	Maximum mount count:      22
	Last checked:             Mon Dec  8 14:33:57 2003
	Check interval:           15552000 (6 months)
	Next check after:         Sat Jun  5 14:33:57 2004
	Reserved blocks uid:      0 (user root)
	Reserved blocks gid:      0 (group root)
	First inode:              11
	Inode size:               128

In my case, I need the user "van" to be able to read and write to the ramdisk, so I must change the ownership
and permissions of the /mnt/rd directory:
	[root]# chown van:root /mnt/rd
	[root]# chmod 0770 /mnt/rd
	[root]# ls -ald /mnt/rd
	drwxrwx---    2 van     root         4096 Dec  8 11:09 /mnt/rd

The ownership and permissions on the ramdisk filesystem/directory should be tailored to your particular
needs.

Step 5: Use the ramdisk
Now that it has been created, you can copy, move, delete, edit, and list files on the ramdisk exactly as if
they were on a physical disk partiton. This is a great place to view decrypted GPG or OpenSSL files, as well
as a good place to create files that will be encrypted. After your host is powered down, all traces of files
created on the ramdisk are gone.

To unmount the ramdisk, simply enter the following:
	[root]# umount -v /mnt/rd
	/dev/ram0 umounted

Note:  If you remount the ramdisk, your data will still be there. Once memory has been allocated to the
ramdisk, it is flagged so that the kernel will not try to reuse the memory later. Therefore, you cannot
"reclaim" the RAM after you are done with using the ramdisk. For this reason, you will want to be careful not
to allocate more memory to the ramdisk than is absolutely necessary. In my case, I am allocating < 10% of the
physical RAM. You will have to tailor the ramdisk size to your needs. Of course, you can always free up the
space with a reboot!

-------------------------------------------------------------------------------------------------------------

Automating Ramdisk Creation
If you need to create and mount a ramdisk every time your system boots, you can automate the process by
adding some commands to your /etc/rc.local init script. Here are the lines that I added:
	# Formats, mounts, and sets permissions on my 16MB ramdisk
	/sbin/mke2fs -q -m 0 /dev/ram0
	/bin/mount /dev/ram0 /mnt/rd
	/bin/chown van:root /mnt/rd
	/bin/chmod 0750 /mnt/rd

-------------------------------------------------------------------------------------------------------------

Conclusion
You have now seen how to setup and use a ramdisk on your GNU/Linux system. Hopefully, you will find this
information to be interesting and useful!

-------------------------------------------------------------------------------------------------------------

Resources

  * /usr/src/linux-2.4/Documentation/ramdisk.txt
  * /usr/src/linux-2.4/drivers/block/rd.c
  * man mke2fs
  * Ramdisk article by Mark Nielsen for Red Hat 6.0

  

---
http://www.thegeekstuff.com/2008/11/overview-of-ramfs-and-tmpfs-on-linux/

Overview of RAMFS and TMPFS on Linux

[Linux Ramfs and Tmpfs]Using ramfs or tmpfs you can allocate part of the physical memory to be used as a
partition. You can mount this partition and start writing and reading files like a hard disk partition. Since
you?ll be reading and writing to the RAM, it will be faster.

When a vital process becomes drastically slow because of disk writes, you can choose either ramfs or tmpfs
file systems for writing files to the RAM.

Both tmpfs and ramfs mount will give you the power of fast reading and writing files from and to the primary
memory. When you test this on a small file, you may not see a huge difference. You?ll notice the difference
only when you write large amount of data to a file with some other processing overhead such as network.

1. How to mount Tmpfs
	# mkdir -p /mnt/tmp
	# mount -t tmpfs -o size=20m tmpfs /mnt/tmp

The last line in the following df -k shows the above mounted /mnt/tmp tmpfs file system.
	# df -k
	Filesystem      1K-blocks  Used     Available Use%  Mounted on
	/dev/sda2       32705400   5002488  26041576  17%   /
	/dev/sda1       194442     18567    165836    11%   /boot
	tmpfs           517320     0        517320    0%    /dev/shm
	tmpfs           20480      0        20480     0%    /mnt/tmp

2. How to mount Ramfs
	# mkdir -p /mnt/ram
	# mount -t ramfs -o size=20m ramfs /mnt/ram
	
The last line in the following mount command shows the above mounted /mnt/ram ramfs file system.
	# mount
	/dev/sda2 on / type ext3 (rw)
	proc on /proc type proc (rw)
	sysfs on /sys type sysfs (rw)
	devpts on /dev/pts type devpts (rw,gid=5,mode=620)
	/dev/sda1 on /boot type ext3 (rw)
	tmpfs on /dev/shm type tmpfs (rw)
	none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
	sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)
	fusectl on /sys/fs/fuse/connections type fusectl (rw)
	tmpfs on /mnt/tmp type tmpfs (rw,size=20m)
	ramfs on /mnt/ram type ramfs (rw,size=20m)

You can mount ramfs and tmpfs during boot time by adding an entry to the /etc/fstab.

3. Ramfs vs Tmpfs
Primarily both ramfs and tmpfs does the same thing with few minor differences.

  * Ramfs will grow dynamically.   So, you need control the process that writes the data to make sure ramfs
    doesn?t go above the available RAM size in the system. Let us say you have 2GB of RAM on your system and
    created a 1 GB ramfs and mounted as /tmp/ram. When the total size of the /tmp/ram crosses 1GB, you can
    still write data to it.   System will not stop you from writing data more than 1GB. However, when it goes
    above total RAM size of 2GB, the system may hang, as there is no place in the RAM to keep the data.
  * Tmpfs will not grow dynamically. It would not allow you to write more than the size you?ve specified
    while mounting the tmpfs. So, you don?t need to worry about controlling the process that writes the data
    to make sure tmpfs doesn?t go above the specified limit. It may give errors similar to ?No space left on
    device?.
  * Tmpfs uses swap.
  * Ramfs does not use swap.

4. Disadvantages of Ramfs and Tmpfs
Since both ramfs and tmpfs is writing to the system RAM, it would get deleted once the system gets rebooted,
or crashed. So, you should write a process to pick up the data from ramfs/tmpfs to disk in periodic
intervals. You can also write a process to write down the data from ramfs/tmpfs to disk while the system is
shutting down. But, this will not help you in the time of system crash.

                       Table: Comparison of ramfs and tmpfs
+--------------------------------------------------------------------------------+
|            Experimentation            |      Tmpfs       |        Ramfs        |
|---------------------------------------+------------------+---------------------|
|Fill maximum space and continue writing|Will display error|Will continue writing|
|---------------------------------------+------------------+---------------------|
|Fixed Size                             |Yes               |No                   |
|---------------------------------------+------------------+---------------------|
|Uses Swap                              |Yes               |No                   |
|---------------------------------------+------------------+---------------------|
|Volatile Storage                       |Yes               |Yes                  |
+--------------------------------------------------------------------------------+

If you want your process to write faster, opting for tmpfs is a better choice with precautions about the
system crash.

This article was written by SathiyaMoorthy. He is working at bksystems, interested in writing articles and  
contribute to open source in his leisure time. The Geek Stuff welcomes your tips and guest articles.



---
http://unix.stackexchange.com/questions/66329/creating-a-ram-disk-on-linux

Creating a ram disk on Linux

               I have a machine with 62GB of RAM, and a trunk that's only 7GB, so I thought I would create a
               RAM disk and compile there. I am not a Linux expert. I found instructions on the internet to
               create the RAM disk:
		mkfs -q /dev/ram1 8192

               but I changed the 8192 to 16777216 in an attempt to allocate 16GB of ram disk.

               I got the following error:
		       mkfs.ext2: Filesystem larger than apparent device size.
		       Proceed anyway? (y,n)

               At which point I got spooked and bailed.
			sudo dmidecode --type 17 | grep Size

	       shows
			8x8192MB + 2048MB = 67584 MB

               but du on /dev gives 804K.
               Is that the problem? Can I overcome that /dev size?

***
               12    Did you try tmpfs? It is a filesystem in RAM, no need for ext2. mount -o size=16G -t
                     tmpfs none /mnt/tmpfs ? t-8ch Feb 27 '13 at 18:17
                     That worked! Thanks! But so far, not much speed-up: I think the tools I'm using to build
                     are still using the regular disk. I'll put more stuff on the ram disk. ? Frank Feb 27 '13
                     at 18:24
               2     Putting the tools themselves on the ramdisk shouldn't make much difference as the kernel
                     will cache them anyways in ram. ? t-8ch Feb 27 '13 at 18:28
               1     @goldilocks It's anecdotal evidence, but when compiling our Java projects with Maven,
                     there is a significant speedup when using a ramdisk. I would guess though that this is
                     more because of seek time than read time. ? SpellingD Feb 27 '13 at 18:54
               1     /dev/shm, actually /run/shm, can be used; it's almost always there. ? Camille Goudeseune 
                     Feb 17 '14 at 22:06

***		     
          The best way to create a ram disk on linux is tmpfs. It's a filesystem living in ram, so there is
          no need for ext2. You can create a tmpfs of 16Gb size with:
		mount -o size=16G -t tmpfs none /mnt/tmpfs

***		
              on my system, with nothing at all in /mnt, it says: ls: cannot access /mnt/tmpfs: No such file
          2   or directory mount: mount point /mnt/tmpfs does not exist. Is that something to worry about? If
              I simply mkdir /mnt/tmpfs, does that defeat the purpose (by creating tmpfs on the regular disk
              - please no flames, I'm a beginner here). ? Frank Feb 27 '13 at 19:23
              You need a mountpoint (directory) as target, so after you created this directory (you can use
          9   any directory, existing contents are shadowed) you can mount it with the command from the
              answer. ? t-8ch Feb 27 '13 at 19:26

***	      
        Linux is very efficient in using RAM. There is little surprise that you see little if any speedup
        with tmpfs. The largest pieces to read into memory (and thus able to slow the process down) are the
        tools (compiler, assembler, linker), and in a longish make they will be loaded into memory at startup
        and never leave it. What is left is reading in source (the writing out of the results won't slow you
        down, unless severely memory constrained). Again, comon header files will stay around, only the
        user's source will require reading. And that is unlikely to be more than a few megabytes. Creating a
	large RAMdisk (or even much use of tmpfs) can very well slow things down (by making the build memory
	constrained, the files on RAMdisk or on tmpfs can not be used directly from there).

***
              What! How can they not be used directly from there? ? Kazark Feb 28 '13 at 16:08

              They are in RAM, but not in a format that is directly usable. ? vonbrand Feb 28 '13 at 16:09

        1     Really! How so? (Pardon my slowness.) ? Kazark Feb 28 '13 at 16:34

              @Kazark, to handle executables in memory special data structures are used. As RAMdisks and tmpfs
        6     aren't in common use to store executables (RAMdisks are a remnant from the good old days of
              excruciatingly slow floppy disks and such, tmpfs is for stricty temporary data), nobody has
              considered it important enough to add the required ugly hacks. ? vonbrand Feb 28 '13 at 16:39
              I have tried running my rails code from a tmpfs (RAM) filesystem, and I did not see any
        5     difference at all. I was really hoping for a noticeable difference but I was disappointed by how
              awesome linux is. ? Khaja Minhajuddin Mar 4 '13 at 19:25

***	      
        The problem is that the maximum size of a ramdisk, more specifically of size of memory that can be
        accessed via the ramdisk driver is configured at compiletime, can be overwritten at boottime, but
        remains fixed once the kernel is loaded into memory. The default value is probably measured in
        Megabytes. If I recall correctly the memory for a ramdisk is reserved right when the driver is
        loaded, all ramdisks are the same size and there is are some 16 ramdisks by default. So not even you
        want a ramdisk size of 16G :-)

	As stated in the other answer, tmpfs is what you want to use. Further, you won't win a lot by having
	your entire OS in a ramdisk/tmpfs. Just copy your builddir to a tmpfs and do your compiling then. You
	may have to ensure that all temporary results are written to a location thats in the tmpfs as well.

***	
              They don't actually use any memory until you write things to them. The boot time limit is just
              the limit. Even after filling one you can free the memory back up with blockdev --flushbufs. ? 
              psusi Feb 28 '13 at 13:57
              @psusi: can you give us more information on that? I can only find statements mentioning that
              once claimed by the ramdisk memory is never reclaimed, e.g. in Documentation/blockdev/
              ramdisk.txt in the kernel sources. And on my answer: that file also says the ramdisk grows as
              memory is consumed so it is not all allocated at once. ? Bananguin Mar 1 '13 at 14:46
              What sort of information? You run the command and it frees the ram, assuming you don't still
              have it mounted anyhow. ? psusi Mar 1 '13 at 15:13
              How do you know that the command does what you say it does? Its man page doesn't confirm that
              and the documentation in the kernel source tree can be understood to contradict your
              information. ? Bananguin Mar 1 '13 at 20:40
        4     I read the source code, and verified it by trying it. ? psusi Mar 1 '13 at 20:50

***	
             To make a large ram disk after boot, with no messing around with kernel parameters, this seems
             to work. Use tmpfs, make a file, mount it via loop, and mount that via a filesystem:
		     mount -t tmpfs -o size=200M tmpfs temp/
		     cd temp/
		     dd if=/dev/zero of=disk.img bs=1M count=199
		     losetup /dev/loop0 disk.img
		     mkfs.ext4 /dev/loop0
		     mount /dev/loop0 temp2/

             Probably a bit of performance penalty going through multiple different layers... but at least it
             works.

***
                 OP the amount of RAM is expressed in MB. So all you need to enter there is 16384. And then
                 voila you'd be in business.


---
http://superuser.com/questions/45342/when-should-i-use-dev-shm-and-when-should-i-use-tmp

When should I use /dev/shm/ and when should I use /tmp?

                        When should I use /dev/shm/ and when should I use /tmp? Can I always rely on them
                        both being there on Unices?

***			
           /dev/shm is a temporary file storage filesystem, i.e., tmpfs, that uses RAM for the backing
           store.  It can function as a shared memory implementation that facilitates IPC.

           From Wikipedia:
               Recent 2.6 Linux kernel builds have started to offer /dev/shm as shared memory in the form of
               a ramdisk, more specifically as a world-writable directory that is stored in memory with a
               defined limit in /etc/default/tmpfs.  /dev/shm support is completely optional within the
               kernel config file.  It is included by default in both Fedora and Ubuntu distributions, where
               it is most extensively used by the Pulseaudio application. ????????????^(Emphasis added.)

           /tmp is the location for temporary files as defined in the Filesystem Hierarchy Standard, which is
           followed by almost all Unix and Linux distributions.

	   Since RAM is significantly faster than disk storage, you can use /dev/shm instead of /tmp for the
	   performance boost, if your process is I/O intensive and extensively uses temporary files.

           To answer your questions: No, you cannot always rely on /dev/shm being present, certainly not on
           machines strapped for memory. You should use /tmp unless you have a very good reason for using /
           dev/shm.

           Remember that /tmp can be part of the / filesystem instead of a separate mount, and hence can grow
           as required. The size of /dev/shm is limited by excess RAM on the system, and hence you're more
           likely to run out of space on this filesystem.

***	   
                 I will be using it to redirect output from a commands' standard error output to a file. Then
                 I will read this file and process it. I will be doing this several thousand times (it's part
                 of the condition of a loop construct). I thought memory would be nice in this case. But I
                 also want it to be portable. I guess I'll check if /dev/shm exists, use it if it does, or
                 fallback to /tmp. Does that sound good? ? Deleted Sep 23 '09 at 16:04
           1     I'd also add a check for the minimum size and current usage level of /dev/shm to guard
                 against inadvertently filling it up. ? nagul Sep 23 '09 at 21:01
                 Under Linux 2.6 and later the /dev/shm is required to be mounted for the POSIX shared memory
           3     system calls like shm_open() to work. In other words some programs will break if its not
                 mounted - so it should be. It is not just a RAM disk. So you should make sure some of /dev/
                 shm is free. ? EdH Nov 30 '12 at 21:07
                 There is no performance boost by using /dev/shm. /dev/shm is memory (tmpfs) backed by the
           2     disk (swap). /var/tmp is memory (disk cache) backed by the disk (on-disk filesystem). In
                 practice, performance is about the same (tmpfs has a slight edge but not enough to matter). /
                 tmp may be tmpfs or not depending on how the administrator configured it. There is no good
                 reason to use /dev/shm in your scripts. ? Gilles Jun 18 '13 at 7:13
                 @GaretClaborn There's plenty of good reasons to use memory backed by swap, but that's called
                 normal process memory. If you're using a file, it's called a filesystem, and all filesystems
                 are memory (cache), which is backed by swap if the filesystem is something like tmpfs.
           2     Allocating disk space between swap and other storage areas is typically in the real of the
                 administrator. If an application wants files that tend to remain in RAM, /tmp is the normal
                 location (with $TMPDIR to override). The choice to make /tmp backed by swap, other disk space
                 or nothing is the administrator's. ? Gilles Jun 5 '14 at 14:09

***		 
        Okay, here's the reality.

        Both tmpfs and a normal filesystem are a memory cache over disk.

        The tmpfs uses memory and swapspace as it's backing store a filesystem uses a specific area of disk,
        neither is limited in the size the filesystem can be, it is quite possible to have a 200GB tmpfs on a
        machine with less than a GB of ram if you have enough swapspace.

        The difference is in when data is written to the disk. For a tmpfs the data is written ONLY when
        memory gets too full or the data unlikely to be used soon. OTOH most normal Linux filesystems are
        designed to always have a more or less consistent set of data on the disk so if the user pulls the
        plug they don't lose everything.

        Personally, I'm used to having operating systems that don't crash and UPS systems (eg: laptop
        batteries) so I think the ext2/3 filesystems are too paranoid with their 5-10 second checkpoint
        interval. The ext4 filesystem is better with a 10 minute checkpoint, except it treats user data as
	second class and doesn't protect it. (ext3 is the same but you don't notice it because of the 5
	second checkpoint)

        This frequent checkpointing means that unnecessary data is being continually written to disk, even
        for /tmp.

        So the result is you need to create swap space as big as you need your /tmp to be (even if you have
        to create a swapfile) and use that space to mount a tmpfs of the required size onto /tmp.

        NEVER use /dev/shm.

        Unless, you're using it for very small (probably mmap'd) IPC files and you are sure that it exists
        (it's not a standard) and the machine has more than enough memory + swap available.

***	
            Agreed, except for the conclusion, "NEVER use /dev/shm". You want to use /dev/shm in cases where
            you don't want a file to be written to the disk at all, and you want to minimize disk i/o. For
            example, I need to download very large zip files from an FTP server, unzip them, and then import
        9   them into a database. I unzip to /dev/shm so that for both the unzip and the import operations
            the HDD only needs to perform half the operation, rather than moving back and forth between
            source and destination. It speeds up the process immensely. That's one example of many, but I
            agree that it's a niche tool. ? Nathan Stretch Dec 11 '14 at 23:13

***	    
       In descending order of tmpfs likelyhood:

       +++++++++++++++++++++++++++++++++++++++++++++
       + /dev/shm  + always tmpfs + Linux specific +
       +++++++++++++++++++++++++++++++++++++++++++++
       + /tmp      + can be tmpfs + FHS 1.0        +
       +++++++++++++++++++++++++++++++++++++++++++++
       + /var/tmp  + never tmpfs  + FHS 1.0        +
       +++++++++++++++++++++++++++++++++++++++++++++

       Since you are asking about a Linux specific tmpfs mountpoint versus a portably defined directory that
       may be tmpfs (depending on your sysadmin and what's default for your distro), your question has two
       aspects, which other answers have emphasized differently:
		1. When to use these directories, based on good practice
		2. When it is appropriate to use tmpfs

       ------------------------------------------------------------------------------------------------------
       
       Good practices
       Conservative edition (mixture of conventions from FHS and common use):
		 * When in doubt, use /tmp.
		 * Use /var/tmp for large data that may not easily fit in ram.
		 * Use /var/tmp for data that is beneficial to keep across reboots (like a cache).
		 * Use /dev/shm as a side-effect of calling shm_open(). The intended audience is data buffers of
		   bounded size that are overwritten frequently and endlessly.
		 * If still in doubt, provide a way for the user to override. For example, the mktemp program 
		   honors the TMPDIR environment variable.

       Pragmatic edition:
       Use /dev/shm when it is important to use tmpfs, /var/tmp when it is important not to, else /tmp.

       Where tmpfs excels
       fsync is a no-op on tmpfs. This syscall is the number one enemy of (IO) performance (and flash
       longevity, if you care about that), though if you find yourself using tmpfs (or eatmydata) just to
       defeat fsync, then you (or some other developer in the chain) are doing something wrong. It means that
       the transactions toward the storage device are unnecessarily fine grained for your purpose ? you are
       clearly willing to skip some savepoints for performance, as you have now gone to the extreme of
       sabotaging them all ? seldom the best compromise. Also, it is here in transaction performance land
       where some of the greatest benefits of having an SSD are ? any decent SSD is going to perform
       out-of-this-world compared to what a spinning disk can possibly take (7200 rpm = 120 Hz, if notihing
       else is accessing it), not to mention flash memory cards, which vary widely on this metric (not least
       because it is a tradeoff with sequential performance, which is what they are rated by, e.g. SD card
       class rating). So beware, developers with blazing fast SSDs, not to force your users into this use
       case!

       Wanna hear a ridiculous story? My first fsync lesson: I had a job that involved routinely "upgrading"
       a bunch of Sqlite databases (kept as testcases) to an ever-changing current format. The "upgrade"
       framework would run a bunch of scripts, making at least one transaction each, to upgrade one database.
       Of course, I upgraded my databases in parallel (8 in parallel, since I was blessed with a mighty 8
       core CPU). But as I found out, there was no parallelization speedup whatsoever (rather a slight hit)
       because the process was entirely IO bound. Hilariously, wrapping the upgrade framework in a script
       that copied each database to /dev/shm, upgraded it there, and copied it back to disk was like 100
       times faster (still with 8 in parallel). As a bonus, the PC was usable too, while upgrading databases.

       Where tmpfs is appropriate
       The appropriate use of tmpfs is to avoid unnecessary writing of volatile data. Effectively disabling
       writeback, like setting /proc/sys/vm/dirty_writeback_centisecs to infinity on a regular filesystem.

       This has very little to do with performance, and failing this is a much smaller concern than abusing
       fsync: The writeback timeout determines how lazily the disk content is updated after the pagecache
       content, and the default of 5 seconds is a long time for a computer ? an application can overwrite a
       file as frequently as it wants, in pagecache, but the content on disk is only updated about once every
       5 seconds. Unless the application forces it through with fsync, that is. Think about how many times an
       application can output a small file in this time, and you see why fsyncing every single one would be a
       much bigger problem.

       What tmpfs can not help you with
         * Read performance. If your data is hot (which it better be if you consider keeping it in tmpfs),
           you will hit the pagecache anyway. The difference is when not hitting the pagecache; if this is
           the case, go to "Where tmpfs sux", below.
         * Short lived files. These can live their entire lives in the pagecache (as dirty pages) before ever
           being written out. Unless you force it with fsync of course.

       Where tmpfs sux
       Keeping cold data. You might be tempted to think that serving files out of swap is just as efficient
       as a normal filesystem, but there are a couple of reasons why it isn't:

         * The simplest reason: There is nothing that contemporary storage devices (be it harddisk or flash
           based) loves more than reading fairly sequential files neatly organized by a proper filesystem;
           swapping in 4KiB blocks is unlikely to improve on that.
         * More significantly, the cost of swapping out: Tmpfs pages are dirty ? they need to be written
           somewhere (to swap) to be evicted from pagecache, as opposed to file backed clean pages that can
           be dropped instantly. This extra write penalty is felt by whoever else needed that memory, which
           is hard to know, but deserves to be part of your performance evaluation.

***	   
        Use /tmp/ for temporary files. Use /dev/shm/ when you want shared memory (ie, interprocess
        communication through files).

        You can rely on /tmp/ being there, but /dev/shm/ is a relatively recent Linux only thing.

***	
             Isn't there a performance aspect as well? As /dev/shm is most often mounted as a tmpfs volume
             and essentially a RAM-disk? ? Deleted Sep 23 '09 at 9:37
             You can also mount /tmp as a tmpfs filesystem, I do so on my netbook to speed some things up by
             reducing writes to the (slow) SSD. There are disadvantages to doing so, of course (mainly the
             RAM use, but my netbook has far more RAM than it generally needs anyway). ? David Spillett Sep
             23 '09 at 10:55
             For my specific case I would use it for a sort of process communication. I capture the output of
             standard error from an application and act on the contents (and I still need the standard output
             untouched, so I can't do any 1>/dev/null 2>&1. I would do this several thousand times so a tmpfs
             would be nice. However if I release the script I can't rely on tmpfs being used for /tmp as I
             think it's not that common. If it's more common for /dev/shm then that's better for me. But I'm
             looking for guidelines regarding portability etc. ? Deleted Sep 23 '09 at 16:00

***	     
           /dev/shm is used for shared virtual memory system specific device drivers and programs.

           If you are creating a program that requires a virtual memory heap that should be mapped to virtual
           memory. This goes double so if you need multiple processes or threads to be able to safely access
           that memory.

           The fact is that just because the driver uses a special version of tmpfs for it, doesn't mean you
	   should use it as a generic tmpfs partition. Instead, you should just create another tmpfs
	   partition if you want one for your temporary directory.

***	   
         In PERL, having 8GB minimum on any machine (all running Linux Mint), I am of what I think is a good
         habit of doing DB_File-based (data structure in a file) complex algorithms with millions of reads
         and writes using /dev/shm

         In other languages, not having gigether everywhere, to avoid the starts and stops in network
         transfer (working locally on a file that is located on a server in a client-server atmosphere),
         using a batch file of some type, I will copy the whole (300-900MB) file at once to /dev/shm, run the
         program with output to /dev/shm, write the results back to the server, and delete from /dev/shm

	 Naturally, if I had less RAM, I would not be doing this. Ordinarily, the in-memory file system of /
	 dev/shm reads as a size being one half of your available RAM. However, ordinary use of RAM is
         constant. So you really couldn't do this on a device with 2GB or less. To turn paraphrase to
         hyperbole, there is often things in RAM that even the system doesn't report well.

***	 
              (I think this is in the spirit of what was originally asked.) What I mean basically is that I'm
              comfortable using /dev/shm as a RAM disk as long as I have sufficient memory. If it is
              inefficient to do so somehow, that should not dissuade you from doing so, but should trigger a
              question like "How can I have a ram disk on linux?". The answer is /dev/shm ? David Grove Sep
              27 '15 at 21:44



---
https://forums.plex.tv/discussion/80100/plex-transcoding-on-ramdisk

Plex Transcoding on RAMDisk

Hey all,
I just recently stumbled on an article that made me feel like I was back in 1994 again and it was about
RAMDisk's and how much faster they are than SSD's.  I decided to try it out and indeed the RAMDisk I made
benchmarked at over 5 GB/s read and 6 GB/s write speeds (my SSD's get 250+ MB/s).  It got me thinking, I have
this home media server with an abundance of extra RAM (32 GB total) and I'd like to find a way to utilize
that.  Then I was wondering what exactly I'd do with a RAMDisk and I was considering if this would be a
viable transcoding drive for Plex.  I've Googled it, but haven't found much information especially as it
pertains to Plex.

Currently, I don't have many issues with Plex and network speed isn't one of them, so I'm not looking to
"speed" things up necessarily.  What I'm more interested in is whether or not this could solve the issue that
no matter what I do, I can't watch videos streamed by Plex and continue downloading and processing data in
the background.  I'm almost positive that the reason the video freezes on me when this happens is because I'm
running SATA drives and if I had SAS drives that would allow simultaneous read/write, I don't think this
would be an issue.  But, instead of purchasing a SAS controller card at a few hundred bucks and then spending
hundreds more on SAS drives, what if I just used all this extra RAM I have and make a RAMDisk?

I'd be very interested in hearing if anybody is currently using this, how well it works, etc.  I'd also like
to know how transcoding with Plex is done, more specifically, does it do a frame at a time and then push it
to the device?  How big would the RAMDisk need to be for it to be efficient?

I appreciate any input in this matter!

***
    It depends what transcoding you're wanting to speed up. Many transcoding operations are very CPU-limited,
    meaning the CPU is the bottleneck, not any other part of the system. Granted, this is more true for video
    than it is for music, but for the most part you could probably speed up your storage system and find it
    wouldn't matter one bit.

    It also might not make any sense to speed up the transcoding, if Plex's on the fly transcoding we're
    talking about. For example, if your server can transcode video at 2x realtime (say), it can already keep
    up with the demands of any single media player. Being able to transcode a single stream at 4x real time
    makes no difference whatsoever.

    Sequential transfer rates sound really impressive for RAM disks, but again they're pointless for this
    sort of application. The bitrate of a raw CD stream is 1440 kbits/sec, or 180KB/sec. Any compressed
    2-channel, 16-bit 44kHz audio will by definition be less than that. Your SSD can stream that data at
    least a million times faster than that; what's the point of a RAM disk at that point?

    Bluray's maximum bitrate is something in the region of 60Mbit/sec, or call it 7.5MB/sec. That's a paltry
    data rate for a modern computer to keep up with, and again by definition any compressed media will have a
    lower rate. A cheap software RAID array of mechanical disks can easily outdo that by a factor of 10 or
    more and your SSD is 33 times faster. For transcoding, there's no point in being able to shovel the data
    at the CPU any faster as it simply can't keep up.

    RAM disks are a pain in the bum, to be honest. They excel as temporary scratch space for working on data
    with next to no access time hit, but they're hopeless otherwise. As soon as you shut the machine down,
    the RAM disk's contents are lost, and have to be repopulated the next time the system starts up.

    IMHO, if you wanted to make use of the extra RAM on your home server, a better approach might be to get
    into virtualisation.

    I have a Vsphere whitebox at home ("whitebox" is the term given to a server that's built from
    comparatively cheap commodity hardware rather than anything that's expensive and on VMware's hardware
    compatibility lists). It's quad-core Ivy bridge (i5-3470) system with 16GB of RAM, a boot/datastore SSD
    and a handful of 3TB drives; it runs the free version of Vsphere 5.1 (register with VMware and they give
    you a key to turn the trial version into something permanent), but it could quite easily be built on top
    of Microsoft's Hyper-V or something open-source like Xen. I chose Vsphere as that's what I wanted to
    learn at the time.

    On there I run an instance of FreeNAS (with the onboard SATA controller handed over to that VM), several
    instances of Ubuntu 12.04 for various purposes (including one that runs Plex server), an instance of
    WinXP for a couple of bits and bobs I'm playing with that are Windows-only and a small cluster of virtual
    machines for work.

    Doing things this way means I've been free to pick and choose between functions. I like ZFS as a
    filesystem, so something BSD-based made a lot of sense and FreeNAS was simple to get up and running.
    However, a lot of other software runs on Linux; if I'd dedicated the entire machine to FreeNAS, I would
    have been out of luck in running any of that.

    Another nice side-effect is the segregation between functions. For example, nothing I do to the VM
    running Plex can affect my FreeNAS install; I can't bork my data just because I much up something in
    Ubuntu. Similarly, I can feel free to fire up new VMs for work or whatever that I can trash if I make a
    complete mess of them, and it affects nothing else.

    The hardware cost no more than a pre-built Atom NAS box, consumes about the same amount of idle power
    (Ivy Bridge idles at single-digit Watts; it's damn impressive) and offers far more flexibility in what I
    can do with the system. Instead of hoping everything plays nicely with one another under a single OS, I
    have over a dozen servers up and running that all do their own thing. The main cost over a NAS is my
    time; I had to spend the time to set everything up and so forth.

    The reason RAM is important is that every instance of a VM incurs some overhead. I'm running many
    instances of different (and sometimes the same) operating system, which isn't free. However, RAM is
    cheap, and ~100MB or so per instance of (say) Ubuntu server is something I'd planned for by building with
    16GB.

    The problem with virtualisation is it really has to be planned from the beginning. It's hard to take a
    machine that already has data on it and turn it into a VM factory (where does the data go in the
    meantime?). It's also hard to take just any old machine and turn it into a Vsphere system; there are
    certain hardware features that are very desirable for running Vsphere, and not all processors, chipsets
    and motherboards support them.

    Like I said, it cost me some time to set up, but it's opened up a world of possibilities that I wouldn't
    otherwise have.

***
    So I read your topic and decided to try it out. Just set the transcoder temporary directory to the
    mounted tmpfs and it's working smoothly.

    If  you're not familiar with ramfs / tmpfs here's a good read:
	http://www.thegeekstuff.com/2008/11/overview-of-ramfs-and-tmpfs-on-linux/#more-251

    I'd recommend a tmpfs.

    The transcoder, it seems, stores many .ts files in different directories for each show being watched. I
    believe it cleans up after itself after the video finishes. I of course made my initial tmpfs 1024m so
    it's taking the better part of a movie to see what happens when it reaches the limit. 

    I read tmpfs will pour over into swap once it's full, I really hope plex will just cleanup watched ts
    files out as the tmpfs fills up.

    @Smegheid - your post was an interesting read, the reason I'd continue to use a ram disk for transcoding
    is to remove unnecessary read and writes on my SSD.

    EDIT:
    well finally played to the 1GB mark, plex clears the tmp dir and my 1GB tmpfs is empty again, the
    transcoder kicks off and hangs as the player was still buffering & w/ cpu utilization but nothing written
    to the tmp dir.

    Some purge logic needs to be introduced to manage the transcoder's temp directory if we want to have a
    limited directory size.

    TBH it would be nice to not have to write the transcoded data back to disk if we don't have to. For
    multi-user setups that come under concurrent load this could prove to be quite useful.

***
    Thanks for the responses and very solid info!

    @Smegheid - I really don't have any need to speed things up per se.  I guess what I'm trying to say is my
    primary issue isn't speed at all, but instead it's doing too much disk access at one time or at least I
    think that's the problem :).  Here's my setup:  i7-3770k overclocked to 4.2Ghz, MSI Z77A-GD65 mobo, 32 GB
    of RAM, PowerColor 7870 Myst Edition, Corsair SATA III 128 GB SSD's (for the OS which includes my
    installed programs) and my video drive is a 3 TB USB 3.0 external Seagate 7200 rpm drive.  When I'm
    downloading something and I'm watching a video at the same time, it's fine until the download gets
    processed and is being extracted.  When that happens, my video that I'm transcoding freezes and won't
    recover unless I restart the video from scratch after the entire process is over.  So what I was
    wondering is if I use a RAMdisk as the transcoding destination, would this eliminate the freezing?
     Currently my transcoding drive is setup to transcode to the external 3 TB drive (which again is what I'm
    playing the video from as well as where the downloaded data is being written) although I've also had it
    transcoding on the SSD and there was no difference on the freezing.  I suppose this could also be an
    issue with the processor, but that just seems so unlikely considering I've ran this thing through
    seemingly much higher loads in benchmarking and it hasn't hiccuped or done anything weird.  It just seems
    like a disk access issue and so I was wondering if a RAMdisk would offload that stress on these drives.
     I do have a bunch of other hard drives, none RAIDed, just random old drives that I've thrown in here and
    I haven't tried putting the transcoder on any of those either to see if it would help.  I suppose I could
    do that to test it as well.  I just figured that since I overdid it on the RAM with 32 GB and I've maybe
    used at most, 10 GB of that at any given time that I could utilize that extra RAM with the RAMdisk and
    save some money instead of buying commercial-grade SAS equipment.  I definitely am interested in
    transcoding to multiple devices simultaneously at some point in the future as well.

    @Vulcanworlds - I never really thought about it from the perspective of conserving read/writes on the SSD
    to prolong longevity, but that's a good point. :)  I have a trial edition of Dataram's RAMdisk and it's a
    great program, but only allows for a max of 4 GB to a single disk.  I was wondering whether or not if
    you're transcoding a 13 GB MKV file if that would mean that I'd at least need a 13 GB RAMdisk to
    effectively transcode or if I'd need more RAM allocated for that.  I'm totally willing to purchase the
    software because it would only be $20 and I like the fact that you can have Windows mount the drive on
    startup, yet you can still throw away the data after each reboot and not commit it to the saved image
    file.  When you say some "purge logic needs to be introduced" I believe you're saying that it doesn't
    automatically purge the transcode directory, correct?  I noticed a while back when the transcoding was
    still setup on my SSD that WinDirStat showed a huge amount of data being eaten up by the transcoding
    directory, so I suppose that would be the case.  With this program, it'll theoretically throw away that
    data every reboot, but that doesn't help if the thing never reboots, which is the goal...  Maybe there's
    some Windows scripting that could be done on this to automate clearing the directory out?

    Again, thanks for the helpful info!  Whenever I get a plan figured out and have more time, I'd be happy
    to post my findings on here as well.

***
    RandomTask83RandomTask83 Posts: 81Members, Plex Pass Plex Pass
    September 2013
    I've done it in Archlinux and it doesn't really is worthy because the bottleneck would not be your HD , I
    think SATA III is 3 gbps IIRC so split it in a half, so 1,5 per up and down . Still enough. As plex uses
    ffmpeg for all things, and it relies on your CPU speed , that is the bottleneck, do a test, encode a file
    manually with ffmpeg with x264 and mp3 or AAC and that is exactly what plex does to transcode. What I'm
    frying to argue is that a bluray movie is 40 Mbps < 1,5 gbps so the drive wouldn't be a bottleneck issue
    AFAIK.

    If you want to preserve read/write cycles in SSD to prevent isolation then is a good choice but you need
    at least 16-32 Gb of ram, because tmpfs uses only half of your ram at most, so if plex is transcoding and
    tmpfs wants out of space then your transcoding session aka your movie and your joy will end suddenly.

***    
    @jvillanova - I wouldn't even call this a bottleneck issue really.  I have no speed concerns for wanting
    to do this.  It's a matter of figuring out if my HDD/SSD are under too much stress from read/writes and
    whether or not a RAMdisk will solve that and preserving read/write cycles would be an added benefit.  I
    understand that the CPU is what does the heavy lifting on the transcoding process :)  Also SATA III is 6
    Gbps theoretical.  On my SSD I see real-world speeds around 250 Mb/s (2 Gbps) sequential and 150 Mb/s
    (1.2 Gbps) random.

    Maybe I should just forget about it and build a 21 Tb SuperNAS like Linus did... 

***
    I'd think your bottleneck is the USB 3.0 drive, put one of your spare hdd's in the box and set that as
    the transcoding directory. With it being the only I/O for that disk, you should be better off than having
    the transcoding write to the external hdd. Or, use a spare hdd as the download destination or extract
    destination. It'd be better to have 1 disk be read from while writing to another rather than your current
    setup which is attempting to read 2 different files (the archive and the file to transcode) while
    attempting to write 2 different files (the transcoded data & the extracted data) all over the same USB
    port. Sounds like a good recipe for some I/O blockage.

    It sounds like you're running windows, have you watched your drive I/O at all? Task Manager > Performance
    Tab > Resource Monitor

    In my experience, my 3770k @ 4.5 seems to handle transcoding 2 different 1080p movies simultaneously to
    the same 1 TB wd black sata III drive haven't really tried anything past that, though cpu utilization
    wise it seems like maybe 3 is all I'd manage.

    Technically you're correct about the ramdisk size. I'm thinking plex doesn't clear the transcoding
    directory until the file finishes playing or (a guess) you navigate back to the library. So, if you had
    enough space in your ramdisk for the entire transcoded file it should work without freezing & crashing
    PMS. If you want, try it out with a 20gb ramdisk and leave the other 12gb for windows. As long as you've
    got a single user or multiple users aren't all watching movies you may be okay.

    The purge logic I mentioned is something that the plex developers should / would need to implement such
    that the transcoded directory only holds on to the previous few minutes you just watched rather than from
    the beginning of the file.

***
    @Vulcanworlds - I offloaded the transcoding directory for Plex to a spare drive that I just got.  It's a
    2 TB drive with a bunch of reallocated sectors, so if it fails, no big loss.  I'll have to see how this
    goes, but I'm a bit skeptical of whether or not this will help.  The logistics of how data flows in from
    my downloads and then becomes available in the Plex library might be impossible to solve.  I don't see
    how I can get the data downloaded, uncompressed, moved to the library, but yet play from that same
    library simultaneously without encountering issues.

    For instance, say you're using Sickbeard/Couchpotato/Sabnzbd and you have them all installed on your
    local disk C:.  By default they download to a directory on C:, but you can of course change that download
    destination to a different drive like V:\.  Now on V:\ you want Plex to read that as your library so you
    set it to the directory there.  Now say you have another drive that you set as your transcoding drive T:
    \.  Now you have something downloading and you watch something at the same time so it's downloading to V:
    \ and you're watching a transcoded file, it's still accessing the V:\ drive for your video and then
    trasncoding it to T:\ right?  Eventually the download gets done and it needs to extract and process, so
    it's doubling the reads and writing to V: as well, correct?  Even if you left Sab to download to your C:
    \, you'd still need to eventually move it at some point to the V:\ drive to make it available to the Plex
    library, which would still be causing stress on the disk if you're trying to watch something at the same
    time.  After the download completes, Sab needs to process the file and extract it, potentially repair it
    with parity, etc. or am I missing something?

    It just seems like there's no way to get around the disk that houses the library on it from being
    accessed by multiple sources both reading and writing simultaneously, which is why I was considering
    going with SAS drives for that, but of course those are so crazy expensive.  I thought potentially using
    the RAMdisk would at least eliminate the stress caused to the disk by transcoding, but I think the bigger
    issue is simultaneous read/writes...

    Ugh my head is spinning...

    EDIT:  What about RAID'ing the drive that the Plex library resides on?  If I put those in a RAID that
    would increase the bandwidth and cut the read/writes in half correct?

***
    A couple of things:

    1) Raid'ing your drives won't necessarily increase the available bandwidth to your media. It really
    depends on how it's setup.

    2) Unless I miss understood, it seems like your media and your download path are on your external hard
    drive. Is that correct?

    If so, you mentioned your external media drive is USB3, but is it plugged in to a USB3?

    If it is on an external hard drive, that could be your bottle neck/ From my experience with external
    drives (which is not much), transfers over USB usually deteriorate if multiple read/write are occuring on
    the same drive. 

    What I would suggest is that you download your media to your SSD and then manually transfer them to your
    external later, which is a hassle, but could be done automatically with a script.

***
    Running Plex Media Server from a machine with fairly intensive operations on the filesystem I really like
    running transcoder reads/writes on a tmpfs. I've been doing this for a little while now. It all runs
    smoothly, but I do need to restart playback if the tmpfs fills up. So that's for anything where the
    quality after transcoding is still fairly high and the file is lengthy. (say, a 1080p 3 hour movie gets
    transcoded to a high bitrate 720p)

    I see no reason why Plex would hang on to older parts of the transcoding session. It doesn't seem to
    influence seeking much. Can't really think of another reason they would be kept in the first place. Would
    love to hear more reasons if there are any, though.

    So yes, I think it would be great if space would get purged/recycled. Alternatively it would also be
    great to simply have a configurable space limit per transcoding session. (Or a collective limit for all
    sessions, but that seems more error-prone.)

***
    @thejixn0r - if it's setup in a RAID-0, then it's just striped across all drives, right?  That should
    theoretically increase the bandwidth unless I'm mistaken.  Guess it really doesn't matter since my
    largest media storage drives are external and I'd need to rip them out of the enclosures.  Also, yes it's
    on a 3 TB Seagate 7200 RPM USB 3.0 drive.  The drive typically sees sequential read/writes around 145 MB/
    s when transferring to/from my SSD.  Not sure about how multiple connections degrade it, but it
    definitely is degraded.  As soon as something decompresses in SAB, whatever I'm watching, whether
    transcoding or not freezes up.  I've even tried just watching something in VLC and that freezes as soon
    as something is unpacking in Sab.  After the unpacking is over, the video is still frozen and I have to
    exit out of VLC and restart the video, but then it's fine until it happens again.

    @pzt - it seems as if Plex doesn't remove transcoding data from the transcode directory and if that fills
    up, then I can see how it would cause problems.  It would need more intensive purge logic than just a
    flush though because if you only had the last few minutes as Vulcanworlds suggested, then wouldn't that
    eliminate the ability to effectively search/fast-forward/rewind?  Granted, that feature doesn't seem to
    work too keen for me right now anyways, especially if I'm streaming to a 360, but just throwing out
    questions.

    I haven't had the free time lately that I wish I'd have to really dig into this stuff, test, and post
    results.  I'm also out of money to buy any other equipment to benchmark against.

***
    Vulcanworlds, that's an interesting idea. I hadn't considered that plex would generate intermediate files
    in the process of transcoding; I figured it would just be a plain old stream that didn't actually land
    anywhere.

    In that case, tmpfs is perfect. It's pretty much designed for this sort of thing, for data that is
    short-lived and not permanent.

    One word of warning to anyone else reading that has a passing familiarity with Unix/Linux is that /tmp is
    no longer a RAM disk on a bunch of Linux distributions. Ubuntu (and a bunch of its derivatives) now leave
    /tmp on the root filesystem, which  can be a surprise. Even the server version of Ubuntu (certainly
    12.04) does this these days.

***
    I've been trying to cleanup the transcode dir with a cron task:
find /ramdisk/plex-transcode-* -type f \( -iname 'media-0*.ts' ! -iname "*.tmp" \) -mmin 0.33 -exec rm {} \;
find /ramdisk/plex-transcode-* -type f \( -iname 'chunk-0*' ! -iname "*.tmp" \) -mmin 0.33 -exec rm {} \;
     
    Which seems to delete the old files, but  somehow it's not a 100% stable fix

***    
    1st of all.
    Sorry for necroing this thread. :(

    2nd.
    I can not get Plex Media Server to run on a RamDisk. I am Using 32Gb Corsair Vengeance Pro 2400 DDR3 and
    DimmDrive.

    If I run Plex Media Server, from the RamDisk, the client can not connect to the server despite all manual
    workarounds.

    Running Plex Media Server, off of my HDD and Plex connects to my tablet without a hitch.

    I figured I did not have enough to post to create another thread.



---
http://www.linuxfocus.org/English/November1999/article124.html

[ !!! OLD !!! ]
How to use a Ramdisk for Linux

Introduction to RamDisk
This is a brief article about how to setup a RamDisk on a RedHat 6.0 system. It should be very similar for
other Linux distributions.

What is a RamDisk? A RamDisk is a portion of memory that you allocate to use as a partition. Or, in other
words, you are taking memory, pretending to treat it as a hard drive, and you are saving your files to it.
Why would you want to use a RamDisk? Well, if you know that certain files you have are constantly going to be
used, putting the files into memory will increase the performance of your computer since your memory is
faster than your hard drive. Things like web servers with lots of data can be sped up this way. Or, if you
are insane, and you have a PII 550 Mhz computer with 1 gig of memory and an old 500 meg hard drive, you can
use it just to increase your hard drive space. Then again, if you want an almost diskless machine, it might
not be that crazy afterall.

Here are some more resources to help you.
 1. http://metalab.unc.edu/LDP/HOWTO/Kernel-HOWTO.html
 2. http://metalab.unc.edu/LDP/HOWTO/mini/LILO.html
 3. /usr/src/linux/Documentation/ramdisk.txt

How to use RamDisk
Well, it is very easy to use a ramdisk. First of all, the default installation of RedHat 6.0 comes with
ramdisk support. All you have to do is format a ramdisk and then mount it to a directory. To find out all the
ramdisks you have available, do a "ls -al /dev/ram*". This gives you the preset ramdisks available to your
liking. These ramdisks don't actually grab memory until you use them somehow (like formatting them). Here is
a very simple example of how to use a ramdisk.
	# create a mount point:
	mkdir /tmp/ramdisk0
	# create a filesystem:
	mke2fs /dev/ram0
	# mount the ramdisk:
	mount /dev/ram0 /tmp/ramdisk0

Those three commands will make a directory for the ramdisk , format the ramdisk (create a filesystem), and
mount the ramdisk to the directory "/tmp/ramdisk0". Now you can treat that directory as a pretend partition!
Go ahead and use it like any other directory or as any other partition.
If the formatting of the ramdisk faild then you might have no support for ramdisk compiled into the Kernel.
The Kernel configuration option for ramdisk is CONFIG_BLK_DEV_RAM .

The default size of the ramdisk is 4Mb=4096 blocks. You saw what ramdisk size you got while you were running
mke2fs. mke2fs /dev/ram0 should have produced a message like this:
	mke2fs 1.14, 9-Jan-1999 for EXT2 FS 0.5b, 95/08/09
	Linux ext2 filesystem format
	Filesystem label=
	1024 inodes, 4096 blocks
	204 blocks (4.98%) reserved for the super user
	First data block=1
	Block size=1024 (log=0)
	Fragment size=1024 (log=0)
	1 block group
	8192 blocks per group, 8192 fragments per group
	1024 inodes per group

Running df -k /dev/ram0 tells you how much of that you can really use (The filesystem takes also some space):
	>df -k /dev/ram0
	Filesystem  1k-blocks  Used Available Use% Mounted on
	/dev/ram0        3963    13      3746   0% /tmp/ramdisk0

What are some catches? Well, when the computer reboots, it gets wiped. Don't put any data there that isn't
copied somewhere else. If you make changes to that directory, and you need to keep the changes, figure out
some way to back them up.    

Changing the size of the ramdisks
To use a ram disk you either need to have ramdisk support compiled into the Kernel or you need to compile it
as loadable module. The Kernel configuration option is CONFIG_BLK_DEV_RAM . Compiling the ramdisk a loadable
module has the advantage that you can decide at load time what the size of your ramdisks should be.

Okay, first the hard way. Add this line to your lilo.conf file:
	ramdisk_size=10000 (or ramdisk=10000 for old kernels)
and it will make the default ramdisks 10 megs after you type the "lilo" command and reboot the computer. Here
is an example of my /etc/lilo.conf file.
	boot=/dev/hda
	map=/boot/map
	install=/boot/boot.b
	prompt
	timeout=50
	image=/boot/vmlinuz
		label=linux
		root=/dev/hda2
		read-only
		ramdisk_size=10000

Actually, I got a little over 9 megs of usable space as the filesystem takes also a little space.

When you compile ramdisk support as loadable module then you can decide at load time what the size should be.
This is done either with an option line in the /etc/conf.modules file:
	options rd rd_size=10000

or as a command line parameter to ismod:
	insmod rd rd_size=10000

Here is an example which shows how to use the module:
 1. Unmount the ramdisk mounted in the previous chapter, umount /tmp/ramdisk0 .
 2. Unload the module (it was automatically loaded in the previous chapter), rmmod rd
 3. Load the ramdisk module and set the size to 20Mb, insmod rd rd_size=20000
 4. create a file system, mke2fs /dev/ram0
 5. mount the ramdisk, mount /dev/ram0 /tmp/ramdisk0

Example of how to use a RamDisk for a webserver.
Okay, here is an example of how to use 3 ramdisks for a webserver. Let us say you are 99% confident that your
default installation of Apache for RedHat 6.0 won't use more than 9 megs for its cgi-scripts, html, and
icons. Here is how to install one.
First, issue this command to move the real copy of the document root directory of your webserver to a
different place. Also, make the directories to mount the ramdisks .
	mv /home/httpd/ /home/httpd_real
	mkdir /home/httpd
	mkdir /home/httpd/cgi-bin
	mkdir /home/httpd/html
	mkdir /home/httpd/icons

Then, add these commands to the start procedure in your /etc/rc.d/init.d/httpd.init (or where ever the httpd
gets started on your system):
### Make the ramdisk partitions
	/sbin/mkfs -t ext2 /dev/ram0
	/sbin/mkfs -t ext2 /dev/ram1
	/sbin/mkfs -t ext2 /dev/ram2

### Mount the ramdisks to their appropriate places
	mount /dev/ram0 /home/httpd/cgi-bin
	mount /dev/ram1 /home/httpd/icons
	mount /dev/ram2 /home/httpd/html

### Copying real directory to ramdisks (the
### data on the ramdisks is lost after a reboot)
	tar -C /home/httpd_real -c . | tar -C /home/httpd -x

### After this you can start the web-server.

-------------------------------------------------------------------------------------------------------------
                              Webpages maintained by the LinuxFocus Editor team
                                              (C) Mark Nielsen
                                               LinuxFocus 1999
1999-11-01, generated by lfparser version 0.8
[ !!! OLD !!! ]