filename: ramdisk_howto-use-on-linux-multif_20190828.txt
https://www.techrepublic.com/article/how-to-use-a-ramdisk-on-linux/

How to use a ramdisk on Linux
March 28, 2017

   If you need to boost the speed of data writes to storage on your Linux data center servers, a ramdisk
   might be what you need. Here's how to create one, mount it, and back it up.

   There may be instances where you need to include the fastest possible storage you can find on a
   server. In some cases, the best route to that is by making use of a ramdisk. Effectively, a ramdisk
   takes a portion of your system memory and uses it as a disk drive. This method of storage is
   considerably faster than standard hard disk storage, so it is a great tool for when you need
   blistering speed on a specific app.

   Ramdisks, of course, come with a serious caveat. Should you lose power (or shut down the machine),
   whatever you're working on could be lost. Because of that, it is important to do a regular backup of
   the directory used for your ramdisk (more on that in a bit).

   With that said, let's create a ramdisk. I'll be working with Ubuntu 16.04, but this will work on
   nearly any distribution.

Creating the ramdisk directory
   The first thing you must do is create a folder that will be used to mount the ramdisk. I'll create
   the folder /media/ramdisk. To do that, open up a terminal window and issue the command:
sudo mkdir -p /media/ramdisk

   You can name that folder whatever you like and place it anywhere on the directory structure. I like
   /media because it is the same location other drives will be mounted into by default.

Mounting the ramdisk
   Now we actually mount the newly created directory to a temporary storage area (one that will use RAM
   as opposed to hard drive space). This is accomplished with the following command:
sudo mount -t tmpfs -o size=2048M tmpfs /media/ramdisk

   You can adjust both the size and the mount point to fit your needs. In the above example, I have
   mounted 2GB of RAM to be used as a temporary file system to /media/ramdisk. That mounted directory
   can now be used at your discretion.

   When you're done using the ramdisk, you can unmount it with the command:
sudo umount /media/ramdisk

Automounting the ramdisk
   What if you want to have the ramdisk automatically created at boot? This can be done with the help of
   /etc/fstab. Open up that file and add the following (edit to suit your needs):
none /media/ramdisk tmpfs nodev,nosuid,noexec,nodiratime,size=2048M 0 0

   Save and close that file. You can test the newly modified /etc/fstab file with the command mount -a.
   If you receive no warnings, you're good to go.

Backup that ramdisk data
   Because we're dealing with non-persistent memory, you're going to want to set up a regular backup.
   You could create a very simple bash script with the following contents:
#!/bin/bash
â€‹cp -ru /media/ramdisk /BACKUP/PATH

   Where /BACKUP/PATH is a path to a location to house the backup of /media/ramdisk. Save and close that
   file (we'll name it /root/ramdisk_backup.sh). Give the backup script executable permissions with the
   command chmod u+x ramdisk_backup.sh. Next we must create a crontab entry. Issue the command sudo
   crontab -e and then add the following:
*/15 * * * * /root/ramdisk_backup.sh

   The above crontab entry will backup your ramdisk data every fifteen minutes. Now, should you lose
   power or have to reboot the machine, you won't lose data.

Use it wisely
   How you use your ramdisk is up to you. Make sure to use this type of non-persistent storage wisely.
   The last thing you want is to depend upon it, only to lose precious data, thanks to a black out. If
   used wisely, a ramdisk can be a serious benefit to your data center servers. If used poorly, well,
   I'm sure you know how that story ends.


---
https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux

Create a RAM disk in Linux

   Linux penguin There are many reasons for creating a memory based file system in Linux, not least of
   which is to provide a near zero latency and extremely fast area to story files. A prime use of a RAM
   disk is for application caching directories or work areas.

   There are two main types of RAM disk which can be used in Linux and each have their own benefits and
   weaknesses:
     * ramfs
     * tmpfs

   See my other post for the [***]differences between ramfs and tmpfs.

   Check the amount of free RAM you have left on your machine before creating a RAM disk. Use the Linux
   command free to see the unused RAM. The below is an example of a 31GB of ram in a production server.
free -g
       total used free shared buffers cached
Mem:   31    29   2    0      0       8
-/+ buffers/cache: 20 11
Swap:  13    6    7

   The free command shows the amount of RAM availale on your system in addition to the amount of memory
   used, free and used for caching. SWAP space is also displayed and shows if your system is writing
   memory to disk.

   Create a folder to use as a mount point for your RAM disk.
mkdir /mnt/ramdisk

   Then use the mount command to create a RAM disk.
mount -t [TYPE] -o size=[SIZE] [FSTYPE] [MOUNTPOINT]

   Substitute the following attirbutes for your own values:
     * [TYPE] is the type of RAM disk to use; either tmpfs or ramfs.
     * [SIZE] is the size to use for the file system. Remember that ramfs does not have a physical limit
       and is specified as a starting size.
     * [FSTYPE] is the type of RAM disk to use; either tmpfs, ramfs, ext4, etc.

   Example:
mount -t tmpfs -o size=512m tmpfs /mnt/ramdisk

   You can add the mount entry into /etc/fstab to make the RAM disk persist over reboots. Remember
   however, that the data will disappear each time the machine is restarted.
vi /etc/fstab
tmpfs       /mnt/ramdisk tmpfs   nodev,nosuid,noexec,nodiratime,size=1024M   0 0


---
[***]
https://www.jamescoyle.net/knowledge/951-the-difference-between-a-tmpfs-and-ramfs-ram-disk

The Difference Between a tmpfs and ramfs RAM Disk

   Linux penguin There are two file system types built into most modern Linux distributions which allow
   you to create a RAM based storage area which can be mounted and used link a normal folder.

   Before using this type of file system you must understand the benefits and problems of memory file
   system in general, as well as the two different types. The two types of RAM disk file systems are
   tmpfs and ramfs and each type has it's own strengths and weaknesses.

What is a memory based file system (RAM disk)?
   A memory based file system is something which creates a storage area directly in a computers RAM as
   if it were a partition on a disk drive. As RAM is a volatile type of memory which means when the
   system is restarted or crashes the file system is lost along with all it's data.

   The major benefit to memory based file systems is that they are very fast - 10s of times faster than
   modern SSDs. Read and write performance is massively increased for all workload types. These types of
   fast storage areas are ideally suited for applications which need repetitively small data areas for
   caching or using as temporary space. As the data is lost when the machine reboots the data must not
   be precious as even scheduling backups cannot guarantee that all the data will be replicated in the
   even of a system crash.

tmpfs vs. ramfs
   The two main RAM based file system types in Linux are tmpfs and ramfs. ramfs is the older file system
   type and is largely replaced in most scenarios by tmpfs.

ramfs
   ramfs creates an in memory file system which uses the same mechanism and storage space as Linux file
   system cache. Running the command free in Linux will show you the amount of RAM you have on your
   system, including the amount of file system cache in use. The below is an example of a 31GB of ram in
   a production server.
free -g
       total used free shared buffers cached
Mem:   31    29   2    0      0       8
-/+ buffers/cache: 20 11
Swap:  13    6    7

   Currently 8GB of file system cache is in use on the system. This memory is generally used by Linux to
   cache recently accessed files so that the next time they are requested then can be fetched from RAM
   very quickly. ramfs uses this same memory and exactly the same mechanism which causes Linux to cache
   files with the exception that it is not removed when the memory used exceeds threshold set by the
   system.

   ramfs file systems cannot be limited in size like a disk base file system which is limited by it's
   capacity. ramfs will continue using memory storage until the system runs out of RAM and likely
   crashes or becomes unresponsive. This is a problem if the application writing to the file system
   cannot be limited in total size. Another issue is you cannot see the size of the file system in df
   and it can only be estimated by looking at the cached entry in free.

tmpfs
   tmpfs is a more recent RAM file system which overcomes many of the drawbacks with ramfs. You can
   specify a size limit in tmpfs which will give a 'disk full' error when the limit is reached. This
   behaviour is exactly the same as a partition of a physical disk.

   The size and used amount of space on  a tmpfs partition is also displayed in df. The below example
   shows an empty 512MB RAM disk.
df -h /mnt/ramdisk
Filesystem Size Used Avail Use% Mounted on
tmpfs      512M 0    512M  0%   /mnt/ramdisk

   These two differences between ramfs and tmpfs make tmpfs much more manageable  however this is one
   major drawback; tmpfs may use SWAP space. If your system runs out of physical RAM, files in your
   tmpfs partitions may be written to disk based SWAP partitions and will have to be read from disk when
   the file is next accessed. In some environments this can be seen as a benefit as you are less likely
   to get out of memory exceptions as you could with ramfs because more 'memory' is available to use.


---
https://www.linuxbabe.com/command-line/create-ramdisk-linux

How to Easily Create RAM Disk on Debian, Ubuntu, Linux Mint, CentOS
August 18, 2019

   This tutorial will show you how to quickly create a RAM disk in any Linux distro (Debian, Ubuntu,
   Linux, Fedora, Arch Linux, CentOS, etc). Compared to commercial Windows RAM disk software that costs
   money, Linux can utilize this cool feature 100% free of charge.

What is RAM Disk?
   RAM disk is also known as RAM drive. It's a portion of your RAM that are formated with a file system.
   You can mount it to a directory on your Linux system and use it as a disk partition.

Why use RAM disk?
   RAM is ultra-fast compared to even the fastest solid state drive (SSD). As you may know, the main
   performance bottleneck in today's computer is the speed of hard drive, so moving programs and files
   to the RAM disk yields super fast computing experience.

   Pros of RAM disk:
     * Ultra-fast
     * Can sustain countless reads and writes

   Cons of RAM disk:
     * RAM is volatile which means all data in RAM disk will be lost when the computer shutdowns or
       reboots. However, this can be a pro in some situations, if you use it wisely.
     * RAM is expensive so it has limited capacity. You need to make sure not allocate too much space
       for RAM disk, or the operating system would run out of RAM.

   You can do a lot of interesting things with RAM disk.
     * RAM disk is best suited for temporary data or caching directories, such as Nginx FastCGI
       cache. If you use a SSD and there will be a lot of writes to a particular directory, you can
       mount that directory as a RAM disk to reduce wear out of SSD.
     * I also use RAM disk to temporary store screenshots when writing articles on this blog, so when my
       computer shut down, those screenshots will automatically be deleted on my computer.
     * You may not believe it, but I use RAM disk to run virtual machines inside VirtualBox. My SSD is
       about 250G. I can't run many VMs directly on the SSD and I'm not happy about the speed of my 2TB
       mechanical hard drive (HDD). I can move the VM from HDD to RAM disk before starting the VM, so
       the VM can run much faster.  After shutting down the VM, I move the VM files back to HDD, which
       takes less than 1 minute. This of course requires your computer to have a large capacity RAM.

How to Create a RAM Disk in Any Linux Distro
   First make a directory which can be anywhere in the file system such as
sudo mkdir /tmp/ramdisk

   If you want to let every user on your Linux system use the RAM disk, then change its permission to
   777.
sudo chmod 777 /tmp/ramdisk

   Next, check how much free RAM are left on your system with htop command line utility because we don't
   want to use too much RAM.
htop

   Then all left to do is to specify the file system type, RAM disk size, device name and mount it to
   the above directory. You can see from the screenshot above that I have plenty of free RAM, so I can
   easily allocate 1GB for my RAM disk. This can be done with the following one-liner. It will be using
   tmpfs file system and its size is set to 1024MB. myramdisk is the device name I gave to it.
sudo mount -t tmpfs -o size=1024m myramdisk /tmp/ramdisk

   To allocate 10G for the RAM disk, run this instead.
sudo mount -t tmpfs -o size=10G myramdisk /tmp/ramdisk

   If we issue the following command
mount | tail -n 1

   We can see it's successfully mounted.

   Now if I copy my VirtualBox machines file (5.8G) into the RAM disk, my RAM usage suddenly goes up to
   9.22G.


   If I unmount RAM disk,
sudo umount /tmp/ramdisk/

   Everything in that directory will be lost and RAM usage goes down to original.

   This is how you can test if your RAM disk is working.

Test RAM Disk Speed
   To test write speed of RAM disk, you can use dd utility.
sudo dd if=/dev/zero of=/tmp/ramdisk/zero bs=4k count=100000

   Which gave me 2.8GB/s write speed.


   To test read speed, run:
sudo dd if=/tmp/ramdisk/zero of=/dev/null bs=4k count=100000

   Which gave me 3.1 GB/s read speed.

   I also did a speed test on my SSD. The write speed is 534MB/s and read speed 1.6GB/s.

Auto-mount on System Boot
   Edit /etc/fstab file.
sudo nano /etc/fstab

   Add an entry like this:
myramdisk  /tmp/ramdisk  tmpfs  defaults,size=1G,x-gvfs-show  0  0

   x-gvfs-show will let you see your RAM disk in file manager. Save and close the file. Your Linux
   system will automatically mount the RAM disk when your computer boots up.

   To mount it immediately without reboot, run the following command.
sudo mount -a

How to Run VirtualBox VM on RAM Disk
   Note that this requires a large capacity RAM.

   When you create a brand new virtual machine, you should set the machine folder to the RAM disk
   directory (/tmp/ramdisk/).

   If you have an existing VM, then select the VM in the main VirtualBox Manager window and go to the
   menu bar and select Machine -> Move, or right-click the VM and select Move from the context menu. You
   will be prompted to choose a new folder for the virtual machine. Select /tmp/ramdisk/ as the new
   folder.

   Remember to move your VM back to the original folder before shutting down your computer, or your VM
   will be deleted.

Wrapping Up
   And that's the basics of creating RAM disk in Linux.


---
http://www.linuxfocus.org/English/November1999/article124.html

How to use a Ramdisk for Linux

Introduction to RamDisk
   This is a brief article about how to setup a RamDisk on a RedHat 6.0 system. It should be very
   similar for other Linux distributions.

   What is a RamDisk? A RamDisk is a portion of memory that you allocate to use as a partition. Or, in
   other words, you are taking memory, pretending to treat it as a hard drive, and you are saving your
   files to it. Why would you want to use a RamDisk? Well, if you know that certain files you have are
   constantly going to be used, putting the files into memory will increase the performance of your
   computer since your memory is faster than your hard drive. Things like web servers with lots of data
   can be sped up this way. Or, if you are insane, and you have a PII 550 Mhz computer with 1 gig of
   memory and an old 500 meg hard drive, you can use it just to increase your hard drive space. Then
   again, if you want an almost diskless machine, it might not be that crazy afterall.

   Here are some more resources to help you.
    1. http://metalab.unc.edu/LDP/HOWTO/Kernel-HOWTO.html
    2. http://metalab.unc.edu/LDP/HOWTO/mini/LILO.html
    3. /usr/src/linux/Documentation/ramdisk.txt

How to use RamDisk
   Well, it is very easy to use a ramdisk. First of all, the default installation of RedHat 6.0 comes
   with ramdisk support. All you have to do is format a ramdisk and then mount it to a directory. To
   find out all the ramdisks you have available, do a "ls -al /dev/ram*". This gives you the preset
   ramdisks available to your liking. These ramdisks don't actually grab memory until you use them
   somehow (like formatting them). Here is a very simple example of how to use a ramdisk.
# create a mount point:
mkdir /tmp/ramdisk0
# create a filesystem:
mke2fs /dev/ram0
# mount the ramdisk:
mount /dev/ram0 /tmp/ramdisk0

   Those three commands will make a directory for the ramdisk , format the ramdisk (create a
   filesystem), and mount the ramdisk to the directory "/tmp/ramdisk0". Now you can treat that directory
   as a pretend partition! Go ahead and use it like any other directory or as any other partition.
   If the formatting of the ramdisk faild then you might have no support for ramdisk compiled into the
   Kernel. The Kernel configuration option for ramdisk is CONFIG_BLK_DEV_RAM .

   The default size of the ramdisk is 4Mb=4096 blocks. You saw what ramdisk size you got while you were
   running mke2fs. mke2fs /dev/ram0 should have produced a message like this:
mke2fs 1.14, 9-Jan-1999 for EXT2 FS 0.5b, 95/08/09
Linux ext2 filesystem format
Filesystem label=
1024 inodes, 4096 blocks
204 blocks (4.98%) reserved for the super user
First data block=1
Block size=1024 (log=0)
Fragment size=1024 (log=0)
1 block group
8192 blocks per group, 8192 fragments per group
1024 inodes per group

   Running df -k /dev/ram0 tells you how much of that you can really use (The filesystem takes also some
   space):
>df -k /dev/ram0
Filesystem  1k-blocks  Used Available Use% Mounted on
/dev/ram0        3963    13      3746   0% /tmp/ramdisk0

   What are some catches? Well, when the computer reboots, it gets wiped. Don't put any data there that
   isn't copied somewhere else. If you make changes to that directory, and you need to keep the changes,
   figure out some way to back them up.

Changing the size of the ramdisks
   To use a ram disk you either need to have ramdisk support compiled into the Kernel or you need to
   compile it as loadable module. The Kernel configuration option is CONFIG_BLK_DEV_RAM . Compiling the
   ramdisk a loadable module has the advantage that you can decide at load time what the size of your
   ramdisks should be.

   Okay, first the hard way. Add this line to your lilo.conf file:
      ramdisk_size=10000 (or ramdisk=10000 for old kernels)
   and it will make the default ramdisks 10 megs after you type the "lilo" command and reboot the
   computer. Here is an example of my /etc/lilo.conf file.
boot=/dev/hda
map=/boot/map
install=/boot/boot.b
prompt
timeout=50
image=/boot/vmlinuz
        label=linux
        root=/dev/hda2
        read-only
        ramdisk_size=10000

   Actually, I got a little over 9 megs of usable space as the filesystem takes also a little space.

   When you compile ramdisk support as loadable module then you can decide at load time what the size
   should be. This is done either with an option line in the /etc/conf.modules file:
options rd rd_size=10000

   or as a command line parameter to ismod:
insmod rd rd_size=10000

   Here is an example which shows how to use the module:
    1. Unmount the ramdisk mounted in the previous chapter, umount /tmp/ramdisk0 .
    2. Unload the module (it was automatically loaded in the previous chapter), rmmod rd
    3. Load the ramdisk module and set the size to 20Mb, insmod rd rd_size=20000
    4. create a file system, mke2fs /dev/ram0
    5. mount the ramdisk, mount /dev/ram0 /tmp/ramdisk0

Example of how to use a RamDisk for a webserver.
   Okay, here is an example of how to use 3 ramdisks for a webserver. Let us say you are 99% confident
   that your default installation of Apache for RedHat 6.0 won't use more than 9 megs for its
   cgi-scripts, html, and icons. Here is how to install one.
   First, issue this command to move the real copy of the document root directory of your webserver to a
   different place. Also, make the directories to mount the ramdisks .
mv /home/httpd/ /home/httpd_real
mkdir /home/httpd
mkdir /home/httpd/cgi-bin
mkdir /home/httpd/html
mkdir /home/httpd/icons

   Then, add these commands to the start procedure in your /etc/rc.d/init.d/httpd.init (or where ever
   the httpd gets started on your system):

        ### Make the ramdisk partitions
/sbin/mkfs -t ext2 /dev/ram0
/sbin/mkfs -t ext2 /dev/ram1
/sbin/mkfs -t ext2 /dev/ram2

        ### Mount the ramdisks to their appropriate places

mount /dev/ram0 /home/httpd/cgi-bin
mount /dev/ram1 /home/httpd/icons
mount /dev/ram2 /home/httpd/html

        ### Copying real directory to ramdisks (the
  ### data on the ramdisks is lost after a reboot)
tar -C /home/httpd_real -c . | tar -C /home/httpd -x

  ### After this you can start the web-server.

Comments
    1. Please remember one thing, BACKUP YOUR DATA if you change it and you need it. When the computer
       reboots, any changes are lost.
       A cron job should do it. Have it check every 10 minutes and see if any files have changed and
       backup any changes. Another thing you could do is make your changes to the real directory, and
       then copy over the changes to the ramdisks. That is much safer.
    2. A cool use of this would be to have a computer with 1 gig of memory and then use 256 megs for
       "/tmp". If you have lots of processes that use "/tmp", it should help speed up your system. Also,
       anything in /tmp would get lost when the computer reboots, which can be a good thing.
    3. Linux uses all the memory that is not in use by programs as a unified disk-cache but my
       experience is that ramdisks give you despite that still some speed increase.


---
https://stackoverflow.com/questions/354254/ram-drive-for-compiling-is-there-such-a-thing

RAM drive for compiling - is there such a thing?

   An answer (see below) to one of the questions right here on Stack Overflow gave me an
   idea for a great little piece of software that could be invaluable to coders everywhere.

   I'm imagining RAM drive software, but with one crucial difference - it would mirror a real folder on
   my hard drive. More specifically - the folder which contains the project I'm currently working on.
   This way any builds would be nearly instantaneous (or at least a couple orders of magnitude faster).
   The RAM drive would synchronize its contents with the hard disk drive in background using only idle
   resources.

   A quick Google search revealed nothing, but perhaps I just don't know how to Google. Perhaps someone
   knows of such a software? Preferably free, but reasonable fees might be OK too.

   Added: Some solutions have been suggested which I discarded in the very beginning. They would be (in
   no particular order):
     * Buy a faster hard disk drive (SSD maybe or 10K RPM). I don't want a hardware solution. Not
       only software has the potential to be cheaper (freeware, anyone?), but it can also be used in
       environments where hardware modifications would be unwelcome if not impossible - say, at the
       office.
     * Let OS/HDD do the caching - it knows better how to use your free RAM. The OS/HDD have generic
       cache algorithms that cache everything and try to predict which data will be most needed in the
       future. They have no idea that for me the priority is my project folder. And as we all know quite
       well - they don't really cache it much anyway. ;)
     * There are plenty of RAM drives around; use one of those. Sorry, that would be reckless. I need my
       data to be synchronized back to the HDD whenever there is a bit of free time. In the case of a
       power failure I could bear losing the last five minutes of work, but not everything since my last
       checkin.

   Added 2: An idea that came up - use a normal RAM drive plus a background folder synchronizer (but I
   do mean background). Is there any such thing?

   Added 3: Interesting. I just tried out a simple RAM drive at work. The rebuild time drops from
   ~14 secs to ~7 secs (not bad), but incremental build is still at ~5 secs - just like on the HDD. Any
   ideas why? It uses aspnet_compiler and aspnet_merge. Perhaps they do something with other temp files
   elsewhere?

   Added 4: Oh, nice new set of answers! :) OK, I've got a bit more info for all you naysayers. :)

   One of the main reasons for this idea is not the above-mentioned software (14 secs build time), but
   another one that I didn't have access at the time. This other application has a 100 MB code base, and
   its full build takes about 5 minutes. Ah yes, it's in Delphi 5, so the compiler isn't too
   advanced. :) Putting the source on a RAM drive resulted in a BIG difference. I got it below a minute,
   I think. I haven't measured. So for all those who say that the OS can cache stuff better - I'd beg to
   differ.

   Related Question:
RAM disk for speed up IDE

   Note on first link: The question to which it links has been deleted because it was a duplicate. It
   asked:
What do you do while your code's compiling?

   And the answer by Dmitri Nesteruk to which I linked was:

     I compile almost instantly. Partly due to my projects being small, partly due to the use of RAM
     disks.

***
     * Why is hardware modification impossible in the office? We always have some budget available, if
       the value is there. Also, I've been known to buy hardware with my own money, just to make my work
       experience more pleasant. - Jay Bazuzi Dec 9 '08 at 22:01
     * 2
       In my case the builds take ~15s incremental and ~30s full. Not really something to convice the
       boss with. But it would be nice if it were 1s. :) And I don't want to invest my own money in
       this. Besides - there are many people out there and each has a different story. Many might have
       use of this too. - Vilx- Dec 9 '08 at 22:14
     * 4
       If I was your boss, I'd be interested in ways to get your build time down from 15s/30s to 1s. Any
       perceivable delay is an opportunity for improvement. Developer productivity is directly impacted
       by any delay. - Jay Bazuzi Dec 10 '08 at 0:09
     * 2
       I wish you were my boss. :D - Vilx- Dec 10 '08 at 8:03
     * 3
       @Jay unfortunately in many companies equipment and engineering time are completely different
       costs according to the accounting structure, and it often sadly makes financial sense to go cheap
       on the hardware even with the huge extra expense of the engineering time. Boss may not have
       control over it. - Adam Davis Mar 27 '09 at 15:02

***
   In Linux (you never mentioned which OS you're on, so this could be relevant) you can create block
   devices from RAM and mount them like any other block device (that is, a HDD).

   You can then create scripts that copy to and from that drive on start-up / shutdown, as well as
   periodically.

   For example, you could set it up so you had ~/code and ~/code-real. Your RAM block gets mounted at
   ~/code on startup, and then everything from ~/code-real (which is on your standard hard drive) gets
   copied over. On shutdown everything would be copied (rsync'd would be faster) back from ~/code to
   ~/code-real. You would also probably want that script to run periodically, so you didn't lose much
   work in the event of a power failure, etc.

   I don't do this anymore (I used it for Opera when the 9.5 beta was slow, no need anymore).

***
       +1 - Put the script in cron to rsync every five minutes or so, and nice it so it doesn't kill
       performance. I don't know how this would be accomplished on Windows, but there is a task
       scheduler, and there are rsync tools, so those plus a RAM disk app should work for you if that's
       your platform. - Adam Jaskiewicz Dec 9 '08 at 23:06
     * Yap, I use Windows. Vista Business 32-bit, to be precise. :) But other OS are relevant to the
       topic too. And, yes - the idea to use simple ramdisk+folder sync utility (xcopy in the most
       simple case) has already crossed my mind. See above. - Vilx- Dec 9 '08 at 23:10

***
   I'm surprised at how many people suggest that the OS can do a better job at figuring out your caching
   needs than you can in this specialized case. While I didn't do this for compiling, I did do it for
   similar processes and I ended up using a RAM disk with scripts that automated the synchronization.

   In this case, I think I'd go with a modern source control system. At every compile it would check in
   the source code (along an experimental branch if needed) automatically so that every compile would
   result in the data being saved off.

   To start development, start the RAM disk and pull the current base line. Do the editing, compile,
   edit, compile, etc. - all the while the edits are being saved for you.

   Do the final check in when happy, and you don't even have to involve your regular hard disk drive.

   But there are background synchronizers that will automate things - the issue is that they won't be
   optimized for programming either and may need to do full directory and file scans occasionally to
   catch changes. A source code control system is designed for exactly this purpose, so it would likely
   be lower overhead even though it exists in your build setup.

   Keep in mind that a background sync task, in the case of a power outage, is undefined. You would end
   up having to figure out what was saved and what wasn't saved if things went wrong. With a defined
   save point (at each compile, or forced by hand) you'd have a pretty good idea that it was at least in
   a state where you thought you could compile it. Use a VCS and you can easily compare it to the
   previous code and see what changes you've applied already.

***
     * Keeping the source files on ramdisk is dangerous - better to keep them on disk and have automated
       sync'ing to the ramdisk before builds. +1 for OS not always handling specialized needs perfectly,
       though! - snemarch Mar 27 '09 at 5:43
     * 1
       The source files are used and edited on ramdisk, but I'm suggesting that at every compile they
       are saved off to regular disk or repository. I'm not suggesting using a ramdisk alone with no
       form of non-volatile saving. - Adam Davis Mar 27 '09 at 13:10

***
   Speeding up compiles using RAM drives under Gentoo was the subject of a how-to written many eons ago.
   It provides a concrete example of what has been done. The gist is that all source and build
   intermediate file are redirected to a RAM disk for compile, while final binaries are directed to the
   hard drive for install.

   Also, I recommend exploring maintaining your source on hard drive, but git push your latest source
   changes to a clone respository that resides on the RAM disk. Compile the clone. Use your favorite
   script to copy the binaries created.

   I hope that helps.

***
   Your OS will cache things in memory as it works. A RAM disk might seem faster, but that's because you
   aren't factoring in the "copy to RAMDisk" and "copy from RAMDisk" times. Dedicating RAM to a fixed
   size ramdisk just reduces the memory available for caching. The OS knows better what needs to be in
   RAM.

***
     * 3
       This is true if you're copying the stuff to and from RAM every compile, but the idea is that
       you're copying to ram once, and compiling several times after making minor changes. I've done
       this before for related processes (not compiling) and for huge data sets is makes a really big
       difference. - Adam Davis Mar 27 '09 at 3:54
     * 2
       Don't trust the caching strategy of the OS to give you the same performance as your own caching
       strategy. - Adam Davis Mar 27 '09 at 3:55
     * Shouldn't the contents of recently accessed or modified files, i.e., those touched by the
       compiler, be in the file system cache? - Jay Conrod Mar 27 '09 at 5:34
     * 8
       read-caching is only part of the problem, compiling produces output files - possibly with
       suboptimal write patterns, and often a bunch of temporary files. - snemarch Mar 27 '09 at
       5:35
     * I feel like compiling tools flush files to disk, like permanent databases. So, the file may be
       catched but flushing it nevertheless takes Disk access time and am not sure but tools seem
       waiting until flushing completes. You need to disable durability instead of enabling caching. But
       you seems right in practice. My experiment shows that there is no performance difference besides
       the disk thrashing, which does not affect the performance figures. - Val Mar 19 '15 at 17:20

***
   We used to do this years ago for a 4GL macro-compiler; if you put the macro library and support
   libraries and your code on a RAM disk, compiling an application (on an 80286) would go from 20
   minutes to 30 seconds.

***
     * That's all nice and fine - there are plenty classical RAMDrives around. But I don't want my code
       to live SOLELY on the RamDrive. That's a bit dangerous you know. ;) I would like it to be
       synchronized to HDD whenever there is a bit of free time to do so. - Vilx- Dec 9 '08 at 21:39
     * @Steven A. Lowe - set in Scheduled Tasks to run every minute? Now THAT would kill my PC's
       performance. :P Although I suppose I could make it copy only newer files. Still it's pretty much
       work. However you did give me an idea - maybe some background folder synchronizator? - Vilx-
       Dec 9 '08 at 21:53
     * @Vlix: in our scenario, it took about 2 seconds to copy the files to the RAM disk before
       compiling, and 2 seconds to copy them out after compiling. I think some RAM disk products offer a
       shadow/synch feature - Steven A. Lowe Dec 9 '08 at 21:56


***
   I don't have exactly what you're looking for, but I'm now using a combination of Ramdisk and
   DRAM ramdisk. Since this is Windows, I have a hard 3 GB limit for core memory, meaning I cannot
   use too much memory for a RAM disk. 4 GB extra on the 9010 really rocks it. I let my IDE store all
   its temporary stuff on the solid state RAM disk and also the Maven repository. The DRAM RAM disk
   has a battery backup to the flash card. This sounds like an advertisement, but it really is an
   excellent setup.

   The DRAM disk has double SATA-300 ports and comes out with 0.0 ms average seek on most tests ;)
   Something for the Christmas stocking?

***
     * Sweet, but I don't have that much spare money. Plus, as I said - I want it to be software.
       - Vilx- Dec 9 '08 at 21:51
     * This sounds really cool (though not meeting the posters criteria). Does the backup to flash
       happen automatically whenever the drive is powered down, or what? - erickson Dec 10 '08 at
       0:54
     * Yep. The battery is enough to persist dram to the flash card. And it happens when mains power is
       lost. - krosenvold Dec 10 '08 at 7:35
     * The sad thing about these solutions is that the several GB/s of dram is limited to the SATA-300
       interface speeds :( - snemarch Mar 27 '09 at 5:36
     * At least it's dual SATA-300 interface ;) Strangely enough, I don't feel sad about it....
       - krosenvold Mar 27 '09 at 7:54

***
   Then I wrote these scripts to move directories to and from the RAM disk. Backup is made in a tar
   file before moving into the RAM disk. The benefit of doing it this way is that the path stays the
   same, so all your configuration files don't need to change. When you are done, use uramdir to bring
   back to disk.

   Edit: Added C code that will run any command it is given on an interval in background. I am sending
   it tar with --update to update the archive if any changes.

   I believe this general-purpose solution beats making a unique solution to something very simple. KISS

   Make sure you change path to rdbackupd

ramdir

#!/bin/bash

# May need some error checking for bad input.

# Convert relative path to absolute
# /bin/pwd gets real path without symbolic link on my system and pwd
# keeps symbolic link. You may need to change it to suit your needs.
somedir=$(cd $1; /bin/pwd$(;
somedirparent=$(dirname $somedir$(

# Backup directory
/bin/tar cf $somedir.tar $somedir

# Copy, tried move like https://wiki.archlinux.org/index.php/Ramdisk
# suggests, but I got an error.
mkdir -p /mnt/ramdisk$somedir
/bin/cp -r  $somedir /mnt/ramdisk$somedirparent

# Remove  directory
/bin/rm -r $somedir

# Create symbolic link. It needs to be in parent of given folder.
/bin/ln -s /mnt/ramdisk$somedir $somedirparent

#Run updater
~/bin/rdbackupd "/bin/tar -uf $somedir.tar $somedir" &

uramdir

#!/bin/bash

#Convert relative path to absolute
#somepath would probably make more sense
# pwd and not /bin/pwd so we get a symbolic path.
somedir=$(cd $1; pwd$(;

# Remove symbolic link
rm $somedir

# Copy dir back
/bin/cp -r /mnt/ramdisk$somedir $somedir

# Remove from ramdisk
/bin/rm -r /mnt/ramdisk$somedir

# Stop
killall rdbackupd

   rdbackupd.cpp
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <signal.h>
#include <sys/time.h>

struct itimerval it;
char* command;

void update_archive(int sig)
{
    system(command);
}

int main(int argc, char**argv)
{
    it.it_value.tv_sec     = 1;   // Start right now
    it.it_value.tv_usec    = 0;
    it.it_interval.tv_sec  = 60;  // Run every 60 seconds
    it.it_interval.tv_usec = 0;

    if (argc < 2)
    {
        printf("rdbackupd: Need command to run\n");
        return 1;
    }
    command = argv[1];

    signal(SIGALRM, update_archive);
    setitimer(ITIMER_REAL, &it, NULL); // Start

    while(true);

    return 0;
}

***
     * Correct me if I'm wrong, but this only synchronizes to the HDD when you explicitly tell it to,
       NOT in the background, right? - Vilx- Oct 25 '11 at 23:51
     * Correct add a tar command or script to crond - Joe McGrath Oct 26 '11 at 2:38
     * Also should be able to mount as directory with ntfs on atleast windows nt4 and batch files
       - Joe McGrath Oct 26 '11 at 2:41
     * @Vilx- Added C code that will run in background and update the tar file if there are any changes
       to the files. Can specify interval in C code. Making it take time as a parameter is trivial. Does
       everything you need now. - Joe McGrath Oct 31 '11 at 4:20
     * Will kill all the backup processes when uramdir. Can be addressed. - Joe McGrath Oct 31 '11
       at 5:27

***
    1. Profile. Make sure you do good measurements of each option. You can even buy things you've
       already rejected, measure them, and return them, so you know you're working from good data.
    2. Get a lot of RAM. 2 GB DIMMs are very cheap; 4 GB DIMMs are a little over US$100/ea, but that's
       still not a lot of money compared to what computer parts cost just a few years ago. Whether you
       end up with a RAM disk or just letting the OS do its thing, this will help. If you're running
       32-bit Windows, you'll need to switch to 64-bit to make use of anything over 3 GB or so.
    3. Live Mesh can synchronize from your local RAM drive to the cloud or to another computer, giving
       you an up-to-date backup.
    4. Move just compiler outputs. Keep your source code on the real physical disk, but direct .obj,
       .dll, and .exe files to be created on the RAM drive.
    5. Consider a DVCS. Clone from the real drive to a new repository on the RAM drive. "push" your
       changes back to the parent often, say every time all your tests pass.

***
     * 2. Not true. If your hardware supports PAE the OS can address more than 4G, just each
       application's address space is limited to 4G. - Adam Hawes Mar 27 '09 at 4:19
     * 1
       @Adam> only for server editions of Windows - client editions limit you to 4GB of address space
       (yes, AS, not physical memory! mix of market segmentation and "3rd parties wrote buggy drivers"
       excuse). - snemarch Mar 27 '09 at 5:38

***
   I had the same idea and did some research. I found the following tools that do what you are looking
   for:
     * VSuite RAM disk
     * DiskBoost

   However, the second one I couldn't manage to get working on 64-bit Windows 7 at all, and it doesn't
   seem to be maintained at the moment.

   The VSuite RAM disk on the other hands works very well. Unfortunately I couldn't measure any
   significant performance boost compared to the SSD disc in place.

***
   Yep, I've met the same problem. And after fruitless googling I just wrote a Windows Service for lazy
   backing up the RAM drive (actually - any folder, because RAM drive can be mounted in to, for example,
   the desktop).

   http://bitbucket.org/xkip/transparentbackup You can specify interval for full scan (default 5
   minutes). And an interval for scanning only notified files (default 30 seconds). Scan detects changed
   files using the 'archive' attribute (the OS resets that one specially for archiving purpose). Only
   files modified that way are backed up.

   The service leaves a special marker file to make sure that target backup is exactly a backup of the
   source. If the source is empty and does not contain a marker file, the service performs automatic
   restore from backup. So, you can easily destroy the RAM drive and create it again with automatic data
   restoration. It is better to use a RAM drive that is able to create a partition on system start up to
   make it work transparently.

   Another solution that I've recently detected is SuperSpeed SuperCache.

   This company also has a RAM disk, but that is another software. SuperCache allows you use extra RAM
   for block-level caching (it is very different from file caching), and another option - mirror you
   drive to RAM completely. In any scenario you can specify how often to drop dirty blocks back to the
   hard disk drive, making writes like on the RAM drive, but the mirror scenario also makes reads like
   from the RAM drive. You can create a small partition, for example, 2 GB (using Windows) and map the
   entire partition to RAM.

   One interesting and very useful thing about that solution - you can change caching and mirroring
   options any time just instantly with two clicks. For example, if you want your 2 GB back for gamimg
   or virtual machine - you can just stop mirroring instantly and release memory back. Even opened file
   handles does not break - the partition continues to work, but as a usual drive.

   EDIT: I also highly recommend you move the TEMP folder to te RAM drive, because compilers usually
   make a lot of work with temp. In my case it gave me another 30% of compilation speed.

***
   I wonder if you could build something like a software RAID 1 where you have a physical disk/partition
   as a member, and a chunk of RAM as a member.

   I bet with a bit of tweaking and some really weird configuration one could get Linux to do this. I am
   not convinced that it would be worth the effort though.

***
     There are plenty RAMDrives around, use one of those. Sorry, that would be reckless.

   Only if you work entirely in the RAM disc, which is silly..

   Psuedo-ish shell script, ramMake:
# setup locations
$ramdrive = /Volumes/ramspace
$project = $HOME/code/someproject

# ..create ram drive..

# sync project directory to RAM drive
rsync -av $project $ramdrive

# build
cd $ramdrive
make

#optional, copy the built data to the project directory:
rsync $ramdrive/build $project/build

   That said, your compiler can possibly do this with no additional scripts.. Just change your build
   output location to a RAM disc, for example in Xcode, it's under Preferences, Building, "Place Build
   Products in:" and "Place Intermediate Build Files in:".

***
   What can be super beneficial on even a single-core machine is parallel make. Disk I/O is a
   pretty large factor in the build process. Spawning two compiler instances per CPU core can actually
   increase performance. As one compiler instance blocks on I/O the other one can usually jump into the
   CPU intensive part of compiling.

   You need to make sure you've got the RAM to support this (shouldn't be a problem on a modern
   workstation), otherwise you'll end up swapping and that defeats the purpose.

   On GNU make you can just use -j[n] where [n] is the number of simultaneous processes to spawn.
   Make sure you have your dependency tree right before trying it though or the results can be
   unpredictable.

   Another tool that's really useful (in the parallel make fashion) is distcc. It works a treat
   with GCC (if you can use GCC or something with a similar command line interface). distcc actually
   breaks up the compile task by pretending to be the compiler and spawning tasks on remote servers. You
   call it in the same way as you'd call GCC, and you take advantage of make's -j[n] option to call many
   distcc processes.

   At one of my previous jobs we had a fairly intensive Linux operating system build that was performed
   almost daily for a while. Adding in a couple of dedicated build machines and putting distcc on a few
   workstations to accept compile jobs allowed us to bring build times down from a half a day to under
   60 minutes for a complete OS + userspace build.

   There's a lot of other tools to speed compiles existing. You might want to investigate more than
   creating RAM disks; something which looks like it will have very little gain since the OS is doing
   disk caching with RAM. OS designers spend a lot of time getting caching right for most workloads;
   they are (collectively) smarter than you, so I wouldn't like to try and do better than them.

   If you chew up RAM for RAM disk, the OS has less working RAM to cache data and to run your code ->
   you'll end up with more swapping and worse disk performance than otherwise (note: you should profile
   this option before completely discarding it).

***
   This sounds like disk caching which your operating system and / or your hard drive will handle for
   you automatically (to varying degrees of performance, admittedly).

   My advice is, if you don't like the speed of your drive, buy a high speed drive purely for compiling
   purposes. Less labor on your part and you might have the solution to your compiling woes.

   Since this question was originally asked, spinning hard disks have become miserable tortoises when
   compared to SSDs. They are very close to the originally requested RAM disk in a SKU that you can
   purchase from Newegg or Amazon.

***
     * Unfortunately OS/HDD don't let me tell them "cache this folder at all costs". :) And I was
       looking for a software solution instead of hardware because my office PC has enough RAM but I'm
       not sure my employer would be happy if I started messing with the hardware. Plus, it could be
       free. ;) - Vilx- Dec 9 '08 at 21:24
     * 2
       I do agree. A RAM disk is an order of magnitude faster than a hard disk for certain purposes, and
       I'm tired of getting the same "no need for a RAM disk" answer each time I ask for one :-)
       - Stephan Leclercq Dec 9 '08 at 21:31
     * Er... I meant a CACHED hard disk, of course :-) - Stephan Leclercq Dec 9 '08 at 21:31
     * Okay, let's put it another way: this sounds like an optimization problem. Exactly what speed
       problem are you trying to solve? Compile time to actual disk or compile time to runnable binary?
       - Bob Cross Dec 9 '08 at 22:41
     * Even a 10k rpm raptor/velociraptor drive didn't bring that great compile-time reductions over a
       decent 7200rpm drive for me. - snemarch Mar 27 '09 at 5:06

***
   Some ideas off the top of my head:

   Use Sysinternals' Process Monitor (not Process Explorer) to check what goes on during a
   build - this will let you see if %temp% is used, for instance (keep in mind that response files are
   probably created with FILE_ATTRIBUTE_TEMPORARY which should prevent disk writes if possible, though).
   I've moved my %TEMP% to a RAM disk, and that gives me minor speedups in general.

   Get a RAM disk that supports automatically loading/saving disk images, so you don't have to use boot
   scripts to do this. Sequential read/write of a single disk image is faster than syncing a lot of
   small files.

   Place your often-used/large header files on the RAM disk, and override your compiler standard paths
   to use the RAM drive copies. It will likely not give that much of an improvement after first-time
   builds, though, as the OS caches the standard headers.

   Keep your source files on your harddrive, and sync to the RAM disk - not the other way around. Check
   out MirrorFolder for doing realtime synchronization between folders - it achieves this via a
   filter driver, so only synchronizes what is necessary (and only does changes - a 4 KB write to a 2 GB
   file will only cause a 4 KB write to the target folder). Figure out how to make your IDE build
   from the RAM drive although the source files are on your harddisk... and keep in mind that you'll
   need a large RAM drive for large projects.

***
   The disk slowdown you incur is mainly write, and also possibly due to virus scanners. It can vary
   greatly between OSes too.

   With the idea that writes are slowest, I would be tempted to setup a build where intermediate (for
   example, .o files) and binaries get output to a different location such as a RAM drive.

   You could then link this bin/intermediate folder to faster media (using a symbolic link or

***
   My final solution to the problem is vmtouch: https://hoytech.com/vmtouch/ This tool locks the
   current folder into (ram) cache and vmtouch daemonizes into background.
sudo vmtouch -d -L ./

   Put this in shell rc for fast access:
alias cacheThis = 'sudo vmtouch -d -L ./'

   I searched for a ready made script for quite a while, because I didn't want to waste a lot of time on
   writing my own ramdisk-rsync-script. I'm sure I would have missed some edge cases, which would be
   quite unpleasant if important code was involved. And I never liked the polling approach.

   Vmtouch seems like the perfect solution. In addition it doesn't waste memory like a fixed size
   ramdisk does. I didn't do a benchmark, because 90% of my 1Gig source+build folder were already
   cached, but at least it feels faster ;)

***
   Just as James Curran says, the fact that most programs follow the law of locality of references, the
   frequent code and data page count will be narrowed over time to a manageable size by the OS disk
   cache.

   RAM disks were useful when operating systems were built with limitations such as stupid caches (Win
   3.x, Win 95, DOS). The RAM disk advantage is near zero and if you assign a lot of RAM it will suck
   memory available to the system cache manager, hurting overall system performance. The rule of thumb
   is: let your kernel to do that. This is the same as the "memory defragmentation" or "optimizers"
   programs: they actually force pages out of cache (so you get more RAM eventually), but causing the
   system to do a lot of page-faulting over time when your loaded programs begin to ask for code/data
   that was paged out.

   So for more performance, get a fast disk I/O hardware subsystem, maybe RAID, faster CPU, better
   chipset (no VIA!), more physical RAM, etc.

***
     * RAM disks can still offer substantial advantages. 1) you're 100% guaranteed to be in ram, OS
       cache doesn't guarantee this. 2) FS metadatase journalling... 3) overzealous filesync (firefox
       profile on ramdrive can go a lot faster than on a regular disk - remember backups though :) ).
       - snemarch Mar 27 '09 at 5:41
     * 1) For most applications, data not being 100% at RAM is a good thing, I think, due to (again)
       reference locality 2) This could be true, but for good FS journalling algorithms? [examples?] 3)
       I don't know, I'm sure you are using it to assert that :) - HernÃ¡n Mar 27 '09 at 13:17


---
