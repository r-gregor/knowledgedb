filename: hexadecimal-02_20170601.txt
http://thestarman.pcministry.com/asm/hexawhat.html

                            What Is "Hexadecimal" ?

                                      and

                 Where, How, and Why is it used on Computers?

     Copyright (C) 1996, 1999, 2000, 2002, 2004, 2011 by Daniel B. Sedory

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
All new Revision in 1999. Now contains an explanation of the use of Hexadecimal
for R - G - B colors as used in HTML for web pages ( Hexadecimal Colors in HTML
                                       )
   (And a link to a combined free HEX <---> DECIMAL converter and HTML color
                                    coder!)
                    Updated with links to Wikipedia, 2011.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

                                   Introduction

         "Hexa... What?" Well, that's hexa- (six) plus decimal (ten), or
    sixteen.
    It stands for the Base 16 Number System. Programmers often refer to it as
    simply, Hex (which by itself should mean only six, such as the number of
    sides that a "Hex wrench" has, but it almost always means Hexadecimal if
    the subject is computer software rather than hardware).

    You may already know that Binary (or Base 2) is what computers actually use
    to carry out calculations. Octal is Base 8, and Decimal, of course, is Base
    10. And just as we have ten digits, 0 through 9, in the Decimal system,
    there are sixteen digits we could use for Hexadecimal (0-9 and six more).

    
                                 The Basics of Hex
                                 
    The following tables show how the first six letters of the Latin alphabet
    (which are the same for most European languages; including English) are
    used as symbols in Hex so we can have a total of 16 Hexadecimal digits.
    Though it's now standard practice to use the capitals A through F (or
    lower-case forms if their meaning is unambiguous) to symbolize the Tenth
    through Sixteenth digits of the Hexadecimal Number System, remember, this
    is only a convention; any other set of 6 symbols (such as letters from
    Arabic, Korean or Japanese) could function in the same way; as well as any
    other symbols could for the Decimals 0-9.


 Hexadecimal          Decimal    |  Hexadecimal     Decimal
-------------       -----------  |  -----------     -------
 0 through 9        0 through 9  |
                                 |  1D  (1 x 16) + 13 = 29 
      A   ( 9 + 1 = )    10      |  1E     "     + 14 = 30
      B   ( 9 + 2 = )    11      |  1F     "     + 15 = 31
      C   ( 9 + 3 = )    12      |  20  (2 x 16) +  0 = 32
      D   ( 9 + 4 = )    13      |  21     "     +  1 = 33
      E   ( 9 + 5 = )    14      |  22     "     +  2 = 34
      F   ( 9 + 6 = )    15      |  23     "     +  3 = 35
     10   (1 x 16) + 0 = 16      |  24     "     +  4 = 36
     11   (1 x 16) + 1 = 17      |  25     "     +  5 = 37
     12      "    +  2 = 18      |  26     "     +  6 = 38
     13      "    +  3 = 19      |  27     "     +  7 = 39
     14      "    +  4 = 20      |  28     "     +  8 = 40
     15      "    +  5 = 21      |  29     "     +  9 = 41
     16      "    +  6 = 22      |  2A     "     + 10 = 42
     17      "    +  7 = 23      |  2B     "     + 11 = 43
     18      "    +  8 = 24      |  2C     "     + 12 = 44
     19      "    +  9 = 25      |  2D     "     + 13 = 45
     1A      "    + 10 = 26      |  2E     "     + 14 = 46
     1B      "    + 11 = 27      |  2F     "     + 15 = 47
     1C      "    + 12 = 28      |  30  (3 x 16) +  0 = 48


    Just as the location of the digits in a Decimal number represent the amount
    of ones, tens, hundreds, thousands, etc. in that number; which are the
    powers of 10. In a similar way, the digits in a Hex number stand for the
    ones, sixteens (16 to the power of 1), how many 256s (16 to the power of 2
    ), the amount of 4096s (16 to the power of 3), etc. in its numbers.

    The following table includes some important(*) Hex numbers in the PC
    industry; such as 200h (a small h, or capital H, at the end of a number
    means it's a Hexadecimal number; to prevent it from being mistaken as a
    Decimal number).

 Hexadecimal          Decimal   Hexadecimal          Decimal
 -----------          -------   -----------          -------
     30    (3x16) + 0 =  48   |     100    (1x256) =    256
     40    (4x16) + 0 =  64   |(*)  200    (2x256) =    512
     50    (5x16) + 0 =  80   |     400    (4x256) =   1024
     64    (6x16) + 4 = 100   |     500    (5x256) =   1280
(*)  7F    (7x16) +15 = 127   |     800    (8x256) =   2048
     80    (8x16) + 0 = 128   |     A00   (10x256) =   2560
     90    (9x16) + 0 = 144   |     FFF                4095
     9F    (9x16) +15 = 159   |    1000   (1x4096) =   4096
     A0   (10x16) + 0 = 160   |    4000   (4x4096) = 16,384
     B0   (11x16) + 0 = 176   |    5000   (5x4096) = 20,480
     F0   (15x16) + 0 = 240   |    8000   (8x4096) = 32,768
(*)  FF   (15x16) +15 = 255   |(*) FFFF              65,535

    FFFFh = (15x4096) + (15x256) + (15x16) + 15 = 65,535 ; which is the largest
    value that can be represented within sixteen Binary digits. 200h is the Hex
    equivalent for 512, as in: bytes per sector on both floppy and hard disks.
    Multiples of these sectors are sometimes called clusters. The format for a
    Windows 2000 or XP OS partition is usually NTFS; which often has 4 KiB
    clusters (or 8 "sectors per cluster"). Files are always stored on your
    computer (under the FAT or NTFS file systems) by dividing them up into
    clusters. The last cluster is almost never completely filled in by a file
    (it's often called slack space). Just before FAT32 was invented, many
    people had hard drives that used 32 KiB clusters; with lots of wasted space
    on them. The space you save by using Windows 2000/XP with NTFS rather than
    FAT32 can be huge since the size of new drives has already reached triple
    digits of Gigabytes!

┌─────────────────────────────────────────────────────────────────────────────┐
│ So, what does a Base 16 number system have to do with a machine that's      │
│ based ([smiley] pun intended) on zeros and ones?                            │
└─────────────────────────────────────────────────────────────────────────────┘

    Do any of those numbers above look familiar to you, specifically the number
    1024 and its multiples? It's more than just a coincidence that this is
    equal to the term we call a Binary Kilobyte (1024 bytes, or 2 to the power
    of 10 or 1 KiB). The 2 Kib, 4 Kib and 16 Kib multiples of this Binary
    number should now be evident in the Table above. 10,000 Hex (FFFFh + 1) is
    equivalent to 64 Binary KB (65,536 bytes, or 2 to the power of 16) which is
    the largest size a true .COM program* can have.

    After laying some groundwork from the past, we'll return to these
    observations and answer that important question in the box above! Hopefully
    you'll enjoy the following commentary on highlights from the history of
    computing.

*Perhaps you've heard of the file COMMAND.COM (it's the kernel for the MS-DOS
7.1 Operating System on a Windows 98 Boot Disk). Well it's really an .EXE
program! Microsoft(R) simply felt it had to retain the same name for this file,
most likely for compatibility reasons; it hasn't been an actual .COM file since
Windows 95 was released. A true .COM program can never be more than 64 KiB in
size, and does not begin with the letters "MZ" (which you'll find at the
beginning of this COMMAND.COM file and all other .EXE files).


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

               A Quick Look at the Amazing History of Computers
               
Over half a century ago, hot, room-sized machines built with vacuum tubes and
relays were already using the same concepts we still use today to carry out
instructions on numbers stored as "bits" (Binary digits) in structures known as
registers. Today, even our hand-held programmable calculators could blow away
those old computers in speed if not in results (number of digits). And the
registers have shrunk from the size of handfuls of light bulbs to a space so
tiny you need an electron microscope to see it; yet they still continue to add,
subtract and compare bits by the same logical methods already known long before
those now archaic machines could have been built.

Programs were often stored and fed into those first computers from patterns of
holes punched into a roll of paper tape (Punched Tape). This idea came from an
earlier device called the teletype (or teletypewriter or teleprinter), which
used a seven-bit code we now call ASCII to send alphanumeric data over wires.
Essentially this same bit code or expansions upon it, such as Unicode, are
still used to store data on a PC. Designed for communications, the original
code included control characters to signal the start of, success, failure, and
end of transmissions. The ASCII code 7, was used to ring a real bell at a
distant station, thus it is often abbreviated as "bell" in an ASCII chart.
Programs now use it to beep a computer's speaker!

Some of the 33 control codes used decades ago, such as ASCII 8 (a Backspace),
10 [0Ah] (a Line Feed), and 13 [0Dh] (a Carriage-Return) are still fairly close
to their original meanings, while others were so "device dependent" that modern
day equivalents no longer exist.

Seven bits gives us a total of 128 different codes in the standard ASCII
character set. That's 64 + 32 + 16 + 8 + 4 + 2 + 1 or 127, plus the zero. At a
much later date, companies such as IBM(R) and Apple(R) introduced their own
Extended ASCII character sets; which were eventually followed by Unicode.

The revolution in electronics which made home computing possible came about
when integrated circuit companies, such as Motorola(R), Intel(R), Rockwell(R)
and Zilog(R), began mass producing 8-bit microprocessors in the early
Seventies. The Motorola(R) MC6800 series made the loveable little Apple 
computers an instant success, and the Zilog(R) Z-80 made the Tandy(R) (Radio
Shack) TRS-80  a very common product. Finally, in 1979, Intel's 4.77 MHz 8088
chip (a 16-bit CPU with only an 8-bit bus) found a home inside the original IBM
(R) Personal Computer [Note: The Intel 8086, with a full 16-bit bus, had
already been produced in 1978, but IBM considered it too expensive to use for
their first PC project.]  In 1984, IBM introduced it's AT (Advanced Technology)
series based on Intel's 80286 CPU. That computer (made by the 'business
company' IBM), may have been what convinced many managers and CEOs that
microcomputers would soon become the future of computing in the business world.
(Well, that and the fact that further technological advances allowed PCs to be
"Networked" together through server machines! Once they became widely used in
large businesses, the PCs tended to cause data which had only been stored in
the tape libraries of main-frame computers to become distributed among "
workstations" as they're now called; rather than just being "dumb" terminals
that had to access what some still thought of as a "real computer" in order to
do something useful.)

                 A Few Details about the IBM PC and Microsoft

Instead of making its own Disk Operating System, IBM(R) paid a little software
company to put together a DOS for their new IBM Personal Computers. But, IBM
did not pay for exclusive rights to any future uses of this DOS. And when that
little company (called Microsoft(R)) made some changes and started selling
MS-DOS to anyone, it wasn't long until a flood of "AT clones" and "IBM -
compatibles" spread across the globe! Microsoft and Intel(R) made a fortune
selling the essential software and hardware that made up a PC, but IBM simply
acted like its usual "big blue" self over the losses in home and small business
sales. I'm sure that IBM now wishes they had done things differently, but
perhaps that's what they deserved for making a calculated decision to promote
Microsoft's DOS instead of an 8086 version of CP/M by Gary Kildall (which later
became Digital Research DOS). And in spite of what you may read elsewhere, Gary
never 'lost out' to Bill Gates due to any personal differences or missed
meetings! It was simply a business decision by IBM; which appears to have been
done on purpose since IBM's DOS could only be used on their machines, whereas
Gary's OS was almost machine independent. It's a little known fact (these days)
that IBM actually licensed both DOS and CP/M-86 for their PC, but you had to
special order CP/M-86 rather than having it come at a much lower price with
most PCs as IBM's DOS did; that was clearly a business decision on the part of
IBM!

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

                       Bits, Bytes, Characters and Words

    Data in these new microcomputers was contained in 8-bit units called "bytes
    " (a combination of the word bit and to bite; a 4-bit unit is often called
    a "nibble" [smiley] ). IBM(R) later added an extended-ASCII character set
    for their PCs, which doubled the size from 128 to 256 codes. Inside the
    Processor itself (the CPU), there were also registers of 16-bit lengths.
    The machine code which ran the CPU could have instructions of this size
    too, or even larger, arriving at the CPU in a number of successive bytes.
    It was around this time, that the term "word" took on its usual meaning of
    two eight-bit bytes. So, how did they manipulate such large binary numbers
    without making too many mistakes?


                  Why Octal and Hexadecimal are used On Computers

    Long before this, programmers regularly used a convenient method to handle
    large binary numbers in either 3-bit or 4-bit groupings. Most people find
    it quite easy to see what decimal numbers are represented by only three
    bits; for example, 101 is 5, 011 is 3, etc. If we use the 3-bits at a time
    method to convert the binary number 111000101000 into groups of 3-bit
    decimal digits, we obtain: 7 0 5 0. "If you needed to turn this into an
    Octal (Base 8) number, what more would you need to do?" Nothing! The digits
    7050 are the Octal equivalent of this Binary number; it's almost too
    simple. But to convert either of them into Decimal is a lot more difficult
    for most of us; yet it's quite often unnecessary for a programmer to do so.

    Not long after computers needed to be programmed, the actual machine code
    for the computer instructions was replaced by mnemonics (first m is silent 
    when pronouncing this word; it essentially means abbreviations). Three or
    four letters (at first), were used in what was called the Assembly Language
    for a particular CPU; thus, today we have the x86 Assembly code (in various
    forms) for Intel-based computers. It was also possible to use more than one
    base numeration for writing data in these Assembly languages, so
    programmers made sure their Assemblers [the programs which convert Assembly
    language into a particular machine code] could understand Octal as well as
    Binary numbers.

    Well, what about Hexadecimal? The same Binary number above, grouped into 
    four bits at a time, will give us the Hex numerals, E28. Now we're finally
    getting to the bottom of that important question above; and the main reason
    I wanted to write this essay.

    The maximum number a four-bit Binary can represent is 15. Exactly the same
    as a single Hex digit. And if you sum up the next four higher bits in a
    Binary number having eight bits, for example, the ones in 11110000, you'll
    get 16+32+64+128 = 240, or simply 15 times 16. And the next four bits
    beyond that will give you 15 times 256, or 3840.

    Let's compare the differences between grouping the Binary digits in sets of
    fours (for Hexadecimal) and threes (for Octal) in a more graphic manner :

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Binary:  | 2048 1024 512 256 | 128 64 32 16 | 8 4 2 1 | = 1111 1111 1111  ┃
┃   HEX :  |       256's       |     16's     |   1's   | =   F    F    F   ┃
┃ ------------------------------------------------------------------------- ┃
┃ Computing      (15 x 256)    +  (15 x 16 )  +   15                        ┃
┃  Decimal          3840       +     240      +   15      =    4 0 9 5      ┃
┃ equivalent                                                                ┃
┃ ========================================================================= ┃
┃ Binary: |2048 1024 512 | 256 128 64 | 32 16 8 | 4 2 1 | = 111 111 111 111 ┃
┃  OCTAL: |    512's     |     64's   |   8's   |   1's | =  7   7   7   7  ┃
┃ ------------------------------------------------------------------------- ┃
┃ Computing ( 7 x 512 ) +  ( 7 x 64 ) + (7 x 8) +   7                       ┃
┃  Decimal     3584     +     448     +    56   +   7     =    4 0 9 5      ┃
┃ eqivalent                                                                 ┃
┃ ========================================================================= ┃
┃  F F F h  =  7 7 7 7  Octal  =  4 0 9 5 (Decimal).                        ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛


    This shows that it's almost as easy to extract a Hexadecimal number from a
    Binary as it was to obtain its Octal eqivalent. We simply group the Binary
    bits by four digits instead of three.

    
                                    Conclusion

    There are two important aspects to the beauty of using Hexadecimal with
    computers: First, it can represent 16-bit words in only four Hex digits, or
    8-bit bytes in just two; thus, by using a numeration with more symbols, it
    is both easier to work with (saving paper and screen space) and makes it
    possible to understand some of the vast streams of data inside a computer
    merely by looking at the Hex output. This is why programs such as DEBUG,
    use only Hexadecimal to display the actual Binary bytes of a Memory Dump
    rather than a huge number of ones and zeros!

    The second aspect is closely related: Whenever it is necessary to convert
    the Hex representation back into the actual Binary bits, the process is
    simple enough to be done in your own mind. For example, FAD7 hex is
    1111101011010111 (F=1111, A=1010, D=1101, 7=0111) in Binary. The reason one
    might wish to do this is in order to work with "logical" (AND, OR or XOR)
    or "bit-oriented" instructions (Bit tests, etc.) which may make it easier
    (at times) for a programmer to comprehend.

    For example, if you wanted to logically AND the hex number FAD7 with D37E,
    you might have a difficult time without first changing these numbers into
    Binary. If you jot them out in Binary on scratch paper, the task will be
    much easier:

┌─────────────────────────────────────────────────────┐
│    FAD7(hex) =  1 1 1 1  1 0 1 0  1 1 0 1  0 1 1 1  │
│    D37E(hex) =  1 1 0 1  0 0 1 1  0 1 1 1  1 1 1 0  │
│                ------------------------------------ │
│  ANDing gives:  1 1 0 1  0 0 1 0  0 1 0 1  0 1 1 0  │
│    the Answer:     D       2        5       6       │
│      (in hex)                                       │
└─────────────────────────────────────────────────────┘
 

                                  FINAL THOUGHTS

       One final bit of advice: Remember that memory, stored programs, or codes
    always begin counting their locations or offsets with a ZERO (0). So, to
    arrive at a total you must add a one (1) to whatever number you see in the
    tables above: Thus, the amount of total memory locations in FF hex or the
    total length in bytes of a program that ends at offset FFh is 256 (
    inclusive), not just 255. In this case, an old phrase you may have heard,
    "nothing counts," is quite literally true as a zero stands for the first
    (1st) location you start counting from.

    However, any given 8-bit byte of memory, can never hold or count up to
    anything larger than FF hex, or 255, since a zero in a memory register
    represents the idea of nothing being in there (a true nil or null). In this
    case, the zero in a data register does not really count, because it is
    being used as a symbol to convey the idea that there isn't anything in
    there yet; it's only a void or emptiness!


    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
   

                                    APPENDIX on
                            Hexadecimal Colors in HTML
                   (Here's a new file on: The 16 Windows Colors)

    Along with the advances in Microcomputers, "the Internet" has experienced
    many changes as well. A code still used by "Web browsers" today had been
    invented to transfer information from servers to terminals in a way that
    made the Internet a much more effective tool for research. That code is
    called "Hyper-Text Markup Language" (or HTML) and it soon included a method
    which could theoretically reproduce background and text with a total of 16
    million, 777 thousand, 216 different colors.

    The hardware available today has already advanced way beyond that limit.
    The main reason was a push to display pictures "in living color;" now a
    common reality. And one of the first things a new computer user should
    always do is make sure their display can be set to what's called "24-bit"
    or "True Color" (for those 16-million plus possible colors). As a matter of
    fact, almost every video card today has the capacity to reproduce what's
    called "32-bit" color. But all those extra bits are not used for increasing
    the number of colors!  Why?  Well, since the human eye is only capable of
    distinguishing something like 7 million or so different colors, that would
    be a real waste of technology! But you'll have to look for another page
    about video cards if you want to know more; our task here is to simply
    explain the use color with HTML code.

    Soon there were two very typical lines of HTML code being used to create
    background colors:

      <body bgcolor="#FFFFFF">  for an all white background
    and
      <body bgcolor="#CCCCCC">  for a light-gray background

    As a matter of fact, some browsers display an all-white background as their
    default (when no color is given) whereas others use a light-gray color to
    display such backgrounds. And "#000000" is used to make pages with an
    all-black background. The three PRIMARY colors (RED, GREEN and BLUE) were
    each assigned TWO HEXADECIMAL DIGITS within this six-digit hexadecimal
    number : Each of the component colors (R-G-B) can, therefore, contribute a
    maximum of 256 different shades (zero through 255) to the final appearance
    of the background or text color. Here's a list which shows how easy it is
    to make six basic colors. The lines shown here contain the HTML "tag" pairs
    on either side of the TEXT color they create. (For those who may have a
    problem seeing one or more of the colors, the name also appears at the end
    of each line in parentheses):

                                                          HTML TAG Name
 <font color="#FF0000">  RED   </font>  (RED)
 <font color="#00FF00"> GREEN  </font>  (GREEN)    LIME
 <font color="#0000FF">  BLUE  </font>  (BLUE)
 <font color="#FFFF00"> YELLOW </font>  (YELLOW)
 <font color="#FF00FF"> VIOLET </font>  (VIOLET)  FUCHSIA
 <font color="#00FFFF">  CYAN  </font>  (CYAN)     AQUA


    You can now see that YELLOW really is a combination of Red and Green. When
    you combine Red and Blue it makes Violet (FUCHSIA), and displaying Green
    and Blue together causes the eye to see CYAN (AQUA). Other colors are
    formed by limiting the intensity of one or more of the three Primary
    Colors. E.g., cutting the values for the Green and Blue of Cyan in half
    gives you the default color for the MS-Windows 98 Desktop called TEAL
    (color = "#007F7F" ).
    [Note: Although you'll often see the word "Green" as the name for the
    Primary Color represented by "#00FF00" above, when it came time to assign
    the names of colors to HTML "tags" for Netscape's browser, they ended up
    calling this color "Lime" and assigned the name Green to half the full
    value: either "#007F00" (or "#008000").]

    For some reason when the first web browsers (including Netscape) were made,
    even though video cards used what was called VGA and could reproduce 256
    different colors, some of those colors were not compatible with the web
    browsers! Later browsers, such as Microsoft's series, could handle all 256
    colors. Rather than have their webpages possibly look bad for some people,
    many commercial HTML authors still use a subset of the 256 colors which are
    called "Browser Safe" or just "Safety" colors.

    There are FOUR different webpages here which contain SAMPLES of all 216
    colors in this "safety palette." Each consists of a large table that shows
    either the Hexadecimal Code or the R-G-B Notation for each color on a page
    with either a Black or a White background:

    Hexadecimal - White Background
    Hexadecimal - Black Background
    R-G-B Notation - White Background
    and R-G-B Notation - Black Background

    [ Here's the link to that FREE program I promised you. It does HEX and
    DECIMAL conversions, shows Hexadecimal and R-G-B Color Notations, allows
    you to pick a 24-bit "True Color" from a visual display and also performs
    logical operations and conversions on a maximum of 32-bit binaries:       B
    I T S (Version 1.7) ]


     Copyright (C)1996,1997,1999,2000,2002,2003,2004 by  Daniel B. Sedory
                           < Online reply form here >

Revised on November 7th, 2003. Updated: 25 OCT 2004
Last Update: May 31, 2011.
