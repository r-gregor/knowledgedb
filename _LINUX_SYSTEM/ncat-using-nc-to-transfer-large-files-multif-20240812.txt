filename: ncat_using-nc-to-transfer-large-files-multif_20240812.txt
https://superuser.com/questions/98089/sending-file-via-netcat

Sending file via netcat

   I'm using something like this to send file from one computer to another:

   To serve file (on computer A):
$> cat something.zip | nc -l -p 1234

   To receive file (on computer B):
$> netcat server.ip.here. 1234 > something.zip

   My question is... can I do the opposite? Let's say I have file on computer B and I want to send it to
   A but not the way I wrote above, but by making computer that's supposed to receive file (A) be
   'listening' server and connect computer that's 'sending' file (B) to server and send the file? Is it
   possible? I think it might be but I'm not sure how to do this.

   In case my above explanation is messed up: How do I send file TO 'server' instead of serving the file
   on server and then taking it FROM it (like I did above)?

***
   On your server (A):
$> nc -l -p 1234 -q 1 > something.zip < /dev/null

   On your "sender client" (B):
$> cat something.zip | netcat server.ip.here 1234

***
   As a note, if you want to also preserve file permissions, ownership and timestamps, we use tar with
   netcat to do transfers of directories and files.

   On receiving system:
$> nc -l -p 12345 -q 1 | tar xz -C /path/to/root/of/tree

   From sending system:
$> tar czf - ./directory_tree_to_xfer | nc <host name or IP address of receiving system> 12345

   Hope that helps.

***
   Computer A:
$> nc -l -p 1234 > filename.txt

   Computer B:
$> nc server.com 1234 < filename.txt

   Should work too ;)

***
   Init the target listening to the port. AKA receiver end
$> nc -vl 44444 > pick_desired_name_for_received_file

   Send the file to the target. AKA sender end
$> nc -n TargetIP 44444 < /path/to/file/you/want/to/send

   read more https://www.maketecheasier.com/netcat-transfer-files-between-linux-computers/

***
   I cooked everything for you. Keep it handy for regular use case.
   Make sure you change IP and port in this script.

   There are 3 modes.
   1. direct file transfer
   2. compressed file transfer
   3. folder transfer

receivefile() {
	[ $# -lt 1 ] && echo '$0 <file> <port>' && return 1
	local file=$1
	local port=${18080:-2}
	md5sum $file
	nc -v -l 0.0.0.0 -p $port > $file
}

sendfile() {
	[ $# -lt 1 ] && echo '$0 <file> <server> <port>' && return 1
	local file=$1
	local server=${115.98.2.1:-2}
	local port=${18080:-3}
	md5sum $file
	nc -c $server $port < $file
}

receivefilecompressed() {
	[ $# -lt 1 ] && echo '$0 <file> <port>' && return 1
	local file=$1
	local port=${18080:-2}
	md5sum $file
	nc -v -l 0.0.0.0 -p $port | gunzip > $file
}

sendfilecompressed() {
	[ $# -lt 1 ] && echo '$0 <file> <server> <port>' && return 1
	local file=$1
	local server=${115.98.2.1:-2}
	local port=${18080:-3}
	md5sum $file
	gzip -c $file | nc -c $server $port
}

receivefolder() {
	local port=${18080:-1}
	nc -v -l 0.0.0.0 -p $port | tar zxv
}

sendfolder() {
	[ $# -lt 1 ] && echo '$0 <folder> <server> <port>' && return 1
	local folder=$1
	local server=${115.98.2.1:-2}
	local port=${18080:-3}
	tar czp $folder | nc -c $server $port
}


---
https://stackoverflow.com/questions/17797758/using-nc-to-transfer-large-file

Using nc to transfer large file [closed]

   I have a compressed file size of about 9.5 GB and want to transfer from one server to another server,
   I tried to use like the below,

   server2:
$> nc -lp 1234 > file.tar.gz

   server1:
$> nc -w 1 1234 < file.tar.gz

   its not working.
   I tried so many ways.
   One machine is CentOS 6.4 and the other one is Ubuntu 12.04 LTS

   Thanks in advance.

***
   On receiving end:
$> nc -l 1234 > file.tar.gz

   On sending end:
$> cat file.tar.gz | nc <reciever's ip or hostname> 1234

   That should work. Depending on the speed, it may take a while but both processes will finish when the
   transfer is done.

***
   From the nc(1) man page:

     -l Used to specify that nc should listen for an incoming connection rather than initiate a
     connection to a remote host. It is an error to use this option in conjunction with the -p, -s, or
     -z options.

   So your use of -p is wrong.

   Use on server2:
$> nc -l 1234 > file.tar.gz

   And on server1:
$> nc server2 1234 < file.tar.gz

***
   from the sender
$> nc -v -w 30 1337 - l < filename

   where "-v" from verbose, "-w 30" for a wait before and after 30 sec for the connection, "1337" port
   number, "-l" tell nc that this is a sender

   from the receiver
$> nc -v -w 2 ip_add_of_sender 1337 > filename


---
https://www.baeldung.com/linux/netcat-sending-binary-data-established-connection

Netcat for Sending Binary Data to an Established Connection
March 18, 2024

We’ve started a new DevOps area on the site. If you’re interested in writing about DevOps, check out the
Contribution Guidelines.

1. Overview
Netcat, often referred to as the Swiss Army knife of networking tools, is a versatile and powerful utility
used for various network-related tasks. Sending binary data to an established connection is one of its many
capabilities.

In this tutorial, we’ll delve into the details of this process, learning how to effectively use Netcat for
sending binary data. We’ll also discuss the benefits it offers and some practical use cases.

2. Understanding Netcat
Netcat, a command-line networking utility, commonly referred to as nc, is widely available on most Linux
systems. We can utilize it both as a server and as a client for various network operations.

Its primary function is to establish TCP and UDP connections and transfer data between systems.

With its versatility, we can use it to create, listen to, and interact with network connections in multiple
ways. These characteristics make it a vital tool for tasks such as port scanning, banner grabbing, and more.

2.1. Netcat for Sending Binary Data
Here’s the general syntax for sending data with Netcat:
$> nc [options] hostname port

Here, hostname represents the target system’s address, and port represents the target port on which we want
to establish the connection. We can use options to configure the behavior of Netcat, such as specifying the
protocol (TCP or UDP), timeout, and more.

Sending binary data can be achieved by piping data into Netcat. For instance, let’s send the contents of a
binary file:
$> cat binary_file.bin | nc hostname port

In this command, cat is used to read the binary file and send its contents to Netcat via a pipe (|). Netcat,
in turn, sends this data to the specified hostname and port.

2.2. Netcat for Sending Hex Data
To send a hexadecimal string using Netcat, we can convert the hex string to binary and then use Netcat to
transmit the binary data.

Here’s an example of how to send a hex string with Netcat:

# Convert hex string to binary using Python and send it with Netcat
$> echo -n "1A2B3C4D" | xxd -r -p | nc -v -w 2 192.168.1.101 12345

In this example, we use the echo command to send the hex string 1A2B3C4D to the xxd utility, which converts
the hex string to binary (-r -p options). The binary data is then piped into Netcat, which sends it to the
IP address 192.168.1.101 on port 12345:
$> nc -l -p 12345 > received_data.bin

At this IP address, Netcat is listening ( -l option ) for incoming data on source port (-p option) 12345 and
writes the received data to a file named received_data.bin.

2.3. Benefits of Netcat for Sending Binary Data
Netcat’s ability to send binary data is incredibly versatile. We can use it for transferring binary files,
system configurations, and even for remote code execution in some scenarios.

It operates at the network layer and can transfer data quickly. Let’s see how to configure Netcat on a
server Server A to transfer data as quickly as possible to Server B:
$> echo "Hello, Server B!" | nc -u -w 1 -q 1 192.168.1.101 12345

 The -w 1 option specifies a timeout of 1 second, and the -q 1 option tells Netcat to quit after the data is
 sent. This ensures that data is sent rapidly. 

The command-line interface of Netcat makes it easy to use. A single command can be used to initiate a
connection, send data, and close the connection:
$> cat large_file.bin | nc 192.168.1.100 12345

If we need to transfer binary data from a Linux distribution to another system, such as a Windows PC, we can
use Netcat to accomplish this task. To send data using Netcat, we’ll first need to establish a connection
between the sending and receiving systems. We can do this by running the following command on the sending
system:
$> nc -l 1200 < file.bin

This command with the -l option instructs Netcat to listen on port 1200 and send the contents of the file.bin
file to any system that connects to that port.

On the receiving system, we can use a web browser to download the data by browsing to the IP address of the
sending system, followed by the port number. For example, if the sending system has an IP address of 192.168.1.100,
we should enter the URL http://192.168.1.100:1200 in our web browser.

This should prompt our web browser to download the file.bin file. However, if we’re behind a router, we may
need to forward port 1200 to our system to allow incoming connections. We can check our router’s
documentation for instructions on how to do this.

3. Practical Use Cases
Let’s see some of Netcat’s most common and practical use cases.

3.1. File Transfers
Sending binary data with Netcat can be useful for transferring files between systems. Whether we need to
share a software update or backup a configuration file, Netcat simplifies the process.
freestar

Let’s suppose, we have a software update file (software_update.zip) on Server A, and we want to transfer it
to Server B using Netcat:
$> nc -v -w 2 192.168.1.101 12345 < software_update.zip

In this example, Netcat first sends the software update file from Server A with IP Address 192.168.1.100:
$> nc -l -p 12345 > received_update.zip

With the verbose level enabled by the -l option, we receive the software update file on Server B with
IP Address 192.168.1.101.

3.2. Network Diagnostics
Netcat proves invaluable in diagnosing network issues and facilitating the exchange of binary data to and
from specific ports. For instance, the assessment of port 80 connectivity on remote server B with
IP 192.168.1.101:
$> nc -v 192.168.1.101 80
Ncat: Version 7.10 ( https://nmap.org/ncat )
Ncat: Connected to 10.68.180.56:80.

This usage aids in determining whether the targeted port is accessible, providing insights into potential
firewall restrictions.

The integration of binary data into this Netcat-driven network diagnostic process yields several advantages
such as efficiency, performance, reduced overhead, and precision and control. Using binary data enables the
implementation of advanced encryption and compression techniques. It also heightens the security of
transmitted data.

3.3. Network Monitoring
Netcat can be employed for basic network monitoring. We can use it to send and receive binary data to assess
network latency and performance:

$> timestamp=$(date +%s%N); echo $timestamp | nc -v 192.168.1.101 12345; echo "Received on A: $timestamp"; sleep 1
$> nc -l -p 12345 -v > /dev/null 2>&1

In this scenario, Netcat on Server A (192.168.1.100) sends a timestamp to Server B. Subsequently, Netcat on
Server B receives the timestamp and sends it back. By measuring the round-trip time for the message between
the servers, this approach provides a rudimentary estimate of network latency and performance.

The incorporation of binary data in such monitoring practices enhances efficiency, precision, and control over the diagnostic process.

4. Conclusion
In this article, we learned how Netcat’s ability to send binary data to an established connection is its
powerful feature. We can say so because apparently, it provides network administrators, security professionals,
and developers with a versatile tool for this task.

However, as with any powerful tool, it should be used responsibly and ethically, with security and permissions always taken into account.


---
https://unix.stackexchange.com/questions/227951/what-is-the-fastest-way-to-send-massive-amounts-of-data-between-two-computers

What is the fastest way to send massive amounts of data between two computers? [closed]

   This is a situation I am frequently in:
     * I have a source server with a 320GB hard-drive inside of it, and 16GB of ram (exact specs
       available here, but as this is an issue I run into frequently on other machines as well, I would
       prefer the answer to work on any "reasonable" Linux machine)
     * I have a backup server with several terabytes of hard-drive space (exact specs here, see
       disclaimer above)

   I want to transfer 320GB of data from the source server to the target server (specifically, the data
   from /dev/sda).
    1. The two computers are physically next to each other, so I can run cables between them.
    2. I'm on a LAN, and I'm using a new-ish router, which means my network speeds should "ideally"
       be 1000Mbit, right?
    3. Security is not an issue. I am on a local network, and I trust all machines on the network,
       including the router.
    4. (optional) I don't necessarily need a signed checksum of the data, but basic error checking (such
       as dropped packets, or the drive becoming unreadable) should be detected rather than just
       disappear into the output.

   I searched for this question online, and have tested several commands. The one that appears the most
   often is this:
$> ssh user@192.168.1.100 'dd bs=16M if=/dev/sda | gzip' > backup_sda.gz

   This command has proven too slow (it ran for an hour, only got about 80GB through the data). It took
   about 1 minute and 22 seconds for the 1GB test packet, and ended up being twice as fast when not
   compressed. The results may also have been skewed by the fact that the transferred file is less than
   the amount of RAM on the source system.

   Moreover (and this was tested on 1GB test pieces), I'm getting issues if I use the gzip command and
   dd; the resulting file has a different checksum when extracted on the target, than it does if piped
   directly. I'm still trying to figure out why this is happening.

***
   netcat is great for situations like this where security is not an issue:
# on destination machine, create listener on port 9999
$> nc -l 9999 > /path/to/outfile

# on source machine, send to destination:9999
$> nc destination_host_or_ip 9999 < /dev/sda
# or dd if=/dev/sda | nc destination_host_or_ip 9999

   Note, if you are using dd from GNU coreutils, you can send SIGUSR1 to the process and it will emit
   progress to stderr. For BSD dd, use SIGINFO.

   pv is even more helpful in reporting progress during the copy:
# on destination
$> nc -l 9999 | pv > /path/to/outfile

# on source
$> pv /dev/sda | nc destination_host_or_ip 9999
# or dd if=/dev/sda | pv | nc destination_host_or_ip 9999

***
###  on tgt machine...
nc -l 9999 > out.lz4
###  then on src machine...
... lz4 | nc tgt.local 9999

***
   Added on insistence of the original poster in comments to zackse’s answer, although I’m not sure it
   is the fastest in typical circumstances.

   bash has a special redirection syntax:
   For output:     > /dev/tcp/ IP / port
   For input:      < /dev/tcp/ IP / port
   IP ban be either dotted-decimal IP or a hostname; port ban be either a decimal number or a port name
   from /etc/services.

   There is no actual /dev/tcp/ directory. It’s a special syntactic kludge that commands bash to create
   a TCP socket, connect it to the destination specified, and then do the same thing as a usual file
   redirection does (namely, replace the respective standard stream with the socket using dup2(2)).

   Hence, one can stream data from dd or tar at the source machine directly via TCP. Or, conversely, to
   stream data to tar or something alike directly via TCP. In any case, one superfluous netcat is
   eliminated.

Notes about netcat
   There is an inconsistency in syntax between classical netcat and GNU netcat. I’ll use the
   classical syntax I’m accustomed to. Replace -lp with -l for GNU netcat.

   Also, I’m unsure whether does GNU netcat accept -q switch.

Transferring a disk image
   (Along the lines of zackse’s answer.)
   On destination:
$> nc -lp 9999 >disk_image

   On source:
$> dd if=/dev/sda >/dev/tcp/destination/9999
 

Creating a tar.gz archive, with tar
   On destination:
$> nc -lp 9999 >backup.tgz

   On source:
$> tar cz files or directories to be transferred >/dev/tcp/destination/9999

   Replace .tgz with .tbz and cz with cj to get a bzip2-compressed archive.

Transferring with immediate expansion to file system
   Also with tar.
   On destination:
$> cd backups
$> tar x </dev/tcp/destination/9999

   On source:
$> tar c files or directories to be transferred |nc -q 1 -lp 9999

   It will work without -q 1, but netcat will stuck when data ended. See tar(1) for explanation of the
   syntax and caveats of tar. If there are many files with high redundancy (low entropy), then
   compression (e. g. cz and xz instead of c and x) can be tried, but if files are typical and the
   network is fast enough, it would only slow the process. See mikeserv’s answer for details about
   compression.

Alternative style (the destination listens port)
   On destination:
$> cd backups
$> nc -lp 9999 |tar x

   On source:
$> tar c files or directories to be transferred >/dev/tcp/destination/9999

***
   OK I have attempted to answer this question for two computers with "very large pipes" (10Gbe) that
   are "close" to each other.

   The problem you run into here is: most compression will bottleneck at the cpu, since the pipes are so
   large.

   performance to transfer 10GB file (6 Gb network connection [linode], uncompressible data):
$>  time bbcp 10G root@$dest_ip:/dev/null
0m16.5s

iperf:

server:
$> iperf3 -s -F /dev/null
client:
$> time iperf3 -c $dest_ip -F 10G -t 20 # -t needs to be greater than time to transfer complete file
0m13.44s
(30% cpu)

netcat (1.187 openbsd):
server:
$> nc -l 1234 > /dev/null
client:
$> time nc $dest_ip 1234 -q 0 < 10G
0m13.311s
(58% cpu)

scp:
$> time /usr/local/bin/scp 10G root@$dest_ip:/dev/null
1m31.616s
scp with hpn ssh patch (scp -- hpn patch on client only, so not a good test possibly):
1m32.707s

socat:
server:
$> socat -u TCP-LISTEN:9876,reuseaddr OPEN:/dev/null,creat,trunc
client:
$> time socat -u FILE:10G TCP:$dest_ip:9876
0m15.989s

   And two boxes on 10 Gbe, slightly older versions of netcat (CentOs 6.7), 10GB file:
nc: 0m18.706s (100% cpu, v1.84, no -q option
iperf3: 0m10.013s (100% cpu, but can go up to at least 20Gbe with 100% cpu so not sure it matters)
socat: 0m10.293s (88% cpu, possibly maxed out)

   So on one instance netcat used less cpu, on the other socat, so YMMV.

   With netcat, if it doesn't have a "-N -q 0" option it can transfer truncated files, be
   careful...other options like "-w 10" can also result in truncated files.

   What is happening in almost all of these cases is the cpu is being maxed out, not the network. scp
   maxes out at about 230 MB/s, pegging one core at 100% utilization.

   Iperf3 unfortunately creates corrupted files. Some versions of netcat seem to not transfer the
   entire file, very weird. Especially older versions of it.

   Various incantations of "gzip as a pipe to netcat" or "mbuffer" also seemed to max out the cpu with
   the gzip or mbuffer, so didn't result in faster transfer with such large pipes. lz4 might help. In
   addition, some of the gzip pipe stuff I attempted resulted in corrupted transfers for very large (> 4
   GB) files so be careful out there :)

   Another thing that might work especially for higher latency (?) is to tune tcp settings. Here is a
   guide that mention suggested values:

   http://pcbunn.cithep.caltech.edu/bbcp/using_bbcp.htm and
   https://fasterdata.es.net/host-tuning/linux/ (from another answer) possibly IRQ settings:
   https://fasterdata.es.net/host-tuning/100g-tuning/

   suggestions from linode, add to /etc/sysctl.conf:
net.core.rmem_max = 268435456
net.core.wmem_max = 268435456
net.ipv4.tcp_rmem = 4096 87380 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.core.netdev_max_backlog = 250000
net.ipv4.tcp_no_metrics_save = 1
net.core.default_qdisc = fq

   Additionally, they would like you to run:
$> /sbin/ifconfig eth0 txqueuelen 10000

   worth double checking after tweaking to make sure changes don't cause harm too.

   Also may be worth tuning the window size: https://iperf.fr/iperf-doc.php#tuningtcp

   With slow(er) connections compression can definitely help though. If you have big pipes, very fast
   compression might help with readily compressible data, haven't tried it.

   The standard answer for "syncing hard drives" is to rsync the files, that avoids transfer where
   possible.

   Another option: use "parallel scp" (somehow or other), then it will use more cores...


---

