filename: can_GPT-3_understand_contex_20230329.txt
https://www.quora.com/Can-GPT-3-understand-the-meaning-and-context-of-the-text-it-generates-or-is-it-simply-a-robotic-parroting-of-words/answer/Erica-Zen-2

Can GPT-3 understand the meaning and context of the text it generates, or is it simply a robotic parroting
of words?

The way GPT understands the text is different from humans. GPT uses an algorithm called Self-Attention.
A neural network computes a soft weight... The weighted average is the output of the attention mechanism. The
weights are obtained by ... q(i) and k(j), i represents the current word and j represents the word that's
being attended to.

So the algorithm is trying to find the correlated likelihood of a word to all nearby words. In other words,
given a sequence of words, it predicts the most probable words that should appear accordingly. All the words
are just 'number tags,'. It has no meaning to GPT. The algorithm only 'understands' which tag has the
highest probability that goes along with that tag(s).

Humans don't do language in this way. Instead, language has grounded meaning in reality. Each word can be
mapped to the perception of our understanding of the world through consciousness. Words become a
representation of our knowledge. GPT has no grounded mapping to alternative representations, those number
tags are just generic symbols.

When we write sentences, we present our knowledge in logical and reasoning ways. The GPT algorithm does not
use any logical reasoning. It just presents the text in the way of the highest probability.

Example:

I am a math tutor.

Q: What is 11*3 + 11 - 3?
A: The answer is 44.

Q: Close. It's 41. What did you do wrong?
A: I multiplied 11 by 3 and thn added 11, and then subtracted 3.

Q: What do you get when you do that?
A: 44.

Q: Why?
A: 11 * 3 = 33
   33 + 11 = 44
   44 - 3 = 41

Q: Now you said 41. Earlier you said 44. Explain the diffference.
A: I made a mistake when I was subtracting 3. I subtracted 4 instead of 3.



---

