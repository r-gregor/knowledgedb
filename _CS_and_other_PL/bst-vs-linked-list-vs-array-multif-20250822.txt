filename: bst-vs-linked-list-vs-array-multif-20250822.txt
https://quickcodingexplanation.medium.com/data-structures-overview-arrays-stack-queue-linked-list-hash-table-heap-binary-tree-7b88a5711a0b

Data Structures Overview: Array, Stack, Queue, Linked-List, Hash Table, Heap & Binary Tree
Feb 20, 2024

ARRAY
Arrays are one of the most basic and widely used data structures in computer programming. They store elements
in a contiguous block of memory, with each element accessible at a numerical index.

Key Features
  * Fixed Size: Once an array is declared, its size is fixed and cannot be altered during runtime. However,
    dynamic array structures like ArrayLists in Java or Lists in Python can overcome this limitation.
  * Homogeneous Elements: Arrays typically store elements of the same data type, ensuring uniformity of the
    data stored.
  * Contiguous Memory Allocation: Elements are stored in contiguous memory locations, allowing efficient
    access to elements.

Types of Arrays
 1. Single-Dimensional Arrays: The simplest form of an array that represents a list of elements of a single
    row.
 2. Multi-Dimensional Arrays: Arrays that contain one or more arrays as their elements, allowing
    representation of data in multiple dimensions (e.g., a 2D array for a matrix).

Basic Operations
  * Access: Retrieve an element at a given index. Time complexity is O(1) because of direct memory access.
  * Insertion: Add an element at a given position. This requires shifting subsequent elements, making the
    average time complexity O(n).
  * Deletion: Remove an element at a given position. Similar to insertion, it requires shifting elements to
    fill the gap, also averaging O(n) time complexity.
  * Traversal: Go through each element to perform operations like searching or modifying. The time complexity
    is O(n) for a complete traversal.
  * Update: Change the value of an existing element at a given index. This operation is O(1) since it
    involves direct access and modification.

Advantages
  * Random Access: Direct access to any element using its index, providing efficient read operations.
  * Memory Efficient: No extra memory for pointers, unlike linked structures, making arrays more memory
    efficient for storing a large number of elements.
  * Cache-Friendly: Due to contiguous allocation, arrays have better cache locality, improving performance by
    reducing cache misses.

Limitations
  * Fixed Size: The size of a static array is determined at compile-time, making the structure inflexible.
  * Costly Insertions and Deletions: Especially for elements at the beginning or in the middle of the array,
    as it requires shifting elements.
  * Wasteful of Memory: If not fully utilized or if allocated with excess capacity to accommodate future
    growth.

Applications
  * Storing Data: Ideal for storing and managing collections of variables that have a fixed size or whose
    size changes infrequently.
  * Lookup Tables: Arrays can efficiently implement lookup tables, enabling rapid access to precomputed
    values.
  * Implementing Other Data Structures: The underlying structure for more complex data structures like heaps,
    hash tables, and dynamic arrays.
  * Algorithms: Used in a wide range of algorithms, including sorting and searching algorithms, where random
    access to elements significantly optimizes performance.

Efficiency
While arrays offer O(1) access time, which is excellent for read-heavy operations, the efficiency of write
operations (insertions and deletions) can vary significantly depending on the operation's location within the
array and the array's overall size.

Arrays are a fundamental component of programming and computer science, serving as the building block for
many other data structures and algorithms. Their simplicity and efficiency make them indispensable for a wide
range of applications.

STACK
A stack is a fundamental data structure used in computer science. It operates on the principle of "Last-In,
First-Out" (LIFO), meaning that the last element added to the stack will be the first one to be removed. This
concept is similar to a stack of plates, where you can only add or remove the top plate.

Key Operations
  * Push: Adds an element to the top of the stack.
  * Pop: Removes the top element from the stack and returns it. This operation reveals the next element as
    the new top of the stack.
  * Peek (or Top): Returns the top element of the stack without removing it, allowing you to see the value
    without modifying the stack.
  * IsEmpty: Checks whether the stack is empty. This is useful for avoiding errors when attempting to pop or
    peek elements from an empty stack.

Characteristics
  * LIFO Principle: As mentioned, stacks operate on a Last-In, First-Out basis.
  * Dynamic Size: Most stack implementations grow and shrink dynamically with the addition and removal of
    elements.
  * Fast Operations: Adding and removing elements from a stack is generally fast, with operations typically
    having a constant time complexity, O(1).

Use Cases
  * Function Call Management: Stacks are used by programming languages to manage function calls. When a
    function is called, its execution context is pushed onto a call stack, and when the function returns, its
    context is popped off.
  * Undo Mechanisms: Many applications use stacks to keep track of actions for undo operations. Each action
    is pushed onto a stack, and undoing an action pops it off the stack and reverses it.
  * Syntax Parsing: Compilers and interpreters use stacks for parsing and evaluating expressions or checking
    the syntax of code with nested structures like parentheses.
  * Backtracking: In algorithms that involve searching or traversing through possible solutions (like maze
    solving), stacks are used to keep track of the path taken and backtrack if necessary.

Implementation
Stacks can be implemented using various underlying data structures, but the most common are arrays and linked
lists.

  * Array-Based Implementation: Uses an array to store the elements. This implementation has a fixed size,
    although dynamic array techniques (like doubling the size when the array is full) can be used to allow
    the stack to grow.
  * Linked List Implementation: Each element is a node that contains the data and a reference to the next
    node. This implementation allows the stack to grow dynamically without the need to reallocate or resize
    the underlying structure.

Complexity
For a stack, the average time complexities for its key operations are as follows:

  * Push: O(1)
  * Pop: O(1)
  * Peek: O(1)
  * IsEmpty: O(1)

Space complexity for a stack depends on the number of elements it contains, typically O(n) for storing n
elements.

Example
Consider a stack of books. You can only add (push) a book to the top of the stack and remove (pop) the book
from the top. If you want to get a book from the bottom, you must first remove all the books on top of it.
This is a real-world analogy of how a stack operates in computer science.

QUEUE
A queue is a fundamental data structure in computer science that operates on the principle of "First-In,
First-Out" (FIFO). This means that the first element added to the queue will be the first one to be removed,
much like a line of people waiting for a service where the person at the front of the line is served first.

Key Operations
  * Enqueue: Adds an element to the end of the queue.
  * Dequeue: Removes the element at the front of the queue and returns it. This operation shifts the queue
    forward, making the next element the new front.
  * Peek (or Front): Returns the element at the front of the queue without removing it, allowing you to see
    the value without modifying the queue.
  * IsEmpty: Checks whether the queue is empty. This is useful for avoiding errors when attempting to dequeue
    or peek elements from an empty queue.

Characteristics
  * FIFO Principle: Queues operate on a First-In, First-Out basis.
  * Dynamic Size: Most queue implementations grow and shrink dynamically with the addition and removal of
    elements.
  * Efficient Operations: Enqueue and dequeue operations are generally fast, with operations typically having
    a constant time complexity, O(1), in ideal implementations.

Use Cases
  * Job Scheduling: Operating systems use queues to manage processes and tasks that need to be executed,
    scheduling them in the order they arrive.
  * Handling Requests: Web servers use queues to handle incoming request traffic, processing each request in
    the order it was received.
  * Data Streaming: In streaming data applications, queues can be used to buffer data chunks before they are
    processed, ensuring that they are dealt with in the correct order.
  * Breadth-First Search (BFS): In graph algorithms, queues are used to traverse the graph level by level,
    starting from a given node.

Implementation
Queues can be implemented using various underlying data structures, but arrays and linked lists are the most
common.

  * Array-Based Implementation: Utilizes a dynamic or circular array to store the elements. This approach may
    involve shifting elements or using a circular buffer to efficiently use the array space.
  * Linked List Implementation: Each element is a node that contains the data and a reference to the next
    node. The queue maintains a reference to both the head (front) and the tail (end) of the queue for
    efficient operations.

Complexity
For a queue, the average time complexities for its key operations are as follows:

  * Enqueue: O(1)
  * Dequeue: O(1)
  * Peek: O(1)
  * IsEmpty: O(1)

Space complexity for a queue is O(n), where n is the number of elements in the queue, as it needs to store
each element.

Example
Imagine a queue at a grocery store checkout. As customers arrive, they join the end of the queue. The
customer at the front of the queue is the next to be served and leaves the queue once their checkout is
complete. This process continues in a FIFO manner, which mirrors how a computer science queue operates.

LINKED LIST
A linked list is a fundamental data structure in computer science, consisting of a sequence of elements, each
contained in a "node." The nodes are not stored in contiguous memory locations; instead, each node points to
the next node in the sequence via a reference or pointer. This structure allows for efficient insertion and
removal of elements from any position in the sequence, making linked lists a versatile alternative to arrays
in certain situations.

Types of Linked Lists
 1. Singly Linked List: Each node contains data and a pointer to the next node in the sequence, with the last
    node pointing to null, indicating the end of the list.
 2. Doubly Linked List: Each node contains data, a pointer to the next node, and a pointer to the previous
    node, allowing for backward traversal of the list.
 3. Circular Linked List: Similar to a singly or doubly linked list, but the last node points back to the
    first node, forming a circle. This can be useful for applications requiring a continuous loop of
    elements.

Key Operations
  * Insertion: You can insert a new node at the beginning, at the end, or after a given node in the list.
    This operation is generally efficient, with a time complexity of O(1) if you have direct access to the
    point of insertion.
  * Deletion: You can remove a node from the list by adjusting the pointers of the adjacent nodes to bypass
    the node to be deleted. This operation also has a time complexity of O(1) under similar conditions as
    insertion.
  * Traversal: To access or find a node, you typically start from the first node and follow the links until
    you reach the desired node or the end of the list. This operation has a time complexity of O(n), where n
    is the number of nodes in the list.

Features
  * Dynamic Size: Unlike arrays, the size of a linked list can grow or shrink dynamically, making it more
    flexible for certain applications where the amount of data isn't known in advance.
  * Memory Efficient: Linked lists can be more memory efficient than arrays for certain applications because
    they do not reserve more memory than they need. Arrays, on the other hand, might allocate memory that
    remains unused.
  * Use in Implementing Other Data Structures: Linked lists are used as the underlying data structure for
    implementing other complex data structures like stacks, queues, and even some types of hash tables.
  * Polynomial Arithmetic: Linked lists are ideal for representing polynomials because they can efficiently
    store and manipulate terms with non-zero coefficients.
  * Garbage Collection Algorithms: Some garbage collection algorithms use linked lists to keep track of free
    memory blocks or to implement algorithms such as mark-and-sweep.

Limitations
  * Random Access: Unlike arrays, linked lists do not support efficient random access to elements, which
    means accessing an element at a specific position requires traversing the list from the beginning.
  * Memory Overhead: Each node in a linked list requires extra memory for storing the pointer(s) alongside
    the actual data, which can be a significant overhead, especially for lists with a large number of
    small-sized elements.

Linked lists are a powerful, flexible data structure that offers many advantages, especially in scenarios
requiring dynamic memory allocation and frequent insertion and deletion operations. Their versatility makes
them a fundamental component in the implementation of many more complex data structures and algorithms.

HASH TABLE
A hash table, also known as a hash map, is a data structure that implements an associative array, a structure
that can map keys to values. Hash tables use a hash function to compute an index into an array of slots, from
which the desired value can be found. This method allows for efficient data retrieval, insertion, and
deletion operations. Below is an overview of key aspects of hash tables.

Key Concepts
  * Hash Function: A function that takes input (or 'key') and returns an integer, which is used as the index
    at which the value associated with the key is stored. The efficiency of a hash table largely depends on
    the hash function's ability to distribute keys evenly across the hash table.
  * Collision: Occurs when two keys hash to the same index. Collisions are a fundamental issue with hash
    tables that must be addressed through collision resolution techniques.
  * Load Factor: A measure that determines when to increase the hash table's size. It is calculated as the
    number of entries divided by the number of slots in the table. Maintaining an optimal load factor is
    crucial for balancing between space efficiency and access time.

Collision Resolution Techniques
 1. Chaining (Separate Chaining): Each slot of the hash table contains a linked list (or another data
    structure) to hold all the values hashed to the same index. This method allows for an unlimited number of
    collisions to be handled, but it can degrade performance if many keys hash to the same index.
 2. Open Addressing (Probing): All elements are stored within the array itself. When a collision occurs, the
    hash table searches for the next available slot using a probing sequence (linear, quadratic, or double
    hashing). While this method avoids pointers, making it more space-efficient, it can suffer from
    clustering issues, where a sequence of filled slots slows down insertion and retrieval.

Operations
  * Insertion: Adds a new key-value pair to the hash table. The key is hashed, and the value is placed in the
    computed index. Collision resolution is applied if necessary.
  * Deletion: Removes a key-value pair from the hash table. In chaining, this is straightforward, but in open
    addressing, a special marker might be needed to indicate a deleted slot.
  * Search: Retrieves a value associated with a given key. The key is hashed to find the supposed index of
    the value, and then the table or chain is searched for the key. If found, the value is returned.

Time Complexities
 1. Insertion
  * Average Case: O(1)
  * Worst Case: O(n), where n is the number of elements in the hash table. The worst case occurs when all
    elements hash to the same index, leading to a long chain (in the case of chaining) or a full table
    requiring linear probing (in the case of open addressing).

2. Deletion
  * Average Case: O(1)
  * Worst Case: O(n), under the same circumstances as insertion. For open addressing, deletion can also be
    complex because simply removing an element might break the probing sequence. A special marker or strategy
    is needed to handle this.

3. Search/Retrieval
  * Average Case: O(1)
  * Worst Case: O(n), similar to insertion and deletion, especially if a poor hash function leads to many
    collisions or if the table becomes very full.

Factors Affecting Time Complexity
  * Hash Function Quality: A good hash function distributes keys uniformly across the hash table, minimizing
    collisions and thus maintaining closer to O(1) performance for all operations.
  * Collision Resolution Strategy: The method used to resolve collisions (e.g., chaining vs. open addressing)
    impacts performance, especially as the load factor increases.
  * Load Factor: A higher load factor means the table is more filled, increasing the likelihood of collisions
    and the length of chains in chaining or the length of probing sequences in open addressing. Keeping the
    load factor at an optimal level through resizing is essential for maintaining performance.
  * Resizing Strategy: Automatically resizing the hash table when it reaches a certain load factor helps
    maintain the efficiency of operations but can cause temporary performance drops during the resizing
    process.

Advantages
  * Efficient Data Retrieval: Hash tables provide average-case constant time complexity, O(1), for search,
    insert, and delete operations, making them highly efficient for look-up operations.
  * Dynamic Resizing: Many implementations resize the hash table when the load factor reaches a certain
    threshold, maintaining efficiency even as the number of elements grows.

Limitations
  * Space Complexity: While dynamic resizing helps manage the load factor, it can lead to higher space
    complexity, especially in sparse tables.
  * Worst-Case Performance: In the worst-case scenario (e.g., all keys hash to the same index), hash table
    operations can degrade to O(n). However, good hash functions and collision resolution strategies can
    minimize this risk.
  * Ordering: Hash tables do not maintain any order for the stored keys. If ordering is required, additional
    data structures or specific types of hash tables like ordered hash maps may be necessary.

Applications
Hash tables are widely used in various applications due to their efficiency and simplicity. Common uses
include implementing database indexing, caching, unique data representation, and as a building block in many
other data structures like sets and maps in high-level programming languages.

Implementation
Modern programming languages like Python, Java, and C# provide built-in implementations of hash tables,
usually as dictionaries, maps, or hash maps, abstracting away the complexities of hash functions and
collision handling. These implementations are optimized for general use but understanding the underlying
principles is crucial for addressing specific performance and behavior requirements.

HEAP
A heap is a specialized tree-based data structure that satisfies the heap property: in a max heap, for any
given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key
of C. In a min heap, the key of P is less than or equal to the key of C. This property makes heaps useful in
implementing priority queues and for sorting data with the Heap Sort algorithm.

Types of Heaps
  * Max Heap: The largest element is the root, and each parent node is larger than its children.
  * Min Heap: The smallest element is the root, and each parent node is smaller than its children.

Key Operations and Their Time Complexities
 1. Insertion (Add):
  * Operation: Adds a new element to the heap while maintaining the heap property.
  * Time Complexity: O(log(n)), where n is the number of elements in the heap. This is because the element may
    need to be compared and possibly swapped up the tree, a process known as "heapifying up," which in the
    worst case involves moving up from the leaf to the root.

2. Deletion (Remove):
  * Operation: Removes the root element from the heap. In a max heap, this is the maximum element; in a min
    heap, it is the minimum.
  * Time Complexity: O(log(n)). After removing the root, the heap is restructured to maintain the heap
    property, usually by moving the last element to the root and then "heapifying down."

3. Find Maximum/Minimum:
  * Operation: Retrieves the maximum element in a max heap or the minimum element in a min heap without
    removing it.
  * Time Complexity: O(1), as the max/min element is always at the root of the heap.

4. Extract Maximum/Minimum (Pop):
  * Operation: Removes and returns the maximum element in a max heap or the minimum in a min heap.
  * Time Complexity: O(log(n)), as it combines the cost of finding the max/min O(1) and then deleting it
    O(log(n)).

5. Heapify:
  * Operation: Converts an unordered array into a heap.
  * Time Complexity: O(n) for building a heap from an unordered array. This is more efficient than inserting
    elements one by one, which would be O(n log(n)).

6. Increase Key, Decrease Key:
  * Operation: Increases or decreases the value of a key in the heap, then adjusts the heap to maintain the
    heap property.
  * Time Complexity: O(log(n)), as the adjustment may require either "heapifying up" or "heapifying down."

Characteristics and Applications
  * Structure: Heaps are usually implemented as binary trees, but they are often stored in arrays for memory
    efficiency. The children of the node at index i are found at indices 2i+1 and 2i+2 in a zero-based array.
  * Priority Queues: Heaps are the underlying data structure for priority queues, where elements are inserted
    with a priority and the queue always removes the element with the highest (or lowest) priority.
  * Heap Sort: A sorting algorithm that builds a heap from the elements to be sorted and then repeatedly
    extracts the maximum or minimum to get the sorted order. Heap sort has a time complexity of O(n log(n)).
  * Graph Algorithms: Min heaps are used in graph algorithms like Dijkstra's and Prim's algorithms for
    efficiently finding the minimum edge weight or shortest path.

Summary
Heaps are a versatile and efficient data structure for managing prioritized data and for sorting. Their
operations are generally efficient, making them suitable for applications where prioritized access and
removal are frequently required. The binary heap, due to its array-based implementation, is particularly
memory-efficient and is commonly used in many applications and algorithms.

BINARY TREE
A binary tree is a fundamental data structure in computer science, consisting of nodes, where each node has
at most two children, referred to as the left child and the right child. This structure is used for efficient
searching and sorting, among other operations. Binary trees have several variants, including binary search
trees (BST), balanced trees like AVL trees and red-black trees, and heaps.

Key Properties
  * Root: The top node in the tree.
  * Parent and Child Nodes: Every node (except the root) has one parent and can have up to two children.
  * Leaf Nodes: Nodes with no children.
  * Depth of a Node: The number of edges from the root to the node.
  * Height of the Tree: The depth of the deepest node. For an empty tree, the height is -1, and for a tree
    with just one node (the root), the height is 0.

Types of Binary Trees
  * Full Binary Tree: Every node has 0 or 2 children.
  * Complete Binary Tree: All levels are fully filled except possibly the last level, which is filled from
    left to right.
  * Balanced Binary Tree: The height of the left and right subtrees of any node differ by no more than 1.
  * Binary Search Tree (BST): For each node, all elements in the left subtree are less than the node, and all
    elements in the right subtree are greater.

Operations and Time Complexities
For a General Binary Tree
 1. Traversal
  * Types: Pre-order, In-order, Post-order, and Level-order.
  * Time Complexity: O(n), where n is the number of nodes. Each node is visited once.

2. Insertion
  * General Approach: Insertion in a binary tree without any specific properties (like a BST) can be done by
    finding the first vacant spot in level order.
  * Time Complexity: O(n) in the worst case, as it might require traversing the tree to find the insertion
    point.

3. Deletion
  * General Approach: To delete a node, the node's data is replaced with the deepest rightmost node's data,
    and then that node is deleted.
  * Time Complexity: O(n), similar to insertion, due to the need to find the node to delete and the deepest
    rightmost node.

4. Searching
  * Time Complexity: O(n) in the worst case, as it may require visiting every node.

For a Binary Search Tree (BST)
 1. Search
  * Time Complexity: O(log(n)) on average if the tree is balanced. In the worst case (e.g., the tree is a
    straight line), it can degrade to O(n).

2. Insertion
  * Time Complexity: Similar to search, O(log(n)) on average and O(n) in the worst case for an unbalanced tree.

3. Deletion
  * Time Complexity: Also O(log(n)) on average and O(n) in the worst case. The complexity varies depending on
    whether the node to be deleted is a leaf, has one child, or has two children.

For Balanced Binary Trees
For operations in balanced binary trees, like AVL trees or red-black trees, the time complexities are as
follows:
  * Search: O(log(n))
  * Insertion: O(log(n)), including the time to rebalance the tree if necessary.
  * Deletion: O(log(n)), also including rebalancing time.

Applications
  * BSTs are used for efficient searching and sorting.
  * Heaps (a form of a complete binary tree) are used in priority queues and heap sort.
  * Balanced Trees (AVL, red-black trees) are used in databases and filesystems to maintain ordered data and
    ensure quick search, insert, and delete operations.
  * Binary Trees are also used in various algorithms, like those for generating Huffman coding trees, which
    are used for data compression.

Summary
Binary trees are versatile structures that support efficient data manipulation and access operations. The
specific time complexities of operations depend on the tree variant and its balance. Balancing techniques are
crucial for maintaining the efficiency of operations in practical applications.


---
https://www.baeldung.com/cs/binary-trees-vs-linked-lists-vs-hash-tables

Binary Trees vs. Linked Lists vs. Hash Tables
March 11, 2023

1. Introduction
In this tutorial, we'll discuss binary trees, linked lists, and hash tables. We'll define these data
structures, as well as outline where they are used and how they are structured. Finally, we'll compare the
properties of these data structures to point out the similarities and differences between them.

2. Binary Trees
A binary tree is a hierarchical tree-based data structure in which each node has at most two children. The
root node is the topmost node of a binary tree, while the left and right nodes are called left and right
children, respectively. Furthermore, the links between nodes are known as branches, while a node without
children is called a leaf node.

In a binary tree, a single node will contain a data value and a link to each of the child nodes. The following
operations can be performed on binary trees: insertion, searching, and deletion. These operations can be
executed in O(log(n)) time.

2.1. Applications of Binary Trees
In computer science, a binary tree forms the basis of many other data structures, such as binary search trees,
heaps, red-black trees, and hash trees. These data structures utilize the structure and properties of binary
trees to implement a means of organizing and managing data. In addition, routing tables, decision trees, and
sorting are other applications of binary trees.

For more information on the applications of binary trees, read our
article[https://www.baeldung.com/cs/applications-of-binary-trees]here.

2.2. Advantages and Disadvantages of Binary Trees
The main advantage of using binary trees is simplicity. Binary trees possess a simple-to-understand structure
for data management and organization. Additionally, some benefits of binary trees are:
  * They can be used to reflect relationships between data.
  * They can store an arbitrary number of data values.

On the other hand, some limitations to using binary trees are:
  * Deleting nodes is a complex procedure.
  * Insertion, deletion, and search operations are dependent on the height of the tree.

3. Linked Lists
A linked list is a dynamic data structure consisting of nodes and pointers to other nodes. The nodes form a
sequence of nodes that contain data and links to the next nodes.

The basic operations that can be performed on linked lists are searching, insertion, deletion, and update.
Search operations can be done in O(n) time, while insertion and deletion are done in O(1) time.

3.1. Applications of Linked Lists
Just like binary trees, linked lists are also used in the implementation of other data structures, such as
queues, graphs, and stacks. Doubly linked lists, circular linked lists, and singular linked lists are
different variations of this data structure. The structure of a circular linked list is such that it has the
last node pointer pointing to the first node, while a doubly-linked list has pointers to both preceding and
succeeding nodes.

Linked lists are also used in dynamic memory allocation, where memory is assigned to tasks during execution.
Likewise, this data structure can be used to represent sparse matrixes. For more information on other
applications of linked lists, read our article here.

3.2. Advantages and Disadvantages of Linked Lists
A few benefits to using linked lists are:
  * Nodes can be easily deleted and inserted.
  * A linked list can be easily implemented in most programming languages.

On the contrary, some limitations of linked lists are:
  * Nodes must always be accessed sequentially, which is time consuming.
  * The pointers used in linked lists require additional memory.

4. Hash Tables
A hash table is different from binary trees and linked lists in the sense that it is implemented with an
array. It stores data as key-value pairs. Each data value in a hash table has a key or index that is produced
using a technique known as hashing.

In hashing, a hash function is used to convert a variable-length value or data into a fixed-length value. A
hash table uses hashing to generate an index to determine where to store data values.

There are three basic operations that can be performed on hash tables: insertion, searching, and deletion of
data values. These operations can usually be completed in O(1) time.

4.1. Applications of Hash Tables
Hash tables are efficient due to their fast access and are used in many applications, such as address tables,
compiler symbol tables, search engines, password look-ups, and file systems.

4.2. Advantages and Disadvantages of Hash Tables
Consequently, some major benefits of using hash tables are:
  * Insert, delete and search operations are very fast and can be done in O(1) time.
  * Hash tables can store large amounts of data.

Conversely, some limitations of using hash tables are:
  * Hash functions tend to produce duplicate keys, which cause problems with storing data values, known as collisions.
  * Good hash functions that produce distinct keys are expensive and difficult to implement.

5. Comparison
+----------------------------------+-------------------------------------+----------------------------------+
| Binary Tree                      | Linked List                         | Hash Table                       |
+----------------------------------+-------------------------------------+----------------------------------+
| The nodes are connected to       | The nodes are connected to one      | Node connections are arbitratry  |
| 2 other nodes at most            | other node at most                  |                                  |
+----------------------------------+-------------------------------------+----------------------------------+
| Non linear data structure        | Linear data structure               | Can be implemented as both       |
|                                  |                                     | linear and non-linear structures.|
+----------------------------------+-------------------------------------+----------------------------------+
| Insertion, deletion and search   | Search is done in O(n) time         | Insertion, deletion and search   |
| are done in O(log(n)) time       | Insertion and deletion are done in  | are done in O(1) time            |
|                                  | O(1) time                           |                                  |
+----------------------------------+-------------------------------------+----------------------------------+
| Data values usually              | Data values are not ordered         | Data values are not ordered      |
| sorted/ordered                   |                                     |                                  |
+----------------------------------+-------------------------------------+----------------------------------+
| Input data size does not have    | Input data size does not have be    | Input data size must be          |
| to be specified before           | specified before implementation     | specified before the structure   |
| implementation                   |                                     | is created                       |
+----------------------------------+-------------------------------------+----------------------------------+

6. Conclusion
In this article, we reviewed three data structures: binary trees, linked lists, and hash tables. We explored
their structures, uses, and how they can be distinguished from each other. We also highlighted the basic
operations that can be performed on these three data structures.


---
https://www.codeproject.com/Articles/11242/The-Basics-of-Linked-Lists-and-Binary-Trees?msg=1190701

The Basics of Linked Lists and Binary Trees
Aug 7, 2005

The basics of creating and using linked lists, and their cousin binary trees, from scratch

What Is a Linked List?
A linked list can be thought of like an array, for it does basically the same thing. An array is a convenient
way to store and sort many instances of similar data, or in other words, many variables of the same type. A
basic linked list is simply a different approach to this idea.

What's the Difference?
Arrays work in a way that each individual element is stored right after the previous, in succession, and the
only thing needed to access them is a pointer to the first. In this way, you can access the first element by
simply dereferencing that pointer.

char array[5];
*array; //Same as array[0]

Then, since each element is stored in succession, if you want to find the second element, simply look in the
next piece of memory.
*(array + 1); //Same as array[1]

And so on. This approach uses very minimal memory, a must for things such as game programming and robotics
programming, which often times do not have the luxury of a vast amount of memory, that we computer
programmers have.

So, as you might have guessed now, linked lists use up much more, the most complex form of a linked list, a
tree, uses about four times as much memory as an array, depending on the type of data that is being stored.
If each variable is one byte, it would actually be thirteen times as much, but if you're storing strings, or
something similar that can take up very large amounts of memory, the increase in memory usage would not be
that significant.

So far, I've only talked about space issues, and if that's all you're looking at, there's no question that
arrays are the way to go. But, space is not the only issue. There is also speed. One can think of space and
speed as darkness and light. The more light there is, the less darkness there is, and vice versa. Space and
speed often relate in the same way.

So, thus, in terms of speed, arrays are the lacking and linked lists win out. Or at least, that may be what
you're thinking. But, that statement is not entirely true. There are some instances where it is, but there
are also some where it is not. You must understand exactly where the two methods differ in order to know
which will be faster in a given situation.. I've been going on for a while now, and you still probably have
no clue how to make a linked list or use one, so I'll come back to this subject later.

The Basics - A Singly Linked List

A friend once described a basic linked list as a train and each element being stored as its cars. I thought
it was quite a good representation, so I shall do the same.

In a passenger train, each car holds data, the people riding in it, and a link to the next car, a door. An
item, or node as it is called, of a singly linked list is the same. It holds data and a link to the next car,
which in programming would be a pointer.

Now, let's look at the ticket taker. He starts at the front of the train and moves, one car at a time, to the
back, checking each occupant for his or her ticket. In a linked list, the equivalent of the ticket taker
would be a pointer. The pointer would start out pointing to the first node of a linked list. You, as a
programmer, would dereference that pointer and look at the data in that node, perhaps change it or do
something with it. Then, you would access the pointer in that node which points to the next node, and set
that value into your ticket taker pointer. Now, your ticket taker pointer points to the second node, and you
can again look at the data, and when you're done, you can set the ticket taker to point to the next node. The
last item in the list would point to NULL as it's the next node, so you'd know you're done.

Now, this seems a bit complex, I know, but it's all just talking. So, let's put it into some actual code.
I'll be using a C++ class for both the nodes and the linked list as a whole. For now, the data in each node
will just be a simple int.

//Basic node class.
class LLNode {
	public:
		LLNode() //Default Constructor
		{
			p_data = 0;    //No data.
			p_next = NULL; //New node always points to NULL by default.
		}

		LLNode(unsigned int data) //Constructor
		{
			p_data = data; //Set the data
			p_next = NULL; //New node always points to NULL by default.
		}

		//Retrieve the data of the node. Constant function.
		unsigned int data(void) const
		{
			return p_data;
		}

		//Retrieve the next point of the node. Constant function.
		LLNode* next(void) const
		{
			return p_next;
		}

		//Set the data of the node.
		void setdata(unsigned int data)
		{
			p_data = data;
		}

		//Set the next pointer of the node.
		void setnext(LLNode* next)
		{
			p_next = next;
		}
	private:
		//Data stored by the node. protected.
		unsigned int p_data;
		//Pointer to the next node. protected.
		LLNode* p_next;
};

//Linked list class. Handles allocation,
//deallocation, and sorting of nodes.
class LList {
	public:
		LList() //Constructor
		{
			p_first = NULL; //List contains no nodes by default.
		}

		~LList() //Destructor
		{
			//Current node being pointed to.
			LLNode* current = p_first;
			//Variable for storing the node to be deleted.
			LLNode* deleting;

			//While current is not NULL, there are
			//still more items in the list.
			while(current != NULL) {
				//Store the current node to be deleted.
				deleting = current;
				//Move to the next node.
				current = current->next();
				//Delete the stored node.
				delete deleting;
			}
		}

		//Retrieves the first node in the list.
		//Constant function.
		LLNode* first(void) const
		{
			return p_first;
		}

		//Add an item to the end of the list.
		void additem(unsigned int data) {
			//Make sure there are nodes in the list.
			if(!p_first)
				//If there aren't make the first node.
				p_first = new LLNode(data);
			else             //If there are items...
			{
				LLNode* current = p_first;        //Stores the current node.
				while(current->next() != NULL)    //While there is a next node.
					current = current->next();      //Move to the next node.
				LLNode* prev = current;           //Store the current node.
				current = new LLNode(data);       //Make a new node.
				prev->setnext(current);           //Set the stored node to
												  //point to the new one.
			}
		}

		//Delete an item from the list, based on its data.
		bool deleteitem(unsigned int data) {
			if(p_first == NULL)                 //Make sure there are items in the list.
				return 0;                         //If there aren't end the function now.

			LLNode* current = p_first; //Start with the first node.

			//If the first node is the one we want...
			if(current->data() == data)
			{
				p_first = current->next();        //Set p_first to NULL.
				delete current;                   //Delete the node.
				return 1;                         //Success.
			}

			//While there is a next node and it is not the one we want.
			while(current->next() != NULL && current->next()->data() != data) {
				current = current->next();        //Move to the next node.
			}

			if(current->next() != NULL)         //If the node was found.
			{
				//Store the current node.
				LLNode* prev = current;

				//Move to the node to be deleted.
				current = current->next();

				//Remove links to the node.
				prev->setnext(current->next());

				//Delete the node.
				delete current;

				//Success.
				return 1;
			}
			return 0; //Failure.
		}

		//Search the list for a node with specified data.
		LLNode* search(unsigned int data)
		{
			//Set the current node to the first.
			LLNode* current = p_first;
			//While current is not NULL, there are still more nodes.
			while(current != NULL) {
				//If we have found the node, with the correct data...
				if(current->data() == data) {
					return current;     //return it.
					                    //Otherwise, move to the next node and continue.
				}

				current = current->next();
			}

			return NULL; //If we never found the node, return NULL.
		}

		//Insert a new node after a node with specified data.
		bool insertitem(unsigned int prevdata, unsigned int data) {
			//Find the node with the specified data.
			LLNode* prev = search(prevdata);

			//If the node was not found...
			if(prev == NULL) {
				return 0;    //We did not succeed.
			}

			//Store the next node.
			LLNode* next = prev->next();

			//Make the new node.
			LLNode* current = new LLNode(data);

			//Set the previous node to point to the new one.
			prev->setnext(current);

			//Set the new node to point to the next one.
			current->setnext(next);

			return 1; //We did succeed.
		}

		//Insert a new node as the first node.
		void insertfirst(unsigned int data) {
			//Create the new node.
			LLNode* current = new LLNode(data);

			//Make the current node point to the old first node.
			current->setnext(p_first);

			//Set p_first to the current node.
			p_first = current;
		}
	private:
		LLNode* p_first; //First node in the list.
};

There is a lot to take in, yes, but, with the comments, you should be able to understand it, pretty well. In
your own linked list implementations, you can add in other functions you find necessary, or remove those that
you feel are not. It's up to you.

Doubly Linked lists
Now, one thing you might have found about the previous, a singly linked list, is that when you are traversing
it, you may only move in one direction. If your purposes serve, you may take this list and upgrade it to a
doubly linked list. There are just a few things you must add to the node class to do this. Mostly, this is
just a pointer to the previous node, in addition to the pointer to the next node, but you must make sure that
you give this new pointer the correct address value, therefore you must edit both the node's class and the
list's class. I've laid out the only node's class below, simply for space issues. The full code for both
classes can be found in the source, provided with this article.

//Basic Doubly Linked List node class.
class DLLNode {
	public:
		DLLNode() //Default Constructor
		{
			p_data = 0;    //No data.
			               //New node always has a NULL next node.
			p_next = NULL;

			//New node always has a NULL previous node.
			p_prev = NULL;
		}

		DLLNode(unsigned int data) //Constructor
		{
			p_data = data;           //No data.
			                         //New node always has a NULL next node.
			p_next = NULL;

			//New node always has a NULL previous node.
			p_prev = NULL;
		}

		//Retrieve the data of the node. Constant function.
		unsigned int data(void) const {
			return p_data;
		}

		//Retrieve the previous pointer of the node.
		//Constant function.
		DLLNode* prev(void) const {
			return p_prev;
		}

		//Retrieve the previous pointer of the node.
		//Constant function.
		DLLNode* next(void) const {
			return p_next;
		}

		//Set the data of the node.
		void setdata(unsigned int data) {
			p_data = data;
		}

		//Set the previous pointer of the node.
		void setprev(DLLNode* prev) {
			p_prev = prev;
		}

		//Set the next pointer of the node.
		void setnext(DLLNode* next) {
			p_next = next;
		}
	private:
		//Data stored by the node. protected.
		unsigned int p_data;

		//Pointer to the next node. protected.
		DLLNode* p_prev;

		//Pointer to the previous node. protected.
		DLLNode* p_next;
};

Arrays and Linked Lists
So, back to the topic of the differences between the two. I've already discussed the space issues, in depth,
so now I will go into speed.

Arrays are actually very fast, both from a programming aspect and from an executing aspect, but this is only
in certain areas. Accessing and changing the values of array elements is extremely faster than with linked
lists, since all you need to do is dereference a memory address. And finding a specific item in the list is
easy as well. You can go directly to it through simple pointer arithmetic, unlike linked lists which must
cycle through each node until they get to the desired one. Arrays fall very short, though, when it comes to
sorting, re-sorting, inserting, and deleting elements. To sort or re-sort, you must move each individual
element in memory, and there is always the aspect that they must be consecutively stored, that you must keep
in mind. This applies to inserting and deleting, for in either one, you must move each individual element
that follows the inserted or deleted one. This can be very time consuming, in both the coding stage and in
execution.

Linked lists require much more code to perform simple operations, even though the code is simple to
understand. But it is definitely more work than simply saying array[5], or whatever. However, where arrays
are lacking, linked lists soar. Inserting and deleting an item in a list requires two simple changes to the
rest of the list, unlike arrays that must change the entire remaining portion. The same goes for moving an
item. It requires two actions to remove it, and two actions to put it back. Arrays, must do the 'change the
entire list' thing twice, just to move one item.

For most purposes, arrays are quite satisfactory. Linked lists, like binary trees, which you will learn about
in a moment, are mostly used when sorting the items is necessary.

Binary Trees
And now for the biggie. Binary trees are one of the most efficient data structures for sorting data. I'll lay
out a binary tree for you, visually:

      []
    /    \
  []      []
 /  \    /  \
[]  []  []  []

Each set of brackets represents a node, and as you can tell from the middle row of nodes, each one is linked
to two different nodes, a left node and a right node. As I said, the main use of binary trees is for sorting.
Let's say I have a linked list with a single node, storing the value of five.

          [5]

Now, I have a new number, entered by the user, that I need to sort. The number is three. Since that number is
less than the value of my first node, I move to the left. Of course, there is no left node, so I simply add
in a new one, containing the number three.

         [5]
        /
     [3]

If I get another number that is greater than the first node, say eight, I would go to the right. Again, there
is no right node, so I go ahead and add in a new one.

         [5]
        /   \
     [3]     [8]

Next up I have a six. It is greater than five, so I move to the right. But this time, there is a node to the
right, so I do the same checks on it. Six is less than eight, so I move left. Since there is no node there, I
add it. (Get the pattern yet?)

         [5]
        /   \
     [3]     [8]
            /
          [6]

From here, I'll just skip the text. If you haven't picked it up yet, you will.

         [5]
        /   \
     [3]     [8]
       \     /
       [4] [6]

         [5]
        /   \
     [3]     [8]
    /   \   /
  [2]  [4] [6]

         [5]
        /   \
     [3]     [8]
    /   \   /
  [2]  [4]  [6]
             \
             [7]

         [5]
        /   \
     [3]     [8]
    /   \   /   \
  [2]  [4]  [6] [9]
             \
             [7]

         [5]
        /   \
     [3]     [8]
    /   \   /   \
  [2]  [4]  [6] [9]
  /          \
[1]          [7]

And now, we have a complete binary tree, that sorts the numbers one through nine. As you might have noticed,
the actual structure of the tree depends upon how the numbers are entered. You could also have had...

    [3]
   /   \
[1]     [7]
   \   /   \
  [2] [5]   [8]
      / \     \
    [4] [6]   [9]

or...

     [6]
    /   \
 [1]    [7]
    \      \
    [4]    [9]
    / \     /
  [3] [5]  [8]
  /
[2]

or, you might have even had a balanced tree...

         [5]
        /   \
     [2]     [8]
    /   \   /   \
  [1]  [4] [6]   [9]
        /    \
      [3]    [7]

Although, technically, a "perfectly" balanced tree would also have a zero and a ten on the bottom corners. A
balanced tree is just the term used for a tree in which each and every path is of the same length.

As I said, binary trees are a very efficient and fast way of sorting. However, this depends upon the
structure of the tree. If you have a very unbalanced tree, it will take longer to sort something on the
larger side, than on the smaller side. It's important to know this when using binary trees. And, as with
linked lists, you can, if you desire, make yourself a doubly linked binary tree, where each node also points
to the previous node. In fact, it would probably be preferable, for a link to the previous node makes
outputting the sorted data, in a sorted order, much easier. The example I have provided incorporates this.
But, it all depends on how you plan to use it.

When it comes to coding, there are only two things that you need to know how to do. Traversing the list and
searching it. Both involve the idea of recursion, in which a function calls itself. I'll use the search
function as an example, but again, the full code is available for download.

//Private, recursive, function for searching.
BTNode* p_search(unsigned int item, BTNode* node) {
	if(node != NULL) //If the node is not NULL...
	{
		//If we have found the node...
		if(item == node->data()) {
			return node;    //Return it.
			                //If the node's data is greater than the search item...
		}

		if(item < node->data()) {
			//Search the left node.
			return p_search(item, node->left());
		}

		//If the node's data is less than the search item...
		else {
			//Search the right node.
			return p_search(item, node->right());
		}
	} else {
		//If the node is NULL, return NULL.
		return NULL;
	}
}

With the comments, it should be self-explanatory. The code for traversing the list is slightly more complex,
since you must be sure to traverse each and every node, rather than just those that exist down the path that
you need to travel to find the node. To add a node, you would really just use the search function, but when a
node is null, rather than failure, it means you have found the point where the node belongs, and you then
insert it. Again, all the code is zipped for download.


---
https://www.quora.com/What-is-the-difference-between-a-binary-tree-and-a-linked-list-What-are-the-advantages-and-disadvantages-of-each

What is the difference between a binary tree and a linked list? What are the advantages and disadvantages of
each?


Hello,
Each node in a binary tree allow you to access (potentially) to two different node; one being considered as
"smaller" and one being considered as "greater".

Those two nodes are completely distinct from the node we are coming from. We could imagine binary tree in a
form like:

    level 0                           Node 1 (root)
                                      /          \
                                     /            \
                                    /              \
    level 1                     NODE 2            NODE 3
                                / \               /  \
                               /   \             /    \
                              /     \           /      \
    level 2                NODE 4   NODE 5    NODE 6   NODE 7
                            / \      / \       / \       / \
                           /   \    /   \     /   \     /   \
    level 3               N8   N9  N10   N11 N12  N13  N14  N15

As you can see, there is always only one node which (potentially) "comes in" (if it exists), but theyre are
always two nodes (whose are different that the one which "comes in") whose (potentially) "go out" (if them
exist).

Linked list has - always - one node which (potentielly) "comes in" (if it exists) and only one node which
(potentially) "goes out" (if it exists).

You can - eventually - have a so called "double linked list", in which each node can effectively be "linked
back" to the "incoming node" (if it exists), in a form like

          NODE1 |------------>NODE 2  |------------>NODE 2
    previous  NEXT     previous   NEXT      previous  NEXT
             |-------------|     |---------------|

which allows you to iterate on all nodes of your list in the order you want "from left to right" or "from
right to left", but, according to the order used to iterate on the nodes, there will allways have ... only one
"incoming node" and only one "outgouing node".

Note that those two structure will use completely different manipulation algorithms, and will be more
efficient in completely different use case:

Binary trees are very inefficient to fill, because the main idea is to keep them "balanced" : you should -
idealy - not have more than one level of decallage between last nodes (in my "picture", you could add one or
two node at "level 4", but you chould not have any "level 5" node before all nodes in "level 4" are used). And
it may require many manipulation to achieve that goal when adding or removing nodes.

But binary tree are very efficient when searching for one specific node, because, for each tested node, you
can divide the number of possible node by 2 (we call that "dichotomy).

In the other hand, (double) linked list will be really fast to add (or to insert) a new node (in a given
position). But it will be really inefficient for searching some specific node, because the only way to be sure
to find some specific node (or to be sure that the node does'nt exists) require to visit ... all existent nodes
in the list.


---
https://stackoverflow.com/questions/29225391/binary-trees-arrays-vs-linked

Binary Trees, arrays vs linked

In general, binary tree based abstractions can be implemented either using actual linked node objects, where
each node has pointers to it's two children, or an array, where the children of node in index k are 2k and
2k+1.

Other than the small extra memory overhead of nodes, the complexity in general seems to be identical.

Are there any concrete advantages of one over the other? Anecdotally, I've seen that binary heaps tend to use
the array implementation, while binary search trees tend to use linked nodes implementation. Any reason for
this?

***
Arrays cannot efficiently represent arbitrarily-shaped binary trees, only complete trees. A complete binary
tree is one in which all levels are full, OR all levels except the deepest level are full and the deepest
level has all of its nodes as far to the left as possible. (You can imagine that the levels are filled with
nodes from left to right, and one level has to be filled before the next level can begin.)

Heaps are, by definition, complete binary trees - hence the array implementation is used due to its superior
memory efficiency. On the other hand, binary search trees that must support insertion and removal at
arbitrary locations (and thus may not be complete trees) cannot use the array implementation.

  * 7
    Arrays CAN represent arbitrarily-shaped binary trees. The caveat is that the representation might not be
    efficient.
  * 
    @MCP can you please explain why using array might not be efficient ? I'm a bit perplexed because we can
    just have no child represented as nil
  * 
    @MCP also what about avl trees since they are always balanced is it more efficient to use arrays instead
    of linked nodes ?

***
First of all, it is a legitimate question: binary trees can indeed be embedded in arrays. phari's answer is
incorrect: it is possible with some effort to embed trees of arbitrary shapes into arrays (as long as you
have enough memory). A straightforward representation would involve defining a Node as a variant type: either
it is Filled or Empty, where Filled contains the key and the auxiliary data, and Empty is analogous to Nil
(aka the null pointer). If the only operation you need to support is delete, then you're all set up: just
implement the build operation to return a complete tree and then implement the normal binary tree delete
operation. No balancing required to achieve O(log(n)) complexity bound (where n is the initial number of items
the tree).

It is also possible with a significant effort to implement the insert operation by maintaining the tree in a
balanced shape. Simplifying a bit, you maintain a nearly-complete tree with storage size no more than 2n
(where n is the current number of items in the tree). When a new item is inserted, you check where the
appropriate array cell to insert it is: if it is inside the allocated storage, you just write it to that
cell. Otherwise, you go up the tree starting from the parent of that cell until you find a subtree whose
storage has enough room to fit all items including the new one; if no such subtree exists, you double the
storage. After finding that subtree, you rebuild it into a nearly-complete shape and insert the new item into
the correct array cell (which is now guaranteed to be within the allocated storage). All this can be done in
amortized O(log^2(n)) time, or in amortized O(log(n)) time with even more effort.

The above algorithm sketch is based on "Cache Oblivious Search Trees via Binary Trees of Small Height".

I have implemented a data structure called TeardownTree, which uses this kind of embedding. I support build,
delete, delete_range, query_range, iter operations on the master branch, and an experimental insert operation
on the insert branch. The project page also contains some benchmarks that show the data structure is
definitely viable at least for some usages.

You might also be interested in this blog post explaining how to build trees in constant auxiliary space (a
very fast method in practice).


---
https://www.wscubetech.com/resources/dsa/array-vs-linked-list

Array vs Linked List: All Differences With Comparison
28 Feb 2025

Introduction
Having a clear idea about the difference between an array and a linked list is essential for anyone learning
data structures and algorithms. Both arrays and linked lists are used to store collections of elements, but
they operate in different ways. 

An array is a collection of elements stored in a contiguous block of memory, allowing fast access to any
element. A linked list, on the other hand, stores elements in nodes that are connected by pointers, allowing
for flexible memory usage. 

Let's know about the array vs linked list, comparing their structures, operations, use cases, and more.

What is Array?
An array is a data structure that stores a fixed-size sequence of elements of the same type in a contiguous
block of memory. This means that all the elements are stored next to each other in memory, with each element
being accessible directly using its index. 

The first element is at index 0, the second at index 1, and so on. Because of this, accessing any element in
an array is very fast (O(1) time complexity), as the index can be used to directly calculate the memory
address of the element.

What is Linked List?
A linked list is a data structure that stores a collection of elements, called nodes, where each node contains
two parts: the data and a reference (or pointer) to the next node in the sequence. 

Unlike arrays, linked lists do not store elements in a contiguous block of memory. Instead, each element is
stored in a separate node that can be located anywhere in memory, with the nodes linked together by pointers. 

This allows for flexible memory usage and easy insertion or deletion of elements, especially at the beginning
or middle of the list.

There are different types of linked lists:
  * Singly Linked List
  * Doubly Linked List
  * Circular Linked List

Array vs Linked List: Memory Allocation

Array Memory Allocation
In an array, memory is allocated in a contiguous block. This means that all the elements of the array are
stored next to each other in a single, uninterrupted sequence in memory.

When an array is created, a fixed amount of memory is reserved for it, based on the size of the array and the
data type of its elements.

For example, if you create an array of 10 integers, and each integer takes 4 bytes of memory, then a
continuous block of 40 bytes is allocated in memory.

The contiguous memory allocation allows for very fast access to any element in the array. Since the elements
are stored sequentially, the memory address of any element can be calculated using its index. 

Linked List Memory Allocation
In a linked list, memory is allocated in a non-contiguous manner. Each element in a linked list is stored in a
separate node, and these nodes can be located anywhere in memory. Each node contains two parts: the data and a
reference (or pointer) to the next node in the sequence.

Because the nodes are not required to be stored next to each other, linked lists do not need a contiguous
block of memory.

The non-contiguous allocation gives linked lists a significant advantage in terms of flexibility. Since nodes
are allocated dynamically as needed, the linked list can grow or shrink in size without the need to allocate
or reallocate large blocks of memory.

When to Use Array and Linked List?
+--------------------------+---------------------------------+----------------------------------------------+
| Criteria                 | Use Arrays When...              | Use Linked Lists When...                     |
+--------------------------+---------------------------------+----------------------------------------------+
| Memory Allocation        | Memory needs to be allocated in | Memory can be allocated dynamically and      |
|                          | a contiguous block.             | non-contiguously.                            |
+--------------------------+---------------------------------+----------------------------------------------+
| Access Speed             | Fast access to elements by      | Access speed is not the primary concern,     |
|                          | index is required (O(1) access).| and traversal is acceptable.                 |
+--------------------------+---------------------------------+----------------------------------------------+
| Size of Data Structure   | The size of the data structure  | The size of the data structure is dynamic or |
|                          | is fixed or known in advance.   | frequently changing.                         |
+--------------------------+---------------------------------+----------------------------------------------+
| Insertion/Deletion       | Insertions and deletions are    | Frequent insertions and deletions are        |
|                          | infrequent and mostly at the    | needed, especially at the beginning or       |
|                          | end.                            | middle.                                      |
+--------------------------+---------------------------------+----------------------------------------------+
| Memory Efficiency        | Memory efficiency is            | Slightly higher memory usage is acceptable   |
|                          | important, and overhead from    | due to the overhead of pointers.             |
|                          | pointers should be minimized.   |                                              |
+--------------------------+---------------------------------+----------------------------------------------+
| Complexity of            | Simplicity and ease of          | Flexibility and dynamic memory management    |
| Implementation           | implementation are priorities.  | are priorities.                              |
+--------------------------+---------------------------------+----------------------------------------------+
| Cache Performance        | Cache performance is critical,  | Cache performance is less critical, and      |
|                          | and data should be stored       | non-contiguous storage is acceptable.        |
|                          | contiguously for better cache   |                                              |
|                          | locality.                       |                                              |
+--------------------------+---------------------------------+----------------------------------------------+
| Sorting and Searching    | Frequent sorting and searching  | Sorting and searching are less common or     |
|                          | operations are required,        | handled differently.                         |
|                          | especially binary search        |                                              |
|                          | (O(log(n))).                    |                                              |
+--------------------------+---------------------------------+----------------------------------------------+
| Fixed Data Types         | A collection of elements of     | A flexible data structure with nodes that    |
|                          | the same data type is needed.   | can store different data types or complex    |
|                          |                                 | objects is needed.                           |
+--------------------------+---------------------------------+----------------------------------------------+
| Real-Time Systems        | The data structure needs to     | Real-time access is less critical, and       |
|                          | support real-time access and    | flexibility in structure is more important.  |
|                          | processing.                     |                                              |
+--------------------------+---------------------------------+----------------------------------------------+

Array vs Linked List: Time Complexity
Know the difference between array and linked list data structure in terms of time complexity:

+--------------------------+---------------------------------+-----------------------------+
| Operation                | Array Time Complexity           | Linked List Time Complexity |
+--------------------------+---------------------------------+-----------------------------+
| Access (by Index)        | O(1)                            | O(n)                        |
+--------------------------+---------------------------------+-----------------------------+
| Search (Unsorted)        | O(n)                            | O(n)                        |
+--------------------------+---------------------------------+-----------------------------+
| Search (Sorted)          | O(log(n)) with Binary Search    | O(n)                        |
+--------------------------+---------------------------------+-----------------------------+
| Insertion (at Beginning) | O(n)                            | O(1)                        |
+--------------------------+---------------------------------+-----------------------------+
| Insertion (at End)       | O(1) (if space available)       | O(1) (with tail pointer)    |
+--------------------------+---------------------------------+-----------------------------+
| Insertion (at Middle)    | O(n)                            | O(n)                        |
+--------------------------+---------------------------------+-----------------------------+
| Deletion (at Beginning)  | O(n)                            | O(1)                        |
+--------------------------+---------------------------------+-----------------------------+
| Deletion (at End)        | O(1) (if space available)       | O(1) (with tail pointer)    |
+--------------------------+---------------------------------+-----------------------------+
| Deletion (at Middle)     | O(n)                            | O(n)                        |
+--------------------------+---------------------------------+-----------------------------+

Array vs Linked List: Space Complexity
Check the difference between array and linked list in terms of space complexity:

+--------------------------+---------------------------------+------------------------------+
| Aspect                   | Array Space Complexity          | Linked List Space Complexity |
+--------------------------+---------------------------------+------------------------------+
| Storage of Elements      | O(n)                            | O(n)                         |
+--------------------------+---------------------------------+------------------------------+
| Memory Overhead          | None                            | O(n) for pointers            |
|                          |                                 |  (additional overhead)       |
+--------------------------+---------------------------------+------------------------------+
| Dynamic Sizing           | Fixed size, no dynamic resizing | Dynamic size, grows and      |
|                          |                                 | shrinks as needed            |
+--------------------------+---------------------------------+------------------------------+
| Efficiency               | More memory-efficient without   | Less memory-efficient due    |
|                          | pointers                        | to pointers.
+--------------------------+---------------------------------+------------------------------+

Difference Between Array and Linked List: Comparison
This is a comprehensive comparison showing the difference between array and linked list with example:

+--------------------------+--------------------------------------+-----------------------------------------+
| Aspect                   | Array                                | Linked List                             |
+--------------------------+--------------------------------------+-----------------------------------------+
| Definition               | A collection of elements stored in   | A collection of elements (nodes) linked |
|                          | a contiguous block of memory.        | by pointers, stored non-contiguously.   |
+--------------------------+--------------------------------------+-----------------------------------------+
| Memory Allocation        | Contiguous memory block.             | Non-contiguous memory; each element is  |
|                          |                                      | stored in a node with a pointer to the  |
|                          |                                      | next.                                   |
+--------------------------+--------------------------------------+-----------------------------------------+
| Types                    | One-dimensional, multi-dimensional   | Singly Linked List, Doubly Linked List, |
|                          | arrays (e.g., 2D, 3D arrays).        | Circular Linked List.                   |
+--------------------------+--------------------------------------+-----------------------------------------+
| Access Time Complexity   | O(1) - Direct access by index.       | O(n) - Traversal needed to access       |
|                          |                                      | elements.                               |
+--------------------------+--------------------------------------+-----------------------------------------+
| Search Time Complexity   | O(n) for unsorted, O(log(n)) for     | O(n) - Linear search required.          |
|                          | sorted (using binary search).        |                                         |
+--------------------------+--------------------------------------+-----------------------------------------+
| Insertion (at Beginning) | O(n) - All elements must be shifted. | O(1) - Direct insertion without         |
|                          |                                      | shifting.                               |
+--------------------------+--------------------------------------+-----------------------------------------+
| Insertion (at End)       | O(1) if space is available; O(n) if  | O(1) with a tail pointer; O(n) without  |
|                          | array is full (need resizing).       | a tail pointer.                         |
+--------------------------+--------------------------------------+-----------------------------------------+
| Insertion (at Middle)    | O(n) - Elements must be shifted to   | O(n) - Traversal required to find       |
|                          | make room.                           | insertion point.                        |
+--------------------------+--------------------------------------+-----------------------------------------+
| Deletion (at Beginning)  | O(n) - All elements must be shifted. | O(1) - Direct removal of the first      |
|                          |                                      | node.                                   |
+--------------------------+--------------------------------------+-----------------------------------------+
| Deletion (at End)        | O(n) if array is full.               | O(1) with tail pointer; O(n) without a  |
|                          |                                      | tail pointer.                           |
+--------------------------+--------------------------------------+-----------------------------------------+
| Deletion (at Middle)     | O(n) - Elements must be shifted      | O(n) - Traversal required to find and   |
|                          | after deletion.                      | remove the node.                        |
+--------------------------+--------------------------------------+-----------------------------------------+
| Dynamic Resizing         | Not flexible - Fixed size; resizing  | Flexible - Grows and shrinks            |
|                          | requires allocation of new memory    | dynamically as needed.                  |
|                          | block.                               |                                         |
+--------------------------+--------------------------------------+-----------------------------------------+
| Memory Overhead          | Efficient - Only stores the          | Higher overhead - Each node requires    |
|                          | elements.                            | additional memory for pointers.         |
+--------------------------+--------------------------------------+-----------------------------------------+
| Cache Performance        | Better - Contiguous memory           | Worse - Non-contiguous memory reduces   |
|                          | improves cache locality.             | cache efficiency.                       |
+--------------------------+--------------------------------------+-----------------------------------------+
| Space Complexity         | O(n) - Space is allocated for n      | O(n) + O(n) for pointers - Extra space  |
|                          | elements.                            | is needed for pointers in each node.    |
+--------------------------+--------------------------------------+-----------------------------------------+
| Implementation           | Simple to implement and manage.      | More complex due to pointer management  |
| Complexity               |                                      | and dynamic memory allocation.          |
+--------------------------+--------------------------------------+-----------------------------------------+
| Best Use Cases           | - When quick access to elements is   | - When frequent insertions and          |
|                          |   required.                          |   deletions are required.               |
+--------------------------+--------------------------------------+-----------------------------------------+
|                          | - When the number of elements is     | - When memory usage needs to be         |
|                          |   fixed and known in advance.        |   dynamic and flexible.                 |
+--------------------------+--------------------------------------+-----------------------------------------+
| Drawbacks                | - Fixed size, resizing is costly.    | - Slow access time, extra memory        |
|                          |                                      |   overhead for pointers.                |
+--------------------------+--------------------------------------+-----------------------------------------+
|                          | - Inserting and deleting elements    | - Requires traversal for accessing      |
|                          |   is costly due to shifting.         |   elements.                             |
+--------------------------+--------------------------------------+-----------------------------------------+
| Example Applications     | - Static data storage, tables,       | - Dynamic memory allocation, queues,    |
|                          |   matrices.                          |   history management (e.g., browser     |
|                          |                                      |   history)                              |
+--------------------------+--------------------------------------+-----------------------------------------+


---
https://makemesenpai.medium.com/linked-lists-binary-trees-b54fa2906822

Linked lists & Binary Trees
Oct 7, 2020

Linked Lists and Binary Trees are an essecial part of programming. As these data structures make our code run
a lot faster and gives us more capabilities. The best example of this would be an autocomplete function, in
which you put in the first few letters of a word, and are given a suggestion as to what word it thinks you
might be typing. If this was done with a regular array of letters as opposed to a Binary Tree, then the run
time would be unbarible. You would be waiting a long time for a suggestion that not only might be wrong, but
will take away from the rest of your computers efficiency. As a coder, we love efficiency! So lets waste no
time on introductions and jump right into how to build one, and how they work!

Linked Lists and Binary Trees are made up of one very important element known as a Node. A Node is kinda like
a bucket that holds our information inside of it, along with instructions as how to get to it's next
destination. Linked List and Binary Trees are not built in functions of python, unlike dictionaries and
arrays. So we will have to build our own using class objects.

#!python3

#Node example
class Node():
	def __init__(self, data):
		self.data = data
		self.pointer = None

node1 = Node('1')

Nodes can contain multiple pointers, and in a Double Linked List require directions for both the next node
and before it. We can set those directions to assign the order of our Linked List as seen below. The code
below goes over how to build a Double Linked List and some of it's basic methods.

#!python3

#Double Linked list example
class Node():
	def __init__(self, data):
		self.data = data
		self.next = None
		self.previous = None

class double_ll(object):
	def __init__(self):
		self.head = None
		self.tail = None

	# creates our linked list methods
	def append(self, item):
		# creates a node to add to the END of our list
		new_node = Node(item)

		# Check if this linked list is empty
		if self.head is None:
			# Assign head to new node
			self.head = new_node

			# sets previous to none, as it is the beggining of the list
			new_node.previous = None

			# Otherwise set previous as tail & insert new node after tail
		else:
			new_node.previous = self.tail
			self.tail.next = new_node

		# Update tail to new node regardless
		self.tail = new_node

	def prepend(self, item):
		# Create a new node to add to the BEGINNING of our list
		new_node = Node(item)

		if self.head is None: # if empty make head new node
			self.head = new_node
			self.tail = new_node
		else:
			# otherwise set new node to head
			new_node.next = self.head
			new_node.previous = None
			self.head = new_node

	def delete_from_tail(self):
		# Delete the last item in the linked list
		current = self.head

		# Searches for the end of our double linked list
		while current != None:
			if current.next == self.tail:
				break

		# focus on the node right before the tail
		current = current.next
		"""you can't really delete items in a linked list so we remove
access to it completely, and therefore have removed it from the list"""
		current.next = None
		current.previous = None
		self.tail = current

	def delete_from_head(self):
		second = self.head.next
		second.previous = None
		self.head = sencond

	""" And becuase we have created a double link list, we can traverse through it forwards and backwards! """
	def forward_print(self):
		current = self.head
		while current != None:
			print(current.data)
			current = current.next

	def backward_print(self):
		current = self.tail
		while current != None:
			print(current.data)
			current = current.previous

Despit Double Linked Lists being a bit more work to make, they can be very useful! Learning how to create
Linked Lists can help you create stacks and queues for recursive functions. "But Anthony!", I hear you
asking, "what's the difference between a Single Linked List and a Double?". Simply put, a Single Linked List
has only one direction it's going in, while a Double Linked List goes both ways. I drew a demonstration below
(sorry for the sloppy handwriting).

          SINGLE:
          Head                  Tail
           |                     |
           |                     V
           +-->( 1 )-->( 2 )-->( 3 )-->None


          DOUBLE:
          Head                  Tail
           |                     |
           |                     V
           +-->( 1 )-->( 2 )-->( 3 )-->None
      None <-- (   )<--(   )<--(   )

The circles represent our nodes, that are holding ints as data. The node.next defines the next node's objects
id in our list, which helps our list find it's way to our second node -which is holding the data of 2. A
node.previous is added, as to go the other direction in our Double Linked List. Just as the tail points to
None, so will our node.previous when at the beginning of the list.

The second reason I explained a Double ll, rather than a Single, is because we can use two different
directions to our advantage -when creating a Binary Tree. There is no .next or .previous attribute. However,
there is a .left and .right attribute. We will use these in order to build our tree, and give or nodes
instructions on where we would like it to go. So grab some tea and take a deep breath before jumping into our
next large section of code.

#!python3

# Binary Tree Example
class Node:
	def __init__(self, data):
		self.data = data
		# left and right attributes
		self.left = None
		self.right = None
	
	# creating our nodes
	node1 = Node(4)
	node2 = Node(2)
	node3 = Node(6)
	node4 = Node(1)
	node5 = Node(3)
	node6 = Node(5)

	# building our tree
	root = node1
	node1.left = node2
	node1.right = node3
	node2.left = node4
	node2.right = node5
	node3.left = node6

	# search the tree
	def search(node, target):
		if node is None: # checks if there are no items left to search
			return None
		elif node.data == target: # checks if the node is our target
			return node
	elif node.data < target: # go right
		 return search(node.right, target)
	 else: # go left
		return search(node.left, target)

	"""The function will recursively calls itself and check if the value is higher or lower then what we are
	looking for. For example, we call the function looking for 5. The funcion will figure out that our root
	node(node1.data == 4) is too small, and therefore go right as a result. Then when it reads our node3.data,
	it will determine that it is less than 6, and go left as a result. Finally finding 5, and returning the
	result."""
	 result = search(root, 5)

	# now lets insert a new node into our tree
	node7 = Node(7)

	def insert(node, new_node):
		if new_node.data > node.data:
			# put new child on right if space
				if node.right is None:
					node.right = new_node
					return

		# otherwise keep looking
		else:
			insert(node.right, new_node)

		if new_node.data < node.data:
			# put new child on the left if space
			if node.left is None:
				node.left = new_node
				return
		# otherwise keep looking
		else:
			insert(node.left, new_node)

	"""Here we created a Node with the value of 7. This function will recursively call itself until it finds
	an open spot for 7 -that makes sense in the database. Simularly to our search funtion, it will check -if
	it cannot find an empty space for our node- if our node's value/data belongs on the left or right side
	based on how big it is. You can choose any node to try and insert to, but for this example we have used
	the root node to cycle threw the entire tree."""
	insert(root, node7)
	insert(root, Node(8))

	def delete(node, target):
		result = search(node, target - 1)
		if result.left == target:
			result.left = None
		elif result.right == target:
			result.right = None

		# does a second search to try and find a parent node
		result = search(node, target + 1)
		if result.left == target:
			result.left = None
		elif result.right == target:
			result.right = None
		# else, we print a not found response
		else:
			print(f"Could not find {target} in Tree.")

	"""Here we take advantage of our search function in order to find the previous node. Becuase we are trying
	to delete 8, we have to look for the node with a value of 7. Note that if we were looking for 5, we would
	have to look for the parenting node, with a value of 6. As well, this example only works for integer based
	binary trees."""
	delete(root, 8)

	# Finally we can print our tree out.
	def in_order_traversal(node):
		if node is not None:
			#traverse
			in_order_traversal(node.left)
			print(node.data)
			in_order_traversal(node.right)
		else:
			return None

	in_order_traversal(root)

And this is what our Tree should look like after it is all said and done. (apologies again for the bad
handwriting)

    BINARY TREE:

                    (4)
             ______/   \______
           (2)               (2)
          /   \             /   \
       (1)    (3)          (1)   (3)
      /  \    / \         /  \   /  \
  None None None None None None None None

I know looking at so much text and code can be sore for eyes. Please comment on any questions you might have,
and if there's anything I can do to improve this explanation! But most importantly, happy coding, and have a
great day!


---

