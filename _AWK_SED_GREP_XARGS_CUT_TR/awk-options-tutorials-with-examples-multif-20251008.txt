filename: awk-options-tutorials-with-examples-multif-20251008.txt
https://www.math.utah.edu/docs/info/gawk_11.html

AWK Built-in Variables

   Most awk variables are available for you to use for your own purposes; they never change except when
   your program assigns values to them, and never affect anything except when your program examines
   them. However, a few variables in awk have special built-in meanings. Some of them awk examines
   automatically, so that they enable you to tell awk how to do certain things. Others are set
   automatically by awk, so that they carry information from the internal workings of awk to your
   program.

   This chapter documents all the built-in variables of gawk. Most of them are also documented in the
   chapters describing their areas of activity.
     * User-modified: Built-in variables that you change to control awk.
     * Auto-set: Built-in variables where awk gives you information.
     * ARGC and ARGV: Ways to use ARGC and ARGV.

Built-in Variables that Control awk
   This is an alphabetical list of the variables which you can change to control how awk does certain
   things. Those variables that are specific to gawk are marked with an asterisk, '*'.

   CONVFMT
          This string controls conversion of numbers to strings (see section Conversion of
          Strings and Numbers). It works by being passed, in effect, as the first argument to the
          sprintf function (see section Built-in Functions for String Manipulation). Its default
          value is "%.6g". CONVFMT was introduced by the POSIX standard.

   FIELDWIDTHS *
          This is a space separated list of columns that tells gawk how to split input with fixed,
          columnar boundaries. It is an experimental feature. Assigning to FIELDWIDTHS overrides the use
          of FS for field splitting. See section Reading Fixed-width Data, for more information.
          If gawk is in compatibility mode (see section Command Line Options), then FIELDWIDTHS has
          no special meaning, and field splitting operations are done based exclusively on the value
          of FS.

   FS
          FS is the input field separator (see section Specifying How Fields are Separated). The
          value is a single-character string or a multi-character regular expression that matches
          the separations between fields in an input record. If the value is the null string (""),
          then each character in the record becomes a separate field. The default value is " ", a
          string consisting of a single space. As a special exception, this value means that any
          sequence of spaces and tabs is a single separator. It also causes spaces and tabs at the
          beginning and end of a record to be ignored. You can set the value of FS on the command line
          using the '-F' option:
$> awk -F, 'program' input-files

          If gawk is using FIELDWIDTHS for field-splitting, assigning a value to FS will cause gawk
          to return to the normal, FS-based, field splitting. An easy way to do this is to simply
          say 'FS = FS', perhaps with an explanatory comment.

   IGNORECASE *
          If IGNORECASE is non-zero or non-null, then all string comparisons, and all regular
          expression matching are case-independent. Thus, regexp matching with '~' and '!~', and the
          gensub, gsub, index, match, split and sub functions, record termination with RS, and field
          splitting with FS all ignore case when doing their particular regexp operations. See
          section Case-sensitivity in Matching. If gawk is in compatibility mode (see section
          Command Line Options), then IGNORECASE has no special meaning, and string and
          regexp operations are always case-sensitive.

   OFMT
          This string controls conversion of numbers to strings (see section Conversion of
          Strings and Numbers) for printing with the print statement. It works by being passed, in
          effect, as the first argument to the sprintf function (see section Built-in Functions
          for String Manipulation). Its default value is "%.6g". Earlier versions of awk also used OFMT
          to specify the format for converting numbers to strings in general expressions; this is
          now done by CONVFMT.

   OFS
          This is the output field separator (see section Output Separators). It is output
          between the fields output by a print statement. Its default value is " ", a string
          consisting of a single space.

   ORS
          This is the output record separator. It is output at the end of every print statement. Its
          default value is "\n". (See section Output Separators.)

   RS
          This is awk's input record separator. Its default value is a string containing a single
          newline character, which means that an input record consists of a single line of text. It can
          also be the null string, in which case records are separated by runs of blank lines, or a
          regexp, in which case records are separated by matches of the regexp in the input
          text. (See section How Input is Split into Records.)

   SUBSEP
          SUBSEP is the subscript separator. It has the default value of "\034", and is used to separate
          the parts of the indices of a multi-dimensional array. Thus, the expression foo["A", "B"]
          really accesses foo["A\034B"] (see section Multi-dimensional Arrays).

Built-in Variables that Convey Information
   This is an alphabetical list of the variables that are set automatically by awk on certain occasions
   in order to provide information to your program. Those variables that are specific to gawk are marked
   with an asterisk, '*'.
   ARGC
   ARGV
          The command-line arguments available to awk programs are stored in an array called ARGV. ARGC
          is the number of command-line arguments present. See section Other Command Line
          Arguments. Unlike most awk arrays, ARGV is indexed from zero to ARGC - 1. For example:
$> awk 'BEGIN {
>   	for (i = 0; i < ARGC; i++)
>   		print ARGV[i]
>   }' inventory-shipped BBS-list
-| awk
-| inventory-shipped
-| BBS-list

          In this example, ARGV[0] contains "awk", ARGV[1] contains "inventory-shipped", and ARGV[2]
          contains "BBS-list". The value of ARGC is three, one more than the index of the last
          element in ARGV, since the elements are numbered from zero. The names ARGC and ARGV, as well
          as the convention of indexing the array from zero to ARGC - 1, are derived from the C
          language's method of accessing command line arguments. See section Using ARGC and ARGV,
          for information about how awk uses these variables.

   ARGIND *
          The index in ARGV of the current file being processed. Every time gawk opens a new data file
          for processing, it sets ARGIND to the index in ARGV of the file name. When gawk is processing
          the input files, it is always true that 'FILENAME == ARGV[ARGIND]'. This variable is useful in
          file processing; it allows you to tell how far along you are in the list of data files, and to
          distinguish between successive instances of the same filename on the command line. While you
          can change the value of ARGIND within your awk program, gawk will automatically set it to a
          new value when the next file is opened. This variable is a gawk extension. In other awk
          implementations, or if gawk is in compatibility mode (see section Command Line Options),
          it is not special.

   ENVIRON
          An associative array that contains the values of the environment. The array indices are
          the environment variable names; the values are the values of the particular
          environment variables. For example, ENVIRON["HOME"] might be '/home/arnold'. Changing this
          array does not affect the environment passed on to any programs that awk may spawn via
          redirection or the system function. (In a future version of gawk, it may do so.) Some
          operating systems may not have environment variables. On such systems, the ENVIRON array
          is empty (except for ENVIRON["AWKPATH"]).

   ERRNO *
          If a system error occurs either doing a redirection for getline, during a read for
          getline, or during a close operation, then ERRNO will contain a string describing the
          error. This variable is a gawk extension. In other awk implementations, or if gawk is in
          compatibility mode (see section Command Line Options), it is not special.

   FILENAME
          This is the name of the file that awk is currently reading. When no data files are listed on
          the command line, awk reads from the standard input, and FILENAME is set to "-". FILENAME is
          changed each time a new file is read (see section Reading Input Files). Inside a BEGIN
          rule, the value of FILENAME is "", since there are no input files being processed
          yet.(7) (d.c.)

   FNR
          FNR is the current record number in the current file. FNR is incremented each time a new
          record is read (see section Explicit Input with getline). It is reinitialized to zero each
          time a new input file is started.

   NF
          NF is the number of fields in the current input record. NF is set each time a new record
          is read, when a new field is created, or when $0 changes (see section Examining
          Fields).

   NR
          This is the number of input records awk has processed since the beginning of the program's
          execution (see section How Input is Split into Records). NR is set each time a new record
          is read.

   RLENGTH
          RLENGTH is the length of the substring matched by the match function (see section
          Built-in Functions for String Manipulation). RLENGTH is set by invoking the match
          function. Its value is the length of the matched string, or -1 if no match was found.

   RSTART
          RSTART is the start-index in characters of the substring matched by the match function
          (see section Built-in Functions for String Manipulation). RSTART is set by invoking the
          match function. Its value is the position of the string where the matched substring
          starts, or zero if no match was found.

   RT *
          RT is set each time a record is read. It contains the input text that matched the text denoted
          by RS, the record separator. This variable is a gawk extension. In other awk implementations,
          or if gawk is in compatibility mode (see section Command Line Options), it is not special.

   A side note about NR and FNR. awk simply increments both of these variables each time it reads a
   record, instead of setting them to the absolute value of the number of records read. This means
   that your program can change these variables, and their new values will be incremented for each
   record (d.c.). For example:
$> echo '1
> 2
> 3
> 4' | awk 'NR == 2 { NR = 17 }
> { print NR }'
-| 1
-| 17
-| 18
-| 19

   Before FNR was added to the awk language (see section Major Changes between V7 and SVR3.1), many
   awk programs used this feature to track the number of records in a file by resetting NR to zero
   when FILENAME changed.

Using ARGC and ARGV
   In section Built-in Variables that Convey Information, you saw this program describing the
   information contained in ARGC and ARGV:
$> awk 'BEGIN {
> 	for (i = 0; i < ARGC; i++)
> 		print ARGV[i]
> }' inventory-shipped BBS-list
-| awk
-| inventory-shipped
-| BBS-list

   In this example, ARGV[0] contains "awk", ARGV[1] contains "inventory-shipped", and ARGV[2] contains
   "BBS-list".

   Notice that the awk program is not entered in ARGV. The other special command line options, with
   their arguments, are also not entered. But variable assignments on the command line are treated as
   arguments, and do show up in the ARGV array.

   Your program can alter ARGC and the elements of ARGV. Each time awk reaches the end of an input file,
   it uses the next element of ARGV as the name of the next input file. By storing a different
   string there, your program can change which files are read. You can use "-" to represent the
   standard input. By storing additional elements and incrementing ARGC you can cause additional files
   to be read.

   If you decrease the value of ARGC, that eliminates input files from the end of the list. By recording
   the old value of ARGC elsewhere, your program can treat the eliminated arguments as something other
   than file names.

   To eliminate a file from the middle of the list, store the null string ("") into ARGV in place
   of the file's name. As a special feature, awk ignores file names that have been replaced with the
   null string. You may also use the delete statement to remove elements from ARGV (see section
   The delete Statement).

   All of these actions are typically done from the BEGIN rule, before actual processing of the
   input begins. See section Splitting a Large File Into Pieces, and see section Duplicating
   Output Into Multiple Files, for an example of each way of removing elements from ARGV.

   The following fragment processes ARGV in order to examine, and then remove, command line options.

BEGIN {
	for (i = 1; i < ARGC; i++) {
		if (ARGV[i] == "-v")
			verbose = 1
		else if (ARGV[i] == "-d")
			debug = 1
		else if (ARGV[i] ~ /^-?/) {
			e = sprintf("%s: unrecognized option -- %c",
					ARGV[0], substr(ARGV[i], 1, ,1))
			print e > "/dev/stderr"
		} else
			break
		delete ARGV[i]
	}
}


---
https://www.dcs.warwick.ac.uk/people/academic/M.S.Joy/book/s.11.6.2.php

Awk

Special variables
   Just as the shell can use predefined variables such as HOME, so can Awk. There are many of these, all
   of which use capital letters only (so variable names you choose yourself should use lower-case
   letters). Some of them we discuss here:

   FILENAME   The pathname of the current input file
   FS         Input field separator, usually Space
   NF         Number of fields in current record
   NR         Number of current record from start of input
   FNR        Number of current record from start of current input file
   OFS        Output field separator used by print, usually Space
   ORS        Output record separator used by print, usually Newline

   Each input record is counted, starting at 1. Given that the variable NR contains the number of the
   current record, the following script will prepend each input line with the line number (unless
   otherwise specified, a record is assumed to be a single line). The format is that of cat -n, where
   six spaces are allowed for the line numbers, which are separated from the line contents by two
   blanks. The format specification %6d indicates an integer right-justified within six spaces.
{ printf "%6d  %s\n", NR, $0 }

   Try this Awk script, and also cat -n, with a file such as vegetables.

Worked example
   Using awk, select the first three lines of standard input, in the manner of head -3.
   Solution: Display only those lines whose number, as given by NR, is at most three. When NR is equal
   to three, the program should finish - otherwise it will continue reading input until the input
   terminates. The action exit causes awk to terminate.
NR <= 3 { print $0 }
NR == 3 { exit }

   The variable NR starts off with value 1 on the first line of input, and continues counting however
   many files you have given as argument to awk. There is another variable FNR, which is similar to NR,
   but is reset to 1 each time a new file is read as input. The variable FILENAME holds the name of the
   current data file being read in.

Worked example
   Write an Awk script firstlines to read from a number of files and display the first line of each file
   preceded by the message The first line of filename is: in the following manner:

$> awk -f firstlines vegetables /usr/dict/words
The first line of vegetables is:
potatoes 0.50 5
The first line of /usr/dict/words is:
AAAA

   Solution: Use variable FNR to form the pattern to find the first line of each input file, then printf
   to display that line ($0).
FNR == 1 { printf "The first line of %s is:\n%s\n", FILENAME, $0 }

   Each record consists of a number of fields. The variable NF is the number of fields contained in the
   current record. Try the following:

$> awk '{ print NF }'
hello there
2
A B C D E
5
(blank line)
0
ctrl-D

Worked example
   If some data in vegetables had been mistyped, there might be lines in the file containing either less
   than or more than three fields. Such lines cannot be processed correctly by the previous Awk scripts.
   Write an Awk script to read a file and display a list of those lines containing a number of fields
   different to three.

   Solution: Use the pattern NF != 3 to choose those lines, and the value of NR to indicate which lines
   they are:

NF != 3 { printf "Line %d has %d fields\n", NR, NF }

   Use this script to check that your file vegetables is indeed of the correct format. Try it on some
   other files you own and see what happens.


---
https://www.baeldung.com/linux/awk-multiple-input-files

Process Multiple Input Files Using Awk
March 18, 2024

1. Overview
            awk is a convenient and powerful command-line utility for processing text. Sometimes, we
            need to read and process multiple input files.
            In this tutorial, we'll learn how to process multiple input files using the awk command.

2. Processing Multiple Files
            Sometimes, we want to process a collection of data files and generate some output.
            For example, suppose we have three input files containing user scores:

$> head score*.txt
==> score1.txt <==
Tom 20
Jerry 40
Mark 25
Amanda 37

==> score2.txt <==
Mark 75
Tom 70
Jerry 7
Amanda 40

==> score3.txt <==
Mark 73
Amanda 47
Jerry 79
Tom 40
            Notice that all files share the same format: each line contains a name and a score,
            separated by whitespace.

            Let's calculate the sum of scores for each user from the files above:
$> awk '{ sum[$1]+=$2 } END { for(user in sum) print user, sum[user] }' score*.txt
Tom 130
Jerry 126
Mark 173
Amanda 124

            In the code above, we created an associative array sum to calculate and store the sum of
            scores of each user. Finally, in the END block, we printed elements in the array.
            When our input files share the same format, we can treat multiple input files as a single
            merged input. This is a relatively simple situation.

            However, in practice, we often need to handle the associations between input files. In the
            following sections, we'll see these situations in detail.

3. Processing Two Associated Input Files
            In our next example, we'll show how to process two associated input files using line numbers
            and awk's built-in NR and FNR variables.

3.1. Understanding the NR and FNR
            NR and FNR are two built-in awk variables. NR tells us the total number of records that
            we've read so far, while FNR gives us the number of records we've read in the current input
            file.

            Let's understand the two variables through an example. First, let's create two files:
$> head file1.txt file2.txt
==> file1.txt <==
file1-1
file1-2
file1-3
file1-4
file1-5

==> file2.txt <==
file2-1
file2-2
file2-3
file2-4
file2-5

            Then we create a simple awk one-liner, which takes the two files above as input and prints
            lines in each file together with the values of NR and FNR:
$> awk '{ printf "Line:%s, NR:%d, FNR:%d\n", $0, NR, FNR}' file1.txt file2.txt
Line:file1-1, NR:1, FNR:1
Line:file1-2, NR:2, FNR:2
Line:file1-3, NR:3, FNR:3
Line:file1-4, NR:4, FNR:4
Line:file1-5, NR:5, FNR:5
Line:file2-1, NR:6, FNR:1
Line:file2-2, NR:7, FNR:2
Line:file2-3, NR:8, FNR:3
Line:file2-4, NR:9, FNR:4
Line:file2-5, NR:10, FNR:5

            The output above shows us:
               * For the first input file, the values of NR and FNR are always the same
               * When awk reads a new input file, the FNR variable will be reset to 1, whereas NR keeps
                 incrementing

            In the next section, we'll see how to distinguish between the input files from the NR and
            FNR and handle the relations.

3.2. Print Lines by Defined Line Numbers
            Let's start with an example.
            We prepared two files:
$> head all_lines.txt lines_to_show.txt
==> all_lines.txt <==
line-01
line-02
line-03
line-04
line-05
line-06
line-07
line-08
line-09
line-10

==> lines_to_show.txt <==
2
3
4
5
7

            In the file all_lines.txt, we have ten lines of text, while the file lines_to_show.txt
            stores line numbers. Now, we want to output a line from the all_lines.txt file only if its
            line number is defined in the file lines_to_show.txt.

            Let's have a look at the solution, then understand how it works:
$> awk 'NR==FNR { out[$1]=1; next } { if (out[FNR]==1) print $0 }' lines_to_show.txt all_lines.txt
line-02
line-03
line-04
line-05
line-07

            We solved this problem in two steps:
              1. Read the file lines_to_show.txt and save the line numbers in an array.
              2. As we read lines from file all_lines.txt, we print the line if the current line number
                 exists in the array.

            Now, let's take a closer look at the awk code above to understand how it works.

            Step 1: NR==FNR{ out[$1]=1; next }
               * awk reads the first line from the first file lines_to_show.txt, which is: 2
               * Both NR and FNR now have the same value 1, so we create an associative array named
                 *ut and set out[2]=1
               * The next statement will make awk skip the remaining processing and read the next record
               * Because during the processing of the first input file, NR==FNR is always True, after
                 awk processes the file lines_to_show.txt, we have: out[2]=out[3]=out[4]=out[5]=out[7]=1

            Step 2: { if (out[FNR]==1) print $0 }
               * When we start processing the second file, all_lines.txt, FNR is reset to 1, thus, FNR
                 and NR have different values
               * In the array out, we don't have an element out[1], so we don't print
               * awk reads the next line, line-02; now FNR is 2, and we have out[2]=1, so this line will
                 be printed *ut by print $0
               * In this way, after awk goes through the second input file, we'll get the required
                 output

            It's worthwhile to mention that, in awk:
               * A non-zero number will be evaluated as True - in other words, '{ if (out[FNR] == 1)
                 print $0 }' can be written as '{ if(*ut[FNR]) print $0 }'
               * A True value will trigger the default action: printing the current record, so '{
                 if(out[FNR]) print $0 }' can be written as 'out[FNR]'

            Therefore, we can write the awk one-liner solution to this problem more compactly:
$> awk 'NR==FNR { out[$1]=1; next } out[FNR]' lines_to_show.txt all_lines.txt

3.3. Join and Calculate
            In this section, we'll see another practical example. As usual, let's first take a look at
            the two input files:
$> head price.txt purchasing.txt
==> price.txt <==
Product Price(USD/Kg) Supplier
Apple 3.20 Supplier_X
Orange 3.00 Supplier_Y
Peach 5.35 Supplier_Y
Pear 5.00 Supplier_X
Mango 12.00 Supplier_Y
Pineapple 7.70 Supplier_X

==> purchasing.txt <==
Product Volume(Kg) Date
Orange 120 2020-04-02
Apple 400 2020-04-03
Peach 70 2020-04-05
Pear 50 2020-04-17

            We want to generate a cost report containing Product, Date, and a new column, Cost, where
            Cost = Price * Volume.

            Let's look at the solution first:
$> awk 'BEGIN { print "Product Cost Date" }
	FNR>1 && NR==FNR { price[$1]=$2; next }
	FNR>1 { printf "%s $%.2f %s\n",$1, price[$1]*$2, $3}' price.txt purchasing.txt

Product Cost Date
Orange $360.00 2020-04-02
Apple $1280.00 2020-04-03
Peach $374.50 2020-04-05
Pear $250.00 2020-04-17

            Now let's take a closer look at the code and understand how it works:
               * The BEGIN block prints the header
               * FNR>1 skips the header line from the input file
               * NR==FNR{ price[$1]=$2; next } creates an associative array price, reads each line from
                 the first input file, and st*res Name:Price as Key:Value elements in the array
               * When we process the second file, we find the price value from the associative array
                 price, calculate the Cost, and print the output using printf

3.4. Common Pattern for Handling Two Input Files
            If we need to handle two input files using awk, we can consider using this typical pattern
            to solve the problem:
awk 'NR==FNR {
	// read lines from the first input file
	// do calculation and save required value
	// in variables or arrays
	next
}

{
	// process the lines from the second file
	// with the variables or arrays we prepared above
}'  inputFile1 inputFile2

4. Processing More Than Two Associated Input Files
            We've learned the compact way to handle two input files by comparing the values of FNR and
            NR.

            However, if we have more than two input files, this method will not work.
            This is because the FNR is always going to be reset to 1, once the input file changes. We
            cannot distinguish between the input files by the FNR variable anymore.

4.1. The FILENAME Variable
            FILENAME is a built-in variable that stores the name of the input file the awk command is
            currently processing:
$> awk '{ print $0 " => " FILENAME}' file1.txt file2.txt file3.txt
file1-1 => file1.txt
file1-2 => file1.txt
file1-3 => file1.txt
file1-4 => file1.txt
file1-5 => file1.txt
file2-1 => file2.txt
file2-2 => file2.txt
file2-3 => file2.txt
file2-4 => file2.txt
file2-5 => file2.txt
file3-1 => file3.txt
file3-2 => file3.txt
file3-3 => file3.txt
file3-4 => file3.txt
file3-5 => file3.txt

            We can make use of this variable to distinguish the input files and apply different
            processing logic.

4.2. Join and Calculate Revised
            In an earlier section, we've generated a report on the fruit purchasing cost.
            Let's review the example quickly. We have two input files:
               *  price.txt: containing the price and supplier data: Product, Price, Supplier
               * purchasing.txt: storing the purchasing activities: Product, Volume(Kg), Date

            Due to the good partnership with suppliers, they agreed to offer us some discounts. Now,
            we'll add a third file, discount.txt:
$> cat discount.txt
Supplier Discount
Supplier_X 0.10
Supplier_Y 0.20

            Let's generate a new report on purchasing cost from the three input files:

$> awk 'fname != FILENAME { fname = FILENAME; idx++ }
	FNR > 1 && idx == 1 { discount[$1] = $2 }
	FNR > 1 && idx == 2 { price[$1] = $2 * ( 1 - discount[$3] ) }
	FNR > 1 && idx == 3 { printf "%s $%.2f %s\n",$1, price[$1]*$2, $3 }
' discount.txt price.txt purchasing.txt

Orange $288.00 2020-04-02
Apple $1152.00 2020-04-03
Peach $299.60 2020-04-05
Pear $225.00 2020-04-17

            In the code above, we used FNR>1 to skip the header lines from input files. Also, we created
            associative arrays to share data between different file processings.

            However, the key to distinguishing between input files is this line of code:
fname != FILENAME{ fname = FILENAME; idx++ }

            Now, let's understand how it works:
              1. We declare a variable fname to store the current FILENAME, and create an idx variable
                 to store the index of the current input file.
              2. When the current input file changes, fname != FILENAME will be True.
              3. Then we update fname with the new FILENAME and increment the idx variable.
              4. Later, we distinguish the input files by the idx variable and process each input file
                 differently.

            This is one of the common techniques for handling multiple input files.

4.3. Input File Index vs. Filename
            We've seen that the built-in FILENAME variable stores the name of the current input file.
            While reading the code in the previous section, we may come up with a question: why do we
            distinguish between input files by the index of each input instead of comparing the filename
            directly, as in the example:
FNR > 1 && FILENAME == "discount.txt" {...}
FNR > 1 && FILENAME == "price.txt" {...}
FNR > 1 && FILENAME == "purchasing.txt" {...}

            Comparing the FILENAME variable with the filename works for this example, too. However, it
            has some disadvantages.

            Most notably, it brings hardcoded filenames into our awk script. That is, when we change the
            name of a file, we must update the code, too.

            For example, if we change the second file price.txt to "/full/path/to/price.txt", we'd have
            to change our script.

            Sometimes, we have to pass the filename with shell variables, such as "$PWD/price.txt". In
            this case, we don't know the exact value of the FILENAME variable.

            A workaround is using the regular expression match operator ~ instead of == as in:
FNR > 1 && FILENAME ~ /\/price[.]txt$/ {...}

            However, the workaround will fail when we feed the awk command by a process substitution
            as an input "file".

            With a process substitution, the name of the input file is going to be automatically
            generated by the pipe() system call. The filename will be dynamic.

            Let's see an example of this case:
$> echo "a dummy line" > dummy.txt
$> awk '{print FILENAME}' dummy.txt <(cat dummy.txt )
dummy.txt
/proc/self/fd/11

            Therefore, we prefer to distinguish between input files using the index of an input file
            over the filename.

5. Conclusion
            In this article, we've discussed how to handle multiple input files when we work with the
            awk command.


---
https://www.geeksforgeeks.org/linux-unix/awk-command-unixlinux-examples/

AWK command in Unix/Linux with examples
11 Apr, 2025

   Awk is a scripting language used for manipulating data and generating reports. The awk command
   programming language requires no compiling and allows the user to use variables, numeric functions,
   string functions, and logical operators.

   Awk is a utility that enables a programmer to write tiny but effective programs in the form of
   statements that define text patterns that are to be searched for in each line of a document and the
   action that is to be taken when a match is found within a line. Awk is mostly used for pattern
   scanning and processing. It searches one or more files to see if they contain lines that matches with
   the specified patterns and then perform the associated actions.

   Awk is abbreviated from the names of the developers - Aho, Weinberger, and Kernighan.

Syntax:

awk options 'selection _criteria {action }' input-file > output-file

   ------------------------------------------
   Option    Description
   ------------------------------------------
   -F        Sets a custom field separator
   -f        Reads awk program from a file
   '{}'      Encloses action to take on match
   ------------------------------------------

WHAT CAN WE DO WITH AWK?
   1. AWK Operations:
   (a) Scans a file line by line
   (b) Splits each input line into fields
   (c) Compares input line/fields to pattern
   (d) Performs action(s) on matched lines

   2. Useful For:
   (a) Transform data files
   (b) Produce formatted reports

   3. Programming Constructs:
   (a) Format output lines
   (b) Arithmetic and string operations
   (c) Conditionals and loops

   Sample Commands

   Example:
   Consider the following text file as the input file for all cases below:
$cat > employee.txt
ajay manager account 45000
sunil clerk account 25000
varun manager sales 50000
amit manager account 47000
tarun peon sales 15000
deepak clerk sales 23000
sunil peon sales 13000
satvik director purchase 80000

1. Print All Lines (Default Behavior)
   By default Awk prints every line of data from the specified file.
$> awk '{print}' employee.txt

   Output:
ajay manager account 45000
sunil clerk account 25000
varun manager sales 50000
amit manager account 47000
tarun peon sales 15000
deepak clerk sales 23000
sunil peon sales 13000
satvik director purchase 80000

   In the above example, no pattern is given. So the actions are applicable to all the lines. Action
   print without any argument prints the whole line by default, so it prints all the lines of the file
   without failure.

2. Search Lines with a Keyword
$> awk '/manager/ {print}' employee.txt

   Output:
ajay manager account 45000
varun manager sales 50000
amit manager account 47000

   In the above example, the awk command prints all the line which matches with the 'manager'.

3. Print Specific Columns
   For each record i.e line, the awk command splits the record delimited by whitespace character by
   default and stores it in the $n variables. If the line has 4 words, it will be stored in $1, $2, $3
   and $4 respectively. Also, $0 represents the whole line.
$> awk '{print $1,$4}' employee.txt

   Output:
ajay 45000
sunil 25000
varun 50000
amit 47000
tarun 15000
deepak 23000
sunil 13000
satvik 80000

   In the above example, $1 and $4 represents Name and Salary fields respectively.

Built-In Variables In Awk
   Awk's built-in variables include the field variables-$1, $2, $3, and so on ($0 is the entire line) -
   that break a line of text into individual words or pieces called fields.
     * NR: NR command keeps a current count of the number of input records. Remember that records are
       usually lines. Awk command performs the pattern/action statements once for each record in a
       file.
     * NF: NF command keeps a count of the number of fields within the current input record.
     * FS: FS command contains the field separator character which is used to divide fields on the input
       line. The default is "white space", meaning space and tab characters. FS can be reassigned to
       another character (typically in BEGIN) to change the field separator.
     * RS: RS command stores the current record separator character. Since, by default, an input line is
       the input record, the default record separator character is a newline.
     * OFS: OFS command stores the output field separator, which separates the fields when Awk prints
       them. The default is a blank space. Whenever print has several parameters separated with commas,
       it will print the value of OFS in between each parameter.
     * ORS: ORS command stores the output record separator, which separates the output lines when Awk
       prints them. The default is a newline character. print automatically outputs the contents of ORS
       at the end of whatever it is given to print.

   Examples:

Use of NR built-in variables (Display Line Number)
$> awk '{print NR,$0}' employee.txt

   Output:
1 ajay manager account 45000
2 sunil clerk account 25000
3 varun manager sales 50000
4 amit manager account 47000
5 tarun peon sales 15000
6 deepak clerk sales 23000
7 sunil peon sales 13000
8 satvik director purchase 80000

   In the above example, the awk command with NR prints all the lines along with the line number.

Use of NF built-in variables (Display Last Field)
$> awk '{print $1,$NF}' employee.txt

   Output:
ajay 45000
sunil 25000
varun 50000
amit 47000
tarun 15000
deepak 23000
sunil 13000
satvik 80000

   In the above example $1 represents Name and $NF represents Salary. We can get the Salary using $NF,
   where $NF represents last field.

Another use of NR built-in variables (Display Line From 3 to 6)
$> awk 'NR==3, NR==6 {print NR,$0}' employee.txt

   Output:
3 varun manager sales 50000
4 amit manager account 47000
5 tarun peon sales 15000
6 deepak clerk sales 23000

More Examples
   For the given text file:
$cat > geeksforgeeks.txt
A    B    C
Tarun    A12    1
Man    B6    2
Praveen    M42    3

1) To print the first item along with the row number(NR) separated with " - " from each line in
geeksforgeeks.txt:

$> awk '{print NR "- " $1 }' geeksforgeeks.txt
1 - A
2 - Tarun
3 - Manav
4 - Praveen

2) To return the second column/item from geeksforgeeks.txt:
   The question should be:- To return the second column/item from geeksforgeeks.txt:
$> awk '{print $2}' geeksforgeeks.txt
B
A12
B6
M42

3) To print any non empty line if present
$> awk 'NF < 0' geeksforgeeks.txt

   here NF should be 0 not less than and the user have to print the line number also:

   correct answer : awk 'NF == 0 {print NR}'  geeksforgeeks.txt

   OR

   awk 'NF <= 0 {print NR}'  geeksforgeeks.txt
0

4) To find the length of the longest line present in the file:
$> awk '{ if (length($0) > max) max = length($0) } END { print max }' geeksforgeeks.txt
13

5) To count the lines in a file:
$> awk 'END { print NR }' geeksforgeeks.txt
3

6) Printing lines with more than 10 characters:
$> awk 'length($0) > 10' geeksforgeeks.txt
Tarun    A12    1
Praveen    M42    3

7) To find/check for any string in any specific column:
$> awk '{ if($3 == "B6") print $0;}' geeksforgeeks.txt

8) To print the squares of first numbers from 1 to n say 6:
$> awk 'BEGIN { for(i=1;i<=6;i++) print "square of", i, "is",i*i; }'
square of 1 is 1
square of 2 is 4
square of 3 is 9
square of 4 is 16
square of 5 is 25
square of 6 is 36

Conclusion
   The Unix/Linux AWK command is a very straightforward yet extremely useful utility for any text file,
   log, or command-line data you're dealing with. A beginner or an old hand system admin, the AWK makes
   your life easier by assisting you in searching, filtering, and formatting data instantly and
   efficiently - all from the terminal.

   With AWK, you don't have to program lengthy scripts. A one-liner can yield employee salaries, remove
   logs, or even spit out quick reports. It is pattern-aware, breaks lines into fields, and allows you
   to do things such as print, count, compute, and format - all within a few lines.

   From loops, NR, FS, and $1 to printing a particular row, column, or even automating tiny things - AWK
   saves time, prevents manual errors, and increases productivity on Linux platforms.


---
https://www.gnu.org/software/gawk/manual/html_node/Auto_002dset.html

7.5.2 Built-in Variables That Convey Information (AWK)

   The following is an alphabetical list of variables that awk sets automatically on certain occasions
   in order to provide information to your program.

   The variables that are specific to gawk are marked with a pound sign ('#'). These variables are gawk
   extensions. In other awk implementations or if gawk is in compatibility mode (see Command-Line
   Options), they are not special:

   ARGC, ARGV
          The command-line arguments available to awk programs are stored in an array called ARGV. ARGC
          is the number of command-line arguments present. See Other Command-Line Arguments. Unlike
          most awk arrays, ARGV is indexed from 0 to ARGC − 1. In the following example:

$> awk 'BEGIN {
> 	for (i = 0; i < ARGC; i++)
> 		print ARGV[i]
> }' inventory-shipped mail-list
-| awk
-| inventory-shipped
-| mail-list

          ARGV[0] contains 'awk', ARGV[1] contains 'inventory-shipped', and ARGV[2] contains
          'mail-list'. The value of ARGC is three, one more than the index of the last element in ARGV,
          because the elements are numbered from zero.

          The names ARGC and ARGV, as well as the convention of indexing the array from 0 to ARGC − 1,
          are derived from the C language's method of accessing command-line arguments.

          The value of ARGV[0] can vary from system to system. Also, you should note that the program
          text is not included in ARGV, nor are any of awk's command-line options. See Using ARGC
          and ARGV for information about how awk uses these variables. (d.c.)

   ARGIND #
          The index in ARGV of the current file being processed. Every time gawk opens a new data file
          for processing, it sets ARGIND to the index in ARGV of the file name. When gawk is processing
          the input files, 'FILENAME == ARGV[ARGIND]' is always true.

          This variable is useful in file processing; it allows you to tell how far along you are in the
          list of data files as well as to distinguish between successive instances of the same file
          name on the command line.

          While you can change the value of ARGIND within your awk program, gawk automatically sets it
          to a new value when it opens the next file.

   ENVIRON
          An associative array containing the values of the environment. The array indices are the
          environment variable names; the elements are the values of the particular environment
          variables. For example, ENVIRON["HOME"] might be /home/arnold.

          For POSIX awk, changing this array does not affect the environment passed on to any programs
          that awk may spawn via redirection or the system() function.

          However, beginning with version 4.2, if not in POSIX compatibility mode, gawk does update its
          own environment when ENVIRON is changed, thus changing the environment seen by programs that
          it creates. You should therefore be especially careful if you modify ENVIRON["PATH"], which is
          the search path for finding executable programs.

          This can also affect the running gawk program, since some of the built-in functions may pay
          attention to certain environment variables. The most notable instance of this is mktime() (see
          Time Functions), which pays attention the value of the TZ environment variable on many
          systems.

          Some operating systems may not have environment variables. On such systems, the ENVIRON array
          is empty (except for ENVIRON["AWKPATH"] and ENVIRON["AWKLIBPATH"]; see The AWKPATH
          Environment Variable and see The AWKLIBPATH Environment Variable).

   ERRNO #
          If a system error occurs during a redirection for getline, during a read for getline, or
          during a close() operation, then ERRNO contains a string describing the error.

          In addition, gawk clears ERRNO before opening each command-line input file. This enables
          checking if the file is readable inside a BEGINFILE pattern (see The BEGINFILE and ENDFILE
          Special Patterns).

          Otherwise, ERRNO works similarly to the C variable errno. Except for the case just mentioned,
          gawk never clears it (sets it to zero or ""). Thus, you should only expect its value to be
          meaningful when an I/O operation returns a failure value, such as getline returning −1. You
          are, of course, free to clear it yourself before doing an I/O operation.

          If the value of ERRNO corresponds to a system error in the C errno variable, then
          PROCINFO["errno"] will be set to the value of errno. For non-system errors, PROCINFO["errno"]
          will be zero.

   FILENAME
          The name of the current input file. When no data files are listed on the command line, awk
          reads from the standard input and FILENAME is set to "-". FILENAME changes each time a new
          file is read (see Reading Input Files). Inside a BEGIN rule, the value of FILENAME is "",
          because there are no input files being processed yet. Note, though, that using
          getline (see Explicit Input with getline) inside a BEGIN rule can give FILENAME a value.

   FNR    The current record number in the current file. awk increments FNR each time it reads a new
          record (see How Input Is Split into Records). awk resets FNR to zero each time it starts a
          new input file.

   NF     The number of fields in the current input record. NF is set each time a new record is read,
          when a new field is created, or when $0 changes (see Examining Fields).

          Unlike most of the variables described in this subsection, assigning a value to NF has the
          potential to affect awk's internal workings. In particular, assignments to NF can be used to
          create fields in or remove fields from the current record. See Changing the Contents of a
          Field.

   FUNCTAB #
          An array whose indices and corresponding values are the names of all the built-in,
          user-defined, and extension functions in the program.

     NOTE: Attempting to use the delete statement with the FUNCTAB array causes a fatal error. Any
           attempt to assign to an element of FUNCTAB also causes a fatal error.

   NR     The number of input records awk has processed since the beginning of the program's execution
          (see How Input Is Split into Records). awk increments NR each time it reads a new record.

   PROCINFO #
          The elements of this array provide access to information about the running awk program. The
          following elements (listed alphabetically) are guaranteed to be available:

   PROCINFO["argv"]
          The PROCINFO["argv"] array contains all of the command-line arguments (after glob expansion and
          redirection processing on platforms where that must be done manually by the program) with subscripts
          ranging from 0 through argc − 1. For example, PROCINFO["argv"][0] will contain the name by which
          gawk was invoked. Here is an example of how this feature may be used:

gawk '
BEGIN {
	for (i = 0; i < length(PROCINFO["argv"]); i++)
		print i, PROCINFO["argv"][i]
}'

           Please note that this differs from the standard ARGV array which does not include
           command-line arguments that have already been processed by gawk (see Using ARGC and
           ARGV).

   PROCINFO["egid"]                The value of the getegid() system call.

   PROCINFO["errno"]
           The value of the C errno variable when ERRNO is set to the associated error message.

   PROCINFO["euid"]                The value of the geteuid() system call.

   PROCINFO["FS"]
           This is "FS" if field splitting with FS is in effect, "FIELDWIDTHS" if field splitting
           with FIELDWIDTHS is in effect, "FPAT" if field matching with FPAT is in effect, or "API"
           if field splitting is controlled by an API input parser.

   PROCINFO["gid"]                The value of the getgid() system call.

   PROCINFO["identifiers"]
           A subarray, indexed by the names of all identifiers used in the text of the awk program.
           An identifier is simply the name of a variable (be it scalar or array), built-in
           function, user-defined function, or extension function. For each identifier, the value
           of the element is one of the following:

         "array"
                 The identifier is an array.

         "builtin"
                 The identifier is a built-in function.

         "extension"
                 The identifier is an extension function loaded via @load or -l.

         "scalar"
                 The identifier is a scalar.

         "untyped"
                 The identifier is untyped (could be used as a scalar or an array; gawk doesn't
                 know yet).

         "user"
                 The identifier is a user-defined function.

           The values indicate what gawk knows about the identifiers after it has finished parsing
           the program; they are not updated while the program runs.

   PROCINFO["platform"]
           This element gives a string indicating the platform for which gawk was compiled. The
           value will be one of the following:

         "mingw"
                 Microsoft Windows, using MinGW.

         "os390"
                 OS/390 (also known as z/OS).

         "posix"
                 GNU/Linux, Cygwin, macOS, and legacy Unix systems.

         "vms"
                 OpenVMS.

   PROCINFO["pgrpid"]  The process group ID of the current process.

   PROCINFO["pid"]     The process ID of the current process.

   PROCINFO["pma"]     The version of the PMA memory allocator compiled into gawk. This element will not be
                       present if the PMA allocator is not available for use. See Preserving Data Between
                       Runs.

   PROCINFO["ppid"]   The parent process ID of the current process.

   PROCINFO["strftime"]
           The default time format string for strftime(). Assigning a new value to this element
           changes the default. See Time Functions.

   PROCINFO["uid"]
           The value of the getuid() system call.

   PROCINFO["version"]
           The version of gawk.

     The following additional elements in the array are available to provide information about the
     MPFR and GMP libraries if your version of gawk supports arbitrary-precision arithmetic (see
     Arithmetic and Arbitrary-Precision Arithmetic with gawk):

   PROCINFO["gmp_version"]    The version of the GNU MP library.

   PROCINFO["mpfr_version"]  The version of the GNU MPFR library.

   PROCINFO["prec_max"]      The maximum precision supported by MPFR.

   PROCINFO["prec_min"]      The minimum precision required by MPFR.

     The following additional elements in the array are available to provide information about the
     version of the extension API, if your version of gawk supports dynamic loading of extension
     functions (see Writing Extensions for gawk):

   PROCINFO["api_major"]  The major version of the extension API.

   PROCINFO["api_minor"]  The minor version of the extension API.

     On some systems, there may be elements in the array, "group1" through "groupN" for some N. N
     is the number of supplementary groups that the process has. Use the in operator to test for
     these elements (see Referring to an Array Element).

     The following elements allow you to change gawk's behavior:

   PROCINFO["BUFFERPIPE"]
           If this element exists, all output to pipelines becomes buffered. See Speeding Up
           Pipe Output.

   PROCINFO["command", "BUFFERPIPE"]
           Make output to command buffered. See Speeding Up Pipe Output.

   PROCINFO["NONFATAL"]
           If this element exists, then I/O errors for all redirections become nonfatal. See
           Enabling Nonfatal Output.

   PROCINFO["name", "NONFATAL"]
           Make I/O errors for name be nonfatal. See Enabling Nonfatal Output.

   PROCINFO["command", "pty"]
           For two-way communication to command, use a pseudo-tty instead of setting up a two-way
           pipe. See Two-Way Communications with Another Process for more information.

   PROCINFO["input_name", "READ_TIMEOUT"]
           Set a timeout for reading from input redirection input_name. See Reading Input with
           a Timeout for more information.

   PROCINFO["input_name", "RETRY"]
           If an I/O error that may be retried occurs when reading data from input_name, and this
           array entry exists, then getline returns −2 instead of following the default behavior of
           returning −1 and configuring input_name to return no further data. An I/O error that may
           be retried is one where errno has the value EAGAIN, EWOULDBLOCK, EINTR, or ETIMEDOUT.
           This may be useful in conjunction with PROCINFO["input_name", "READ_TIMEOUT"] or
           situations where a file descriptor has been configured to behave in a non-blocking
           fashion. See Retrying Reads After Certain Input Errors for more information.

   PROCINFO["sorted_in"]
           If this element exists in PROCINFO, its value controls the order in which array indices
           will be processed by 'for (indx in array)' loops. This is an advanced feature, so we
           defer the full description until later; see Using Predefined Array Scanning Orders
           with gawk.

   RLENGTH
          The length of the substring matched by the match() function (see String-Manipulation
          Functions). RLENGTH is set by invoking the match() function. Its value is the length of the
          matched string, or −1 if no match is found.

   RSTART
          The start index in characters of the substring that is matched by the match() function (see
          String-Manipulation Functions). RSTART is set by invoking the match() function. Its value
          is the position of the string where the matched substring starts, or zero if no match was
          found.

   RT #
          The input text that matched the text denoted by RS, the record separator. It is set every time
          a record is read.

   SYMTAB #
          An array whose indices are the names of all defined global variables and arrays in the
          program. SYMTAB makes gawk's symbol table visible to the awk programmer. It is built as gawk
          parses the program and is complete before the program starts to run.

          The array may be used for indirect access to read or write the value of a variable:

foo = 5
SYMTAB["foo"] = 4
print foo    # prints 4

          The isarray() function (see Getting Type Information) may be used to test if an element in
          SYMTAB is an array. Also, you may not use the delete statement with the SYMTAB array.

          Prior to version 5.0 of gawk, you could use an index for SYMTAB that was not a predefined
          identifier:

SYMTAB["xxx"] = 5
print SYMTAB["xxx"]

          This no longer works, instead producing a fatal error, as it led to rampant confusion.

          The SYMTAB array is more interesting than it looks. Andrew Schorr points out that it
          effectively gives awk data pointers. Consider his example:

# Indirect multiply of any variable by amount, return result

function multiply(variable, amount)
{
	return SYMTAB[variable] *= amount
}

          You would use it like this:

BEGIN {
	answer = 10.5
		multiply("answer", 4)
		print "The answer is", answer
}

          When run, this produces:

$> gawk -f answer.awk
-| The answer is 42

     NOTE: In order to avoid severe time-travel paradoxes, neither FUNCTAB nor SYMTAB is
     available as an element within the SYMTAB array.

Changing NR and FNR
   awk increments NR and FNR each time it reads a record, instead of setting them to the absolute value
   of the number of records read. This means that a program can change these variables and their new
   values are incremented for each record. (d.c.) The following example shows this:
$> echo '1
> 2
> 3
> 4' | awk 'NR == 2 { NR = 17 }
> { print NR }'
-| 1
-| 17
-| 18
-| 19

   Before FNR was added to the awk language (see Major Changes Between V7 and SVR3.1), many awk
   programs used this feature to track the number of records in a file by resetting NR to zero when
   FILENAME changed.


---

