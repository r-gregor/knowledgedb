filename: python_oop_refactoring_TDD_testing-multif_20171005.txt
http://blog.thedigitalcatonline.com/blog/2015/05/13/python-oop-tdd-example-part1/#.WdXtAFs-8-U

A simple example of Python OOP development (with TDD) - Part 1
13/05/2015 Series Part 1 of "Python OOP and TDD" 

   If you are eager to learn some Python and do not know how to start, this post may give you some
   hints. I will develop a very simple Python package from scratch, exemplifying some Object-oriented
   Programming (OOP) techniques and concepts, and using a Test-Driven Development (TDD) approach.

   The package will provide some classes to deal with binary numbers (see the Rationale section), but
   remember that it is just a toy project. Nothing in this package has been designed with performance in
   mind: it wants to be as clear as possible.

Rationale
   Binary numbers are rather easy to understand, even if becoming familiar with them requires some time.
   I expect you to have knowledge of the binary numeral system. If you need to review them just take a
   look at the [15]Wikipedia entry or one of the countless resources on Internet.

   The package we are going to write will provide a class that represents binary numbers (Binary) and a
   class that represents binary numbers with a given bit size (SizeBinary). They shall provide basic
   binary operations like logical (and, or, xor), arithmetic (addition, subtraction, multiplication,
   division), shifts and indexing.

   A quick example of what the package shall do:
>>> b = Binary('0101110001')
>>> hex(b)
'0x171'
>>> int(b)
369
>>> b[0]
'1'
>>> b[9]
'0'
>>> b.SHR()
'10111000'

Python and bases
   Binary system is just a representation of numbers with base 2, just like hexadecimal (base 16) and
   decimal (base 10). Python can already natively deal with different bases, even if internally numbers
   are always stored as decimal integers. Let us check it
>>> a = 5
>>> a
5
>>> a = 0x5
>>> a
5
>>> a = 0b101
>>> a
5
>>> hex(0b101)
'0x5'
>>> bin(5)
'0b101'

   As you can see Python understands some common bases out of the box, using the 0x prefix for
   hexadecimal numbers and the 0b for binary ones (and 0o) for octals). However the number is always
   printed in its base-10 form (5 in this case). This means however that a binary number cannot be
   indexed, since integers does not provide support for this operation
>>> 0b101[0]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'int' object is not subscriptable

   You can also use a different base when converting things to integers, through the base parameter
>>> a = int('101', base=2)
>>> a
5
>>> a = int('10', base=5)
>>> a
5

Test-driven development
   Simple tasks are the best way to try and use new development methodologies, so this is a good
   occasion to start working with the so-called test-driven approach. Test-driven Development (TDD)
   basically means that the first thing you do when developing is to write some tests, that is programs
   that use what you are going to develop. The purpose of those programs is to test that your final
   product complies with a given behaviour. So they provide
     * Documentation for your API: they are examples of use of your package.
     * Regression checks: when you change the code to develop new features they shall not break the
       behaviour of the previous package versions.
     * TODO list: until all tests run successfully you have something still waiting to be implemented.

   I suggest you to follow this post until we wrote some tests (section "Writing some tests" included),
   then write your own class, trying to make it pass all the tests. This way, actually developing
   something, you can really learn both TDD and Python. Then you can check your code against mine and
   perhaps provide a far better solution that the one found by me.

Development environment
   Let us set up a simple environment for the upcoming development. First of all create a Python virtual
   environment
~$ virtualenv -p python3 venv

   then activate the virtualenv and install py.test, which is what we will use to write tests.
~$ source venv/bin/activate
(venv)~$ pip install pytest

   Then create a directory for the package, the __init__.py file and a directory for tests
(venv)~$ mkdir binary
(venv)~$ cd binary
(venv)~/binary$ touch __init__.py
(venv)~/binary$ mkdir tests

   Finally, let us check that everything is correctly working. Py.test does not find any test so it
   should exit without errors.
(venv)~/binary$ py.test
===================== test session starts =====================
[...]
collected 0 items

=======================  in 0.00 seconds ======================

   where [...] will be filled with information about your execution environment.

Py.test

   The approach used by py.test is very straightforward: to test your library you just have to write
   some functions that use it. Those functions shall run without raising any exception; if a test (a
   function) runs without raising an exception it passes, otherwise it fails. Let us start writing a
   very simple test to learn the basic syntax. Create a tests/test_binary.py file and write the
   following code
def test_first():
    pass

   If you run py.test again you shall obtain this result
(venv)~/binary$ py.test
===================== test session starts =====================
[...]
collected 1 items

tests/test_binary.py .

=================== 1 passed in 0.01 seconds ==================

   if you prefer (as I do) you may use the -v verbose switch to get detailed information about what
   tests have been executed
(venv)~/binary$ py.test -v
===================== test session starts =====================
[...]
collected 1 items

tests/test_binary.py::test_first PASSED

=================== 1 passed in 0.01 seconds ==================

   By default py.test looks for Python files which name starts with test_, and this is why it processes
   our file tests/test_binary.py. For each file it runs all functions which name, again, starts with
   test_, and this is why test_first() has been executed.

   This latter does nothing, so it runs without raising any exception and the test passes. Let us try to
   raise an exception
def test_first():
    raise ValueError

   which gives the following py.test output
(venv)~/binary$ py.test -v
===================== test session starts =====================
[...]
collected 1 items

tests/test_binary.py::test_first FAILED

=========================== FAILURES ==========================
__________________________ test_first _________________________

    def test_first():
>       raise ValueError
E       ValueError

tests/test_binary.py:2: ValueError
=================== 1 failed in 0.01 seconds ==================

   To easily write tests that raise exceptions when failing we may use the assert Python statement,
   which shall be followed by an expression. If the expression returns a true value, assert does
   nothing, otherwise it raises an AssertionError exception. Let us do a quick check in the Python
   console
>>> assert True
>>> assert False
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AssertionError
>>>
>>> assert 1 == 1
>>> assert 1 == 2
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AssertionError

   So usually our tests will contain some code and one or more assertions. I prefer to have just one
   assertion for each test, except perhaps when testing the very same feature more than once (for
   example getting various elements from a list). This way you are immediately aware of what assertion
   raised the exception, that is you immediately know what feature does not work as expected.

Writing some tests
   So now we will pretend we have already developed our Binary class and write some tests that check its
   behaviour. You will find the whole file in the Resources section at the end of the post, I will show
   here just some snippets.

Initialization

from binary import Binary

def test_binary_init_int():
    binary = Binary(6)
    assert int(binary) == 6

   This is our first real test. First of all we import the class from the binary.py file (which doesn't
   exists yet). The test_binary_init_int() function shall (as the name suggests) initialize a Binary
   with an integer. The assertion checks that the newly created binary variable has a consistent integer
   representation, which is the number we used to initialize it.

   We want to be able to initialize a Binary with a wide range of values: bit strings ('110'), binary
   strings ('0b110'), hexadecimal strings ('0x6'), hexadecimal values (0x6), lists of integers ([1,1,0])
   and list of strings (['1','1','0']). The following tests check all those cases
def test_binary_init_bitstr():
    binary = Binary('110')
    assert int(binary) == 6

def test_binary_init_binstr():
    binary = Binary('0b110')
    assert int(binary) == 6

def test_binary_init_hexstr():
    binary = Binary('0x6')
    assert int(binary) == 6

def test_binary_init_hex():
    binary = Binary(0x6)
    assert int(binary) == 6

def test_binary_init_intseq():
    binary = Binary([1,1,0])
    assert int(binary) == 6

def test_binary_init_strseq():
    binary = Binary(['1','1','0'])
    assert int(binary) == 6

   Finally, let us check that our Binary class cannot be initialized with a negative number. I decided
   to represent negative numbers through the two's complement technique, which however requires a
   predefined bit length. So for simple binaries I just discard negative numbers.
import pytest

[...]

def test_binary_init_negative():
    with pytest.raises(ValueError):
        binary = Binary(-4)

   As you can see, now we have to check that our class raises an exception, but if we make the class
   raise it the test will fail. To let the test pass we shall check that the exception is raised but
   suppress it, and this can be done with pytest.raises, which is a suitable [16]context manager.

Conversions
   I want to check that my binary numbers can be correctly converted to integers (through int()), binary
   strings (through bin()), hexadecimals (through hex()) and to strings (through str()). I want the
   string representation to be a plain sequence of zeros and ones, that is the binary string
   representation without the 0b prefix.

   Some examples (check the full code for the whole set of tests)
def test_binary_int():
    binary = Binary(6)
    assert int(binary) == 6

def test_binary_str():
    binary = Binary(6)
    assert str(binary) == '110'

Project structure
   I warmly suggest to check [17]this page for a project layout that allows py.test to work flawlessly.
   To avoid putting too many things in this post I am going to run py.test with a custom PYTHONPATH to
   make it correctly import the code. However, please remember that this setup is just a trick for
   simplicity's sake. Check [18]this detailed post by Jeff Knupp to learn a lot about Python packaging
   and project layouts.

Writing the class

   Trying to run the tests at this point just returns a big failure due to an import error, since the
   binary.py module does not exists yet.
(venv)~/binary$ PYTHONPATH=. py.test -v
===================== test session starts =====================
[...]
collected 0 items / 1 errors
============================ ERRORS ===========================
____________ ERROR collecting tests/test_binary.py ____________
tests/test_binary.py:2: in <module>
    from binary import Binary
E   ImportError: No module named 'binary'

=================== 1 error in 0.01 seconds ===================

   Let us create the file binary.py in the project root (i.e. inside the binary/ directory you created,
   together with __init__.py and tests/) and start creating the Binary class.
class Binary:
    pass

   Now running py.test shows that all tests can be run and that all them fail (I will just show the
   first one)
(venv)~/binary$ PYTHONPATH=. py.test -v
===================== test session starts =====================
[...]
collected 13 items

tests/test_binary.py::test_binary_init_int FAILED
[...]

============================ FAILURES ==========================
_____________________ test_binary_init_int _____________________

    def test_binary_init_int():
>       binary = Binary(6)
E       TypeError: object() takes no parameters

tests/test_binary.py:5: TypeError
[...]
=================== 13 failed in 0.03 seconds ==================

   So now you can start writing code and use your test battery to check if it works as expected.
   Obviously "as expected" means that all the tests you wrote pass, but this does not imply you covered
   all cases. TDD is an iterative methodology: when you find a bug or a missing feature you first write
   a good test or a set of tests that address the matter and then produce some code that make the tests
   pass.

   At this point you are warmly encouraged to write the code by yourself and to check your product with
   the given battery of tests. Just download the first version of the tests file
   ([19]test_binary_ver1.py) and put it in the tests/ directory. Then read it carefully to understand
   what the requirements are and start writing the class. When you think you are done with a part of it
   just run the tests and see if everything works well, then move on.

My solution
   The most complex part of the class is the initialization, since I want it to accept a wide range of
   data types. Basically we have to deal with sequences (strings and lists) or with plain values. The
   latter ones shall be convertible to an integer, otherwise trying to initialize a binary number with
   them makes no sense. Since binary numbers are just a representation of integers I decided to store
   the value in the class as an integer inside the self._value attribute. Pay attention that this
   decision means that all leading zeros will be stripped from the number, i.e., Binary('000101') is
   equal to Binary('101'). This will be important for indexing and slicing.

   This is the code
import collections

class Binary:
    def __init__(self, value=0):
        if isinstance(value, collections.Sequence):
            if len(value) > 2 and value[0:2] == '0b':
                self._value = int(value, base=2)
            elif len(value) > 2 and value[0:2] == '0x':
                self._value = int(value, base=16)
            else:
                self._value = int(''.join([str(i) for i in value]), base=2)
        else:
            try:
                self._value = int(value)
                if self._value < 0:
                    raise ValueError("Binary cannot accept negative numbers. Use SizedBinary instead")
            except ValueError:
                raise ValueError("Cannot convert value {} to Binary".format(value))

    def __int__(self):
        return self._value

   Running the tests I get 4 failed, 9 passed in 0.02 seconds, which is a good score. The tests that
   still fail are test_binary_eq, test_binary_bin, test_binary_str and test_binary_hex. Since I still
   wrote no code for the conversions those failures were expected.

   Let us review the code I wrote. I make use of the collections module to tell apart sequences from
   plain values in a pythonic way. If you do not know what Abstract Base Classes are, please check
   [20]this post and the [21]collections.abc module documentation.

   WARNING: if you are using Python 3.2 or less you will find those classes in the collections module
   instead of collections.abc, which has been introduced with Python 3.3

   Basically through isinstance(value, collections.abc.Sequence) we check that the incoming value
   behaves like a sequence, which is different from saying that it is a list, a string, or other
   sequences. The first case covers an incoming string in the form 0bXXXXX, which is converted to an
   integer through the int() function. The second case is the same but for hexadecimal strings in the
   form 0xXXXXX.

   The third case covers a generic sequence of values that shall be individually convertible to 0 or 1.
   The code converts each element of the sequence to a string, joins them in a single string and
   converts it with base 2. This covers the case of a string of zeros and ones and the case of an
   iterable of integers, like a list for example.

   If the incoming value is not a sequence it shall be convertible to an integer, which is exactly what
   the try part does. Here we also check if the value is negative and raise a suitable exception.

   Finally, the __int__() method (one of the Python magic methods) is automatically called when we apply
   int() to our binary, just like we do in a lot of the tests. This method is basically the one
   responsible of providing a conversion to integer of a given class. In this case we just have to
   return the value we stored internally.

   Obviously I didn't write this code in a single burst. I had to run the tests more than once to tune
   my code.

   I already wrote the method that performs the conversion to an integer. Some tests however (namely
   test_binary_bin and test_binary_hex) still fail with the error message TypeError: 'Binary' object
   cannot be interpreted as an integer.

   According to [22]the official documentation, "If x is not a Python int object, it has to define an
   __index__() method that returns an integer." so this is what we are missing. As for __index__(), the
   [23]documentation states that "In order to have a coherent integer type class, when __index__() is
   defined __int__() should also be defined, and both should return the same value."

   So we just have to add
def __index__(self):
    return self.__int__()

   inside the class, and we get two more successful tests.

   To make test_binary_str pass we have to provide a magic method that converts the object into a
   string, which is
def __str__(self):
    return bin(self)[2:]

   It makes use of the internal Python algorithm provided by bin() stripping the 0b prefix.

   The last failing test is test_binary_eq which tests for equality between two Binary objects
def test_binary_eq():
    assert Binary(4) == Binary(4)

   Out of the box, Python compares objects on a very low level, just checking if the two references
   point to the same object in memory. To make it smarter we have to provide the __eq__() method
def __eq__(self, other):
    return int(self) == int(other)

   And now all the tests run successfully.

Binary operations
   Now it is time to add new features to our Binary class. As already said, the TDD methodology wants us
   to first write the tests, then to write the code. Our class is missing some basic arithmetic and
   binary operations so the tests are (again you will find all tests in the attached file)
def test_binary_addition_int():
    assert Binary(4) + 1 == Binary(5)

def test_binary_addition_binary():
    assert Binary(4) + Binary(5) == Binary(9)

def test_binary_division_int():
    assert Binary(20) / 4 == Binary(5)

def test_binary_division_rem_int():
    assert Binary(21) / 4 == Binary(5)

def test_binary_get_bit():
    binary = Binary('0101110001')
    assert binary[0] == '1'
    assert binary[5] == '1'

def test_binary_not():
    assert ~Binary('1101') == Binary('10')

def test_binary_and():
    assert Binary('1101') & Binary('1') == Binary('1')

def test_binary_shl_pos():
    assert Binary('1101') << 5 == Binary('110100000')

   The first two tests check that adding both an integer and a Binary to a Binary works as expected. The
   division checks two different cases: because integer division produces a remainder, which is not
   considered here. The test_binary_get_bit function tests indexing and is one of the few tests that
   contain more than one assertion. Please note that binary indexing, unlike standard sequence indexing
   in Python, starts from the rightmost element.

   Bitwise and arithmetic operations are implemented using Python magic methods. Please check [24]the
   official documentation for a complete list of operators and related methods.

   Now download the file [25]test_binary_ver2.py and use it to develop the new features.

   The code that implements the required behaviour is
    def __and__(self, other):
        return Binary(self._value & Binary(other)._value)

    def __or__(self, other):
        return Binary(self._value | Binary(other)._value)

    def __xor__(self, other):
        return Binary(self._value ^ Binary(other)._value)

    def __lshift__(self, pos):
        return Binary(self._value << pos)

    def __rshift__(self, pos):
        return Binary(self._value >> pos)

    def __add__(self, other):
        return Binary(self._value + Binary(other)._value)

    def __sub__(self, other):
        return Binary(self._value - Binary(other)._value)

    def __mul__(self, other):
        return Binary(self._value * Binary(other)._value)

    def __truediv__(self, other):
        return Binary(int(self._value / Binary(other)._value))

    def __getitem__(self, item):
        return str(self)[-(item + 1)]

    def __invert__(self):
        return Binary([abs(int(i) - 1) for i in str(self)])

   All methods are straightforward, except perhaps __getitem__() and __invert__(). The __invert__()
   method is called when performing a bitwise NOT operation (~) and is implemented avoiding negative
   numbers. A simple solution is to convert the Binary into a string and then reverse every digit
   (abs(int(i) - 1) returns 0 for '1' and 1 for '0').

   The __getitem__() method is required to provide indexing, and as said shall index starting from the
   rightmost element and moving left. This is the reason of the -(item + 1) index. Please notice that
   this method will be changed later to provide full support to slicing.

Slicing
   I want Binary to support slicing, just like lists. The difference between lists and my Binary type is
   that for the latter indexes start from the rightmost element. So when I get bits 3:7 of an 8-bit
   Binary I obtain the four leftmost ones. The desired behaviour is thus exemplified by
>>> b = Binary('01101010')
>>> b[4:7]
<binary.Binary object at 0x...> (110)
>>> b[1:3]
<binary.Binary object at 0x...> (101)

   that can immediately be converted into tests
def test_binary_slice():
    assert Binary('01101010')[0:3] == Binary('10')
    assert Binary('01101010')[1:4] == Binary('101')
    assert Binary('01101010')[4:] == Binary('110')

   You will find the new tests in the [26]test_binary_ver3.py file.

   Running the tests shows that the __getitem__() function does not provide support for slice objects,
   raising the exception TypeError: unsupported operand type(s) for +: 'slice' and 'int'. Checking
   [27]the documentation of __getitem__() we notice that it shall manage both integers and slice objects
   (this is the missing part) and that it shall raise IndexError for illegal indexes to make for loops
   work. So I immediately add a test for this rule
def test_binary_illegal_index():
    with pytest.raises(IndexError):
        Binary('01101010')[7]

   and other tests to match the correct behaviour (you will find them in the full code). Remember that
   leading zeros are stripped, so getting the index number 7 shall fail, since the binary number has
   just 7 digits, even if the incoming string has 8 characters.

   Instead of trying to reimplement the whole list slicing behaviour with reversed indexes, it is much
   simpler to make use of it. We can just take the string version of our Binary, slice its reversed
   version and return the result (reversed again). The result of the slice can be a single element,
   however, so we have to check it against the Sequence class
def __getitem__(self, key):
        reversed_list = [int(i) for i in reversed(str(self))]
        sliced = reversed_list.__getitem__(key)
        if isinstance(sliced, collections.abc.Sequence):
            if len(sliced) > 0:
                return Binary([i for i in reversed(sliced)])
            else:
                return Binary(0)
        else:
            return Binary(sliced)

   The first list comprehension returns a list of integers with the reversed version of the binary
   number (i.e. from Binary('01101') to [1, 0, 1, 1], remember that leading zeros are stripped). Then we
   delegate the slice to the list type, calling __getitem__(). The result of this call may be a sequence
   or a single element (integer), so we tell apart the two cases. In the first case we reverse the
   result again, in the second case we just return it. In both cases we create a Binary object. The
   check on the length of the list must be introduced because the slice may return no elements, but the
   Binary class does not accept an empty list.

Splitting binaries
   The last feature I want to add is a split() function that divides the binary number in two binaries.
   The rightmost one shall have the given size in bits, while the leftmost just contains the remaining
   bits. The following tests exemplify the behaviour of split()
def test_binary_split_no_remainder():
    assert Binary('110').split(4) == (0, Binary('110'))

def test_binary_split_remainder():
    assert Binary('110').split(2) == (1, Binary('10'))

def test_binary_split_exact():
    assert Binary('100010110').split(9) == (0, Binary('100010110'))

def test_binary_split_leading_zeros():
    assert Binary('100010110').split(8) == (1, Binary('10110'))

   These new tests are in the file [28]test_binary_ver4.py.

   The code that implements it is
def split(self, bits):
    return (self[bits:], self[:bits])

   The code developed in this post can be found here:
     * The full code of the Binary class is [35]here.
     * The last version of the tests file is [36]here.
        35. http://blog.thedigitalcatonline.com/code/python-oop-tdd-part1/binary.py
        36. http://blog.thedigitalcatonline.com/code/python-oop-tdd-part1/test_binary_ver4.py
        
**************************************************************************************************************
http://blog.thedigitalcatonline.com/code/python-oop-tdd-part1/binary.py
<code>
import collections.abc


class Binary:

    def __init__(self, value=0):
        if isinstance(value, collections.abc.Sequence):
            if len(value) > 2 and value[0:2] == '0b':
                self._value = int(value, base=2)
            elif len(value) > 2 and value[0:2] == '0x':
                self._value = int(value, base=16)
            else:
                self._value = int(''.join([str(i) for i in value]), base=2)
        else:
            try:
                self._value = int(value)
                if self._value < 0:
                    raise ValueError(
                        "Binary cannot accept negative numbers. Use SizedBinary instead")
            except ValueError:
                raise ValueError(
                    "Cannot convert value {} to Binary".format(value))

    def __repr__(self):
        return "{0} ({1})".format(super().__repr__(), str(self))

    def __int__(self):
        return self._value

    def __index__(self):
        return self.__int__()

    def __str__(self):
        return bin(self)[2:]

    def __eq__(self, other):
        return int(self) == int(other)

    def __and__(self, other):
        return Binary(self._value & Binary(other)._value)

    def __or__(self, other):
        return Binary(self._value | Binary(other)._value)

    def __xor__(self, other):
        return Binary(self._value ^ Binary(other)._value)

    def __lshift__(self, pos):
        return Binary(self._value << pos)

    def __rshift__(self, pos):
        return Binary(self._value >> pos)

    def __add__(self, other):
        return Binary(self._value + Binary(other)._value)

    def __sub__(self, other):
        return Binary(self._value - Binary(other)._value)

    def __mul__(self, other):
        return Binary(self._value * Binary(other)._value)

    def __truediv__(self, other):
        return Binary(int(self._value / Binary(other)._value))

    def __getitem__(self, key):
        reversed_list = [int(i) for i in reversed(str(self))]
        sliced = reversed_list.__getitem__(key)
        if isinstance(sliced, collections.abc.Sequence):
            if len(sliced) > 0:
                return Binary([i for i in reversed(sliced)])
            else:
                return Binary(0)
        else:
            return Binary(sliced)

    def __invert__(self):
        return Binary([abs(int(i) - 1) for i in str(self)])

    def split(self, bits):
        return (self[bits:], self[:bits])
</code>
**************************************************************************************************************
http://blog.thedigitalcatonline.com/code/python-oop-tdd-part1/test_binary_ver4.py
<code>
import pytest
from binary import Binary


def test_binary_init_int():
    binary = Binary(6)
    assert int(binary) == 6


def test_binary_init_negative():
    with pytest.raises(ValueError):
        binary = Binary(-4)


def test_binary_init_bitstr():
    binary = Binary('110')
    assert int(binary) == 6


def test_binary_init_binstr():
    binary = Binary('0b110')
    assert int(binary) == 6


def test_binary_init_hexstr():
    binary = Binary('0x6')
    assert int(binary) == 6


def test_binary_init_hex():
    binary = Binary(0x6)
    assert int(binary) == 6


def test_binary_init_intseq():
    binary = Binary([1, 1, 0])
    assert int(binary) == 6


def test_binary_init_strseq():
    binary = Binary(['1', '1', '0'])
    assert int(binary) == 6


# Conversions

def test_binary_eq():
    assert Binary(4) == Binary(4)


def test_binary_int():
    binary = Binary(6)
    assert int(binary) == 6


def test_binary_bin():
    binary = Binary(6)
    assert bin(binary) == '0b110'


def test_binary_str():
    binary = Binary(6)
    assert str(binary) == '110'


def test_binary_hex():
    binary = Binary(6)
    assert hex(binary) == '0x6'


# Basic operations

def test_binary_addition_int():
    assert Binary(4) + 1 == Binary(5)


def test_binary_addition_binary():
    assert Binary(4) + Binary(5) == Binary(9)


def test_binary_subtraction_int():
    assert Binary(4) - 1 == Binary(3)


def test_binary_subtraction_binary():
    assert Binary(5) - Binary(4) == Binary(1)


def test_binary_multiplication_int():
    assert Binary(5) * 4 == Binary(20)


def test_binary_multiplication_binary():
    assert Binary(5) * Binary(6) == Binary(30)


def test_binary_division_int():
    assert Binary(20) / 4 == Binary(5)


def test_binary_division_rem_int():
    assert Binary(21) / 4 == Binary(5)


def test_binary_division_binary():
    assert Binary(20) / Binary(5) == Binary(4)


def test_binary_division_rem_binary():
    assert Binary(21) / Binary(5) == Binary(4)


def test_binary_get_bit():
    binary = Binary('0101110001')
    assert binary[0] == '1'
    assert binary[5] == '1'


def test_binary_negative_index():
    assert Binary('0101110001')[-1] == '1'
    assert Binary('0101110001')[-2] == '0'


def test_binary_illegal_index():
    with pytest.raises(IndexError):
        Binary('01101010')[7]


def test_binary_inappropriate_type_index():
    with pytest.raises(TypeError):
        Binary('01101010')['key']


def test_binary_for_loop():
    assert [int(i) for i in Binary('01101010')] == [0, 1, 0, 1, 0, 1, 1]


def test_binary_not():
    assert ~Binary('1101') == Binary('10')


def test_binary_and():
    assert Binary('1101') & Binary('1') == Binary('1')


def test_binary_or():
    assert Binary('1101') | Binary('1') == Binary('1101')


def test_binary_or():
    assert Binary('1101') ^ Binary('1') == Binary('1100')


def test_binary_shl():
    assert Binary('1101') << 1 == Binary('11010')


def test_binary_shl_pos():
    assert Binary('1101') << 5 == Binary('110100000')


def test_binary_shr():
    assert Binary('1101') >> 1 == Binary('110')


def test_binary_shr_pos():
    assert Binary('1101') >> 5 == Binary('0')


# Slicing

def test_binary_slice():
    assert Binary('01101010')[0:3] == Binary('10')
    assert Binary('01101010')[1:4] == Binary('101')
    assert Binary('01101010')[4:] == Binary('110')


# Split

def test_binary_split_no_remainder():
    assert Binary('110').split(4) == (0, Binary('110'))


def test_binary_split_remainder():
    assert Binary('110').split(2) == (1, Binary('10'))


def test_binary_split_exact():
    assert Binary('100010110').split(9) == (0, Binary('100010110'))


def test_binary_split_leading_zeros():
    assert Binary('100010110').split(8) == (1, Binary('10110'))

</code>
**************************************************************************************************************

Final words
   If you tried and write your own class before checking my solution I'm sure you experienced both some
   frustration when tests failed and a great joy when they finally passed. I'm also sure that you could
   appreciate the simplicity of TDD and perhaps understand why so many programmes adopt it.

   In the next post I will guide you through the addition of the SizeBinary class, again following the
   TDD methodology.


---
http://blog.thedigitalcatonline.com/blog/2015/09/10/python-oop-tdd-example-part2/#.WdXtkVs-8-U

A simple example of Python OOP development (with TDD) - Part 2
10/09/2015 Series Part 2 of "Python OOP and TDD" 

   In the first part of this small series I introduced you to TDD with Python by means of the
   powerful py.test package. We developed together a simple library which provides a Binary class that
   is a bit more useful than the default binary representation that Python provides with the bin()
   builtin function.

   In this part I'll go on with the development of the library, discussing the implementation of a
   binary number with a fixed size, which is a very interesting and useful matter, being the foundation
   of the computer we are working with. Fixed-size binaries may also represent negative numbers with the
   two's complement technique, and this will be an important point to test.

   You may happen to dislike some decisions about the interface or the behaviour of the resulting class.
   Since this post is just a way to show you a concrete TDD session you are totally free to change the
   tests and to come up with a better solution than mine. Feel free to get in touch and submit better
   ideas, I'm always looking for something new to learn.

   As already suggested in the first instalment try to follow the post up to the section where I write
   the tests. Then move on implementing your own class and try to make it pass all the tests: this is
   the best way for you to learn TDD, actually applying it.

Fixed-size binaries
   As soon as you build an electronic circuit to store information (a flip-flop, for example) you start
   dealing with binary numbers and with fixed-size quantities. Limiting the number of digits brings
   immediately the limitation of having a maximum number that can be represented and requires to decide
   what to do with bigger numbers. Another issue that arises is that of the representation of negative
   numbers. Since we can only use two symbols (one and zero) we have to decide a "syntax" for negative
   values.

   You will find a lot of information about some of those issues in the following Wikipedia articles:
   [16]Integer overflow and [17]signed number representations. Check also this page on [18]bitwise
   operations as some of them will be implemented.

Object interface
   So we aim to create a class called SizeBinary that provides the following interface:
     * Can be instantiated giving a size in bits and a value. The value is optional, if not specified is
       0.
     * The value can be set after instantiation with a set() method.
     * If instantiated or set with a value greater than the maximum representable one the overflow
       attribute of the object becomes True.
     * May initialized with all the data types supported by the Binary class developed in the first
       post.
     * Just like the Binary class may be converted into an integer (e.g. 42, a binary string (e.g.
       0b101010, an hexadecimal string (0x2a) and a bit string (101010). May also be converted to a
       Binary without size limitations.
     * Support binary logic operations such as: NOT, AND, OR, XOR, shift left and right (without carry).
     * Can be splitted in two arbitrary sized SizeBinary objects.
     * Can be negated with both one's complement and two's complement techniques.

   So now, obeying the TDD methodology, I will write some tests that exploit these features. After this
   I'm going to develop an object that makes all test pass. Like we did in the previous post you may
   follow along as I write te tests and then write your own class.

Initialization
   The SizeBinary object shall support all the initialization options supported by Binary, but its main
   interface is different because when creating a SizeBinary we must be allowed to specify the size. The
   first tests are though pretty straightforward.
def test_size_binary_init_int():
    size_binary = SizeBinary(8, 6)
    assert int(size_binary) == 6

def test_size_binary_init_int_overflow():
    size_binary = SizeBinary(8, 512)
    assert int(size_binary) == 0
    assert size_binary.overflow == True

def test_size_binary_set():
    size_binary = SizeBinary(8, 0)
    size_binary.set(22)
    assert str(size_binary) == '00010110'
    assert size_binary.overflow == False

def test_size_binary_set_overflow():
    size_binary = SizeBinary(8, 0)
    size_binary.set(512)
    assert str(size_binary) == '00000000'
    assert size_binary.overflow == True

   I will cover all the cases already covered for the Binary class. As you can see, I'm specifying the
   bit size when instantiating the object and testing the overflow condition. Other initialization and
   conversion tests are very similar to their Binary counterpart and I will not copy them here, as you
   can find them in the source code.

Splitting
   One of the requirements is to provide a method to split a SizeBinary object into two arbitrarily
   sized Binary objects. The tests are
def test_size_binary_split():
    size_binary8 = SizeBinary(8, '01010110')
    size_binary4u, size_binary4l = size_binary8.split(4, 4)
    assert (size_binary4u, size_binary4l) == (SizeBinary(4, '0101'), SizeBinary(4, '0110'))

def test_size_binary_split_asymmetric():
    size_binary8 = SizeBinary(8, '01010110')
    size_binary9u, size_binary3l = size_binary8.split(9, 3)
    assert (size_binary9u, size_binary3l) == (SizeBinary(9, '000001010'), SizeBinary(3, '110'))

   As you can see the split shall be able to pad the resulting values if the number of bits exceedes
   that of the available ones.

Negative numbers
   There are many techniques to represent negative numbers with binary digits, and there is no way to
   tell from a binary number neither if it is positive or negative nor which technique has been used. It
   is a matter of conventions into the system in use. We want to implement [19]one's complement and
   [20]two's complement, which are described in detail in the linked Wikipedia articles. The tests to
   check the correct behaviour are
def test_size_binary_OC():
    # 6 = 0b00000110 -> 0b11111001
    size_binary = SizeBinary(8, 6)
    assert size_binary.oc() == SizeBinary(8, '11111001')

    # 7 = 0b00000111 -> 0b11111000
    size_binary = SizeBinary(8, 7)
    assert size_binary.oc() == SizeBinary(8, '11111000')

    # 15 = 0b00001111 -> 0b11110000
    size_binary = SizeBinary(8, 15)
    assert size_binary.oc() == SizeBinary(8, '11110000')

    # 15 = 0b0000000000001111 -> 0b1111111111110000
    size_binary = SizeBinary(16, 15)
    assert size_binary.oc() == SizeBinary(16, '1111111111110000')

def test_size_binary_TC():
    # 6 = 0b00000110 -> 0b11111010
    size_binary = SizeBinary(8, 6)
    assert size_binary.tc() == SizeBinary(8, '11111010')

    # 7 = 0b00000111 -> 0b11111001
    size_binary = SizeBinary(8, 7)
    assert size_binary.tc() == SizeBinary(8, '11111001')

    # 15 = 0b00001111 -> 0b11110001
    size_binary = SizeBinary(8, 15)
    assert size_binary.tc() == SizeBinary(8, '11110001')

    # 15 = 0b0000000000001111 -> 0b1111111111110001
    size_binary = SizeBinary(16, 15)
    assert size_binary.tc() == SizeBinary(16, '1111111111110001')

Mathematics, indexing and slicing
   The basic mathematical and logical operations are the same implemented for the Binary class. Some
   tests have been added to check what happens when performing operations between two SizeBinary with a
   different size. We expect the result to have the size of the bigger of the two operands.
def test_binary_addition_int():
    assert SizeBinary(8, 4) + 1 == SizeBinary(8, 5)

def test_binary_addition_binary():
    assert SizeBinary(8, 4) + SizeBinary(8, 5) == SizeBinary(8, 9)

def test_binary_addition_binary_different_size():
    assert SizeBinary(8, 4) + SizeBinary(16, 5) == SizeBinary(16, 9)

   Being very straightforward, I do not copy here all the tests written to cover this part, you will
   find them in the source code.

   Even the shift left operation now drops bits if there is not enough space for them, while the Binary
   class did it only for the shift right operation. For simplicity's sake I didn't implement a carry
   flag, i.e. there is no way to retrieve the bits shifted outside the available space. You are free to
   try and implement it, it's a good exercise but remember to write tests first!

   The indexing and slicing operations are basically the same as in the Binary case. The slicing
   operation produces a new SizeBinary with the correct size.

Implementation time!
   Now be a good OOP programmer and go, write a class that passes all the tests you find in the
   [21]source code. Just an advice, before you start headlong: being a SizeBinary mostly a Binary object
   with some new features it is recommended to use inheritance as the key delegation technique.

My solution
   Following my own advice my SizeBinary class inherits from Binary
from binary import Binary

class SizeBinary(Binary):
    pass

   and with this simple declaration I get 1 test passed and still 50 to go. We obviously may also create
   a new object that does not inherit from Binary but we would have to explicitly delegate a lot of
   functions to this latter class. So, in this case, better to stick to an automatic delegation
   mechanism like inheritance. To get a review of those two concepts read [22]this post.

   Composition could be another viable solution, with a Binary value stored internally and accessed
   whenever we call super() in the inheritance version. In this case, however, inheritance and
   composition lead to very similar results, with the latter being somehow counter-intuitive and thus
   not the best choice.

   We need to reimplement many of the special methods already implemented in the Binary class. This
   because Python resolves magic methods through a dedicated channel that avoids the __getattr__() and
   __getattribute__() methods, making the whole thing faster. This makes impossible to automatically
   delegate magic methods, except by means of metaclasses, which are however too complex to be a useful
   addition to this post.

   The initialization function shall store the bit length and initialize a flag to signal the overflow
   condition. Since I also want to have a set() function that changes the value I implement it and call
   it in the __init__() method.
    def __init__(self, bits, value):
        self.bits = bits
        self.overflow = False

        super().__init__(0)

        self.set(value)

    def set(self, value):
        binary = Binary(value)
        upper, lower = binary.split(self.bits)

        if upper != 0:
            self.overflow = True

        self._value = Binary(lower)._value

   I'm not that happy to poke into the Binary class implementation setting the _value attribute, but
   this is the only way to change the value of the underlying Binary class. If the Binary class had a
   set() method we could call it through super(), and I cannot directly set it through __init__()
   because I need to check the overflow condition.

   With this code I get a surprising result of 37 passed tests, while 14 still refuse to let me call it
   a day. This is however misleading, as many tests assume the SizeBinary object correctly performs
   comparison, which is not the case, as shown by the failure of the test_binary_equality_checks_bits
   test.

   This was done on purpose, to show you that writing tests is not something that automatically
   guarantees you to have correct code. As a matter of fact, in this case tests like
def test_binary_addition_int():
    assert SizeBinary(8, 4) + 1 == SizeBinary(8, 5)

   do not fail, even if the result of the addition is a Binary and not a SizeBinary.

   Let us check why this happens. The SizeBinary object is also a Binary object, and its __add__()
   method returns a Binary. The subsequent comparison is made using the __eq__() method of the Binary
   class, since the SizeBinary one does not provide its own version of the comparison. Since Binary
   classes just compare their value the test ends successfully.

   Let us add some code to implement the correct comparision
    def __eq__(self, other):
        return super().__eq__(other) and self.bits == other.bits

   which adds a check on the number of bits to the check already made by the Binary class. This results
   in 35 failed tests and 16 passed, showing that the previous result was biased by "inaccurate" tests.
   As a matter of fact, the presence of a test that shows if the comparison is correct or not makes
   perfectly reasonable to have tests that take it for granted.

   One simple thing to add is the right padding with zeros that shall be provided for input values that
   are shorter than the given number of bits
    def __str__(self):
        s = super().__str__()
        return s.rjust(self.bits, '0')

   And this simple addition lowers the count of failed tests from 35 to 30. Another small addition that
   satisfies 2 more tests is the splitting function, which shall return SizeBinary objects instead of
   Binary ones
    def split(self, upper_bits, lower_bits):
        upper, lower = super().split(lower_bits)
        return SizeBinary(upper_bits, upper), SizeBinary(lower_bits, lower)

   As already explained we want to get the negative version of the number both with the one's complement
   and the two's complement techniques. For starters, let's deal with one's complement.

   A very smart way to reverse all the n bits of a value x is to compute (1 << n) - x - 1. An example
   will show you that this works, avoiding long and boring mathematical explanations. We want to negate
   the number 1 represented as 8 bits ('00000001'). First we compute 1 << 8 which returns 100000000,
   then we subtract the value 1 of the number which returns 1111111 and finally we subtract the constant
   1, which returns 11111110. Look and behold! So this is exactly what I will implement for my oc()
   function
    def oc(self):
        return SizeBinary(self.bits, (1 << self.bits) - self._value - 1)

   From the same boring mathematics tomes we may discover that the two's complement representation of a
   number is its one's complement version plus 1. So the implementation of tc() is straightforward
    def tc(self):
        return self.oc() + 1

   As a matter of fact this function doesn't make the relative test (test_size_binary_TC) pass, because
   it depends on the correct implementation of the sum operation, which is still not implemented. So now
   the updated battle report is: 27 failed, 24 passed.

   Right and left shifts are the same of the Binary class, except that the result shall fit into the
   given bits. So we may delegate them to the Binary class implementation
    def __lshift__(self, pos):
        return SizeBinary(self.bits, super().__lshift__(pos))

    def __rshift__(self, pos):
        return SizeBinary(self.bits, super().__rshift__(pos))

   And this is enough to make the 5 related tests pass.

   Now it's time for some arithmetic and logic functions. Since the internal representation of our value
   is always in base 10, as already done with the arithmetic functions of the Binary class we may go
   back to the base-10 world, perform the requested operation, and go back to the base-2 representation.

   The problem with those functions is that if we mix binaries with different sizes we want to "promote"
   the smaller one, to that the result has the size of the bigger. To handle this situation I isolated
   some code in a helper function called _max_and_convert()
    def _max_and_convert(self, other):
        try:
            other_bits = other.bits
            sb_other = other
        except AttributeError:
            other_bits = self.bits
            sb_other = SizeBinary(other_bits, other)

        return max(self.bits, other_bits), sb_other

   It checks if the other argument has a bits attribute, otherwise converts it into a SizeBinary. Then
   it returns the converted argument and the greatest length between this latter and self. Using this
   function I can then implement some magic methods such as
    def __add__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__add__(sb_other))

   This template is used to implement __add__(), __sub__(), __mul__(), __truediv__(), __and__(),
   __or__(), __xor__(). The __invert__() method is simpler, missing the second argument
    def __invert__(self):
        return SizeBinary(self.bits, super().__invert__())

   With those functions I now have 49 successful tests and 2 still failing, namely
   test_size_binary_to_binary and test_binary_slice. The first one depends on the missing to_binary()
   method
    def to_binary(self):
        return Binary(self)

   The second needs some consideration: slicing depends on the __getitem__() magic method, which is used
   also for the simple indexing, tested by test_binary_get_bit and test_binary_negative_index, for
   example. The requested behaviour of the SizeBinary class is to return a single character when
   indexing a single bit and a SizeBinary or the correct length when slicing. The following code handles
   both situations
    def __getitem__(self, key):
        res = super().__getitem__(key)
        bits = len(list(res))

        if bits > 1:
            return SizeBinary(bits, res)
        else:
            return res

   First of all I use the slicing function of the underlying Binary object which was already tested and
   correctly working. Then I compute the length of that result and act depending on the result.

Resources

     * Wikipedia entries on [23]integer overflow, [24]signed number representations, and [25]bitwise
       operations.

   The code developed in this post can be found here:
     * The full code of the SizeBinary class is [26]here, while the tests file is [27]here.
     * [28]Here you find a zip file containing both source code files and the relative tests.
            26. http://blog.thedigitalcatonline.com/code/python-oop-tdd-part2/size_binary.py
            27. http://blog.thedigitalcatonline.com/code/python-oop-tdd-part2/test_size_binary.py
            28. http://blog.thedigitalcatonline.com/code/python-oop-tdd-part2/binary.zip
            
**************************************************************************************************************            
http://blog.thedigitalcatonline.com/code/python-oop-tdd-part2/size_binary.py
<code>
from binary import Binary

class SizeBinary(Binary):

    def __init__(self, bits, value):
        self.bits = bits
        self.overflow = False

        super().__init__(0)

        self.set(value)

    def set(self, value):
        binary = Binary(value)
        upper, lower = binary.split(self.bits)

        if upper != 0:
            self.overflow = True

        self._value = Binary(lower)._value

    def __eq__(self, other):
        return super().__eq__(other) and self.bits == other.bits

    def __str__(self):
        s = super().__str__()
        return s.rjust(self.bits, '0')

    def split(self, upper_bits, lower_bits):
        upper, lower = super().split(lower_bits)
        return SizeBinary(upper_bits, upper), SizeBinary(lower_bits, lower)

    def oc(self):
        return SizeBinary(self.bits, (1 << self.bits) - self._value - 1)

    def tc(self):
        return self.oc() + 1

    def __lshift__(self, pos):
        return SizeBinary(self.bits, super().__lshift__(pos))

    def __rshift__(self, pos):
        return SizeBinary(self.bits, super().__rshift__(pos))

    def _max_and_convert(self, other):
        try:
            other_bits = other.bits
            sb_other = other
        except AttributeError:
            other_bits = self.bits
            sb_other = SizeBinary(other_bits, other)

        return max(self.bits, other_bits), sb_other

    def __add__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__add__(sb_other))

    def __sub__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__sub__(sb_other))

    def __mul__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__mul__(sb_other))

    def __truediv__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__truediv__(sb_other))

    def __and__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__and__(sb_other))

    def __or__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__or__(sb_other))

    def __xor__(self, other):
        bits, sb_other = self._max_and_convert(other)
        return SizeBinary(bits, super().__xor__(sb_other))

    def __invert__(self):
        return SizeBinary(self.bits, super().__invert__())

    def __getitem__(self, key):
        res = super().__getitem__(key)
        bits = len(list(res))

        if bits > 1:
            return SizeBinary(bits, res)
        else:
            return res

    def to_binary(self):
        return Binary(self)
</code>
**************************************************************************************************************
http://blog.thedigitalcatonline.com/code/python-oop-tdd-part2/test_size_binary.py
<code>
import pytest

from binary import Binary
from size_binary import SizeBinary

def test_size_binary_init_int():
    size_binary = SizeBinary(8, 6)
    assert int(size_binary) == 6

def test_size_binary_init_int_overflow():
    size_binary = SizeBinary(8, 512)
    assert int(size_binary) == 0
    assert size_binary.overflow == True

def test_size_binary_set():
    size_binary = SizeBinary(8, 0)
    size_binary.set(22)
    assert str(size_binary) == '00010110'
    assert size_binary.overflow == False

def test_size_binary_set_overflow():
    size_binary = SizeBinary(8, 0)
    size_binary.set(512)
    assert str(size_binary) == '00000000'
    assert size_binary.overflow == True

def test_size_binary_init_bitstr():
    size_binary = SizeBinary(8, '110')
    assert int(size_binary) == 6

def test_size_binary_init_binstr():
    size_binary = SizeBinary(8, '0b110')
    assert int(size_binary) == 6

def test_size_binary_init_hexstr():
    size_binary = SizeBinary(8, '0x6')
    assert int(size_binary) == 6

def test_size_binary_init_hex():
    size_binary = SizeBinary(8, 0x6)
    assert int(size_binary) == 6

def test_size_binary_init_intseq():
    size_binary = SizeBinary(8, [1,1,0])
    assert int(size_binary) == 6

def test_size_binary_init_strseq():
    size_binary = SizeBinary(8, ['1','1','0'])
    assert int(size_binary) == 6


## Comparison

def test_binary_equality_checks_value():
    assert SizeBinary(8, 1) != SizeBinary(8, 2)

def test_binary_equality_checks_bits():
    assert SizeBinary(8, 1) != SizeBinary(16, 1)


## Conversions

def test_size_binary_eq():
    assert SizeBinary(8, 6) == SizeBinary(8, 6)

def test_size_binary_bin():
    register8 = SizeBinary(8, 126)
    assert bin(register8) == '0b1111110'

def test_size_binary_str():
    register8 = SizeBinary(8, 126)
    assert str(register8) == '01111110'

def test_size_binary_hex():
    register8 = SizeBinary(8, 126)
    assert hex(register8) == '0x7e'

def test_size_binary_to_binary():
    register8 = SizeBinary(8, 126)
    assert register8.to_binary() == Binary('1111110')

## Split

def test_size_binary_split():
    size_binary8 = SizeBinary(8, '01010110')
    size_binary4u, size_binary4l = size_binary8.split(4, 4)
    assert (size_binary4u, size_binary4l) == (SizeBinary(4, '0101'), SizeBinary(4, '0110'))

def test_size_binary_split_asymmetric():
    size_binary8 = SizeBinary(8, '01010110')
    size_binary9u, size_binary3l = size_binary8.split(9, 3)
    assert (size_binary9u, size_binary3l) == (SizeBinary(9, '000001010'), SizeBinary(3, '110'))

## Negative numbers

def test_size_binary_OC():
    # 6 = 0b00000110 -> 0b11111001
    size_binary = SizeBinary(8, 6)
    assert size_binary.oc() == SizeBinary(8, '11111001')

    # 7 = 0b00000111 -> 0b11111000
    size_binary = SizeBinary(8, 7)
    assert size_binary.oc() == SizeBinary(8, '11111000')
    
    # 15 = 0b00001111 -> 0b11110000
    size_binary = SizeBinary(8, 15)
    assert size_binary.oc() == SizeBinary(8, '11110000')

    # 15 = 0b0000000000001111 -> 0b1111111111110000
    size_binary = SizeBinary(16, 15)
    assert size_binary.oc() == SizeBinary(16, '1111111111110000')

def test_size_binary_TC():
    # 6 = 0b00000110 -> 0b11111010
    size_binary = SizeBinary(8, 6)
    assert size_binary.tc() == SizeBinary(8, '11111010')

    # 7 = 0b00000111 -> 0b11111001
    size_binary = SizeBinary(8, 7)
    assert size_binary.tc() == SizeBinary(8, '11111001')

    # 15 = 0b00001111 -> 0b11110001
    size_binary = SizeBinary(8, 15)
    assert size_binary.tc() == SizeBinary(8, '11110001')

    # 15 = 0b0000000000001111 -> 0b1111111111110001
    size_binary = SizeBinary(16, 15)
    assert size_binary.tc() == SizeBinary(16, '1111111111110001')


## Basic operations

def test_binary_addition_int():
    assert SizeBinary(8, 4) + 1 == SizeBinary(8, 5)

def test_binary_addition_binary():
    assert SizeBinary(8, 4) + SizeBinary(8, 5) == SizeBinary(8, 9)

def test_binary_addition_binary_different_size():
    assert SizeBinary(8, 4) + SizeBinary(16, 5) == SizeBinary(16, 9)

def test_binary_subtraction_int():
    assert SizeBinary(8, 4) - 1  == SizeBinary(8, 3)

def test_binary_subtraction_binary():
    assert SizeBinary(8, 5) - SizeBinary(8, 4)  == SizeBinary(8, 1)

def test_binary_subtraction_binary_different_size():
    assert SizeBinary(16, 5) - SizeBinary(8, 4)  == SizeBinary(16, 1)

def test_binary_multiplication_int():
    assert SizeBinary(8, 5) * 4  == SizeBinary(8, 20)

def test_binary_multiplication_binary():
    assert SizeBinary(8, 5) * SizeBinary(8, 6)  == SizeBinary(8, 30)

def test_binary_multiplication_binary_different_size():
    assert SizeBinary(8, 5) * SizeBinary(16, 6)  == SizeBinary(16, 30)

def test_binary_division_int():
    assert SizeBinary(8, 20) / 4  == SizeBinary(8, 5)

def test_binary_division_rem_int():
    assert SizeBinary(8, 21) / 4 == SizeBinary(8, 5)

def test_binary_division_binary():
    assert SizeBinary(8, 20) / SizeBinary(8, 5) == SizeBinary(8, 4)

def test_binary_division_binary_different_size():
    assert SizeBinary(16, 20) / SizeBinary(8, 5) == SizeBinary(16, 4)

def test_binary_division_rem_binary():
    assert SizeBinary(8, 21) / SizeBinary(8, 5) == SizeBinary(8, 4)

def test_binary_division_rem_binary_different_size():
    assert SizeBinary(8, 21) / SizeBinary(16, 5) == SizeBinary(16, 4)

def test_binary_get_bit():
    size_binary = SizeBinary(8, '01110001')
    assert size_binary[0] == '1'
    assert size_binary[5] == '1'

def test_binary_negative_index():
    size_binary = SizeBinary(8, '01110001')
    assert size_binary[-1] == '0'
    assert size_binary[-2] == '1'

def test_binary_illegal_index():
    with pytest.raises(IndexError):
        SizeBinary(8, '01101010')[8]

def test_binary_inappropriate_type_index():
    with pytest.raises(TypeError):
        SizeBinary(8, '01101010')['key']

def test_binary_for_loop():
    assert [int(i) for i in SizeBinary(8, '01101010')] == [0, 1, 0, 1, 0, 1, 1, 0]

def test_binary_not():
    assert ~SizeBinary(4, '1101') == SizeBinary(4, '0010')

def test_binary_and():
    assert SizeBinary(4, '1101') & SizeBinary(4, '1') == SizeBinary(4, '1')

def test_binary_or():
    assert SizeBinary(4, '1101') | SizeBinary(4, '1') == SizeBinary(4, '1101')

def test_binary_xor():
    assert SizeBinary(4, '1101') ^ SizeBinary(4, '1') == SizeBinary(4, '1100')

def test_binary_shl():
    assert SizeBinary(4, '1101') << 1 == SizeBinary(4, '1010')

def test_binary_shl_pos():
    assert SizeBinary(8, '1101') << 5 == SizeBinary(8, '10100000')

def test_binary_shl_pos_drop():
    assert SizeBinary(4, '1101') << 4 == SizeBinary(4, '0000')

def test_binary_shr():
    assert SizeBinary(4, '1101') >> 1 == SizeBinary(4, '110')

def test_binary_shr_pos():
    assert SizeBinary(4, '1101') >> 5 == SizeBinary(4, '0')

## Slicing

def test_binary_slice():
    assert SizeBinary(8, '01101010')[0:3] == SizeBinary(2, '10')
    assert SizeBinary(8, '01101010')[1:4] == SizeBinary(3, '101')
    assert SizeBinary(8, '01101010')[4:] == SizeBinary(3, '110')
</code>
**************************************************************************************************************


---
http://blog.thedigitalcatonline.com/blog/2016/03/06/python-mocks-a-gentle-introduction-part-1/#.WdXtdFs-8-U

Python Mocks: a gentle introduction - Part 1
06/03/2016 Series Part 1 of "Python Mocks: a gentle introduction"

   As already stressed in the two introductory posts on TDD (you can find them [17]here) testing
   requires to write some code that uses the functions and objects you are going to develop. This means
   that you need to isolate a given (external) function that is part of your public API and demonstrate
   that it works with standard inputs and in edge cases.

   For example, if you are going to develop an object that stores percentages (such as for example poll
   results), you should test the following conditions: the class can store a standard percentage such as
   42%, the class shall give an error if you try to store a negative percentage, the class shall give an
   error if you store a percentage greater than 100%.

   Tests shall be idempotent and isolated. Idempotent in mathematics and computer science identifies a
   process that can be run multiple times without changing the status of the system. Isolated means that
   a test shall not change its behaviour depending on previous executions of itself, nor depend on the
   previous execution (or missing execution) of other tests.

   Such restrictions, which guarantee that your tests are not passing due to a temporary configuration
   of the system or the order in which they are run, can raise big issues when dealing with external
   libraries and systems, or with intrinsically mutable concepts such as time. In the testing
   discipline, such issues are mostly faced using mocks, that is objects that pretend to be other
   objects.

   In this series of posts I am going to review the Python mock library and exemplify its use. I will
   not cover everything you may do with mock, obviously, but hopefully I'll give you the information you
   need to start using this powerful library.

Installation
   First of all, mock is a Python library which development started around 2008. It was selected to be
   included in the standard library as of Python 3.3, which however does not prevent you to use other
   libraries if you prefer.

   Python 3 users, thus, are not required to take any step, while for Python 2 projects you are still
   required to issue a pip install mock to install it into the system or the current virtualenv.

   You may find the official documentation [18]here. It is very detailed, and as always I strongly
   recommend taking your time to run through it.

Basic concepts
   A mock, in the testing lingo, is an object that simulates the behaviour of another (more complex)
   object. When you (unit)test an object of your library you need sometimes to access other systems your
   object want to connect to, but you do not really want to be forced to run them, for several reasons.

   The first one is that connecting with external systems means having a complex testing environment,
   that is you are dropping the isolation requirement of you tests. If your object wants to connect with
   a website, for example, you are forced to have a running Internet connection, and if the remote
   website is down you cannot test your library.

   The second reason is that the setup of an external system is usually slow in comparison with the
   speed of unit tests. We expect to run hundred of tests in seconds, and if we have to fetch
   information from a remote server for each of them the time easily increases by several orders of
   magnitude. Remember: having slow tests means that you cannot run them while you develop, which in
   turn means that you will not really use them for TDD.

   The third reason is more subtle, and has to to with the mutable nature of an external system, thus
   I'll postpone the discussion of this issue for the moment.

   Let us try and work with a mock in Python and see what it can do. First of all fire up a Python shell
   or a [19]Jupyter Notebook and import the library
from unittest import mock

   If you are using Python 2 you have to install it and use
import mock

   The main object that the library provides is Mock and you can instantiate it without any argument
m = mock.Mock()

   This object has the peculiar property of creating methods and attributes on the fly when you require
   them. Let us first look inside the object to take a glance of what it provides
>>> dir(m)
['assert_any_call', 'assert_called_once_with', 'assert_called_with', 'assert_has_calls', 'attach_mock', 'call_
args', 'call_args_list', 'call_count', 'called', 'configure_mock', 'method_calls', 'mock_add_spec', 'mock_call
s', 'reset_mock', 'return_value', 'side_effect']

   As you can see there are some methods which are already defined into the Mock object. Let us read a
   non-existent attribute
>>> m.some_attribute
<Mock name='mock.some_attribute' id='140222043808432'>
>>> dir(m)
['assert_any_call', 'assert_called_once_with', 'assert_called_with', 'assert_has_calls', 'attach_mock', 'call_
args', 'call_args_list', 'call_count', 'called', 'configure_mock', 'method_calls', 'mock_add_spec', 'mock_call
s', 'reset_mock', 'return_value', 'side_effect', 'some_attribute']

   Well, as you can see this class is somehow different from what you are accustomed to. First of all
   its instances do not raise an AttributeError when asked for a non-existent attribute, but they
   happily return another instance of Mock itself. Second, the attribute you tried to access has now
   been created inside the object and accessing it returns the same mock object as before.
>>> m.some_attribute
<Mock name='mock.some_attribute' id='140222043808432'>

   Mock objects are callables, which means that they may act both as attributes and as methods. If you
   try to call the mock it just returns you another mock with a name that includes parentheses to signal
   its callable nature
>>> m.some_attribute()
<Mock name='mock.some_attribute()' id='140247621475856'>

   As you can understand, such objects are the perfect tool to mimic other objects or systems, since
   they may expose any API without raising exceptions. To use them in tests, however, we need them to
   behave just like the original, which implies returning sensible values or performing operations.

Return value

   The simplest thing a mock can do for you is to return a given value every time you call it. This is
   configured setting the return_value attribute of a mock object
>>> m.some attribute.return_value = 42
>>> m.some attribute()
42

   Now the object does not return a mock object any more, instead it just returns the static value
   stored in the return_value attribute. Obviously you can also store a callable such as a function or
   an object, and the method will return it, but it will not run it. Let me give you an example
>>> def print_answer():
...  print("42")
...
>>>
>>> m.some_attribute.return_value = print_answer
>>> m.some_attribute()
<function print_answer at 0x7f8df1e3f400>

   As you can see calling some_attribute() just returns the value stored in return_value, that is the
   function itself. To return values that come from a function we have to use a slightly more complex
   attribute of mock objects called side_effect.

Side effect
   The side_effect parameter of mock objects is a very powerful tool. It accepts three different
   flavours of objects, callables, iterables, and exceptions, and changes its behaviour accordingly.

   If you pass an exception the mock will raise it
>>> m.some_attribute.side_effect = ValueError('A custom value error')
>>> m.some_attribute()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/lib/python3.4/unittest/mock.py", line 902, in __call__
    return _mock_self._mock_call(*args, **kwargs)
  File "/usr/lib/python3.4/unittest/mock.py", line 958, in _mock_call
    raise effect
ValueError: A custom value error

   If you pass an iterable, such as for example a generator, or a plain list, tuple, or similar objects,
   the mock will yield the values of that iterable, i.e. return every value contained in the iterable on
   subsequent calls of the mock. Let me give you an example
>>> m.some_attribute.side_effect = range(3)
>>> m.some_attribute()
0
>>> m.some_attribute()
1
>>> m.some_attribute()
2
>>> m.some_attribute()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/lib/python3.4/unittest/mock.py", line 902, in __call__
    return _mock_self._mock_call(*args, **kwargs)
  File "/usr/lib/python3.4/unittest/mock.py", line 961, in _mock_call
    result = next(effect)
StopIteration

   As promised, the mock just returns every object found in the iterable (in this case a range object)
   once at a time until the generator is exhausted. According to the iterator protocol (see [20]this
   post) once every item has been returned the object raises the StopIteration exception, which means
   that you can correctly use it in a loop.

   The last and perhaps most used case is that of passing a callable to side_effect, which shamelessly
   executes it with its own same parameters. This is very powerful, especially if you stop thinking
   about "functions" and start considering "callables". Indeed, side_effect also accepts a class and
   calls it, that is it can instantiate objects. Let us consider a simple example with a function
   without arguments
>>> def print_answer():
...     print("42")
>>> m.some_attribute.side_effect = print_answer
>>> m.some_attribute.side_effect()
42

   A slightly more complex example: a function with arguments
>>> def print_number(num):
...     print("Number:", num)
...
>>> m.some_attribute.side_effect = print_number
>>> m.some_attribute.side_effect(5)
Number: 5

   And finally an example with a class
>>> class Number(object):
...     def __init__(self, value):
...         self._value = value
...     def print_value(self):
...         print("Value:", self._value)
...
>>> m.some_attribute.side_effect = Number
>>> n = m.some_attribute.side_effect(26)
>>> n
<__main__.Number object at 0x7f8df1aa4470>
>>> n.print_value()
Value: 26

Testing with mocks

   Now we know how to build a mock and how to give it a static return value or make it call a callable
   object. It is time to see how to use a mock in a test and what facilities do mocks provide. I'm going
   to use [21]pytest as a testing framework. You can find a quick introduction to pytest and TDD
   [22]here).

Setup
   If you want to quickly setup a pytest playground you may execute this code in a terminal (you need to
   have Python 3 and virtualenv installed in your system)
mkdir mockplayground
cd mockplayground
virtualenv venv3 -p python3
source venv3/bin/activate
pip install --upgrade pip
pip install pytest
echo "[pytest]" >> pytest.ini
echo "norecursedirs=venv*" >> pytest.ini
mkdir tests
touch myobj.py
touch tests/test_mock.py
PYTHONPATH="." py.test

   The PYTHONPATH environment variable is an easy way to avoid having to setup a whole Python project to
   just test some simple code.

The three test types
   According to Sandy Metz we need to test only three types of messages (calls) between objects:
     * Incoming queries (assertion on result)
     * Incoming commands (assertion on direct public side effects)
     * Outgoing commands (expectation on call and arguments)

   You can see the original talk [23]here or read the slides [24]here. The final table is shown in slide
   number 176.

   As you can see when dealing with external objects we are only interested in knowing IF a method was
   called and WHAT PARAMETERS the caller passed to the object. We are not testing if the remote object
   returns the correct result, this is faked by the mock, which indeed returns exactly the result we
   need.

   So the purpose of the methods provided by mock objects is to allow us to check what methods we called
   on the mock itself and what parameters we used in the call.

Asserting calls
   To show how to use Python mocks in testing I will follow the TDD methodology, writing tests first and
   then writing the code that makes the tests pass. In this post I want to give you a simple overview of
   the mock objects, so I will not implement a real world use case, and the code will be very trivial.
   In the second part of this series I will test and implement a real class, in order to show some more
   interesting use cases.

   The first thing we are usually interested in when dealing with an external object is to know that a
   given method has been called on it. Python mocks provide the assert_called_with() method to check
   this condition.

   The use case we are going to test is the following. We instantiate the myobj.MyObj class, which
   requires an external object. The class shall call the connect() method of the external object without
   any parameter.
from unittest import mock
import myobj

def test_instantiation():
    external_obj = mock.Mock()
    myobj.MyObj(external_obj)
    external_obj.connect.assert_called_with()

   The myobj.MyObj class, in this simple example, needs to connect to an external object, for example a
   remote repository or a database. The only thing we need to know for testing purposes is if the class
   called the connect() method of the external object without any parameter.

   So the first thing we do in this test is to instantiate the mock object. This is a fake version of
   the external object, and its only purpose is to accept calls from the MyObj object under test and
   return sensible values. Then we instantiate the MyObj class passing the external object. We expect
   the class to call the connect() method so we express this expectation calling
   external_obj.connect.assert_called_with().

   What happens behind the scenes? The MyObj class receives the external object and somewhere is its
   initialization process calls the connect() method of the mock object and this creates the method
   itself as a mock object. This new mock records the parameters used to call it and the subsequent call
   to assert_called_with() checks that the method was called and that no parameters were passed.

   Running pytest the test obviously fails.
$ PYTHONPATH="." py.test
========================================== test session starts ==========================================
platform linux -- Python 3.4.3+, pytest-2.9.0, py-1.4.31, pluggy-0.3.1
rootdir: /home/leo/devel/mockplayground, inifile: pytest.ini
collected 1 items

tests/test_mock.py F

=============================================== FAILURES ================================================
___________________________________________ test_instantiation __________________________________________

    def test_instantiation():
        external_obj = mock.Mock()
>       myobj.MyObj(external_obj)
E       AttributeError: 'module' object has no attribute 'MyObj'

tests/test_mock.py:6: AttributeError
======================================= 1 failed in 0.03 seconds ========================================
$

   Putting this code in myobj.py is enough to make the test pass
class MyObj():
    def __init__(self, repo):
        repo.connect()

   As you can see, the __init__() method actually calls repo.connect(), where repo is expected to be a
   full-featured external object that provides a given API. In this case (for the moment) the API is
   just its connect() method. Calling repo.connect() when repo is a mock object silently creates the
   method as a mock object, as shown before.

   The assert_called_with() method also allows us to check the parameters we passed when calling. To
   show this let us pretend that we expect the MyObj.setup() method to call setup(cache=True,
   max_connections=256) on the external object. As you can see we pass a couple of arguments (namely
   cache and max_connections) to the called method, and we want to be sure that the call was exactly in
   this form. The new test is thus
def test_setup():
    external_obj = mock.Mock()
    obj = myobj.MyObj(external_obj)
    obj.setup()
    external_obj.setup.assert_called_with(cache=True, max_connections=256)

   As usual the first run fails. Be sure to check this, it is part of the TDD methodology. You must have
   a test that DOES NOT PASS, then write some code that make it pass.
$ PYTHONPATH="." py.test
========================================== test session starts ==========================================
platform linux -- Python 3.4.3+, pytest-2.9.0, py-1.4.31, pluggy-0.3.1
rootdir: /home/leo/devel/mockplayground, inifile: pytest.ini
collected 2 items

tests/test_mock.py .F

=============================================== FAILURES ================================================
______________________________________________ test_setup _______________________________________________

    def test_setup():
        external_obj = mock.Mock()
        obj = myobj.MyObj(external_obj)
>       obj.setup()
E       AttributeError: 'MyObj' object has no attribute 'setup'

tests/test_mock.py:14: AttributeError
================================== 1 failed, 1 passed in 0.03 seconds ===================================
$

   To show you what type of check the mock object provides let me implement a partially correct solution
class MyObj():
    def __init__(self, repo):
        self._repo = repo
        repo.connect()

    def setup(self):
        self._repo.setup(cache=True)

   As you can see the external object has been stored in self._repo and the call to self._repo.setup()
   is not exactly what the test expects, lacking the max_connections parameter. Running pytest we obtain
   the following result (I removed most of the pytest output)
E           AssertionError: Expected call: setup(cache=True, max_connections=256)
E           Actual call: setup(cache=True)

   and you see that the error message is very clear about what we expected and what happened in our
   code.

   As you can read in the official documentation, the Mock object also provides the following methods
   and attributes: assert_called_once_with, assert_any_call, assert_has_calls, assert_not_called,
   called, call_count. Each of them explores a different aspect of the mock behaviour concerning calls,
   make sure to check their description and the examples provided along.

Final words
   In this first part of the series I described the behaviour of mock objects and the methods they
   provide to simulate return values and to test calls. They are a very powerful tool that allows you to
   avoid creating complex and slow tests that depend on external facilities to run, thus missing the
   main purpose of tests, which is that of continuously helping you to check your code.

   In the next issue of the series I will explore the automatic creation of mock methods from a given
   object and the very important patching mechanism provided by the patch decorator and context manager.


---
http://blog.thedigitalcatonline.com/blog/2016/09/27/python-mocks-a-gentle-introduction-part-2/#.WdXtdVs-8-U

Python Mocks: a gentle introduction - Part 2
27/09/2016 Series Part 2 of "Python Mocks: a gentle introduction" 

   In the first post I introduced you to Python mocks, objects that can imitate other objects and
   work as placeholders, replacing external systems during unit testing. I described the basic behaviour
   of mock objects, the return_value and side_effect attributes, and the assert_called_with() method.

   In this post I will briefly review the remaining assert_* methods and some interesting attributes
   that allow to check the calls received by the mock object. Then I will introduce and exemplify
   patching, which is a very important topic in testing.

Other assertions and attributes
   The [18]official documentation of the mock library lists many other assertion, namely
   assert_called_once_with(), assert_any_call(), assert_has_calls(), assert_not_called(). If you grasped
   how assert_called_with() works, you will have no troubles in understanding how those other behave. Be
   sure to check the documentation to get a full description of what mock object can assert about their
   history after being used by your code.

   Together with those methods, mock objects also provide some useful attributes, two of which have been
   already reviewed in the first post. The remaining attributes are as expected mostly related to calls,
   and are called, call_count, call_args, call_args_list, method_calls, mock_calls. While these also are
   very well described in the official documentation, I want to point out the two method_calls and
   mock_calls attributes, that store the detailed list of methods which are called on the mock, and the
   call_args_list attribute that lists the parameters of every call.

   Do not forget that methods called on a mock object are mocks themselves, so you may first access the
   main mock object to get information about the called methods, and then access those methods to get
   the arguments they received.

Patching
   Mocks are very simple to introduce in your tests whenever your objects accept classes or instances
   from outside. In that case, as described, you just have to instantiate the Mock class and pass the
   resulting object to your system. However, when the external classes instantiated by your library are
   hardcoded this simple trick does not work. In this case you have no chance to pass a mock object
   instead of the real one.

   This is exactly the case addressed by patching. Patching, in a testing framework, means to replace a
   globally reachable object with a mock, thus achieving the target of having the code run unmodified,
   while part of it has been hot swapped, that is, replaced at run time.

A warm-up example
   Let us start with a very simple example. Patching can be complex to grasp at the beginning so it is
   better to learn it with trivial code. If you do not have it yet, create the testing environment
   mockplayground with the instruction given in the previous post.

   I want to develop a simple class that returns information about a given file. The class shall be
   instantiated with the file name, which can be a relative path.

   For the sake of brevity I will not show you every step of the TDD development of the class. Remember
   that TDD requires you to write a test and then implement the code, but sometimes this could be too
   fine grained, so do not use the TDD rules without thinking.

   The tests for the initialization of the class are
from fileinfo import FileInfo

def test_init():
    filename = 'somefile.ext'
    fi = FileInfo(filename)
    assert fi.filename == filename

def test_init():
    filename = 'somefile.ext'
    relative_path = '../{}'.format(filename)
    fi = FileInfo(relative_path)
    assert fi.filename == filename

   You can put them into the tests/test_fileinfo.py file. The code that makes the tests pass could be
   something like
import os


class FileInfo:
    def __init__(self, path):
        self.original_path = path
        self.filename = os.path.basename(path)

   Up to now I didn't introduce any new feature. Now I want the get_info() function to return a tuple
   with the file name, the original path the class was instantiated with, and the absolute path of the
   file.

   You immediately realise that you have an issue in writing the test. There is no way to easily test
   something as "the absolute path", since the outcome of the function called in the test is supposed to
   vary with the path of the test itself. Let us write part of the test
def test_get_info():
    filename = 'somefile.ext'
    original_path = '../{}'.format(filename)
    fi = FileInfo(original_path)
    assert fi.get_info() == (filename, original_path, '???')

   where the '???' string highlights that I cannot put something sensible to test the absolute path of
   the file.

   Patching is the way to solve this problem. You know that the function will use some code to get the
   absolute path of the file. So in the scope of the test only you can replace that code with different
   code and perform the test. Since the replacement code has a known outcome writing the test is now
   possible.

   Patching, thus, means to inform Python that in some scope you want a globally accessible
   module/object replaced by a mock. Let's see how we can use it in our example
from unittest.mock import patch

[...]

def test_get_info():
    filename = 'somefile.ext'
    original_path = '../{}'.format(filename)

    with patch('os.path.abspath') as abspath_mock:
        test_abspath = 'some/abs/path'
        abspath_mock.return_value = test_abspath
        fi = FileInfo(original_path)
        assert fi.get_info() == (filename, original_path, test_abspath)

   Remember that if you are using Python 2 you installed the mock module with pip, so your import
   statement becomes form mock import patch.

   You clearly see the context in which the patching happens, as it is enclosed in a with statement.
   Inside this statement the module os.path.abspath will be replaced by a mock created by the function
   patch and called abspath_mock. We can now give the function a return_value as we did with standard
   mocks in the first post and run the test.

   The code that make the test pass is
class FileInfo:
    [...]

    def get_info(self):
        return self.filename, self.original_path, os.path.abspath(self.filename)

   Obviously to write the test you have to know that you are going to use the os.path.abspath function,
   so patching is somehow a "less pure" practice in TDD. In pure OOP/TDD you are only concerned with the
   external behaviour of the object, and not with its internal structure. This example, however, shows
   that you have to cope with some real world issues, and patching is a clean way to do it.

The patching decorator
   The patch function we imported from the unittest.mock module is very powerful, and can be used as a
   function decorator as well. When used in this fashion you need to change the decorated function to
   accept a mock as last argument.
@patch('os.path.abspath')
def test_get_info(abspath_mock):
    filename = 'somefile.ext'
    original_path = '../{}'.format(filename)

    test_abspath = 'some/abs/path'
    abspath_mock.return_value = test_abspath
    fi = FileInfo(original_path)
    assert fi.get_info() == (filename, original_path, test_abspath)

   As you can see the patch decorator works like a big with statement for the whole function. Obviously
   in this way you replace the target function os.path.abspath in the scope of the whole function. It is
   then up to you to decide if you need to use patch as a decorator or in a with block.

Multiple patches
   We can also patch more that one object. Say for example that we want to change the above test to
   check that the outcome of the FileInfo.get_info() method also contains the size of the file. To get
   the size of a file in Python we may use the os.path.getsize() function, which returns the size of the
   file in bytes.

   So now we have to patch os.path.getsize as well, and this can be done with another patch decorator.
@patch('os.path.getsize')
@patch('os.path.abspath')
def test_get_info(abspath_mock, getsize_mock):
    filename = 'somefile.ext'
    original_path = '../{}'.format(filename)

    test_abspath = 'some/abs/path'
    abspath_mock.return_value = test_abspath

    test_size = 1234
    getsize_mock.return_value = test_size

    fi = FileInfo(original_path)
    assert fi.get_info() == (filename, original_path, test_abspath, test_size)

   Please notice that the decorator which is nearest to the function is applied first. Always remember
   that the decorator syntax with @ is a shortcut to replace the function with the output of the
   decorator, so two decorators result in
@decorator1
@decorator2
def myfunction():
    pass

   which is a shorcut for
def myfunction():
    pass
myfunction = decorator1(decorator2(myfunction))

   This explains why, in the test code, the function receives first abspath_mock and then getsize_mock.
   The first decorator applied to the function is the patch of os.path.abspath, which appends the mock
   that we call abspath_mock. Then the patch of os.path.getsize is applied and this appends its own
   mock.

   The code that makes the test pass is
class FileInfo:
    [...]

    def get_info(self):
        return self.filename, self.original_path, os.path.abspath(self.filename), os.path.getsize(self.filenam
e)

   We can write the above test using two with statements as well
def test_get_info():
    filename = 'somefile.ext'
    original_path = '../{}'.format(filename)

    with patch('os.path.abspath') as abspath_mock:
        test_abspath = 'some/abs/path'
        abspath_mock.return_value = test_abspath

        with patch('os.path.getsize') as getsize_mock:
            test_size = 1234
            getsize_mock.return_value = test_size

            fi = FileInfo(original_path)
            assert fi.get_info() == (filename, original_path, test_abspath, test_size)

   Using more than one with statement, however, makes the code difficult to read, in my opinion, so in
   general I prefer to avoid complex with trees if I do not need a limited scope of the patching.

Patching immutable objects
   The most widespread version of Python is CPython, which is written, as the name suggests, in C. Part
   of the standard library is also written in C, while the rest is written in Python itself.

   The objects (classes, modules, functions, etc) that are implemented in C are shared between
   interpreters, which is something that you can do embedding the Python interpreter in a C program, for
   example. This requires those objects to be immutable, so that you cannot alter them at runtime from a
   single interpreter.

   For an example of this immutability just check the following code
>>> a = 1
>>> a.conjugate = 5
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'int' object attribute 'conjugate' is read-only

   Here I'm trying to replace a method with an integer, which is pointless, but nevertheless shows the
   issue we are facing.

   What has this immutability to do with patching? What patch does is actually to temporarily replace an
   attibute of an object (method of a class, class of a module, etc), so if that object is immutable the
   patching action fails.

   A typical example of this problem is the datetime module, which is also one of the best candidates
   for patching, since the output of time functions is by definition time-varying.

   Let me show the problem with a simple class that logs operations. The class is the following (you can
   put it into a file called logger.py)
import datetime

class Logger:
    def __init__(self):
        self.messages = []

    def log(self, message):
        self.messages.append((datetime.datetime.now(), message))

   This is pretty simple, but testing this code is problematic, because the log() method produces
   results that depend on the actual execution time.

   If we try to write a test patching datetime.datetime.now we have a bitter surprise. This is the test
   code, that you can put in tests/test_logger.py
from unittest.mock import patch

from logger import Logger

def test_init():
    l = Logger()
    assert l.messages == []

@patch('datetime.datetime.now')
def test_log(mock_now):
    test_now = 123
    test_message = "A test message"
    mock_now.return_value = test_now

    l = Logger()
    l.log(test_message)
    assert l.messages == [(test_now, test_message)]

   and the execution of pytest returns a TypeError: can't set attributes of built-in/extension type
   'datetime.datetime', which is exactly a problem of immutability.

   There are several ways to address this problem, but all of them leverage the fact that, when you
   import of subclass an immutable object what you get is a "copy" of that is now mutable.

   The easiest example in this case is the module datetime itself. In the test_log function we try to
   patch directly the datetime.datetime.now object, affecting the builtin module datetime. The file
   logger.py, however, does import datetime, so that this latter becomes a local symbol in the logger
   module. This is exactly the key for our patching. Let us change the code to
@patch('logger.datetime.datetime')
def test_log(mock_datetime):
    test_now = 123
    test_message = "A test message"
    mock_datetime.now.return_value = test_now

    l = Logger()
    l.log(test_message)
    assert l.messages == [(test_now, test_message)]

   As you see running the test now the patching works. What we did was to patch logger.datetime.datetime
   instead of datetime.datetime.now. Two things changed, thus, in our test. First, we are patching the
   module imported in the logger.py file and not the module provided globally by the Python interpreter.
   Second, we have to patch the whole module because this is what is imported by the logger.py file. If
   you try to patch logger.datetime.datetime.now you will find that it is still immutable.

   Another possible solution to this problem is to create a function that invokes the immutable object
   and returns its value. This last function can be easily patched, because it just uses the builtin
   objects and thus is not immutable. This solution, however, requires to change the source code to
   allow testing, which is far from being desirable. Obviously it is better to introduce a small change
   in the code and have it tested than to leave it untested, but whenever is possible I avoid solutions
   that introduce code which wouldn't be required without tests.

Final words
   In this second part of this small series on Python testing we reviewed the patching mechanism and run
   through some of its subtleties. Patching is a really effective technique, and patch-based tests can
   be found in many different packages. Take your time to become confident with mocks and patching,
   since they will be one of your main tools while working with Python and any other object-oriented
   language.

   As always, I strongly recommend finding some time to read the official documentation of the mock
   library.


---
http://blog.thedigitalcatonline.com/blog/2017/07/21/refactoring-with-test-in-python-a-practical-example/#.WdXtdls-8-U

Refactoring with tests in Python: a practical example
21/07/2017 

   This post contains a step-by-step example of a refactoring session guided by tests. When dealing with
   untested or legacy code refactoring is dangerous and tests can help us do it the right way,
   minimizing the amount of bugs we introduce, and possibly completely avoiding them.

   Refactoring is not easy. It requires a double effort to understand code that others wrote, or that we
   wrote in the past, and moving around parts of it, simplifying it, in one word improving it, is by no
   means something for the faint-hearted. Like programming, refactoring has its rules and best
   practices, but it can be described as a mixture of technique, intuition, experience, risk.

   Programming, after all, is craftsmanship.

The starting point
   The simple use case I will use for this post is that of a service API that we can access, and that
   produces data in JSON format, namely a list of elements like the one shown here
{
    "age": 20,
    "surname": "Frazier",
    "name": "John",
    "salary": "28943"
}

   Once we convert this to a Python data structure we obtain a list of dictionaries, where 'age' is an
   integer, and the remaining fields are strings.

   Someone then wrote a class that computes some statistics on the input data. This class, called
   DataStats, provides a single method stats(), whose inputs are the data returned by the service (in
   JSON format), and two integers called iage and isalary. Those, according to the short documentation
   of the class, are the initial age and the initial salary used to compute the average yearly increase
   of the salary on the whole dataset.

   The code is the following
import math
import json


class DataStats:

    def stats(self, data, iage, isalary):
        # iage and isalary are the starting age and salary used to
        # compute the average yearly increase of salary.

        # Compute average yearly increase
        average_age_increase = math.floor(
            sum([e['age'] for e in data])/len(data)) - iage
        average_salary_increase = math.floor(
            sum([int(e['salary'][1:]) for e in data])/len(data)) - isalary

        yearly_avg_increase = math.floor(
            average_salary_increase/average_age_increase)

        # Compute max salary
        salaries = [int(e['salary'][1:]) for e in data]
        threshold = '' + str(max(salaries))

        max_salary = [e for e in data if e['salary'] == threshold]

        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        min_salary = [e for e in data if e['salary'] ==
                      '{}'.format(str(min(salaries)))]

        return json.dumps({
            'avg_age': math.floor(sum([e['age'] for e in data])/len(data)),
            'avg_salary': math.floor(sum(
                [int(e['salary'][1:]) for e in data])/len(data)),
            'avg_yearly_increase': yearly_avg_increase,
            'max_salary': max_salary,
            'min_salary': min_salary
        })

The goal
   It is fairly easy, even for the untrained eye, to spot some issues in the previous class. A list of
   the most striking ones is
     * The class exposes a single method and has no __init__(), thus the same functionality could be
       provided by a single function.
     * The stats() method is too big, and performs too many tasks. This makes debugging very difficult,
       as there is a single inextricable piece of code that does everything.
     * There is a lot of code duplication, or at least several lines that are very similar. Most notably
       the two operations '' + str(max(salaries)) and '{}'.format(str(min(salaries))), the two
       different lines starting with salaries =, and the several list comprehensions.

   So, since we are going to use this code in some part of our Amazing New Project, we want to possibly
   fix these issues.

   The class, however, is working perfectly. It has been used in production for many years and there are
   no known bugs, so our operation has to be a refactoring, which means that we want to write something
   better, preserving the behaviour of the previous object.

The path
   In this post I want to show you how you can safely refactor such a class using tests. This is
   different from TDD, but the two are closely related. The class we have has not been created using
   TDD, as there are no tests, but we can use tests to ensure its behaviour is preserved. This should
   therefore be called Test Driven Refactoring (TDR).

   The idea behind TDR is pretty simple. First, we have to write a test that checks the behaviour of
   some code, possibly a small part with a clearly defined scope and output. This is a posthumous (or
   late) unit test, and it simulates what the author of the code should have provided (cough cough, it
   was you some months ago...).

   Once you have you unit test you can go and modify the code, knowing that the behaviour of the
   resulting object will be the same of the previous one. As you can easily understand, the
   effectiveness of this methodology depends strongly on the quality of the tests themselves, possibly
   more than when developing with TDD, and this is why refactoring is hard.

Caveats
   Two remarks before we start our first refactoring. The first is that such a class could easily be
   refactored to some functional code. As you will be able to infer from the final result there is no
   real reason to keep an object-oriented approach for this code. I decided to go that way, however, as
   it gave me the possibility to show a design pattern called wrapper, and the refactoring technique
   that leverages it.

   The second remark is that in pure TDD it is strongly advised not to test internal methods, that is
   those methods that do not form the public API of the object. In general, we identify such methods in
   Python by prefixing their name with an underscore, and the reason not to test them is that TDD wants
   you to shape objects according to the object-oriented programming methodology, which considers
   objects as behaviours and not as structures. Thus, we are only interested in testing public methods.

   It is also true, however, that sometimes even tough we do not want to make a method public, that
   method contains some complex logic that we want to test. So, in my opinion the TDD advice should
   sound like "Test internal methods only when they contain some non-trivial logic".

   When it comes to refactoring, however, we are somehow deconstructing a previously existing structure,
   and usually we end up creating a lot of private methods to help extracting and generalising parts of
   the code. My advice in this case is to test those methods, as this gives you a higher degree of
   confidence in what you are doing. With experience you will then learn which tests are required and
   which are not.

Setup of the testing environment
   Clone [16]this repository and create a virtual environment. Activate it and install the required
   packages with
pip install -r requirements.txt

   The repository already contains a configuration file for pytest and you should customise it to avoid
   entering your virtual environment directory. Go and fix the norecursedirs parameter in that file,
   adding the name of the virtual environment you just created; I usually name my virtual environments
   with a venv prefix, and this is why that variable contains the entry venv*.

   At this point you should be able to run pytest -svv in the parent directory of the repository (the
   one that contains pytest.ini), and obtain a result similar to the following
========================== test session starts ==========================
platform linux -- Python 3.5.3, pytest-3.1.2, py-1.4.34, pluggy-0.4.0
cachedir: .cache
rootdir: datastats, inifile: pytest.ini
plugins: cov-2.5.1
collected 0 items

====================== no tests ran in 0.00 seconds ======================

   The given repository contains two branches. master is the one that you are into, and contains the
   initial setup, while develop points to the last step of the whole refactoring process. Every step of
   this post contains a reference to the commit that contains the changes introduced in that section.

Step 1 - Testing the endpoints

   Commit: [17]27a1d8c

   When you start refactoring a system, regardless of the size, you have to test the endpoints. This
   means that you consider the system as a black box (i.e. you do not know what is inside) and just
   check the external behaviour. In this case we can write a test that initialises the class and runs
   the stats() method with some test data, possibly real data, and checks the output. Obviously we will
   write the test with the actual output returned by the method, so this test is automatically passing.

   Querying the server we get the following data
test_data = [
    {
        "id": 1,
        "name": "Laith",
        "surname": "Simmons",
        "age": 68,
        "salary": "27888"
    },
    {
        "id": 2,
        "name": "Mikayla",
        "surname": "Henry",
        "age": 49,
        "salary": "67137"
    },
    {
        "id": 3,
        "name": "Garth",
        "surname": "Fields",
        "age": 70,
        "salary": "70472"
    }
]

   and calling the stats() method with that output, with iage set to 20, and isalary set to 20000, we
   get the following JSON result
{
    "avg_age": 62,
    "avg_salary": 55165,
    "avg_yearly_increase": 837,
    "max_salary": [{
        "id": 3,
        "name": "Garth",
        "surname": "Fields",
        "age": 70,
        "salary": "70472"
    }],
    "min_salary": [{
        "id": 1,
        "name": "Laith",
        "surname": "Simmons",
        "age": 68,
        "salary": "27888"
    }]
}

   Caveat: I'm using a single very short set of real data, namely a list of 3 dictionaries. In a real
   case I would test the black box with many different use cases, to ensure I am not just checking some
   corner case.

   The test is the following
import json

from datastats.datastats import DataStats


def test_json():
    test_data = [
        {
            "id": 1,
            "name": "Laith",
            "surname": "Simmons",
            "age": 68,
            "salary": "27888"
        },
        {
            "id": 2,
            "name": "Mikayla",
            "surname": "Henry",
            "age": 49,
            "salary": "67137"
        },
        {
            "id": 3,
            "name": "Garth",
            "surname": "Fields",
            "age": 70,
            "salary": "70472"
        }
    ]

    ds = DataStats()

    assert ds.stats(test_data, 20, 20000) == json.dumps(
        {
            'avg_age': 62,
            'avg_salary': 55165,
            'avg_yearly_increase': 837,
            'max_salary': [{
                "id": 3,
                "name": "Garth",
                "surname": "Fields",
                "age": 70,
                "salary": "70472"
            }],
            'min_salary': [{
                "id": 1,
                "name": "Laith",
                "surname": "Simmons",
                "age": 68,
                "salary": "27888"
            }]
        }
    )

   As said before, this test is obviously passing, having been artificially constructed from a real
   execution of the code.

   Well, this test is very important! Now we know that if we change something inside the code, altering
   the behaviour of the class, at least one test will fail.

Step 2 - Getting rid of the JSON format
   Commit: [18]65e2997

   The method returns its output in JSON format, and looking at the class it is pretty evident that the
   conversion is done by json.dumps().

   The structure of the code is the following
class DataStats:

    def stats(self, data, iage, isalary):
        [code_part_1]

        return json.dumps({
            [code_part_2]
        })

   Where obviously code_part_2 depends on code_part_1. The first refactoring, then, will follow this
   procedure
    1. We write a test called test__stats() for a _stats() method that is supposed to return the data as
       a Python structure. We can infer this latter manually from the JSON or running json.loads() from
       a Python shell. The test fails.
    2. We duplicate the code of the stats() method that produces the data, putting it in the new
       _stats() method. The test passes.

class DataStats:

    def _stats(parameters):
        [code_part_1]

        return [code_part_2]

    def stats(self, data, iage, isalary):
        [code_part_1]

        return json.dumps({
            [code_part_2]
        })

    1. We remove the duplicated code in stats() replacing it with a call to _stats()

class DataStats:

    def _stats(parameters):
        [code_part_1]

        return [code_part_2]

    def stats(self, data, iage, isalary):
        return json.dumps(
            self._stats(data, iage, isalary)
        )

   At this point we could refactor the initial test test_json() that we wrote, but this is an advanced
   consideration, and I'll leave it for some later notes.

   So now the code of our class looks like this
class DataStats:

    def _stats(self, data, iage, isalary):
        # iage and isalary are the starting age and salary used to
        # compute the average yearly increase of salary.

        # Compute average yearly increase
        average_age_increase = math.floor(
            sum([e['age'] for e in data])/len(data)) - iage
        average_salary_increase = math.floor(
            sum([int(e['salary'][1:]) for e in data])/len(data)) - isalary

        yearly_avg_increase = math.floor(
            average_salary_increase/average_age_increase)

        # Compute max salary
        salaries = [int(e['salary'][1:]) for e in data]
        threshold = '' + str(max(salaries))

        max_salary = [e for e in data if e['salary'] == threshold]

        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        min_salary = [e for e in data if e['salary'] ==
                      '{}'.format(str(min(salaries)))]

        return {
            'avg_age': math.floor(sum([e['age'] for e in data])/len(data)),
            'avg_salary': math.floor(sum(
                [int(e['salary'][1:]) for e in data])/len(data)),
            'avg_yearly_increase': yearly_avg_increase,
            'max_salary': max_salary,
            'min_salary': min_salary
        }

    def stats(self, data, iage, isalary):
        return json.dumps(
            self._stats(data, iage, isalary)
        )

   and we have two tests that check the correctness of it.

Step 3 - Refactoring the tests
   Commit: [19]d619017

   It is pretty clear that the test_data list of dictionaries is bound to be used in every test we will
   perform, so it is high time we moved that to a global variable. There is no point now in using a
   fixture, as the test data is just static data.

   We could also move the output data to a global variable, but the upcoming tests are not using the
   whole output dictionary any more, so we can postpone the decision.

   The test suite now looks like
import json

from datastats.datastats import DataStats


test_data = [
    {
        "id": 1,
        "name": "Laith",
        "surname": "Simmons",
        "age": 68,
        "salary": "27888"
    },
    {
        "id": 2,
        "name": "Mikayla",
        "surname": "Henry",
        "age": 49,
        "salary": "67137"
    },
    {
        "id": 3,
        "name": "Garth",
        "surname": "Fields",
        "age": 70,
        "salary": "70472"
    }
]


def test_json():

    ds = DataStats()

    assert ds.stats(test_data, 20, 20000) == json.dumps(
        {
            'avg_age': 62,
            'avg_salary': 55165,
            'avg_yearly_increase': 837,
            'max_salary': [{
                "id": 3,
                "name": "Garth",
                "surname": "Fields",
                "age": 70,
                "salary": "70472"
            }],
            'min_salary': [{
                "id": 1,
                "name": "Laith",
                "surname": "Simmons",
                "age": 68,
                "salary": "27888"
            }]
        }
    )


def test__stats():

    ds = DataStats()

    assert ds._stats(test_data, 20, 20000) == {
        'avg_age': 62,
        'avg_salary': 55165,
        'avg_yearly_increase': 837,
        'max_salary': [{
            "id": 3,
            "name": "Garth",
            "surname": "Fields",
            "age": 70,
            "salary": "70472"
        }],
        'min_salary': [{
            "id": 1,
            "name": "Laith",
            "surname": "Simmons",
            "age": 68,
            "salary": "27888"
        }]
    }

Step 4 - Isolate the average age algorithm
   Commit: [20]9db1803

   Isolating independent features is a key target of software design. Thus, our refactoring shall aim to
   disentangle the code dividing it into small separated functions.

   The output dictionary contains five keys, and each of them corresponds to a value computed either on
   the fly (for avg_age and avg_salary) or by the method's code (for avg_yearly_increase, max_salary,
   and min_salary). We can start replacing the code that computes the value of each key with dedicated
   methods, trying to isolate the algorithms.

   To isolate some code, the first thing to do is to duplicate it, putting it into a dedicated method.
   As we are refactoring with tests, the first thing is to write a test for this method.
def test__avg_age():

    ds = DataStats()

    assert ds._avg_age(test_data) == 62

   We know that the method's output shall be 62 as that is the value we have in the output data of the
   original stats() method. Please note that there is no need to pass iage and isalary as they are not
   used in the refactored code.

   The test fails, so we can dutifully go and duplicate the code we use to compute 'avg_age'
    def _avg_age(self, data):
        return math.floor(sum([e['age'] for e in data])/len(data))

   and once the test passes we can replace the duplicated code in _stats() with a call to _avg_age()
        return {
            'avg_age': self._avg_age(data),
            'avg_salary': math.floor(sum(
                [int(e['salary'][1:]) for e in data])/len(data)),
            'avg_yearly_increase': yearly_avg_increase,
            'max_salary': max_salary,
            'min_salary': min_salary
        }

   Checking after that that no test is failing. Well done! We isolated the first feature, and our
   refactoring produced already three tests.

Step 5 - Isolate the average salary algorithm
   Commit: [21]4122201

   The avg_salary key works exactly like the avg_age, with different code. Thus, the refactoring process
   is the same as before, and the result should be a new test__avg_salary() test
def test__avg_salary():

    ds = DataStats()

    assert ds._avg_salary(test_data) == 55165

   a new _avg_salary() method
    def _avg_salary(self, data):
        return math.floor(sum([int(e['salary'][1:]) for e in data])/len(data))

   and a new version of the final return value
        return {
            'avg_age': self._avg_age(data),
            'avg_salary': self._avg_salary(data),
            'avg_yearly_increase': yearly_avg_increase,
            'max_salary': max_salary,
            'min_salary': min_salary
        }

Step 6 - Isolate the average yearly increase algorithm
   Commit: [22]4005145

   The remaining three keys are computed with algorithms that, being longer than one line, couldn't be
   squeezed directly in the definition of the dictionary. The refactoring process, however, does not
   really change; as before, we first test a helper method, then we define it duplicating the code, and
   last we call the helper removing the code duplication.

   For the average yearly increase of the salary we have a new test
def test__avg_yearly_increase():

    ds = DataStats()

    assert ds._avg_yearly_increase(test_data, 20, 20000) == 837

   a new method that passes the test
    def _avg_yearly_increase(self, data, iage, isalary):
        # iage and isalary are the starting age and salary used to
        # compute the average yearly increase of salary.

        # Compute average yearly increase
        average_age_increase = math.floor(
            sum([e['age'] for e in data])/len(data)) - iage
        average_salary_increase = math.floor(
            sum([int(e['salary'][1:]) for e in data])/len(data)) - isalary

        return math.floor(average_salary_increase/average_age_increase)

   and a new version of the _stats() method
    def _stats(self, data, iage, isalary):
        # Compute max salary
        salaries = [int(e['salary'][1:]) for e in data]
        threshold = '' + str(max(salaries))

        max_salary = [e for e in data if e['salary'] == threshold]

        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        min_salary = [e for e in data if e['salary'] ==
                      '{}'.format(str(min(salaries)))]

        return {
            'avg_age': self._avg_age(data),
            'avg_salary': self._avg_salary(data),
            'avg_yearly_increase': self._avg_yearly_increase(
                data, iage, isalary),
            'max_salary': max_salary,
            'min_salary': min_salary
        }

   Please note that we are not solving any code duplication but the ones that we introduce to refactor.
   The first achievement we should aim to is to completely isolate independent features.

Step 7 - Isolate max and min salary algorithms
   Commit: [23]17b2413

   When refactoring we shall always do one thing at a time, but for the sake of conciseness, I'll show
   here the result of two refactoring steps at once. I'll recommend the reader to perform them as
   independent steps, as I did when I wrote the code that I am posting below.

   The new tests are
def test__max_salary():

    ds = DataStats()

    assert ds._max_salary(test_data) == [{
        "id": 3,
        "name": "Garth",
        "surname": "Fields",
        "age": 70,
        "salary": "70472"
    }]


def test__min_salary():

    ds = DataStats()

    assert ds._min_salary(test_data) == [{
        "id": 1,
        "name": "Laith",
        "surname": "Simmons",
        "age": 68,
        "salary": "27888"
    }]

   The new methods in the DataStats class are
    def _max_salary(self, data):
        # Compute max salary
        salaries = [int(e['salary'][1:]) for e in data]
        threshold = '' + str(max(salaries))

        return [e for e in data if e['salary'] == threshold]

    def _min_salary(self, data):
        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        return [e for e in data if e['salary'] ==
                '{}'.format(str(min(salaries)))]

   and the _stats() method is now really tiny
    def _stats(self, data, iage, isalary):
        return {
            'avg_age': self._avg_age(data),
            'avg_salary': self._avg_salary(data),
            'avg_yearly_increase': self._avg_yearly_increase(
                data, iage, isalary),
            'max_salary': self._max_salary(data),
            'min_salary': self._min_salary(data)
        }

Step 8 - Reducing code duplication
   Commit: [24]b559a5c

   Now that we have the main tests in place we can start changing the code of the various helper
   methods. These are now small enough to allow us to change the code without further tests. While this
   can be true in this case, however, in general there is no definition of what "small enough" means, as
   there is no real definition of what "unit test" is. Generally speaking you should be confident that
   the change that you are doing is covered by the tests that you have. Weren't this the case, you'd
   better add one or more tests until you feel confident enough.

   The two methods _max_salary() and _min_salary() share a great deal of code, even though the second
   one is more concise
    def _max_salary(self, data):
        # Compute max salary
        salaries = [int(e['salary'][1:]) for e in data]
        threshold = '' + str(max(salaries))

        return [e for e in data if e['salary'] == threshold]

    def _min_salary(self, data):
        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        return [e for e in data if e['salary'] ==
                '{}'.format(str(min(salaries)))]

   I'll start by making explicit the threshold variable in the second function. As soon as I change
   something, I'll run the tests to check that the external behaviour did not change.
    def _max_salary(self, data):
        # Compute max salary
        salaries = [int(e['salary'][1:]) for e in data]
        threshold = '' + str(max(salaries))

        return [e for e in data if e['salary'] == threshold]

    def _min_salary(self, data):
        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        threshold = '{}'.format(str(min(salaries)))

        return [e for e in data if e['salary'] == threshold]

   Now, it is pretty evident that the two functions are the same but for the min() and max() functions.
   They still use different variable names and different code to format the threshold, so my first
   action is to even out them, copying the code of _min_salary() to _max_salary() and changing min() to
   max()
    def _max_salary(self, data):
        # Compute max salary
        salaries = [int(d['salary'][1:]) for d in data]
        threshold = '{}'.format(str(max(salaries)))

        return [e for e in data if e['salary'] == threshold]

    def _min_salary(self, data):
        # Compute min salary
        salaries = [int(d['salary'][1:]) for d in data]
        threshold = '{}'.format(str(min(salaries)))

        return [e for e in data if e['salary'] == threshold]

   Now I can create another helper called _select_salary() that duplicates that code and accepts a
   function, used instead of min() or max(). As I did before, first I duplicate the code, and then
   remove the duplication by calling the new function.

   After some passages, the code looks like this
    def _select_salary(self, data, func):
        salaries = [int(d['salary'][1:]) for d in data]
        threshold = '{}'.format(str(func(salaries)))

        return [e for e in data if e['salary'] == threshold]

    def _max_salary(self, data):
        return self._select_salary(data, max)

    def _min_salary(self, data):
        return self._select_salary(data, min)

   I noticed then a code duplication between _avg_salary() and _select_salary():
    def _avg_salary(self, data):
        return math.floor(sum([int(e['salary'][1:]) for e in data])/len(data))

    def _select_salary(self, data, func):
        salaries = [int(d['salary'][1:]) for d in data]

   and decided to extract the common algorithm in a method called _salaries(). As before, I write the
   test first
def test_salaries():

    ds = DataStats()

    assert ds._salaries(test_data) == [27888, 67137, 70472]

   then I implement the method
    def _salaries(self, data):
        return [int(d['salary'][1:]) for d in data]

   and eventually I replace the duplicated code with a call to the new method
    def _salaries(self, data):
        return [int(d['salary'][1:]) for d in data]

    def _select_salary(self, data, func):
        threshold = '{}'.format(str(func(self._salaries(data))))

        return [e for e in data if e['salary'] == threshold]

   While doing this I noticed that _avg_yearly_increase() contains the same code, and fix it there as
   well.
    def _avg_yearly_increase(self, data, iage, isalary):
        # iage and isalary are the starting age and salary used to
        # compute the average yearly increase of salary.

        # Compute average yearly increase
        average_age_increase = math.floor(
            sum([e['age'] for e in data])/len(data)) - iage
        average_salary_increase = math.floor(
            sum(self._salaries(data))/len(data)) - isalary

        return math.floor(average_salary_increase/average_age_increase)

   It would be useful at this point to store the input data inside the class and to use it as self.data
   instead of passing it around to all the class's methods. This however would break the class's API, as
   currently DataStats is initialised without any data. Later I will show how to introduce changes that
   potentially break the API, and briefly discuss the issue. For the moment, however, I'll keep changing
   the class without modifying the external interface.

   It looks like age has the same code duplication issues as salary, so with the same procedure I
   introduce the _ages() method and change the _avg_age() and _avg_yearly_increase() methods
   accordingly.

   Speaking of _avg_yearly_increase(), the code of that method contains the code of the _avg_age() and
   _avg_salary() methods, so it is worth replacing it with two calls. As I am moving code between
   existing methods, I do not need further tests.
    def _avg_yearly_increase(self, data, iage, isalary):
        # iage and isalary are the starting age and salary used to
        # compute the average yearly increase of salary.

        # Compute average yearly increase
        average_age_increase = self._avg_age(data) - iage
        average_salary_increase = self._avg_salary(data) - isalary

        return math.floor(average_salary_increase/average_age_increase)

Step 9 - Advanced refactoring
   Commit: [25]cc0b0a1

   The initial class didn't have any __init__() method, and was thus missing the encapsulation part of
   the object-oriented paradigm. There was no reason to keep the class, as the stats() method could have
   easily been extracted and provided as a plain function.

   This is much more evident now that we refactored the method, because we have 10 methods that accept
   data as a parameter. I would be nice to load the input data into the class at instantiation time, and
   then access it as self.data. This would greatly improve the readability of the class, and also
   justify its existence.

   If we introduce a __init__() method that requires a parameter, however, we will change the class's
   API, breaking the compatibility with every other code that imports and uses it. Since we want to keep
   it, we have to devise a way to provide both the advantages of a new, clean class and of a stable API.
   This is not always perfectly achievable, but in this case the [26]Adapter design pattern (also known
   as Wrapper) can perfectly solve the issue.

   The goal is to change the current class to match the new API, and then build a class that wraps the
   first one and provides the old API. The strategy is not that different from what we did previously,
   only this time we will deal with classes instead of methods. With a stupendous effort of my
   imagination I named the new class NewDataStats. Sorry, but sometimes you just have to get the job
   done.

   The first things, as happens very often with refactoring, is to duplicate the code, and when we
   insert new code we need to have tests that justify it. The tests will be the same as before, as the
   new class shall provide the same functionalities as the previous one, so I just create a new file,
   called test_newdatastats.py and start putting there the first test test_init().
import json

from datastats.datastats import NewDataStats


test_data = [
    {
        "id": 1,
        "name": "Laith",
        "surname": "Simmons",
        "age": 68,
        "salary": "27888"
    },
    {
        "id": 2,
        "name": "Mikayla",
        "surname": "Henry",
        "age": 49,
        "salary": "67137"
    },
    {
        "id": 3,
        "name": "Garth",
        "surname": "Fields",
        "age": 70,
        "salary": "70472"
    }
]


def test_init():

    ds = NewDataStats(test_data)

    assert ds.data == test_data

   This test doesn't pass, and the code that implements the class is very simple
class NewDataStats:

    def __init__(self, data):
        self.data = data

   Now I can start an iterative process:
    1. I will copy one of the tests of DataStats and adapt it to NewDataStats
    2. I will copy some code from DataStats to NewDataStats, adapting it to the new API and making it
       pass the test.

   At this point iteratively removing methods from DataStats and replacing them with a call to
   NewDataStats would be overkill. I'll show you in the next section why, and what we can do to avoid
   that.

   An example of the resulting tests for NewDataStats is the following
def test_ages():

    ds = NewDataStats(test_data)

    assert ds._ages() == [68, 49, 70]

   and the code that passes the test is
    def _ages(self):
        return [d['age'] for d in self.data]

   Once finished, I noticed that, as now methods like _ages() do not require an input parameter any
   more, I can convert them to properties, changing the tests accordingly.
    @property
    def _ages(self):
        return [d['age'] for d in self.data]

   It is time to replace the methods of DataStats with calls to NewDataStats. We could do it method by
   method, but actually the only thing that we really need is to replace stats(). So the new code is
    def stats(self, data, iage, isalary):
        nds = NewDataStats(data)
        return nds.stats(iage, isalary)

   And since all the other methods are no more used we can safely delete them, checking that the tests
   do not fail. Speaking of tests, removing methods will make many tests of DataStats fail, so we need
   to remove them.
class DataStats:

    def stats(self, data, iage, isalary):
        nds = NewDataStats(data)
        return nds.stats(iage, isalary)

Final words
   I hope this little tour of a refactoring session didn't result too trivial, and helped you to grasp
   the basic concepts of this technique. If you are interested in the subject I'd strongly recommend the
   classic book by Martin Fowler "Refactoring: Improving the Design of Existing Code", which is a
   collection of refactoring patterns. The reference language is Java, but the concepts are easily
   adapted to Python.


---
http://blog.thedigitalcatonline.com/blog/2014/10/14/decorators-and-metaclasses/#.WdXtJls-8-U

Advanced use of Python decorators and metaclasses
14/10/2014 

Abstract
   While introducing people to Python metaclasses I realized that sometimes the big problem of the most
   powerful Python features is that programmers do not perceive how they may simplify their usual tasks.
   Therefore, features like metaclasses are considered a fancy but rather unuseful addition to a
   standard OOP language, instead of a real game changer.

   This post wants to show how to use metaclasses and decorators to create a powerful class that can be
   inherited and customized by easily adding decorated methods.

Metaclasses and decorators: a match made in space
   Metaclasses are a complex topic, and most of the times even advanced programmers do not see a wide
   range of practical uses for them. Chances are that this is the part of Python (or other languages
   that support metaclasses, like Smalltalk and Ruby) that fits the least the "standard" object-oriented
   patterns or solutions found in C++ and Java, just to mention two big players.

   Indeed metaclasess usually come in play when programming advanced libraries or frameworks, where a
   lot of automation must be provided. For example, Django Forms system heavily relies on metaclasses to
   provide all its magic.

   We also have to note, however, that we usually call "magic" or "tricks" all those techniques we are
   not familiar with, and as a result in Python many things are called this way, being its
   implementation often peculiar compared to other languages.

   Time to bring some spice into your programming: let's practice some Python wizardry and exploit the
   power of the language!

   In this post I want to show you an interesting joint use of decorators and metaclasses. I will show
   you how to use decorators to mark methods so that they can be automatically used by the class when
   performing a given operation.

   More in detail, I will implement a class that can be called on a string to "process" it, and show you
   how to implement different "filters" through simple decorated methods. What I want to obtain is
   something like this:
class MyStringProcessor(StringProcessor):
    @stringfilter
    def capitalize(self, str):
        [...]

    @stringfilter
    def remove_double_spaces(self, str):
        [...]

msp = MyStringProcessor()
"A test string" == msp("a test  string")

   The module defines a StringProcessor class that I can inherit and customize adding methods that have
   a standard signature (self, str) and are decorated with @stringfilter. This class can later be
   instantiated and the instance used to directly process a string and return the result. Internally the
   class automatically executes all the decorated methods in succession. I also would like the class to
   obey the order I defined the filters: first defined, first executed.

The Hitchhiker's Guide To Metaclasses
   How can metaclasses help to reach this target?

   Simply put, metaclasses are classes that are instantiated to get classes. That means that whenever I
   use a class, for example to instantiate it, first Python builds that class using the metaclass and
   the class definition we wrote. For example, you know that you can find the class members in the
   __dict__ attribute: this attribute is created by the standard metaclass, which is type.

   Given that, a metaclass is a good starting point for us to insert some code to identify a subset of
   functions inside the definition of the class. In other words, we want the output of the metaclass
   (that is, the class) be built exactly as happens in the standard case, but with an addition: a
   separate list of all the methods decorated with @stringfilter.

   You know that a class has a namespace, that is a dictionary of what was defined inside the class. So,
   when the standard type metaclass is used to create a class, the class body is parsed and a dict()
   object is used to collect the namespace.

   We are however interested in preserving the order of definition and a Python dictionary is an
   unordered structure, so we take advantage of the __prepare__ hook introduced in the class creation
   process with Python 3. This function, if present in the metaclass, is used to preprocess the class
   and to return the structure used to host the namespace. So, following the example found in the
   official documentation, we start defining a metaclass like
class FilterClass(type):
    def __prepare__(name, bases, **kwds):
        return collections.OrderedDict()

   This way, when the class will be created, an OrderedDict will be used to host the namespace, allowing
   us to keep the definition order. Please note that the signature __prepare__(name, bases, **kwds) is
   enforced by the language. If you want the method to get the metaclass as a first argument (because
   the code of the method needs it) you have to change the signature to __prepare__(metacls, name,
   bases, **kwds) and decorate it with @classmethod.

   The second function we want to define in our metaclass is __new__. Just like happens for the
   instantiation of classes, this method is invoked by Python to get a new instance of the metaclass,
   and is run before __init__. Its signature has to be __new__(metacls, name, bases, namespace, **kwds)
   and the result shall be an instance of the metaclass. As for its normal class counterpart (after all
   a metaclass is a class), __new__() usually wraps the same method of the parent class, type in this
   case, adding its own customizations.

   The customization we need is the creation of a list of methods that are marked in some way (the
   decorated filters). Say for simplicity's sake that the decorated methods have an attribute _filter.

   The full metaclass is then
class FilterClass(type):
    @classmethod
    def __prepare__(name, bases, **kwds):
        return collections.OrderedDict()

    def __new__(metacls, name, bases, namespace, **kwds):
        result = type.__new__(metacls, name, bases, dict(namespace))
        result._filters = [
            value for value in namespace.values() if hasattr(value, '_filter')]
        return result

   Now we have to find a way to mark all filter methods with a _filter attribute.

The Anatomy of Purple Decorators
   decorate: to add something to an object or place, especially in order to make it more attractive
   (Cambridge Dictionary)

   Decorators are, as the name suggests, the best way to augment functions or methods. Remember that a
   decorator is basically a callable that accepts another callable, processes it, and returns it.

   Used in conjunction with metaclasses, decorators are a very powerful and expressive way to implement
   advanced behaviours in our code. In this case we may easily use them to add an attribute to decorated
   methods, one of the most basic tasks for a decorator.

   I decided to implement the @stringfilter decorator as a function, even if I usually prefer
   implementing them as classes. The reason is that decorator classes behave differently when used to
   implement decorators without arguments rather than decorators with arguments. In this case this
   difference would force to write some complex code and an explanation of that would be overkill now.
   In a future post on dectorators you will find all the gory details, but in the meantime you may check
   the three Bruce Eckel posts listed in the references section.

   The decorator is very simple:
def stringfilter(func):
    func._filter = True
    return func

   As you can see the decorator just creates an attribute called _filter into the function (remember
   that functions are objects). The actual value of this attribute is not important in this case, since
   we are just interested in telling apart class members that contain it.

The Dynamics of a Callable Object
   We are used to think about functions as special language components that may be "called" or executed.
   In Python functions are objects, just like everything else, and the feature that allows them to be
   executed comes from the presence of the __call__() method. Python is polymorphic by design and based
   on delegation, so (almost) everything that happens in the code relies on some features of the target
   object.

   The result of this generalization is that every object that contains the __call__() method may be
   executed like a function, and gains the name of callable object.

   The StringProcessor class shall thus contain this method and perform there the string processing with
   all the contained filters. The code is
class StringProcessor(metaclass=FilterClass):

    def __call__(self, string):
        _string = string
        for _filter in self._filters:
            _string = _filter(self, _string)

        return _string

   A quick review of this simple function shows that it accepts the string as an argument, stores it in
   a local variable and loops over the filters, executing each of them on the local string, that is on
   the result of the previous filter.

   The filter functions are extracted from the self._filters list, that is compiled by the FilterClass
   metaclass we already discussed.

   What we need to do now is to inherit from StringProcessor to get the metaclass machinery and the
   __call__() method, and to define as many methods as needed, decorating them with the @stringfilter
   decorator.

   Note that, thanks to the decorator and the metaclass, you may have other methods in your class that
   do not interfere with the string processing as long as they are not decorated with the decorator
   under consideration.

   An example derived class may be the following
class MyStringProcessor(StringProcessor):

    @stringfilter
    def capitalize(self, string):
        return string.capitalize()

    @stringfilter
    def remove_double_spaces(self, string):
        return string.replace('  ', ' ')

   The two capitalize() and remove_double_spaces() methods have been decorated, so they will be applied
   in order to any string passed when calling the class. A quick example of this last class is
>>> import strproc
>>> msp = strproc.MyStringProcessor()
>>> input_string = "a test  string"
>>> output_string = msp(input_string)
>>> print("INPUT STRING:", input_string)
INPUT STRING: a test  string
>>> print("OUTPUT STRING:", output_string)
OUTPUT STRING: A test string
>>>

   That's it!

Final words
   There are obviously other ways to accomplish the same task, and this post wanted just to give a
   practical example of what metaclasses are good for, and why I think that they should be part of any
   Python programmer's arsenal.

   [Update] Some developers [16]on Reddit and Linkedin raised objections to the content of the post
   mainly about the fact that the example may be perfectly implemented without metaclasses and about the
   dangerous nature of metaclasses. Since I try to learn from everyone, I thank them for their
   suggestions.

   It is especially interesting to know that some developers consider the use of metaclasses a risky
   business, because they hide a lot of the structure of the class and the underlying machinery. This is
   true, so (as you should do for other technologies), think carefully about the reasons that drive you
   to use metaclasses, and be sure you know them well.

Book Trivia

   Section titles come from the following books: A Match Made in Space - George McFly, The Hitchhiker's
   Guide To the Galaxy - Various Authors, The Anatomy of Purple Dragons - Unknown, The Dynamics of an
   Asteroid - James Moriarty.

Source code

   The [17]strproc.py file contains the full source code used in this post.
        http://blog.thedigitalcatonline.com/code/metaclasses/strproc.py

   
**************************************************************************************************************
<code>
# strproc.py
# This file implements the technique explained at
# http://lgiordani.com/blog/2014/10/14/decorators-and-metaclasses/

import collections


class FilterClass(type):

    """
    A metaclass that extracts all methods that have
    a _filter attribute and lists them in order in
    the _filters attribute of the class.
    """

    def __prepare__(name, bases, **kwds):
        # This returns an OrderedDict to host the namespace of the created
        # class
        return collections.OrderedDict()

    def __new__(metacls, name, bases, namespace, **kwds):
        # This method returns an instance of the metaclass
        # aka the created class.

        # Just call the standard creation method
        result = type.__new__(metacls, name, bases, dict(namespace))

        # Process all namespace items and extract the marked ones
        result._filters = [
            value for value in namespace.values() if hasattr(value, '_filter')]
        return result


def stringfilter(func):
    # Just sets the _filter attribute in the input callable
    func._filter = True
    return func


class StringProcessor(metaclass=FilterClass):

    """
    A callable class that filters strings.
    It may be given methods decorated with @stringfilter and it will apply
    them on the input string in definition order.
    """

    def __call__(self, string):
        _string = string

        # Loop on filters and apply them on the string
        for _filter in self._filters:
            _string = _filter(self, _string)

        return _string


class MyStringProcessor(StringProcessor):

    @stringfilter
    def capitalize(self, string):
        # This filter just returns the string with the first letter uppercase
        return string.capitalize()

    @stringfilter
    def remove_double_spaces(self, string):
        # This filter replaces double spaces with single ones
        return string.replace('  ', ' ')

if __name__ == '__main__':
    msp = MyStringProcessor()
    input_string = "a test  string"
    output_string = msp(input_string)
    print("INPUT STRING:", input_string)
    print("OUTPUT STRING:", output_string)
</code>
**************************************************************************************************************
