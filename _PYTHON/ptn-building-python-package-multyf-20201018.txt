https://towardsdatascience.com/how-to-build-your-first-python-package-6a00b02635c9

How to Build Your First Python Package

   About two years ago I published my very first data-science related blogpost. It was about
   Categorical Correlations, and I honestly thought no-one will find it useful. It was
   just experimental, and for myself. 1.7K claps later, I've learned that I cannot determine
   what other people will find useful, and I'm quite happy I can assist others on the web like
   others on the web assist me.

   I was also quite new to Python and Github at that time, so I also experimented with writing
   the code to these categorical-correlations that I wrote about, and publishing it on Github.
   I gave that piece of code a name: Dython, as in Data tools for pYTHON.

   But this isn't what this blogpost is about - it's about the last experimental thing I did
   after everything I just mentioned: I created a Python library and uploaded it to PyPI -
   which you might know as pip install. Again, this all began just as a learning exercise -
   but with around 1.5K installs per month, I realized again that I underestimated my code
   ability to be useful to others.

   But why am I telling you all this? Because almost everyone has some cool code lying
   somewhere on their laptop or on their Github account. This cool code might be very helpful
   to others - though most us think that's probably not true, and "what value can others find
   in my tiny piece of code". I thought so too, and I found out that I was wrong. You might be
   wrong too, and I'm here to persuade you - and assist you - to make your nifty piece of code
   into a full grown Python package in just a few steps - so you can save others hours of
   programming with a single pip install. Be the person that assists other programmers - and
   let me show you how to accomplish this in just six steps. Let's do this.

Before We Begin: Code Cleanup & Source Control
   I believe it quite goes withou2,3}t saying, but still - I'd like to make sure we're on the same
   page. Programmers are divided intotwo types: the ones which write readable code, and the
   ones which use variables named x, x1, x2, yx, etc. If you belong to the first type, you can
   skip ahead. If you're the second type - it's time to switch to the other side. Remember
   that other people will read your code, so make sure it's readable. Give things meaningful
   names, break long functions to short-coded one-purpose methods, etc. You know, like they
   teach in all those coding courses.

   Another thing I assume is that you're using some source-control, probably GitHub. While
   this isn't really required, it is more than recommended. If you've never used GitHub
   before, this is a good point to take a few minutes and learn how - check out the
   official tutorial, or this blog-post, and get started.

Step 1: Choose Your API
   The first real step into turning your code into a package, is deciding how users should use
   it - and make it importable. We'll split this into two actions:

#1: Public and Private Methods
   Your code is probably made of several functions and methods, but not all are meant to be
   used by the users - some are internal functions, supposed to be used only by your code.
   While Python doesn't support private methods, the convention is to mark private methods
   with an underscore prefix: def _private_function(). Rename all your internal functions like
   so, so users will easily understand what is supposed to be exposed to them and what isn't.

   Pro tip: You can use the special variable __all__ to define exactly which functions to
   expose and which not when the users use from your_package import *. Check out this
   thread on StackOverflow for more information.

#2: Adding __init__.py
   If your code is made out of several modules (files), looking like this:
your_package
  |-- module1.py
  |-- module2.py

   You'll need to add another file, __init__.py to your package in order to make Python
   interpret the your_package directory as a Python package. This means now it should look
   like this:
your_package
  |-- __init__.py
  |-- module1.py
  |-- module2.py

   You can leave the file empty as a starting point, but it has to be there in order to allow
   from your_package import module1.

   Pro tip: The code in __init__.py is executed once your package is being imported, and this
   allows you to do all sorts of cool stuff. For example, you can use __init__.py to shorten
   your API. Let's say that the most important method of your code, imp_func, is found in
   module1 . You can allow the users to import it as from your_package import imp_func instead
   of from your_package.module1 import imp_func, by simply adding:
from .module1 import imp_func

   to your __init__.py file.

Step 2: Document
   Documentation is like lining up in a queue - we wish everyone would simply do it, but we
   tend to cut ourselves some slack whenever we can. Step 2 here relates to the previous
   Before We Begin section, as it meant to allow other people to understand what does your
   code do. There are two types of documentations you'll need to add:

#1: Docstrings
   Each function in your library should have a doc-string, which summarizes what the function
   is all about. It should contain:
     * Summary: Explain in a simple language what the function suppose to do
     * Parameters: Explain what are the parameters and parameter-types which the function
       expects
     * Return value: Explain what the function returns
     * Example: While not a must, it is always useful to add a usage example

   Here's an example:

   You can learn more about doc-string formats in this super cool article on DataCamp.

#2: Read-Me
   A Read-Me file is a summary of what your package is all about. When placed in the top
   directory of your package, GitHub uses it as your package "landing-page", being displayed
   to visitors as the first thing they see.

   A good Read-Me file will have an overview of the package, installation information (such as
   requirements) and some Quick-Start examples, describing basic usage of your package.

   Read-Me files are usually written in a format known as MarkDown, which you can learn more
   about here. This is why they're usually named README.md.

Step 3: License
   As your code is about to get public, you should attach a license to it, explaining others
   how they should use your code. You'll probably want to use a common one like the MIT
   License or Apache 2.0 License. GitHub will assist you choosing one by clicking the
   License option, and it will add a new file named LICENSE to your package. If you insist on
   not using GitHub, you can add the file manually.

Step 4: Rearrange for Packaging

   At this point, your package is supposed to look like this:
your_package
  |-- README.md
  |-- LICENSE
  |-- __init__.py
  |-- module1.py
  |-- module2.py

   Now we'll add the file that builds an installable Python package out of your code. For
   this, you'll have to add a new file named setup.py, and rearrange your files in the
   following way:
your_package
  |-- setup.py
  |-- README.md
  |-- LICENSE
  |-- your_package
        |-- __init__.py
        |-- module1.py
        |-- module2.py

   The setup file dictates everything Python installer needs to know when installing your
   package. A very basic one which you can simply copy-paste, looks like this:

   Except for editing your personal info, there are two things you'll have to keep track of:
     * Version: Each time you'll release a new build to PyPI (which we'll discuss in a
       second), you'll have to bump your version number
     * Install requires: This is a list of all the external dependencies of your package. Be
       sure to list everything here, so Python will install them along with your package

Step 5: Sign-Up to PyPI
   We're almost there! Next up: go to pypi.org and create an account. You'll need it to
   upload your new library.

Step 6: Build & Deploy!
   We are pretty much done. All that's left is running some commands which will build an
   installable Python package out of your code - and deploy it to PyPI.

   Before we begin, we'll need to install twine, which will allow us to deploy to PyPI. It is
   as simple as:
pip install twine

   Next, we'll create an installable package. Go to the directory where the setup.py file is,
   and run:
python setup.py sdist bdist_wheel

   This will create several new directories, such as dist, build and your_package.egg-info.
   It's dist which we care about now, as it contains the installation files we want to deploy
   to PyPI. You'll find two files in there: a compressed tar file and a wheel file. And in
   a second, they'll be available to the whole world.

   Pro tip: Add these directories to your .gitignore file, to prevent pushing installation
   files to your repo. (Never heard of .gitignore? Read this)

   Next up, verify the distribution files you just created are okay by running:
twine check dist/*

   Time to upload your package to PyPI. I recommend deploying first to the PyPI test domain,
   so you can verify everything looks as you intended. Do this using:
twine upload --repository-url https://test.pypi.org/legacy/ dist/*

   Go to test.pypi.org and check your new library. Satisfied? Great, let's push it to the
   real PyPI:
twine upload dist/*

   That's it. From now on everyone can install your package using pip install. Great job!

   Pro tip: You can make your life easier with a Bash script, which will build, check and
   deploy your package with a single command. Create a new file named build_deploy.sh in the
   same directory as setup.py. Copy-paste the following code into this file:

   Now all you need to do is run:
./build_deploy.sh

   From the directory where the file is at, and that's it. You can also run:
./build_deploy.sh --test

   to upload to the test domain. (Note you'll have to make the script executable before
   running it the first time. Simply run chmod +x build_deploy.sh in the directory where the
   file is located.)

The Extra Mile: Write a Blogpost
   Your awesome code is now available for everyone to use - but people are still unaware of
   your awesome code which is now available to them. How can you let them know? Write a
   blog-post, and tell why you build this code in the first place, and what are its use-cases.
   Share your story, so others will know how much effort you just saved them with your awesome
   code.

Final Words
   Taking your code into the next level - publishing it to the world - might seem frightening
   when doing it for the first time, both for personal reasons ("who will want to use it?")
   and for technical reasons ("how can I do it?"). I hope that in this post, I assisted you to
   overcome both these setbacks, and now you too can assist thousands of other programmers
   worldwide. Well done, and welcome to the open-source community!


---
https://docs.github.com/en/free-pro-team@latest/actions/guides/building-and-testing-python

Building and testing Python

   You can create a continuous integration (CI) workflow to build and test your Python
   project.

In this article

     * Introduction
     * Prerequisites
     * Starting with the Python workflow template
     * Specifying a Python version
     * Installing dependencies
     * Testing your code
     * Packaging workflow data as artifacts
     * Publishing to package registries

Introduction
   This guide shows you how to build, test, and publish a Python package.

   GitHub-hosted runners have a tools cache with pre-installed software, which includes Python
   and PyPy. You donʼt have to install anything! For a full list of up-to-date software and
   the pre-installed versions of Python and PyPy, see "Specifications for GitHub-hosted
   runners".

Prerequisites
   You should be familiar with YAML and the syntax for GitHub Actions. For more information,
   see "Learn GitHub Actions."

   We recommend that you have a basic understanding of Python, PyPy, and pip. For more
   information, see:
     * Getting started with Python
     * PyPy
     * Pip package manager

Starting with the Python workflow template
   GitHub provides a Python workflow template that should work for most Python projects. This
   guide includes examples that you can use to customize the template. For more information,
   see the Python workflow template.

   To get started quickly, add the template to the .github/workflows directory of your
   repository.
name: Python package

on: [push]

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [2.7, 3.5, 3.6, 3.7, 3.8]

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    - name: Test with pytest
      run: |
        pytest

Specifying a Python version
   To use a pre-installed version of Python or PyPy on a GitHub-hosted runner, use the
   setup-python action. This action finds a specific version of Python or PyPy from the tools
   cache on each runner and adds the necessary binaries to PATH, which persists for the rest
   of the job. If a specific version of Python is not pre-installed in the tools cache, the
   setup-python action will download and set up the appropriate version from the
   python-versions repository.

   Using the setup-python action is the recommended way of using Python with GitHub Actions
   because it ensures consistent behavior across different runners and different versions of
   Python. If you are using a self-hosted runner, you must install Python and add it to PATH.
   For more information, see the setup-python action.

   The table below describes the locations for the tools cache in each GitHub-hosted runner.
--------------------------------------------------------------------------------------------------------------
            Ubuntu                         Mac                                      Windows
--------------------------------------------------------------------------------------------------------------
Tool Cache  /opt/hostedtoolcache/*         /Users/runner/hostedtoolcache/*          C:\hostedtoolcache\windows\*
Directory
--------------------------------------------------------------------------------------------------------------
Python Tool /opt/hostedtoolcache/Python/*  /Users/runner/hostedtoolcache/Python/*   C:\hostedtoolcache\windows\Python\*
Cache
--------------------------------------------------------------------------------------------------------------
PyPy Tool   /opt/hostedtoolcache/PyPy/*    /Users/runner/hostedtoolcache/PyPy/*     C:\hostedtoolcache\windows\PyPy\*
Cache
--------------------------------------------------------------------------------------------------------------

   If you are using a self-hosted runner, you can configure the runner to use the setup-python
   action to manage your dependencies. For more information, see using setup-python with
   a self-hosted runner in the setup-python README.

   GitHub supports semantic versioning syntax. For more information, see "Using semantic
   versioning" and the "Semantic versioning specification."

Using multiple Python versions
name: Python package
on: [push]
jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      # You can use PyPy versions in python-version.
      # For example, pypy2 and pypy3
      matrix:
        python-version: [2.7, 3.5, 3.6, 3.7, 3.8]

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    # You can test your matrix by printing the current Python version
    - name: Display Python version
      run: python -c "import sys; print(sys.version)"

Using a specific Python version
   You can configure a specific version of python. For example, 3.8. Alternatively, you can
   semantic version syntax to get the latest minor release. This example uses the latest minor
   release of Python 3.
name: Python package
on: [push]
jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.x
      uses: actions/setup-python@v2
      with:
        # Semantic version range syntax or exact version of a Python version
        python-version: ʼ3.xʼ
        # Optional - x64 or x86 architecture, defaults to x64
        architecture: ʼx64ʼ
    # You can test your matrix by printing the current Python version
    - name: Display Python version
      run: python -c "import sys; print(sys.version)"

Excluding a version
   If you specify a version of Python that is not available, setup-python fails with an error
   such as: ##[error]Version 3.4 with arch x64 not found. The error message includes the
   available versions.

   You can also use the exclude keyword in your workflow if there is a configuration of Python
   that you do not wish to run. For more information, see "Workflow syntax for GitHub
   Actions."
name: Python package
on: [push]
jobs:
  build:

    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: [2.7, 3.6, 3.7, 3.8, pypy2, pypy3]
        exclude:
          - os: macos-latest
            python-version: 3.6
          - os: windows-latest
            python-version: 3.6

Using the default Python version
   We recommend using setup-python to configure the version of Python used in your workflows
   because it helps make your dependencies explicit. If you donʼt use setup-python, the
   default version of Python set in PATH is used in any shell when you call python. The
   default version of Python varies between GitHub-hosted runners, which may cause unexpected
   changes or use an older version than expected.
   GitHub-hosted runner Description
   Ubuntu Ubuntu runners have multiple versions of system Python installed under
   /usr/bin/python and /usr/bin/python3. The Python versions that come packaged with Ubuntu
   are in addition to the versions that GitHub installs in the tools cache.
   Windows Excluding the versions of Python that are in the tools cache, Windows does not ship
   with an equivalent version of system Python. To maintain consistent behavior with other
   runners and to allow Python to be used out-of-the-box without the setup-python action,
   GitHub adds a few versions from the tools cache to PATH.
   macOS The macOS runners have more than one version of system Python installed, in addition
   to the versions that are part of the tools cache. The system Python versions are located in
   the /usr/local/Cellar/python/* directory.

Installing dependencies
   GitHub-hosted runners have the pip package manager installed. You can use pip to install
   dependencies from the PyPI package registry before building and testing your code. For
   example, the YAML below installs or upgrades the pip package installer and the setuptools
   and wheel packages.

   You can also cache dependencies to speed up your workflow. For more information, see
   "Caching dependencies to speed up your workflow."
steps:
- uses: actions/checkout@v2
- name: Set up Python
  uses: actions/setup-python@v2
  with:
    python-version: ʼ3.xʼ
- name: Install dependencies
  run: python -m pip install --upgrade pip setuptools wheel

Requirements file
   After you update pip, a typical next step is to install dependencies from requirements.txt.
steps:
- uses: actions/checkout@v2
- name: Set up Python
  uses: actions/setup-python@v2
  with:
    python-version: ʼ3.xʼ
- name: Install dependencies
  run: |
    python -m pip install --upgrade pip
    pip install -r requirements.txt

Caching Dependencies
   You can cache pip dependencies using a unique key, and restore the dependencies when you
   run future workflows using the cache action. For more information, see "Caching
   dependencies to speed up workflows."

   Pip caches dependencies in different locations, depending on the operating system of the
   runner. The path youʼll need to cache may differ from the Ubuntu example below depending on
   the operating system you use. For more information, see Python caching examples.
steps:
- uses: actions/checkout@v2
- name: Setup Python
  uses: actions/setup-python@v2
  with:
    python-version: ʼ3.xʼ
- name: Cache pip
  uses: actions/cache@v2
  with:
    # This path is specific to Ubuntu
    path: ~/.cache/pip
    # Look to see if there is a cache hit for the corresponding requirements file
    key: ${{ runner.os }}-pip-${{ hashFiles(ʼrequirements.txtʼ) }}
    restore-keys: |
      ${{ runner.os }}-pip-
      ${{ runner.os }}-
- name: Install dependencies
  run: pip install -r requirements.txt

   Note: Depending on the number of dependencies, it may be faster to use the dependency
   cache. Projects with many large dependencies should see a performance increase as it cuts
   down the time required for downloading. Projects with fewer dependencies may not see a
   significant performance increase and may even see a slight decrease due to how pip installs
   cached dependencies. The performance varies from project to project.

Testing your code
   You can use the same commands that you use locally to build and test your code.

Testing with pytest and pytest-cov
   This example installs or upgrades pytest and pytest-cov. Tests are then run and output in
   JUnit format while code coverage results are output in Cobertura. For more information, see
   JUnit and Cobertura.
steps:
- uses: actions/checkout@v2
- name: Set up Python
  uses: actions/setup-python@v2
  with:
    python-version: ʼ3.xʼ
- name: Install dependencies
  run: |
    python -m pip install --upgrade pip
    pip install -r requirements.txt
- name: Test with pytest
  run: |
    pip install pytest
    pip install pytest-cov
    pytest tests.py --doctest-modules --junitxml=junit/test-results.xml --cov=com --cov-report=xml -
-cov-report=html

Using Flake8 to lint code

   The following example installs or upgrades flake8 and uses it to lint all files. For more
   information, see Flake8.
steps:
- uses: actions/checkout@v2
- name: Set up Python
  uses: actions/setup-python@v2
  with:
    python-version: ʼ3.xʼ
- name: Install dependencies
  run: |
    python -m pip install --upgrade pip
    pip install -r requirements.txt
- name: Lint with flake8
  run: |
    pip install flake8
    flake8 .

Running tests with tox
   With GitHub Actions, you can run tests with tox and spread the work across multiple jobs.
   Youʼll need to invoke tox using the -e py option to choose the version of Python in your
   PATH, rather than specifying a specific version. For more information, see tox.
name: Python package

on: [push]

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python: [2.7, 3.7, 3.8]

    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python }}
      - name: Install Tox and any other packages
        run: pip install tox
      - name: Run Tox
        # Run tox using the version of Python in `PATH`
        run: tox -e py

Packaging workflow data as artifacts
   You can upload artifacts to view after a workflow completes. For example, you may need to
   save log files, core dumps, test results, or screenshots. For more information, see
   "Persisting workflow data using artifacts."

   The following example demonstrates how you can use the upload-artifact action to archive
   test results from running pytest. For more information, see the upload-artifact
   action.
name: Python package

on: [push]

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [2.7, 3.5, 3.6, 3.7, 3.8]

      steps:
      - uses: actions/checkout@v2
      - name: Setup Python # Set Python version
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      # Install pip and pytest
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest
      - name: Test with pytest
        run: pytest tests.py --doctest-modules --junitxml=junit/test-results-${{ matrix.python-versi
on }}.xml
      - name: Upload pytest test results
        uses: actions/upload-artifact@v2
        with:
          name: pytest-results-${{ matrix.python-version }}
          path: junit/test-results-${{ matrix.python-version }}.xml
        # Use always() to always run this step to publish test results when there are test failures
        if: ${{ always() }}

Publishing to package registries
   You can configure your workflow to publish your Python package to any package registry
   youʼd like when your CI tests pass.

   You can store any access tokens or credentials needed to publish your package using
   repository secrets. The following example creates and publishes a package to PyPI using
   twine and dist. For more information, see "Creating and using encrypted secrets."
name: Upload Python Package

on:
  release:
    types: [created]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: ʼ3.xʼ
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install setuptools wheel twine
    - name: Build and publish
      env:
        TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}
        TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}
      run: |
        python setup.py sdist bdist_wheel
        twine upload dist/*

   For more information about the template workflow, see python-publish.


---
https://www.tutorialsteacher.com/python/python-package

Python - Packages

   We organize a large number of files in different folders and subfolders based on some
   criteria, so that we can find and manage them easily. In the same way, a package in Python
   takes the concept of the modular approach to next logical level. As you know, a module
   can contain multiple objects, such as classes, functions, etc. A package can contain one or
   more relevant modules. Physically, a package is actually a folder containing one or more
   module files.

   Let's create a package named mypackage, using the following steps:
     * Create a new folder named D:\MyApp.
     * Inside MyApp, create a subfolder with the name 'mypackage'.
     * Create an empty __init__.py file in the mypackage folder.
     * Using a Python-aware editor like IDLE, create modules greet.py and functions.py with
       following code:

   greet.py
   (BUTTON) Copy
def SayHello(name):
    print("Hello " + name)
    return

   functions.py
   (BUTTON) Copy
def sum(x,y):
    return x+y

def average(x,y):
    return (x+y)/2

def power(x,y):
    return x**y

   That's it. We have created our package called mypackage. The following is a folder
   structure:
   Package Folder Structure Package Folder Structure

Importing a Module from a Package
   Now, to test our package, invoke the Python prompt from the MyApp folder.
   D:\MyApp>python

   Import the functions module from the mypackage package and call its power() function.
   >>> from mypackage import functions
   >>> functions.power(3,2)
   9

   It is also possible to import specific functions from a module in the package
   >>> from mypackage.functions import sum
   >>> sum(10,20)
   30
   >>> average(10,12)
   Traceback (most recent call last):
   File "<pyshell#13>", line 1, in <module>
   NameError: name 'average' is not defined

__init__.py
   The package folder contains a special file called __init__.py, which stores the package's
   content. It serves two purposes:
    1. The Python interpreter recognizes a folder as the package if it contains __init__.py
       file.
    2. __init__.py exposes specified resources from its modules to be imported.

   An empty __init__.py file makes all functions from above modules available when this
   package is imported. Note that __init__.py is essential for the folder to be recognized by
   Python as a package. You can optionally define functions from individual modules to be made
   available.
   Note:
   We shall also create another Python script in the MyApp folder and import the mypackage
   package in it. It should be at the same level of the package to be imported.

   The __init__.py file is normally kept empty. However, it can also be used to choose
   specific functions from modules in the package folder and make them available for import.
   Modify __init__.py as below:
   __init__.py
   (BUTTON) Copy
from .functions import average, power
from .greet import SayHello

   The specified functions can now be imported in the interpreter session or another
   executable script.

   Create test.py in the MyApp folder to test mypackage.
   test.py
   (BUTTON) Copy
from mypackage import power, average, SayHello
SayHello()
x=power(3,2)
print("power(3,2) : ", x)

   Note that functions power() and SayHello() are imported from the package and not from their
   respective modules, as done earlier. The output of above script is:
   D:\MyApp>python test.py
   Hello world
   power(3,2) : 9

Install a Package Globally
   Once a package is created, it can be installed for system wide use by running the setup
   script. The script calls setup() function from setuptools module.

   Let's install mypackage for system-wide use by running a setup script.

   Save the following code as setup.py in the parent folder 'MyApp'. The script calls the
   setup() function from the setuptools module. The setup() function takes various arguments
   such as name, version, author, list of dependencies etc. The zip_safe argument defines
   whether the package is installed in compressed mode or regular mode.
   Example: setup.py
   (BUTTON) Copy
from setuptools import setup
setup(name='mypackage',
version='0.1',
description='Testing installation of Package',
url='#',
author='malhar',
author_email='mlathkar@gmail.com',
license='MIT',
packages=['mypackage'],
zip_safe=False)

   Now execute the following command to install mypack using the pip utility. Ensure that the
   command prompt is in the parent folder, in this case D:\MyApp.
   D:\MyApp>pip install .
   Processing d:\MyApp
   Installing collected packages: mypack
   Running setup.py install for mypack ... done
   Successfully installed mypackage-0.1

   Now mypackage is available for system-wide use and can be imported in any script or
   interpreter.
   D:\>python
   >>> import mypackage
   >>>mypackage.average(10,20)
   15.0
   >>>mypackage.power(10,2)
   100

   You may also want to publish the package for public use. PyPI (stands for Python Package
   Index) is a repository of Python packages and is hosted at www.pypi.org. Those
   interested in finding out more about the procedure of uploading a package to PyPI visit
   https://packaging.python.org/distributing.


---
