filename: ptn_packaging_python_projects_2-multif_20181211.txt
https://www.digitalocean.com/community/tutorials/how-to-package-and-distribute-python-applications

How To Package And Distribute Python Applications
January 14, 2014 

Introduction
   All Python libraries (i.e. application packages) that you download using a package manager (e.g. pip)
   are distributed using a utility dedicated to do the job. These utilities create "Python
   distributions" which are basically versioned (and compressed) archives. All related elements to
   what's being distributed, such as source files and resource files, are contained within it.

   In this DigitalOcean article, we are going to talk about the necessary tools for distribution and go
   over the key steps to allow you to package your own useful libraries, modules, or applications --
   which should help you when deploying your project on a droplet or sharing on the internet.

Python Distributions and Packages
   Even if you have worked only a little with Python, you will be familiar with the concept of using a
   package manager (e.g. pip, easy_install) to download modules and libraries (e.g. application
   development frameworks) which are then imported and used to create a new one.

   These package management tools, operating locally, connect to a source (i.e. Python Package Index -
   PyPI) and perform a desired action (e.g. search and install) as they work these resources which are
   actually called Python distributions.

   The way to distribute an application consists of wrapping its directory with some must-have files
   (along with a few recommended ones), specifying related elements (e.g. resources, dependencies etc.)
   and releasing it or using it elsewhere...that simple.

   Note: You are highly encouraged to work with virtual environments to isolate Python downloads,
   modules, and applications you are working with.

Python Packages
   In Python, a package [technically] is an importable directory (with __init__.py) containing source
   files (i.e. modules). This shall not be confused with operating-system packages, which are
   [technically] actual applications (i.e. a Debian package). However, it must be noted that Python
   distributions are indeed called packages as well.

   Example package structure:
package
  |
  |-- __init__.py

Python Applications
   Although anything from a single file to one with hundreds scattered across various packages can be
   considered an application in Python, in most realistic scenarios, an application will consist of
   multiple modules and a certain amount of external imports (from libraries).

   Example application structure:
myapp
  |
  |-- __init__.py
  |-- amodule.py
  |-- anothermod.py
  |__ tests
  |     |
  |     |-- __init__.py
  |     |-- ..
  |     |-- .
  | ..

Python Distribution Tools and Libraries
   Given the popular nature of Python and the rich amount of third-party libraries / applications
   written for it, a simpler and unified way of distributing has always been a necessity. There have
   been several different tools and libraries used for creating Python distributions.

   In order to deal with the tasks of distribution, Python distribution utilities toolset distutils was
   created.

Python Package Index (PyPI)
   Python Package Index, or PyPI, is a central [online] repository for projects (Python distributions).
   Package managing tools such as pip use this repository in order to host, find and install them.

Getting Started
   Let"s begin with creating a simple, general Python flask application [structure] which we then can
   use to package.

Creating the Application Structure
   We aim to create an example that resembles most real-world projects. Therefore, it will be best to
   imagine a scenario with modularised components.

   Example structure:
/MyApplication
    |-- run.py
    |-- config.py
    |__ /app
         |-- __init__.py
         |-- /module_one
             |-- __init__.py
             |-- controllers.py
             |-- models.py
         |__ /templates
             |-- module_one
                 |-- hello.html
         |__ /static
         |__ ..
         |__ .

Create the folders:

mkdir ~/MyApplication
cd    ~/MyApplication
touch run.py
touch config.py
mkdir app
cd    app
touch __init__.py
mkdir templates
mkdir static
mkdir module_one
cd    module_one
touch __init__.py
touch controllers.py
touch models.py
cd    ../templates
mkdir module_one
cd    module_one
touch hello.html

Edit run.py using nano:
nano ~/MyApplication/run.py

   Place the contents:
# Run a test server.
from app import app
app.run(debug=True)

   Save and exit using CTRL+X and confirm with with Y.

Edit config.py using nano:
nano ~/MyApplication/config.py

   Place the contents:
DEBUG = True

THREADS_PER_PAGE = 4

CSRF_ENABLED     = True
CSRF_SESSION_KEY = "secret"

   Save and exit using CTRL+X and confirm with with Y.

Edit app/init.py using nano:
nano ~/MyApplication/app/__init__.py

   Place the contents:
from flask import Flask, render_template

app = Flask(__name__)
app.config.from_object("config")

from app.module_one.controllers import module_one

app.register_blueprint(module_one)

   Save and exit using CTRL+X and confirm with with Y.

Edit app/module_one/controllers.py using nano:
nano app/module_one/controllers.py

   Place the contents:
from flask import Blueprint, request, render_template

module_one = Blueprint("auth", __name__, url_prefix="/auth")

@module_one.route("/hello")
def hello():
    return render_template("module_one/hello.html")

   Save and exit using CTRL+X and confirm with with Y.

   Place the contents:

Edit app/templates/module_one/hello.html using nano:
nano app/templates/module_one/hello.html

   Place the contents:
    &lt!DOCTYPE html>
    &lthtml lang="en">
    &lthead>
        &lttitle>{% block title %}My Site{% endblock %}
        {% block css %}
        {% endblock %}
        &ltmeta name="viewport" content="width=device-width, initial-scale=1.0">
      &lt/head>
    &ltbody>
    Hello, world!
    &lt/body>
    &lt/html>

   Save and exit using CTRL+X and confirm with with Y.

Beginning with Application Distribution / Packaging
   Having created an exemplary application structure of a web site that uses flask, we can continue with
   taking the first step into preparing the distribution.

Altering the Folder Structure
   In order to package our application well, we need to make some additions to our folder structure.
/MyApplication
    |-- run.py
    |__ /app
         |-- __init__.py
         |-- /module_one
             |-- __init__.py
             |-- controllers.py
             |-- models.py
         |__ /templates
             |-- module_one
                 |-- hello.html
         |__ /static
         |__ ..
         |__ .
    |-- setup.py    # Distribution setup file
    |-- README.txt  # Read-me file
    |-- MANIFEST.in # Distribution manifest file
    |-- CHANGES.txt # Changes log

   Alter the folder structure to create necessary files:
touch ~/MyApplication/setup.py
touch ~/MyApplication/README.py
touch ~/MyApplication/MANIFEST.py
touch ~/MyApplication/CHANGES.py
mv    ~/MyApplication/run.py ~/MyApplication/bin/run

Create the setup.py
nano ~/MyApplication/setup.py

   Place the below self explanatory contents:
from distutils.core import setup

setup(
    # Application name:
    name="MyApplication",

    # Version number (initial):
    version="0.1.0",

    # Application author details:
    author="name surname",
    author_email="name@addr.ess",

    # Packages
    packages=["app"],

    # Include additional files into the package
    include_package_data=True,

    # Details
    url="http://pypi.python.org/pypi/MyApplication_v010/",

    #
    # license="LICENSE.txt",
    description="Useful towel-related stuff.",

    # long_description=open("README.txt").read(),

    # Dependent packages (distributions)
    install_requires=[
        "flask",
    ],
)

   Save and exit using CTRL+X and confirm with with Y.

Create the MANIFEST.in
   If you need to ship extra directories (e.g. static or templates), you need to explicitly state them
   in the manifest to be packaged. We will do this inside the MANIFEST.in.
nano ~/MyApplication/MANIFEST.in

   Place the below self explanatory contents:
recursive-include app/templates *
recursive-include app/static *

   Save and exit using CTRL+X and confirm with with Y.

   And that's it! Your Python distribution package is ready to be installed and shipped.

Additional Files
   Please remember that in order to have a complete distribution, your file/directory must contain (and
   linked):
     * README.txt
     * MANIFEST.in
     * LICENSE.txt

Working With the Distribution Ready Application
   As we have finalized creation of our application followed by making necessary amendments to the file
   structure to prepare it for a flawless distribution build, we can begin with going through the
   packaging operations.

How to Create The Distribution File
   In order to generate a distribution file copy, run the following:
cd     ~/MyApplication
python setup.py sdist

   This command will go through your setup, print out the operations being performed and generate a tar
   archive inside the newly created dist directory, similar to:
# root@hostname:~/MyApplication# ls dist
# MyApplication-0.1.0.tar.gz

   Note: Since we did not populate all the sub-folders (i.e. static) and worked with additional files
   (e.g. README.txt), you might see some warnings during the creation process.

How to Install The Application
   From now on, your application can be installed and used by others using the setup.py file created.

   In order to install the application, run the following:
python setup.py install

   If this installation is for development and the requirements are also to be installed, run the
   following:
python setup.py develop

How to Share Your Application
   If you would like to share your code on the Python Packaging Index, you can do so by initiating the
   "register" procedure as per the following:
python setup.py register

   You will need to complete the procedure by following the on-screen instructions.

   If you have a registered login, in order to just upload, you can use the following:
python setup.py sdist upload

How to Create Packages of Your Application's New Versions
    1. Edit the setup.py file with a text editor (e.g. nano) and set the new version number:
       version="0.1.1"
    2. Edit the CHANGES.txt to reflect the changes
    3. Make the necessary adjustments to the LICENSE.txt and README.txt
    4. Upload your code following the previous step.

    

---
https://gehrcke.de/2014/02/distributing-a-python-command-line-application/

Distributing a Python command line application
February 27, 2014

   In this article I show how to create a minimal Python command line application, called ‘bootstrap’. I
   describe how to set it up for publication on [16]PyPI, after which the user can conveniently install
   it via pip install bootstrap. The installation immediately makes the ‘bootstrap’ command available to
   the user — for convenient invocation on Unix as well as on Windows. I show how to make the example
   application live within a proper package structure and how to make it callable and testable in
   different convenient ways. On Python 2 and Python 3 (I actually tested this on CPython 2.7 and 3.3).

   Update March 25, 2014: Thanks for all the feedback. I have updated the article in many places. The
   template structure is now using a __main__.py for convenience (see below). I have created a git
   repository from this template structure. Feel free to clone, fork, and star:
   python-cmdline-bootstrap on GitHub.

Background
   There are many ways to achieve the same thing. In the paragraphs below, I try to give proper advice,
   including current official recommendations, and schemes well-established in the Python community. One
   thing you need to know, and probably already realized yourself, is that Python packaging and package
   distribution can be [18]quite tedious. In the past years, the recommendations for doing things “the
   right way” have often changed. Finally, however, it looks like we have something [19]definite which I
   can base my article on.

   Besides using the right tools, such as setuptools (instead of distribute) and twine, there is a lot
   of tension hidden in the details of the file/directory structure, and in the way you organize your
   application in terms of packages and modules. When do you need absolute or relative imports? What
   would be a convenient entry point for your application? For which parts do you need a wrapper? What
   is the right way to test the application without installing it? I do not deeply want to go into all
   these details in this article, but rather present a working solution. Just be sure that I have
   consulted official [20]docs and [21]guidelines, and taken a deeper look into how various established
   applications (such as [22]sphinx, [23]coverage, [24]pep8, [25]pylint) are set up in this regard. I
   have also consulted several great answers on StackOverflow (e.g. [26]this, [27]this, [28]this,
   [29]this, and [30]this), and finally implemented things [31]myself (also [32]here).

   For this article, I try to break down all this valuable input to a minimal bare bones bootstrap
   project structure that should get you going. I try to reduce complexity, to avoid confusing
   constructs, and to not discuss difficulties anymore, from here on. The outcome is a very short and
   simple thing, really.

File structure

   I recommend the following basic structure:
python-cmdline-bootstrap/
├── docs
├── test
├── bootstrap
│   ├── __init__.py
│   ├── __main__.py
│   ├── bootstrap.py
│   └── stuff.py
├── bootstrap-runner.py
├── LICENSE
├── MANIFEST.in
├── README.rst
└── setup.py

   I have created a git repository from this structure template: [33]python-cmdline-bootstrap on GitHub.
   Fell free to clone and fork.

   Might look random in parts, but it is not. Clarification:
     * All relevant application code is stored within the bootstrap package (which is the bootstrap/
       directory containing the __init__.py file).
     * bootstrap-runner.py is just a simple wrapper script that allows for direct execution of the
       command line application from the source directory, without the need to ‘install’ the
       application.
     * bootstrap/__main__.py makes the bootstrap directory executable as a script.
     * bootstrap/bootstrap.py is meant to be the main module of the application. This module contains a
       function main() which is the entry point of the application.
     * bootstrap/stuff.py is just an example for another module containing application logic, which can
       be imported from within bootstrap.py
     * README.rst and LICENSE should be clear.
     * MANIFEST.in makes sure that (among others) the LICENSE file is included in source distributions
       created with setuptools.
     * setup.py contains instructions for setuptools. It is executed when you, the creator, create a
       distribution file and when the user installs the application. Below, I describe how to configure
       it in a way so that setuptools creates an executable upon installation.

File contents: bootstrap package
   The contents of the files in the bootstrap package, i.e. the application logic. Remember, you can
   find all this [34]on GitHub.

   __init__.py:
   This file makes the bootstrap directory a package. In simple cases, it can be left empty. We make use
   of that and leave it empty.

   bootstrap.py:
# -*- coding: utf-8 -*-

"""bootstrap.bootstrap: provides entry point main()."""

__version__ = "0.2.0"


import sys
from .stuff import Stuff

def main():
    print("Executing bootstrap version %s." % __version__)
    print("List of argument strings: %s" % sys.argv[1:])
    print("Stuff and Boo():\n%s\n%s" % (Stuff, Boo()))

class Boo(Stuff):
    pass

   As stated above, this module contains the function which is the main entry point to our application.
   We commonly call this function main(). This main() function is not called by importing the module, it
   is only called when main() is called directly from an external module. This for instance happens when
   the bootstrap directory is executed as a script — this is magic performed by __main__.py, described
   below.

   Some more things worth discussing in the bootstrap.py module:
     * The module imports from other modules in the package. Therefore it uses relative imports.
       Implicit relative imports are [35]forbidden in Python 3. from .stuff import Stuff is an explicit
       relative import, which you should make use of whenever possible.
     * People often define __version__ in __init__.py. Here, we define it in bootstrap.py, because it is
       simpler to access from within bootstrap.py (;-)) and still accessible from within setup.py (where
       we also need it).

   stuff.py:
# -*- coding: utf-8 -*-

"""bootstrap.stuff: stuff module within the bootstrap package."""

class Stuff(object):
    pass

   As you can see, the bootstrap.stuff module defines a custom class. Once again, bootstrap.bootstrap
   contains an explicit relative import for importing this class.

   __main__.py:
# -*- coding: utf-8 -*-

"""bootstrap.__main__: executed when bootstrap directory is called as script."""

from .bootstrap import main
main()

   Certain workflows require the bootstrap directory to be treated as both a package and as the main
   script, via $ python -m bootstrap invocation. Actually, this calls the __main__.py file if existing
   (or fails if not). From within this file, we simply import our main entry point function (relative
   import!) and invoke it.

Executing the application: running the entry point function
   You might be tempted to perform a $ python bootstrap.py, which would fail with ValueError: Attempted
   relative import in non-package. Is something wrong with the file structure or imports? No, is not.
   The invocation is wrong.

   The right thing is to cd into the project’s root directory, and then execute
 $ python -m bootstrap arg1

   Output:
Executing bootstrap version 0.2.0.
List of argument strings: ['arg1']
Stuff and Boo():
<class 'bootstrap.stuff.Stuff'>
<bootstrap.bootstrap.Boo object at 0x7f6e975e0b10>

   Does this look unusual to you? Well, this is not a 1-file-Python-script anymore. You are designing a
   package, and Python packages have special behavior. This is normal. The $ python -m package kind of
   invocation actually is quite established and your package should support it. As you can see in the
   output above, command line argument support is as expected.

   There is a straight-forward way for achieving the “normal” behavior that you are used to. That is
   what the convenience wrapper bootstrap-runner.py is made for. Its content:
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Convenience wrapper for running bootstrap directly from source tree."""

from bootstrap.bootstrap import main

if __name__ == '__main__':
    main()

   Should be self-explanatory, still: it imports the entry point function main from module
   bootstrap.bootstrap and — if executed by itself as a script — invokes this function. Hence, you can
   use bootstrap-runner.py as a normal script, i.e. as the command line front end to your application.
   Set permissions via $ chmod u+x bootstrap-runner.py and execute it:
$ ./bootstrap-runner.py argtest
Executing bootstrap version 0.2.0.
List of argument strings: ['argtest']
Stuff and Boo():
<class 'bootstrap.stuff.Stuff'>
<bootstrap.bootstrap.Boo object at 0x7f5402343b50>

   Straight-forward, right? You can now use $ python -m bootstrap or bootstrap-runner.py for testing or
   production purposes, without the need to install the application.

Preparing setup.py

   Code upfront:
# -*- coding: utf-8 -*-

"""setup.py: setuptools control."""

import re
from setuptools import setup

version = re.search(
    '^__version__\s*=\s*"(.*)"',
    open('bootstrap/bootstrap.py').read(),
    re.M
    ).group(1)

with open("README.rst", "rb") as f:
    long_descr = f.read().decode("utf-8")

setup(
    name = "cmdline-bootstrap",
    packages = ["bootstrap"],
    entry_points = {
        "console_scripts": ['bootstrap = bootstrap.bootstrap:main']
        },
    version = version,
    description = "Python command line application bare bones template.",
    long_description = long_descr,
    author = "Jan-Philip Gehrcke",
    author_email = "jgehrcke@googlemail.com",
    url = "http://gehrcke.de/2014/02/distributing-a-python-command-line-application",
    )

   Some things to discuss:
     * Might appear trivial, but from setuptools import setup is the currently recommended way to go.
     * Your setup.py should not import your package for reading the version number. This fails for the
       end-user. Instead, always read it directly. In this case, I used regular expressions for
       extracting it. This is up to you. But never import your own module/package.
     * The setup function has many more useful arguments than shown here. For a serious project read the
       docs and make proper use of author, classifiers, platform, etc.
     * I have called the project cmdline-bootstrap here instead of just bootstrap, because I do really
       upload this to PyPI later on (see below). And “bootstrap”, although still free, is just too much
       of a popular name to use it for something that small.

   The essential arguments here are packages and entry_points. packages = ["bootstrap"] tells setuptools
   that we want to install our bootstrap package to the user’s site-packages directory. The
   console_scripts item 'bootstrap = bootstrap.bootstrap:main' instructs setuptools to generate a script
   called bootstrap. This script will invoke bootstrap.bootstrap:main, i.e. the main function of our
   bootstrap.bootstrap module, our application entry point. This is the same as realized within
   bootstrap-runner.py — the difference is that setuptools automatically creates a wrapper script in the
   user’s file system when she/he installs bootstrap via pip install bootstrap. setuptools places this
   wrapper into a directory that is in the user’s PATH, i.e. it immediately makes the bootstrap command
   available to the user. This also works on Windows, where a small .exe file is created in something
   like C:\Python27\Scripts.

Testing the setup
   We use virtualenv to reproduce what users see. Once, for CPython 2(.7), once for CPython 3(.3).
   Create both environments:
$ virtualenv --python=/path/to/python27 venvpy27
...
$ virtualenv --python=/path/to/python33 venvpy33
...

   Activate the 2.7 environment, and install the bootstrap application:
$ source venvpy27/bin/activate
$ python setup.py install
running install
running bdist_egg
running egg_info
[...]
Installed /xxx/venvpy27/lib/python2.7/site-packages/cmdline_bootstrap-0.2.0-py2.7.egg
Processing dependencies for cmdline-bootstrap==0.2.0
Finished processing dependencies for cmdline-bootstrap==0.2.0

   See if (and where) the command has been created:
$ command -v bootstrap
/xxx/venvpy27/bin/bootstrap

   Try it:
$ bootstrap arg
Executing bootstrap version 0.2.0.
List of argument strings: ['arg']
Stuff and Boo():
<class 'bootstrap.stuff.Stuff'>
<bootstrap.bootstrap.Boo object at 0x7f1234d31190>

   Great. Repeat the same steps for venvpy33, and validate:
$ command -v bootstrap
/xxx/venvpy33/bin/bootstrap
$ bootstrap argtest
Executing bootstrap version 0.2.0.
List of argument strings: ['argtest']
Stuff and Boo():
<class 'bootstrap.stuff.Stuff'>
<bootstrap.bootstrap.Boo object at 0x7f4cf931a550>

A note on automated tests
   In the test/ directory you can set up automated tests for your application. You can always directly
   import the development version of your modules from e.g. test/test_api.py, if you modify sys.path:
sys.path.insert(0, os.path.abspath('..'))
from bootstrap.stuff import Stuff

   If you need to directly test the command line interface of your application, then bootstrap-runner.py
   is your friend. You can easily invoke it from e.g. test/test_cmdline.py via the subprocess module.

Upload your distribution file to PyPI
   Create a source distribution of your project, by default this is a gzipped tarball:
$ python setup.py sdist
$ /bin/ls dist
cmdline-bootstrap-0.2.0.tar.gz

   Register your project with PyPI. Then use [36]twine to upload your project (twine is still to be
   improved!):
$ pip install twine
$ twine upload dist/cmdline-bootstrap-0.2.0.tar.gz
Uploading distributions to https://pypi.python.org/pypi
Uploading cmdline-bootstrap-0.2.0.tar.gz
Finished

Final test: install from PyPI
   Create another virtual environment, activate it, install cmdline-bootstrap from PyPI and execute it:
$ virtualenv --python=/xxx/bin/python3.3 venvpy33test
...
$ source venvpy33test/bin/activate
$ bootstrap
bash: bootstrap: command not found
$ pip install cmdline-bootstrap
Downloading/unpacking cmdline-bootstrap
  Downloading cmdline-bootstrap-0.2.0.tar.gz
  Running setup.py egg_info for package cmdline-bootstrap

Installing collected packages: cmdline-bootstrap
  Running setup.py install for cmdline-bootstrap

    Installing bootstrap script to /xxx/venvpy33test/bin
Successfully installed cmdline-bootstrap
Cleaning up...

$ bootstrap testarg
Executing bootstrap version 0.2.0.
List of argument strings: ['testarg']
Stuff and Boo():
<class 'bootstrap.stuff.Stuff'>
<bootstrap.bootstrap.Boo object at 0x7faf433edb90>

   That was it, I hope this is of use to some of you. All code is available on GitHub.



---
https://hackernoon.com/the-one-stop-guide-to-easy-cross-platform-python-freezing-part-1-c53e66556a0a

The one-stop guide to (easy) cross-platform Python freezing: Part 1

   It’s been almost an year since I have been a maintainer for [15]MusicBrainz Picard, a cross-platform
   multi-lingual desktop app, that allows you to tag your music files via this [16]very cool service
   called MusicBrainz.

   Picard, I’d say is a fairly large python app with about ~35k SLoC. With a python app of such size,
   come challenges. One of the toughest challenges I faced this last year has been packaging Picard for
   all the three platforms that it supports, Linux, macOS and Windows after I ported it to Python
   3/PyQt5 for my GSoC project. You can read more about that [17]here.

     “Freezing” your code is creating an executable file to distribute to end-users, that contains all
     of your application code as well as the Python interpreter.

     The advantage of distributing this way is that your application will “just work”, even if the user
     doesn’t already have the required version of Python (or any) installed. On Windows, and even on
     many Linux distributions and OS X, the right version of Python will not already be installed.

Testing my options
   Our existing setup used py2exe and py2app to freeze Picard for Windows and macOS respectively. Since
   they don’t entirely support Python 3 and PyQt5, I was on the lookout for a new freezing tool. I
   finally settled on [19]PyInstaller after testing waters with [20]cx_Freeze.

PyInstaller — A happy surprise
   One thing I’d like to say about PyInstaller — I was absolutely surprised how easy it was to freeze my
   python application, while putting minimal efforts from my side, chasing mythical dependencies. It
   supports Python 2 and 3 and all 3 desktop OSes and even allows you to create portable all-in-one
   binaries for each. How cool is that!

   I plan on giving you a small glimpse of how powerful and simple PyInstaller is, and how, coupled with
   [AppVeyor and TravisCI, you can package your python apps for Windows and macOS without even
   having access to either of them.

Getting started
   In this part of the blog, we will be making a PyInstaller spec file and freezing our package. In the
   next part, we will be looking into TravisCI and AppVeyor for continuous delivery.

Installing PyInstaller
   All you need to do is pip install pyinstaller . It is as simple as that. You can either install it
   globally or in a virtual environment housing your project. The latter is obviously preferable. This
   will give you access to mainly 2 scripts that we will be using in the rest of this
   tutorial — pyinstaller and pyi-makespec .

Project info and structure
   Let’s start with a very basic structure to introduce PyInstaller and make adjustments from there on,
   as per our needs.
package_dir
├── package
│   ├── submodule_bar
│   ├── submodule_foo
│   ├── __init__.py
│   └── main.py
├── entry_point.py
└── setup.py

   The above assume that you have an entry point script called entry_point.py which launches your
   application. See [23]python-packaging for help on how to package your app.

   Now comes the magical part. All you need to do to freeze your app is

   pyinstaller entry_point.py -n foobar

   It is as simple as that! PyInstaller will automagically figure out all the dependencies, include all
   the dynamic libraries that need to be loaded and create adistdirectory with the frozen app named
   foobar.

   The output should as follows
package_dir
├── dist
│   └── foobar
│       ├── ...
│       ├── ...
│       ├── ...
│       └── foobar
├── package
│   ├── submodule_bar
│   ├── submodule_foo
│   ├── __init__.py
│   └── main.py
├── entry_point.py
├── foobar.spec
└── setup.py

   You can execute your app by launching dist/foobar/foobar (Of course it will be foobar.exe or
   foobar.app on Windows and macOS respectively.

Portable apps, what is this magic?
   Now let’s take things a bit further. What if you want you entire app bundled with all its
   dependencies as a single portable executable? Simple, just pass the --onefile flag to PyInstaller.

   pyinstaller entry_point.py -n foobar --onefile

   PyInstaller will output a single portable executable in the dist folder named foobar which can easily
   be launched. Again, PyInstaller will automagically find and bundle all the dependencies inside that
   one file!

It can’t surely be that simple? Can it? What if I need to…

Bundle Libraries
   PyInstaller supports a lot of major frameworks and libraries out of the box. This includes —

   Babel, Django, IPython, matplotlib, numpy, pillow, PyGTK, PyQt4, PyQt5, scipy, sphinx, SQLAlchemy,
   wxPython and [24]many more.

   If your app depends on any of the above libraries, you don’t need to worry about the hassles of
   including dependent libraries, dlls, hidden imports, packages or anything else for that matter.
   PyInstaller takes care of everything for you. It inspects your code recursively and figures out all
   the dependencies.

Add and bundle resources
   Resources can be anything, images, icons, textual data, translation strings. There is a very simple
   recipe to bundle and access your resources. For simplicity, let’s assume all your resources are
   available inside a directory called resources as below —
package_dir
├── package
│   ├── submodule_bar
│   ├── submodule_foo
│   ├── __init__.py
│   └── main.py
├── resources
│   ├── bar.dat
│   └── foo.png
├── entry_point.py
└── setup.py

   Bundling the resources
   Run pyi-makespec entry_point.py -n foobar --onefile. The pyi-makespec script accepts the same
   arguments as pyinstaller but instead of actually running PyInstaller, it creates a foobar.spec spec
   file for you to customise, which can then be called with pyinstaller foobar.spec.

   The spec file is simply a python script albeit with some special callables as shown above. To add
   resources, you simply need to create an array with a list of tuples —
     * The first string specifies the file or files as they are in this system now.
     * The second specifies the name of the folder to contain the files at run-time.

   A simple script to do the same would be —

   IFRAME: /media/5896eea1d4bb6d584f014323c386c40f?postId=c53e66556a0a

   You will be adding the above code to the spec file, which should now look like this —

   IFRAME: /media/6e566f23e898b918fdc7129a69e5cfa7?postId=c53e66556a0a

   Notice the call to get_resources() in a.datas .

   Accessing bundled resources

   Quoting from the [28]PyInstaller wiki —

     You may need to learn at run-time whether the app is running from source, or is “frozen”
     (bundled). For example, you might have data files that are normally found based on a module’s
     __file__ attribute. That will not work when the code is bundled.

     The PyInstaller bootloader adds the name frozen to the sys module. So the test for “are we
     bundled?”

   To summarise, this is what you need to do to access any resources you have bundled —

   Add the following two variables to your utility section —

   IFRAME: /media/4c5b22ff5b9fa967f6d749e73c120831?postId=c53e66556a0a

   You can then use this in your entry_point.py as follows —

   IFRAME: /media/d094b254e31e093ff3565aa35cbd6259?postId=c53e66556a0a

   You can now load your resources in main.py as follows —

   IFRAME: /media/8c223f13b12df58fdd1e19573a59047c?postId=c53e66556a0a

Bundle binaries
   PyInstaller should automagically bundle any .so or .dll files by inspecting your python module. But
   in case it [32]fails to do so, it is easy to add them.

   Bundling binaries or libraries that your app depends on is pretty much similar to how you would
   bundle data files.

   Assuming the following directory structure —
package_dir
├── bin
│   ├── bar.so
│   ├── bar.dll
│   └── bar.dylib
├── package
│   ├── submodule_bar
│   ├── submodule_foo
│   ├── __init__.py
│   └── main.py
├── resources
│   ├── bar.dat
│   └── foo.png
├── entry_point.py
└── setup.py

   Let’s say your app depends on a shared library bar, and you have binaries available for it for all 3
   operating systems.

   You might go around including them as follows —

   IFRAME: /media/402576d2e67f60ee00cd274f7d4d261e?postId=c53e66556a0a

   You might ask, what’s the difference between adding a file as a data file or a binary file, well
   quoting from the PyInstaller Wiki —

     Binary files refers to DLLs, dynamic libraries, shared object-files, and such, which PyInstaller
     is going to search for further binary dependencies. Files like images and PDFs should go into
     thedatas

   So make sure you are adding any dlls or so files as binaries instead of data files.

Freeze a GUI app
   You will probably want to pass the --windowed flag to pyinstaller in order to make sure there is no
   console while opening the App.

Freeze a macOS app
   If you are freezing a one-file windowed macOS app you will want to add an additional callable to your
   spec file like so —

   IFRAME: /media/886bd31ba6ff956da2d98d7870add67e?postId=c53e66556a0a

   See the PyInstaller-Wiki for more information about these options.

     Note: For simple cases, you can also accomplish all the of the above through flags passed to the
     pyisntaller or pyi-makespec scripts. See [36]Using Spec Files for more information.

What’s next?
   The above recipes should be more than enough for all general use cases. I hope the above provides a
   basic guide on how to use PyInstaller. For more advanced use cases, you can sift through the
   PyInstaller Wiki.

   If you want to see the above guide in action, you can have a look at the [38]Picard github repo.

   In the next part of this blog, we will learn how to make use of AppVeyor and TravisCI along with
   PyInstaller to bundle our applications.


---
https://stackoverflow.com/questions/24143422/package-a-command-line-application-for-distribution

Package a command line application for distribution?

   I am currently writing a command line application in Python, which needs to be made available to end
   users in such a way that it is very easy to download and run. For those on Windows, who may not have
   Python (2.7) installed, I intend to use [30]PyInstaller to generate a self-contained Windows
   executable. Users will then be able to simply download "myapp.exe" and run myapp.exe [ARGUMENTS].

   I would also like to provide a (smaller) download for users (on various platforms) who already have
   Python installed. One option is to put all of my code into a single .py file, "myapp.py" (beginning
   with #! /usr/bin/env python), and make this available. This could be downloaded, then run using
   myapp.py [ARGUMENTS] or python myapp.py [ARGUMENTS]. However, restricting my application to a single
   .py file has several downsides, including limiting my ability to organize the code and making it
   difficult to use third-party dependencies.

   Instead I would like to distribute the contents of several files of my own code, plus some (pure
   Python) dependencies. Are there any tools which can package all of this into a single file, which can
   easily be downloaded and run using an existing Python installation?

   Edit: Note that I need these applications to be easy for end users to run. They are not likely to
   have pip installed, nor anything else which is outside the Python core. Using PyInstaller, I can
   generate a file which these users can download from the web and run with one command (or, if there
   are no arguments, simply by double-clicking). Is there a way to achieve this ease-of-use without
   using PyInstaller (i.e. without redundantly bundling the Python runtime)?

***   
       for the second (small) solution, why not use pip? – [38]Janus Troelsen Jun 10 '14 at 14:25
     * You have very similar questions [39]here about Windows and [40]here in general – [41]logc Jun 10
       '14 at 14:28
     * You mention various platforms, but don't mention what they are. Is "sudo apt-get install package"
       easy enough for your end users? – [42]berto Jun 14 '14 at 20:33
     * 1
       "Are there any tools which can package all of this into a single file, which can easily be
       downloaded and run using an existing Python installation?" - Take the sources and zip them. You
       get a single file which can easily be downloaded and which runs in any existing compatible Python
       installation. :) – [43]Trilarion Jun 16 '14 at 12:23
     * 1
       @snapshoe: Assume end users have Python installed (perhaps it came with their system, perhaps
       they installed it themselves), and that they are sufficiently confident to run python myapp.py
       [ARGUMENTS] from the command line. In terms of environments, all I am looking for is a way to run
       a set of Python files (my own and third-party dependencies) as easily as if all of the files were
       concatenated into a single huge script. If a system can run the latter, I would like it to be
       able to run the former. – [44]user200783 Jun 18 '14 at 13:17

***  
   I don't like the single file idea because it becomes a maintenance burden. I would explore an
   approach like the one below.

   I've become a big fan of Python's virtual environments because it allows you to silo your application
   dependencies from the OS's installation. Imagine a scenario where the application you are currently
   looking to distribute uses a Python package requests v1.0. Some time later you create another
   application you want to distribute that uses requests v2.3. You may end up with version conflicts on
   a system where you want to install both applications side-by-side. Virtual environments solve this
   problem as each application would have its own package location.

   Creating a virtual environment is easy. Once you have virtualenv installed, it's simply a matter of
   running, for example, virtualenv /opt/application/env. Now you have an isolated python environment
   for your application. Additionally, virtual environments are very easy to clean up, simply remove the
   env directory and you're done.

   You'll need a setup.py file to install your application into the environment. Say your application
   uses requests v2.3.0, your custom code is in a package called acme, and your script is called
   phone_home. Your directory structure looks like this:
acme/
    __init__.py
    models.py
    actions.py
scripts/
    phone_home
setup.py

   The setup.py would look something like this:
from distutils.core import setup


install_requires = [
    'requests==2.3.0',
]

setup(name='phone_home',
      version='0.0.1',
      description='Sample application to phone home',
      author='John Doe',
      author_email='john@doe.com',
      packages=['acme'],
      scripts=['scripts/phone_home'],
      url='http://acme.com/phone_home',
      install_requires=install_requires,
)

   You can now make a tarball out of your project and host it however you wish (your own web server, S3,
   etc.):
tar cvzf phone_home-0.0.1.tar.gz .

   Finally, you can use pip to install your package into the virtual environment you created:
/opt/application/env/bin/pip install http://acme.com/phone_home-0.0.1.tar.gz

   You can then run phone_home with:
/opt/application/env/bin/phone_home

   Or create a symlink in /usr/local/bin to simply call the script using phone_home:
ln -s /opt/application/env/bin/phone_home /usr/local/bin/phone_home

   All of the steps above can be put in a shell script, which would make the process a single-command
   install.

   And with slight modification this approach works really well for development environments; i.e. using
   pip to install / reference your development directory: pip install -e . where . refers to the current
   directory and you should be in your project directory alongside setup.py.

   Hope this helps!

***  
   You could use pip as suggested in the comments. You need to create a MANIFEST.in and setup.py in your
   project to make it installable. You can also add modules as prerequisites. More info can be found in
   this question (not specific to Django):

   How do I package a python application to make it pip-installable?

   This will make your module available in Python. You can then have users run a file that runs your
   module, by either python path/run.py, ./path/run.py (with +x permission) or python -c "some code
   here" (e.g. for an alias).

   You can even have users install from a git public reporitory, like this
pip install git+https://bitbucket.org/yourname/projectname.git

   ...in which case they also need git.

***  
       You can also install a tarball of the application with pip; this eliminates the git requirement.
       For example: pip install https://yourdomain.com/application.tar.gz – [58]berto Jun 13 '14 at
       22:49



---
https://medium.com/python-pandemonium/better-python-dependency-and-package-management-b5d8ea29dff1

Better Python dependency while packaging your project

   I have been cooking this blog topic idea for a long time. I did a lot of searching, reading and
   trying while working on different projects. But even today after publishing it I don’t think I’m 100%
   satisfied with the provided solution how to manage python project dependencies efficiently.

What is package and dependency management?
   Software released in bundled packages this way it’s easier to manage installed programs.

   The package manager is a collection of libraries that are packaged together, which makes it easier to
   download entire package rather than each library.

   Almost every library in the package has a dependency managed by the dependency manager.

   Dependency management helps manage all the libraries required to make an application work. It’s
   incredibly beneficial when you’re dealing with complex projects and in a multi-environment.
   Dependency management also helps to keep track, update libraries faster and easier, as well as solve
   the problem then one package will depend on another package.

   Every programming language has its flavor of dependency manager.

   To summarize all above :
     * The library is a collection of already pre-written code.
     * The package is a collection of libraries that are built on each other or using each other one way
       or another.

Typical way of managing project dependency today
   Today the most used Python package manager is pip, used to install and manage python software
   packages, found in the [11]Python Package Index. Pip helps us, python developers, effortlessly
   “manually” control installation and lifecycle of publicly available Python packages from their online
   repositories.

   Pip also can upgrade, show, uninstall project dependencies, etc.

   To install the package, you can just run pip install <somepackage> that will build an extra Python
   library in your home directory.

   Running pip freeze,can help to check installed packages and packages versions listed in
   case-insensitive sorted order.

Project setup
   After building your application, you will need to perform some set of actions(steps) to make
   application dependencies available in the different environments.

   Actions will be similar to the one below:
     * Create a virtual environment $ python3 -m venv /path/to/new/virtual/env
     * Install packages using $pip install <package> command
     * Save all the packages in the file with $pip freeze > requirements.txt. Keep in mind that in this
       case, requirements.txt file will list all packages that have been installed in virtual
       environment, regardless of where they came from
     * Pin all the package versions. [12]You should be pinning your dependencies, meaning every package
       should have a fixed version.
     * Add requirements.txt to the root directory of the project. Done.

Install project dependencies
   When if you’re going to share the project with the rest of the world you will need to install
   dependencies by running $pip install -r requirements.txt

   To find more information about individual packages from the requiements.txt you can use $pip show
   <packagename>. But how informative the output is?
   [1*MaCm_07a9iGqTcJQEQuZnw.png]
   Example pip show command

How can project dependencies be easily maintained?
   Personally, I think above setup is not easy to maintain, for the variety of reasons:
    1. Sometime requirements.txt files contain more than thousands of lines. When maintain and update
       package version is hard, it will be even more hard to automate it (for example: delete
       development dependencies, etc.).
    2. If versions are not pinned in requirements.txt the result executing a fresh $ pip install -r
       requirements.txt will result in different packages being installed every time then new, different
       versions of sub-dependencies will be released.
    3. Pip doesn't have dependency resolution.
    4. Sometimes you may want to create requirements.txt as an empty file without modules (this will not
       work with pip freeze command. )

Are there any better alternatives?
Option 1 : multiple requirements.txt files ?
   There are many examples of projects with multiple requirements.txt files. Developers having different
   versions of requirements.txt file for example for different environments (e.g., test or local ) or
   files for different users (e.g., machines vs. people).

   Multiple requirements.txt is a good solution for managing project dependencies? I disagree…managing
   manually various requirements.txt files not a good solution, and it will be not easy if they grow
   more than even ~50lines.

Option 2: can Pipreqs and Pipdeptre make it better?
   I recently tried pipreqsutility, which generates requirements.txt file based on project imports. It’s
   simple to use.

   To generate a requirements.txt file you can run pipreqs /your_project/path
   [1*cvPF9PpsbuiGiZuHuDJblg.png]
   Example pipreqs command

Pipdeptree
   I thought of combining it with pipdeptree another cool and “handy” command line utility which will
   help to display the installed python packages in the form of a dependency tree.

   After executing pipdeptree command in your terminal window in the virtualenv directory of the
   project, all the installed python packages of a dependency tree will be displayed:
   [1*xBA4uG5zES7BAptcWK9O3w.png]
   Example pipdeptree command

   Cool bonus thatpipdeptree will warns you when you have multiple dependencies where the versions don’t
   exactly match.

   I found it’s handy in some cases, like:
     * if you want to create a requirements.txt for a git repository and you only want to list the
       packages required to run that script; packages that the script imports without any “extras”
     * support option like clean command
     * can be used with pipdeptree to verify project dependencies

   There are some downsides too,Pipreq will not include the plugins required for specific projects, and
   you will end up adding plugins information manually in a requirement.txt. It’s not yet a very mature
   utility.

   Option 3: have you tried pip-compile?
   pip-compilemodule provides two commands: pip-compile and pip-sync.

   pip-compile command will generate requirements.inor requirements.txt of top-level summary of the
   packages and all (underlying dependencies) pinned. And you can store .in and .txt files in version
   control.How useful, right?

   This means that we can get the same versions whenever we run pip install, no matter what the new
   version is.

   -generate-hashes flag helps to generate-hashes. In this case pip-compile consults the PyPI index for
   each top level package required, looking up the package versions available.

   To update all packages, periodically re-run pip-compile --upgrade.

   To update a specific package to the latest or a particular version use the --upgrade-package or -P
   flag.

   pip-sync command used to update your virtual environment to reflect exactly what’s in there. Command
   will install/upgrade/uninstall everything necessary to match the requirements.txt contents.

Software dependencies are often the largest attack surface
   To know what dependencies your project hasT is very useful to find out after the fact what packages
   were installed and what dependencies your project has.

   Organizations usually assume most risks come from public-facing web applications. That has changed.
   With dozens of small components in every application, threats can come from anywhere in the codebase.

   Currently using pip freeze will only show the final package list of dependencies.

   I would recommend using pipdeptreemodule which helps to find possible dependency conflicts and
   displaying an actual dependency in the project.

   pipdeptree --reverse leaf package installed first

   Another good advice is start building applications using Docker. Every tool we run in Docker is one
   less tool we have to install locally, so get up-and-running phase will be much faster. But that is a
   different topic.

   Happy Packaging .


---
