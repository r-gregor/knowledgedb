filename: python_when-to-use-oop_20171005.txt
https://www.packtpub.com/books/content/python-3-when-use-object-oriented-programming

Python 3: When to Use Object-oriented Programming
August 2010

Treat objects as objects
   This may seem obvious, but you should generally give separate objects in your problem domain a
   special class in your code. The process is generally to identify objects in the problem and then
   model their data and behaviors.

   Identifying objects is a very important task in object-oriented analysis and programming. But it
   isn't always as easy as counting the nouns in a short paragraph, as we've been doing. Remember,
   objects are things that have both data and behavior. If we are working with only data, we are often
   better off storing it in a list, set, dictionary, or some other Python data structure. On the other
   hand, if we are working with only behavior, with no stored data, a simple function is more suitable.

   An object, however, has both data and behavior. Most Python programmers use built-in data structures
   unless (or until) there is an obvious need to define a class. This is a good thing; there is no
   reason to add an extra level of abstraction if it doesn't help organize our code. Sometimes, though,
   the "obvious" need is not so obvious.

   A Python programmer often starts by storing data in a few variables. As our program expands, we will
   later find that we are passing the same set of related variables to different functions. This is the
   time to think about grouping both variables and functions into a class. If we are designing a program
   to model polygons in two-dimensional space, we might start with each polygon being represented as a
   list of points. The points would be modeled as two-tuples (x,y) describing where that point is
   located. This is all data, stored in two nested data structures (specifically, a list of tuples):
square = [(1,1), (1,2), (2,2), (2,1)]

   Now, if we want to calculate the distance around the perimeter of the polygon, we simply need to sum
   the distances between the two points, but to do that, we need a function to calculate the distance
   between two points. Here are two such functions:
import math
def distance(p1, p2):
   return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)
def perimeter(polygon):
   perimeter = 0
   points = polygon + [polygon[0]]
   for i in range(len(polygon)):
      perimeter += distance(points[i], points[i+1])
   return perimeter

   Now, as object-oriented programmers, we clearly recognize that a polygon class could encapsulate the
   list of points (data) and the perimeter function (behavior). Further, a point class, might
   encapsulate the x and y coordinates and the distance method. But should we do this?

   For the previous code, maybe, maybe not. We've been studying object-oriented principles long enough
   that we can now write the object-oriented version in record time:
import math
class Point:
  def __init__(self, x, y):
    self.x = x
    self.y = y
  def distance(self, p2):
     return math.sqrt((self.x-p2.x)**2 + (self.y-p2.y)**2)
class Polygon:
  def __init__(self):
    self.vertices = []
  def add_point(self, point):
    self.vertices.append((point))
def perimeter(self):
    perimeter = 0
    points = self.vertices + [self.vertices[0]]
    for i in range(len(self.vertices)):
      perimeter += points[i].distance(points[i+1])
    return perimeter

   Now, to understand the difference a little better, let's compare the two APIs in use. Here's how to
   calculate the perimeter of a square using the object-oriented code:
>>> square = Polygon()
>>> square.add_point(Point(1,1))
>>> square.add_point(Point(1,2))
>>> square.add_point(Point(2,2))
>>> square.add_point(Point(2,1))
>>> square.perimeter()
4.0

   That's fairly succinct and easy to read, you might think, but let's compare it to the function-based
   code:
>>> square = [(1,1), (1,2), (2,2), (2,1)]
>>> perimeter(square)
4.0

   Hmm, maybe the object-oriented API isn't so compact! On the other hand, I'd argue that it was easier
   to read than the function example: How do we know what the list of tuples is supposed to represent in
   the second version? How do we remember what kind of object (a list of two-tuples? That's not
   intuitive!) we're supposed to pass into the perimeter function? We would need a lot of external
   documentation to explain how these functions should be used.

   In contrast, the object-oriented code is relatively self documenting, we just have to look at the
   list of methods and their parameters to know what the object does and how to use it. By the time we
   wrote all the documentation for the functional version, it would probably be longer than the
   object-oriented code.

   Besides, code length is a horrible indicator of code complexity. Some programmers (thankfully, not
   many of them are Python coders) get hung up on complicated, "one liners", that do incredible amounts
   of work in one line of code. One line of code that even the original author isn't able to read the
   next day, that is. Always focus on making your code easier to read and easier to use, not shorter.

   As a quick exercise, can you think of any ways to make the object-oriented Polygon as easy to use as
   the functional implementation? Pause a moment and think about it.

   Really, all we have to do is alter our Polygon API so that it can be constructed with multiple
   points. Let's give it an initializer that accepts a list of Point objects. In fact, let's allow it to
   accept tuples too, and we can construct the Point objects ourselves, if needed:
def __init__(self, points = []):
  self.vertices = []
  for point in points:
    if isinstance(point, tuple):
    point = Point(*point)
  self.vertices.append(point)

   This example simply goes through the list and ensures that any tuples are converted to points. If the
   object is not a tuple, we leave it as is, assuming that it is either a Point already, or an unknown
   duck typed object that can act like a Point.

   As we can see, it's not always easy to identify when an object should really be represented as a
   self-defined class. If we have new functions that accept a polygon argument, such as area(polygon) or
   point_in_polygon(polygon, x, y), the benefits of the object-oriented code become increasingly
   obvious. Likewise, if we add other attributes to the polygon, such as color or texture, it makes more
   and more sense to encapsulate that data into a class.

   The distinction is a design decision, but in general, the more complicated a set of data is, the more
   likely it is to have functions specific to that data, and the more useful it is to use a class with
   attributes and methods instead.

   When making this decision, it also pays to consider how the class will be used. If we're only trying
   to calculate the perimeter of one polygon in the context of a much greater problem, using a function
   will probably be quickest to code and easiest to use "one time only". On the other hand, if our
   program needs to manipulate numerous polygons in a wide variety of ways (calculate perimeter, area,
   intersection with other polygons, and more), we have most certainly identified an object; one that
   needs to be extremely versatile.

   Pay additional attention to the interaction between objects. Look for inheritance relationships;
   inheritance is impossible to model elegantly without classes, so make sure to use them. Composition
   can, technically, be modeled using only data structures; for example, we can have a list of
   dictionaries holding tuple values, but it is often less complicated to create an object, especially
   if there is behavior associated with the data.

   Don't rush to use an object just because you can use an object, but never neglect to create a class
   when you need to use a class.

Using properties to add behavior to class data
   Python is very good at blurring distinctions; it doesn't exactly help us to "think outside the box".
   Rather, it teaches us that the box is in our own head; "there is no box".

   Before we get into the details, let's discuss some bad object-oriented theory. Many object-oriented
   languages (Java is the most guilty) teach us to never access attributes directly. They teach us to
   write attribute access like this:
class Color:
  def __init__(self, rgb_value, name):
    self._rgb_value = rgb_value
    self._name = name
  def set_name(self, name):
    self._name = name
  def get_name(self):
    return self._name

   The variables are prefixed with an underscore to suggest that they are private (in other languages it
   would actually force them to be private). Then the get and set methods provide access to each
   variable. This class would be used in practice as follows:
>>> c = Color("#ff0000", "bright red")
>>> c.get_name()
'bright red'
>>> c.set_name("red")
>>> c.get_name()
'red'

   This is not nearly as readable as the direct access version that Python favors:
class Color:
  def __init__(self, rgb_value, name):
    self.rgb_value = rgb_value
    self.name = name
c = Color("#ff0000", "bright red")
print(c.name)
c.name = "red"

   So why would anyone recommend the method-based syntax? Their reasoning is that someday we may want to
   add extra code when a value is set or retrieved. For example, we could decide to cache a value and
   return the cached value, or we might want to validate that the value is a suitable input. In code, we
   could decide to change the set_name() method as follows:
def set_name(self, name):
  if not name:
    raise Exception("Invalid Name")
  self._name = name

   Now, in Java and similar languages, if we had written our original code to do direct attribute
   access, and then later changed it to a method like the above, we'd have a problem: Anyone who had
   written code that accessed the attribute directly would now have to access the method; if they don't
   change the access style, their code will be broken. The mantra in these languages is that we should
   never make public members private. This doesn't make much sense in Python since there isn't any
   concept of private members!

   Indeed, the situation in Python is much better. We can use the Python property keyword to make
   methods look like a class attribute. If we originally wrote our code to use direct member access, we
   can later add methods to get and set the name without changing the interface. Let's see how it looks:
class Color:
  def __init__(self, rgb_value, name):
    self.rgb_value = rgb_value
    self._name = name
  def _set_name(self, name):
    if not name:
      raise Exception("Invalid Name")
    self._name = name
  def _get_name(self):
    return self._name
name = property(_get_name, _set_name)

   If we had started with the earlier non-method-based class, which set the name attribute directly, we
   could later change the code to look like the above. We first change the name attribute into a (semi-)
   private _name attribute. Then we add two more (semi-) private methods to get and set that variable,
   doing our validation when we set it.

   Finally, we have the property declaration at the bottom. This is the magic. It creates a new
   attribute on the Color class called name, which now replaces the previous name attribute. It sets
   this attribute to be a property, which calls the two methods we just created whenever the property is
   accessed or changed. This new version of the Color class can be used exactly the same way as the
   previous version, yet it now does validation when we set the name:
>>> c = Color("#0000ff", "bright red")
>>> print(c.name)
bright red
>>> c.name = "red"
>>> print(c.name)
red
>>> c.name = ""
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "setting_name_property.py", line 8, in _set_name
    raise Exception("Invalid Name")
Exception: Invalid Name

   So if we'd previously written code to access the name attribute, and then changed it to use our
   property object, the previous code would still work, unless it was sending an empty property value,
   which is the behavior we wanted to forbid in the first place. Success!

   Bear in mind that even with the name property, the previous code is not 100% safe. People can still
   access the _name attribute directly and set it to an empty string if they wanted to. But if they
   access a variable we've explicitly marked with an underscore to suggest it is private, they're the
   ones that have to deal with the consequences, not us.

   (For more resources on Python 3, see [67]here.)

How it works
   So, what exactly is that property object doing? Think of the property function as returning an object
   that proxies any requests to set or access the attribute value through the methods we have specified.
   The property keyword is like a constructor for such an object.

   This property constructor can actually accept two additional arguments, a deletion function and a
   docstring for the property. The delete function is rarely supplied in practice, but it can be useful
   for logging that a value has been deleted, or possibly to veto deleting if we have reason to do
   so.The docstring is just a string describing what the property does.If we do not supply this
   parameter, the docstring will instead be copied from the docstring for the first argument: the getter
   method.

   Here is a silly example that simply states whenever any of the methods are called:
class Silly:
  def _get_silly(self):
    print("You are getting silly")
    return self._silly
  def _set_silly(self, value):
    print("You are making silly {}".format(value))
    self._silly = value
def _del_silly(self):
    print("Whoah, you killed silly!")
    del self._silly
silly = property(_get_silly, _set_silly,
    _del_silly, "This is a silly property")

   If we actually use this class, it does indeed print out the correct strings when we ask it to:
>>> s = Silly()
>>> s.silly = "funny"
You are making silly funny
>>> s.silly
You are getting silly
'funny'
>>> del s.silly
Whoah, you killed silly!

   Further, if we look at the help file for the Silly class (by issuing help(silly) at the interpreter
   prompt), it shows us the custom docstring for our silly attribute:
Help on class Silly in module __main__:
class Silly(builtins.object)
| Data descriptors defined here:
|
| __dict__
|  dictionary for instance variables (if defined)
|
| __weakref__
|  list of weak references to the object (if defined)
|
| silly
|  This is a silly property

   Once again, everything is working as we planned. In practice, properties are normally only defined
   with the first two parameters; the getter and setter functions. The docstring is defined as a normal
   docstring on the getter and copied into the property, while the deletion function is left empty
   because object attributes are rarely deleted. If a coder does try to delete one that doesn't have a
   deletion function specified, however, it will raise an exception, so if there is any chance of a
   legitimate reason to delete our property, we should supply that function.

Decorators: another way to create properties
   Decorators were introduced in Python 2.4 as a way to modify functions dynamically by passing them as
   arguments to other functions, which eventually return a new function. We won't be covering decorators
   in-depth at this time, but the basic syntax is easy to grasp. If you've never used them before, you
   can still follow along.

   Applying a decorator can be as simple as prefixing the function name with an @ symbol, and placing
   the result just before the definition of the function that is being decorated. The property function
   itself can be used with decorator syntax to turn a get function into a property:
class Foo:
  @property
  def foo(self):
    return "bar"

   This applies property as a decorator, and is equivalent to applying it as foo = property(foo). The
   main difference, from a readability perspective, is that we get to mark the foo function as a
   property at the top of the method, instead of after it is defined, where it can be easily overlooked.

   Going one step further, we can specify a setter function for the new property as follows:
class Foo:
  @property
  def foo(self):
    return self._foo
  @foo.setter
  def foo(self, value):
    self._foo = value

   This syntax looks a little odd. First we decorate the foo method as a getter. Then we decorate a new
   method with exactly the same name with the setter attribute of the original decorated foo method!
   Remember, the property function returns an object; this object is automatically set up to have a
   setter attribute, and this attribute can be applied as a decorator to other functions. Using the same
   name for the get and set methods is not required, but it does help group the multiple methods that
   create one property together.

   We can, of course, also specify a deletion function with @foo.deleter. We cannot specify a docstring
   using property decorators, so we need to rely on the property copying the docstring from the initial
   getter method.

   Here's our previous Silly class rewritten to use property as a decorator:
class Silly:
  @property
  def silly(self):
    "This is a silly property"
    print("You are getting silly")
    return self._silly
  @silly.setter
  def silly(self, value):
    print("You are making silly {}".format(value))
    self._silly = value
  @silly.deleter
  def silly(self):
    print("Whoah, you killed silly!")
    del self._silly

When should we use properties?
   With the property keyword smearing the division between behavior and data, it can be confusing to
   know which one to choose. The example use case we saw earlier is one of the most common uses of
   properties: we have some data on a class that we later want to add behavior to. There are also other
   factors to take into account when deciding to use a property.

   Technically, in Python, data, properties, and methods are all attributes on a class. The fact that a
   method is callable does not distinguish it from other types of attributes; indeed, it is possible to
   create normal objects that are callable, and also that functions and methods are themselves normal
   objects.

   The fact that methods are just callable attributes, and properties are just customizable attributes
   can help us in our decision. Methods should only represent actions; things that can be done to or
   performed by the object. When you call a method, even with only one argument, it should do something.
   Methods are generally verbs.

   That leaves us to decide between standard data attributes and properties. In general, always use a
   standard attribute until you need to control access to that property in some way. In either case,
   your attribute should be a noun. The only difference between an attribute and a property is that we
   can invoke custom actions automatically when a property is retrieved, set, or deleted.

   Let's try a more realistic example. A common need for custom behavior is caching a value that is
   difficult to calculate or expensive to look up (requiring, for example, a network request or database
   query). The goal is to store the value locally to avoid repeated calls to the expensive calculation.

   We can do this with a custom getter on the property. The first time the value is retrieved, we
   perform the lookup or calculation. Then we could locally cache the value as a private attribute on
   our object (or in dedicated caching software), and the next time the value is requested, we return
   the stored data. Here's how we might cache a webpage:
from urllib.request import urlopen
class WebPage:
  def __init__(self, url):
    self.url = url
    self._content = None
@property
def content(self):
  if not self._content:
    print("Retrieving New Page...")
    self._content = urlopen(self.url).read()
  return self._content

   We can test this code to see that the page is only retrieved once:
>>> import time
>>> webpage = WebPage("http://ccphillips.net/")
>>> now = time.time()
>>> content1 = webpage.content
Retrieving New Page...
>>> time.time() - now
22.43316888809204
>>> now = time.time()
>>> content2 = webpage.content
>>> time.time() - now
1.9266459941864014
>>> content2 == content1
True

   On my awful satellite connection it takes twenty seconds the first time I load the content, but the
   second time, I get the result in two seconds (which is really just the amount of time it took to type
   the lines into the interpreter).

   Custom getters are also useful for attributes that need to be calculated on the fly, based on other
   object attributes. For example, we might want to calculate the average for a list of integers:
class AverageList(list):
  @property
  def average(self):
    return sum(self) / len(self)

   This very simple class inherits from list, so we get list-like behavior for free. We just add a
   property to the class, and presto, our list can have an average:
>>> a = AverageList([1,2,3,4])
>>> a.average
2.5

   Of course, we could have made this a method instead, but then we should call it calculate_average(),
   since methods represent actions. But a property called average is more suitable; both easier to type,
   and easier to read.

   Custom setters are useful for validation, as we've already seen, but they can also be used to proxy a
   value to another location. For example, we could add a content setter to the WebPage class that
   automatically logs into our web server and uploads a new page whenever the value is set.

Summary

   In this article, we focused on identifying objects, especially objects that are not immediately
   apparent; objects that manage and control. In particular, we covered:
    1. Why objects should have both data and behavior
    2. How properties blur the distinction between data and behavior


---
https://www.packtpub.com/books/content/python-3-object-oriented-programming-managing-objects

Python 3 Object Oriented Programming: Managing objects
August 2010

Managing objects
   The difference between these objects and most of the examples we've seen so far is that our examples
   tend to represent concrete ideas. Management objects are more like office managers; they don't do the
   actual "visible" work out on the floor, but without them, there would be no communication between
   departments and nobody would know what they are supposed to do. Analogously, the attributes on a
   management class tend to refer to other objects that do the "visible" work; the behaviors on such a
   class delegate to those other classes at the right time, and pass messages between them.

   As an example, we'll write a program that does a find and replace action for text files stored in a
   compressed ZIP file. We'll need objects to represent the ZIP file and each individual text file
   (luckily, we don't have to write these classes, they're available in the Python Standard Library).
   The manager object will be responsible for ensuring three steps occur in order:
    1. Unzipping the compressed file.
    2. Performing the find and replace action.
    3. Zipping up the new files.

   The class is initialized with the .zip filename and search and replace strings. We create a temporary
   directory to store the unzipped files in, so that the folder stays clean. We also add a useful helper
   method for internal use that helps identify an individual filename inside that directory:
import sys
import os
import shutil
import zipfile
class ZipReplace:
  def __init__(self, filename, search_string,
      replace_string):
    self.filename = filename
    self.search_string = search_string
    self.replace_string = replace_string
    self.temp_directory = "unzipped-{}".format(
      filename)
  def _full_filename(self, filename):
    return os.path.join(self.temp_directory, filename)

   Then we create an overall "manager" method for each of the three steps. This method delegates
   responsibility to other methods. Obviously, we could do all three steps in one method, or indeed, in
   one script without ever creating an object. There are several advantages to separating the three
   steps:
    1. Readability: The code for each step is in a self-contained unit that is easy to read and
       understand. The method names describe what the method does, and no additional documentation is
       required to understand what is going on.
    2. Extensibility: If a subclass wanted to use compressed TAR files instead of ZIP files, it could
       override the zip and unzip methods without having to duplicate the find_replace method.
    3. Partitioning: An external class could create an instance of this class and call the find and
       replace method directly on some folder without having to zip the content.

   The delegation method is the first in the code below; the rest of the methods are included for
   completeness:
def zip_find_replace(self):
    self.unzip_files()
    self.find_replace()
    self.zip_files()
  def unzip_files(self):
    os.mkdir(self.temp_directory)
    zip = zipfile.ZipFile(self.filename)
    try:
      zip.extractall(self.temp_directory)
    finally:
      zip.close()
  def find_replace(self):
    for filename in os.listdir(self.temp_directory):
      with open(self._full_filename(filename)) as file:
        contents = file.read()
      contents = contents.replace(
          self.search_string, self.replace_string)
      with open(
        self._full_filename(filename), "w") as file:
        file.write(contents)
  def zip_files(self):
    file = zipfile.ZipFile(self.filename, 'w')
    for filename in os.listdir(self.temp_directory):
      file.write(
        self._full_filename(filename), filename)
    shutil.rmtree(self.temp_directory)
if __name__ == "__main__":
  ZipReplace(*sys.argv[1:4]).zip_find_replace()

   For brevity, the code for zipping and unzipping files is sparsely documented. Our current focus is on
   object-oriented design; if you are interested in the inner details of the zipfile module, refer to
   the documentation in the standard library, either online at
   [67]http://docs.python.org/library/zipfile.html or by typing import zipfile ; help(zipfile) into your
   interactive interpreter. Note that this example only searches the top-level files in a ZIP file; if
   there are any folders in the unzipped content, they will not be scanned, nor will any files inside
   those folders.

   The last two lines in the code allow us to run the example from the command line by passing the zip
   filename, search string, and replace string as arguments:
python zipsearch.py hello.zip hello hi

   Of course, this object does not have to be created from the command line; it could be imported from
   another module (to perform batch ZIP file processing) or accessed as part of a GUI interface or even
   a higher-level management object that knows what to do with ZIP files (for example to retrieve them
   from an FTP server or back them up to an external disk).

   As programs become more and more complex, the objects being modeled become less and less like
   physical objects. Properties are other abstract objects and methods are actions that change the state
   of those abstract objects. But at the heart of every object, no matter how complex, is a set of
   concrete properties and well-defined behaviors.

Removing duplicate code
   Often the code in management style classes such as ZipReplace is quite generic and can be applied in
   many different ways. It is possible to use either composition or inheritance to help keep this code
   in one place, thus eliminating duplicate code. Before we look at any examples of this, let's discuss
   a tiny bit of theory. Specifically: why is duplicate code a bad thing?

   There are several reasons, but they all boil down to readability and maintainability. When we're
   writing a new piece of code that is similar to an earlier piece, the easiest thing to do is copy the
   old code and change whatever needs to change (variable names, logic, comments) to make it work in the
   new location. Alternatively, if we're writing new code that seems similar, but not identical to code
   elsewhere in the project, the easiest thing to do is write fresh code with similar behavior, rather
   than figure out how to extract the overlapping functionality.

   But as soon as someone has to read and understand the code and they come across duplicate blocks,
   they are faced with a dilemma. Code that might have made sense suddenly has to be understood. How is
   one section different from the other? How are they the same? Under what conditions is one section
   called? When do we call the other? You might argue that you're the only one reading your code, but if
   you don't touch that code for eight months it will be as incomprehensible to you as to a fresh coder.
   When we're trying to read two similar pieces of code, we have to understand why they're different, as
   well as how they're different. This wastes the reader's time; code should always be written to be
   readable first.

   I once had to try to understand someone's code that had three identical copies of the same three
   hundred lines of very poorly written code. I had been working with the code for a month before I
   realized that the three "identical" versions were actually performing slightly different tax
   calculations. Some of the subtle differences were intentional, but there were also obvious areas
   where someone had updated a calculation in one function without updating the other two. The number of
   subtle, incomprehensible bugs in the code could not be counted.

   Reading such duplicate code can be tiresome, but code maintenance is an even greater torment. As the
   preceding story suggests, keeping two similar pieces of code up to date can be a nightmare. We have
   to remember to update both sections whenever we update one of them, and we have to remember how the
   multiple sections differ so we can modify our changes when we are editing each of them. If we forget
   to update both sections, we will end up with extremely annoying bugs that usually manifest themselves
   as, "but I fixed that already, why is it still happening?"

   The result is that people who are reading or maintaining our code have to spend astronomical amounts
   of time understanding and testing it compared to if we had written the code in a non-repetitive
   manner in the first place. It's even more frustrating when we are the ones doing the maintenance. The
   time we save by copy-pasting existing code is lost the very first time we have to maintain it. Code
   is both read and maintained many more times and much more often than it is written. Comprehensible
   code should always be paramount.

   This is why programmers, especially Python programmers (who tend to value elegant code more than
   average), follow what is known as the Don't Repeat Yourself, or DRY principle. DRY code is
   maintainable code. My advice to beginning programmers is to never use the copy and paste feature of
   their editor. To intermediate programmers, I suggest they think thrice before they hit Ctrl + C.

   But what should we do instead of code duplication? The simplest solution is often to move the code
   into a function that accepts parameters to account for whatever sections are different. This isn't a
   terribly object-oriented solution, but it is frequently sufficient. For example, if we have two
   pieces of code that unzip a ZIP file into two different directories, we can easily write a function
   that accepts a parameter for the directory to which it should be unzipped instead. This may make the
   function itself slightly more difficult to read, but a good function name and docstring can easily
   make up for that, and any code that invokes the function will be easier to read.

   That's certainly enough theory! The moral of the story is: always make the effort to refactor your
   code to be easier to read instead of writing bad code that is only easier to write.

   (For more resources on Python 3, see [68]here.)

In practice
   Let's explore two ways we can reuse existing code. After writing our code to replace strings in a ZIP
   file full of text files, we are later contracted to scale all the images in a ZIP file to 640x480.
   Looks like we could use a very similar paradigm to what we used in ZipReplace. The first impulse,
   obviously, would be to save a copy of that file and change the find_replace method to scale_image or
   something similar. But, that's just not cool. What if someday we want to change the unzip and zip
   methods to also open TAR files? Or maybe we want to use a guaranteed unique directory name for
   temporary files. In either case, we'd have to change it in two different places!

   We'll start by demonstrating an inheritance-based solution to this problem. First we'll modify our
   original ZipReplace class into a superclass for processing generic ZIP files:
import os
import shutil
import zipfile
class ZipProcessor:
  def __init__(self, zipname):
    self.zipname = zipname
    self.temp_directory = "unzipped-{}".format(
      zipname[:-4])
  def _full_filename(self, filename):
    return os.path.join(self.temp_directory, filename)
  def process_zip(self):
    self.unzip_files()
    self.process_files()
    self.zip_files()
  def unzip_files(self):
    os.mkdir(self.temp_directory)
    zip = zipfile.ZipFile(self.zipname)
    try:
      zip.extractall(self.temp_directory)
    finally:
      zip.close()
  def zip_files(self):
    file = zipfile.ZipFile(self.zipname, 'w')
    for filename in os.listdir(self.temp_directory):
      file.write(self._full_filename(
        filename), filename)
    shutil.rmtree(self.temp_directory)

   We changed the filename property to zipfile to avoid confusion with the filename local variables
   inside the various methods. This helps make the code more readable even though it isn't actually a
   change in design. We also dropped the two parameters to __init__ (search_string and replace_string)
   that were specific to ZipReplace. Then we renamed the zip_find_replace method to process_zip and made
   it call an (as yet undefined) process_files method instead of find_replace; these name changes help
   demonstrate the more generalized nature of our new class. Notice that we have removed the
   find_replace method altogether; that code is specific to ZipReplace and has no business here.

   This new ZipProcessor class doesn't actually define a process_files method; so if we ran it directly,
   it would raise an exception. Since it actually isn't meant to be run directly, we also removed the
   main call at the bottom of the original script.

   Now, before we move on to our image processing app, let's fix up our original zipsearch to make use
   of this parent class:
from zip_processor import ZipProcessor
import sys
import os
class ZipReplace(ZipProcessor):
  def __init__(self, filename, search_string,
      replace_string):
    super().__init__(filename)
    self.search_string = search_string
    self.replace_string = replace_string
def process_files(self):
  '''perform a search and replace on all files
  in the temporary directory'''
  for filename in os.listdir(self.temp_directory):
    with open(self._full_filename(filename)) as file:
      contents = file.read()
    contents = contents.replace(
      self.search_string, self.replace_string)
    with open(
      self._full_filename(filename), "w") as file:
      file.write(contents)
if __name__ == "__main__":
    ZipReplace(*sys.argv[1:4]).process_zip()

   This code is a bit shorter than the original version, since it inherits its ZIP processing abilities
   from the parent class. We first import the base class we just wrote and make ZipReplace extend that
   class. Then we use super() to initialize the parent class. The find_replace method is still here, but
   we renamed it to process_files so the parent class can call it. Because this name isn't as
   descriptive as the old one, we added a docstring to describe what it is doing.

   Now, that was quite a bit of work, considering that all we have now is a program that is functionally
   no different from the one we started with! But having done that work, it is now much easier for us to
   write other classes that operate on files in a ZIP archive, such as our photo scaler. Further, if we
   ever want to improve the zip functionality, we can do it for all classes by changing only the one
   ZipProcessor base class. Maintenance will be much more effective.

   See how simple it is, now to create a photo scaling class that takes advantage of the ZipProcessor
   functionality. (Note: this class requires the third-party pygame library to be installed. You can
   download it from [69]http://www.pygame.org/.)
from zip_processor import ZipProcessor
import os
import sys
from pygame import image
from pygame.transform import scale
class ScaleZip(ZipProcessor):
  def process_files(self):
    '''Scale each image in the directory to 640x480'''
    for filename in os.listdir(self.temp_directory):
      im = image.load(self._full_filename(filename))
      scaled = scale(im, (640,480))
      image.save(scaled, self._full_filename(filename))
if __name__ == "__main__":
ScaleZip(*sys.argv[1:4]).process_zip()

   All that work we did earlier paid off! Look how simple this class is! All we do is open each file
   (assuming that it is an image; it will unceremoniously crash if the file cannot be opened), scale it,
   and save it back. The ZipProcessor takes care of the zipping and unzipping without any extra work on
   our part.

Or we can use composition
   Now, let's try solving the same problem using a composition-based solution. Even though we're
   completely changing paradigms, from inheritance to composition, we only have to make a minor
   modification to our ZipProcessor class:
import os
import shutil
import zipfile
class ZipProcessor:
  def __init__(self, zipname, processor):
    self.zipname = zipname
    self.temp_directory = "unzipped-{}".format(
      zipname[:-4])
    self.processor = processor
  def _full_filename(self, filename):
    return os.path.join(self.temp_directory, filename)
  def process_zip(self):
    self.unzip_files()
    self.processor.process(self)
    self.zip_files()
  def unzip_files(self):
    os.mkdir(self.temp_directory)
    zip = zipfile.ZipFile(self.zipname)
    try:
      zip.extractall(self.temp_directory)
    finally:
      zip.close()
  def zip_files(self):
    file = zipfile.ZipFile(self.zipname, 'w')
    for filename in os.listdir(self.temp_directory):
      file.write(self._full_filename(filename), filename)
    shutil.rmtree(self.temp_directory)

   All we did was change the initializer to accept a processor object. The process_zip function now
   calls a method on that processor object; the method called accepts a reference to the ZipProcessor
   itself. Now we can change our ZipReplace class to be a suitable processor object that no longer uses
   inheritance:
from zip_processor import ZipProcessor
import sys
import os
class ZipReplace:
  def __init__(self, search_string,
      replace_string):
    self.search_string = search_string
    self.replace_string = replace_string
  def process(self, zipprocessor):
    '''perform a search and replace on all files in the
    temporary directory'''
    for filename in os.listdir(
        zipprocessor.temp_directory):
      with open(
        zipprocessor._full_filename(filename)) as file:
        contents = file.read()
      contents = contents.replace(
        self.search_string, self.replace_string)
      with open(zipprocessor._full_filename(
          filename), "w") as file:
        file.write(contents)
if __name__ == "__main__":
  zipreplace = ZipReplace(*sys.argv[2:4])
  ZipProcessor(sys.argv[1], zipreplace).process_zip()

   We didn't actually change much here; the class no longer inherits from ZipProcessor, and when we
   process the files, we accept a zipprocessor object that gives us the function to calculate
   __full_filename. In the bottom two lines, when we run from the command line, we first construct a
   ZipReplace object. This is then passed into the ZipProcessor constructor so the two objects can
   communicate.

   This design is a terrific separation of interests. Now we have a ZipProcessor that can accept any
   object that has a process method to do the actual processing. Further, we have a ZipReplace that can
   be passed to any method, function, or object that wants to call its process function; it is no longer
   tied to the zip processing code through an inheritance relationship; it could now be applied with
   equal ease to a local or network filesystem, for example, or to a different kind of compressed file
   such as a RAR archive.

   Any inheritance relationship can be modeled as a composition relationship (change the "is a" to a
   "has a parent") instead, but that does not mean it always should be. And the reverse is not true,
   most composition relationships cannot be (properly) modeled as inheritance.

Case study
   For this case study, we'll try to delve further into the question, "when should I choose an object
   versus a built-in type?" We'll be modeling a Document class that might be used in a text editor or
   word processor. What objects, functions, or properties should it have?

   We might start with a str for the Document contents, but strings aren't mutable. A mutable object is
   one that can be changed; but a str is immutable, we can't insert a character into it or remove one
   without creating a brand new string object. That's leaving a lot of str objects for Python's garbage
   collector to clean up behind us. So, instead of a string, we'll use a list of characters, which we
   can modify at will. In addition, a Document would need to know the current cursor position within the
   list, and should also store a filename for the document.

   Now, what methods should it have? There are a lot of things we might want to do to a text document,
   including inserting and deleting characters, cut, copy, paste, and saving or closing the document. It
   looks like there are copious amounts of both data and behavior, so it makes sense to put all this
   stuff into its own Document class.

   The question is, should this class be composed of a bunch of basic Python objects such as str
   filenames, int cursor positions, and a list of characters? Or should some or all of those things be
   specially defined objects in their own right? What about individual lines and characters, do they
   need to have classes of their own?

   We'll answer these questions as we go, but let's just design the simplest possible Document class
   first and see what it can do:
class Document:
  def __init__(self):
    self.characters = []
    self.cursor = 0
    self.filename = ''
  def insert(self, character):
    self.characters.insert(self.cursor, character)
    self.cursor += 1
  def delete(self):
  del self.characters[self.cursor]
  def save(self):
    f = open(self.filename, 'w')
    f.write(''.join(self.characters))
    f.close()
  def forward(self):
    self.cursor += 1
  def back(self):
    self.cursor -= 1

   This simple class allows us full control over editing a basic document. Have a look at it in action:
>>> doc = Document()
>>> doc.filename = "test_document"
>>> doc.insert('h')
>>> doc.insert('e')
>>> doc.insert('l')
>>> doc.insert('l')
>>> doc.insert('o')
>>> "".join(doc.characters)
'hello'
>>> doc.back()
>>> doc.delete()
>>> doc.insert('p')
>>> "".join(doc.characters)
'hellp'

   Looks like it's working. We could connect a keyboard's letter and arrow keys to these methods and the
   document would track everything just fine.

   But what if we want to connect more than just arrow keys. What if we want to connect the Home and End
   keys as well? We could add more methods to the Document class that search forward or backwards for
   newline characters (in Python, a newline character, or \n represents the end of one line and the
   beginning of a new one) in the string and jump to them, but if we did that for every possible
   movement action (move by words, move by sentences, Page Up, Page Down, end of line, beginning of
   whitespace, and more), the class would be huge. Maybe it would be better to put those methods on a
   separate object. What we can do is turn the cursor attribute into an object that is aware of its
   position and can manipulate that position. We can move the forward and back methods to that class,
   and add a couple more for the Home and End keys:
class Cursor:
  def __init__(self, document):
    self.document = document
    self.position = 0
  def forward(self):
    self.position += 1
  def back(self):
    self.position -= 1
  def home(self):
    while self.document.characters[
        self.position-1] != '\n':
      self.position -= 1
      if self.position == 0:
        # Got to beginning of file before newline
        break
def end(self):
  while self.position < len(self.document.characters
        ) and self.document.characters[
          self.position] != '\n':
    self.position += 1

   This class takes the document as an initialization parameter so the methods have access to the
   contents of the document's character list. It then provides simple methods for moving backwards and
   forwards, as before, and for moving to the home and end positions.

   This code is not very safe. You can very easily move past the ending position, and if you try to go
   home on an empty file it will crash. These examples are kept short to make them readable, that
   doesn't mean they are defensive! You can improve the error checking of this code as an exercise; it
   might be a great opportunity to expand your exception handling skills.

   The Document class itself is hardly changed, except for removing the two methods that were moved to
   the Cursor class:
class Document:
  def __init__(self):
    self.characters = []
    self.cursor = Cursor(self)
    self.filename = ''
  def insert(self, character):
    self.characters.insert(self.cursor.position,
      character)
    self.cursor.forward()
  def delete(self):
    del self.characters[self.cursor.position]
  def save(self):
    f = open(self.filename, 'w')
    f.write(''.join(self.characters))
    f.close()

   We simply updated anything that accessed the old cursor integer to use the new object instead. We can
   test that the home method is really moving to the newline character.
>>> d = Document()
>>> d.insert('h')
>>> d.insert('e')
>>> d.insert('l')
>>> d.insert('l')
>>> d.insert('o')
>>> d.insert('\n')
>>> d.insert('w')
>>> d.insert('o')
>>> d.insert('r')
>>> d.insert('l')
>>> d.insert('d')
>>> d.cursor.home()
>>> d.insert("*")
>>> print("".join(d.characters))
hello
*world

   Now, since we've been using that string join function a lot (to concatenate the characters so we can
   see the actual document contents), we can add a property to the Document class to give us the
   complete string:
@property
def string(self):
  return "".join(self.characters)

   This makes our testing a little simpler:
>>> print(d.string)
hello
world

   This framework is easy enough to extend to create a complete text editor document. Now, let's make it
   work for rich text; text that can have bold, underlined, or italic characters. There are two ways we
   could process this; the first is to insert "fake" characters into our character list that act like
   instructions such as "bold characters until you find a stop bold character". The second is to add
   information to each character indicating what formatting it should have. While the former method is
   probably more common, we'll implement the latter solution. To do that, we're obviously going to need
   a class for characters. This class will have an attribute representing the character, as well as
   three boolean attributes representing whether it is bold, italic, or underlined.

   Hmm, Wait! Is this character class going to have any methods? If not, maybe we should use one of the
   many Python data structures instead; a tuple or named tuple would probably be sufficient. Are there
   any actions that we would want to do to, or invoke on a character?

   Well, clearly, we might want to do things with characters, such as delete or copy them, but those are
   things that need to be handled at the Document level, since they are really modifying the list of
   characters. Are there things that need to be done to individual characters?

   Actually, now that we're thinking about what a Character actually is... what is it? Would it be safe
   to say that a Character is a string? Maybe we should use an inheritance relationship here? Then we
   can take advantage of the numerous methods that str instances come with.

   What sorts of methods are we talking about? There's startswith, strip, find, lower, and many more.
   Most of these methods expect to be working on strings that contain more than one character. In
   contrast, if Character were to subclass str, we'd probably be wise to override __init__ to raise an
   exception if a multi-character string were supplied. Since all those methods we'd get for free
   wouldn't really apply to our Character class, it turns out we shouldn't use inheritance, after all.

   This leaves us at our first question; should Character even be a class? There is a very important
   special method on the object class that we can take advantage of to represent our characters. This
   method, called __str__ (two underscores, like __init__), is used in string manipulation functions
   like print and the str constructor to convert any class to a string. The default implementation does
   some boring stuff like printing the name of the module and class and its address in memory. But if we
   override it, we can make it print whatever we like. For our implementation, we can make it prefix
   characters with special characters to represent whether they are bold, italic, or underlined. So we
   will create a class to represent a character, and here it is:
class Character:
  def __init__(self, character,
      bold=False, italic=False, underline=False):
    assert len(character) == 1
    self.character = character
    self.bold = bold
    self.italic = italic
    self.underline = underline
  def __str__(self):
    bold = "*" if self.bold else ''
    italic = "/" if self.italic else ''
    underline = "_" if self.underline else ''
    return bold + italic + underline + self.character

   This class allows us to create characters and prefix them with a special character when the str()
   function is applied to them. Nothing too exciting there. We only have to make a few minor
   modifications to the Document and Cursor classes to work with this class. In the Document class, we
   add these two lines at the beginning of the insert method:
def insert(self, character):
  if not hasattr(character, 'character'):
    character = Character(character)

   This is a rather strange bit of code. Its basic purpose is to check if the character being passed in
   is a Character or a str. If it is a string, it is wrapped in a Character class so all objects in the
   list are Character objects. However, it is entirely possible that someone using our code would want
   to use a class that is neither Character nor string, using duck typing. If the object has a character
   attribute, we assume it is a "Character-like" object. But if it does not, we assume it is a
   "str-like" object and wrap it in a Character. This helps the program take advantage of duck typing as
   well as polymorphism; as long as an object has a character attribute, it can be used in the Document.
   This could be very useful, for example, if we wanted to make a programmer's editor with syntax
   highlighting: we'd need extra data on the character, such as what type of token the character belongs
   to.

   In addition, we need to modify the string property on Document to accept the new Character values.
   All we need to do is call str() on each character before we join it:
@property
def string(self):
  return "".join((str(c) for c in self.characters))

   This code uses a generator expression. It's simply a shortcut to perform a specific action on all the
   objects in a sequence.

   Finally we also need to check Character.character, instead of just the string character we were
   storing before, in the home and end functions when we're looking to see if it matches a newline.
def home(self):
  while self.document.characters[
      self.position-1].character != '\n':
    self.position -= 1
    if self.position == 0:
      # Got to beginning of file before newline
      break
def end(self):
  while self.position < len(
      self.document.characters) and \
      self.document.characters[
        self.position
        ].character != '\n':
    self.position += 1

   This completes the formatting of characters. We can test it to see that it works:
>>> d = Document()
>>> d.insert('h')
>>> d.insert('e')
>>> d.insert(Character('l', bold=True))
>>> d.insert(Character('l', bold=True))
>>> d.insert('o')
>>> d.insert('\n')
>>> d.insert(Character('w', italic=True))
>>> d.insert(Character('o', italic=True))
>>> d.insert(Character('r', underline=True))
>>> d.insert('l')
>>> d.insert('d')
>>> print(d.string)
he*l*lo
/w/o_rld
>>> d.cursor.home()
>>> d.delete()
>>> d.insert('W')
>>> print(d.string)
he*l*lo
W/o_rld
>>> d.characters[0].underline = True
>>> print(d.string)
_he*l*lo
W/o_rld
>>>

   As expected, whenever we print the string, each bold character is preceded by a *, each italic
   character by a /, and each underlined character by a _. All our functions seem to work, and we can
   modify characters in the list after the fact. We have a working rich text document object that could
   be plugged into a user interface and hooked up with a keyboard for input and a screen for output.
   Naturally, we'd want to display real bold, italic, and underlined characters on the screen, instead
   of using our __str__ method, but it was sufficient for the basic testing we demanded of it.

Exercises
   We've looked at various ways that objects, data, and methods can interact with each other in an
   object-oriented Python program. As usual, your first thoughts should be how you can apply these
   principles to your own work. Do you have any messy scripts lying around that could be rewritten using
   an object-oriented manager? Look through some of your old code and look for methods that are not
   actions. If the name isn't a verb, try rewriting it as a property.

   Think about code you've written in any language. Does it break the DRY principle? Is there any
   duplicate code? Did you copy and paste code? Did you write two versions of similar pieces of code
   because you didn't feel like understanding the original code? Go back over some of your recent code
   now and see if you can refactor the duplicate code using inheritance or composition. Try to pick a
   project you're still interested in maintaining; not code so old that you never want to touch it
   again. It helps keep your interest up when you do the improvements!

   Now, look back over some of the examples we saw in this article. Start with the cached webpage
   example which uses a property to cache the retrieved data. An obvious problem with this example is
   that the cache is never refreshed. Add a timeout to the getter for the property, and only return the
   cached page if the page has been requested before the timeout has expired. You can use the time
   module (time.time() - an_old_time returns the number of seconds that have elapsed since an_old_time)
   to determine whether the cache has expired.

   Now look at the composition and inheritance based versions of ZipProcessor. We wrote an
   inheritance-based ScaleZipper, but didn't port it to the composite ZipProcessor. Try writing the
   composite ScaleZipper and compare the two pieces of code. Which version do you find easier to use?
   Which is more elegant? What is easier to read? These are subjective questions; the answer varies for
   each of us. Knowing the answer, however, is important; if you find you prefer inheritance over
   composition, you have to pay attention that you don't overuse inheritance in your daily coding. If
   you prefer composition, make sure you don't miss opportunities to create an elegant inheritance-based
   solution.

   Finally, add some error handlers to the various classes we created in the case study. They should
   ensure single characters are entered, that you don't try to move the cursor past the end or beginning
   of the file, that you don't delete a character that doesn't exist, and that you don't save a file
   without a filename. Try to think of as many edge cases as you can, and account for them. Consider
   different ways to handle them; should you raise an exception when the user tries to move past the end
   of the file, or just stay on the last character?

   Pay attention, in your daily coding, to the copy and paste commands. Every time you use them in your
   editor, consider whether it would be a good idea to improve your program's organization so that you
   only have one version of the code you are about to copy.

Summary
   In this article, we focused on identifying objects, especially objects that are not immediately
   apparent; objects that manage and control. In particular, we covered:
    1. The DRY principle and the follies of duplicate code
    2. Inheritance and composition for reducing code duplication


---
https://www.packtpub.com/books/content/objects-python

Objects in Python
July 2010

Creating Python classes
   We don't have to write much Python code to realize that Python is a very "clean" language. When we
   want to do something, we just do it, without having to go through a lot of setup. The ubiquitous,
   "hello world" in Python, as you've likely seen, is only one line.

   Similarly, the simplest class in Python 3 looks like this:
class MyFirstClass:
    pass

   There's our first object-oriented program! The class definition starts with the class keyword. This
   is followed by a name (of our choice) identifying the class, and is terminated with a colon.

   The class name must follow standard Python variable naming rules (must start with a letter or
   underscore, can only be comprised of letters, underscores, or numbers). In addition, the Python style
   guide (search the web for "PEP 8"), recommends that classes should be named using CamelCase notation
   (start with a capital letter, any subsequent words should also start with a capital).

   The class definition line is followed by the class contents, indented. As with other Python
   constructs, indentation is used to delimit the classes, rather than braces or brackets as many other
   languages use. Use four spaces for indentation unless you have a compelling reason not to (such as
   fitting in with somebody else's code that uses tabs for indents). Any decent programming editor can
   be configured to insert four spaces whenever the Tab key is pressed.

   Since our first class doesn't actually do anything, we simply use the pass keyword on the second line
   to indicate that no further action needs to be taken.

   We might think there isn't much we can do with this most basic class, but it does allow us to
   instantiate objects of that class. We can load the class into the Python 3 interpreter so we can play
   with it interactively. To do this, save the class definition mentioned earlier into a file named
   first_class.py and then run the command python -i first_class.py. The -i argument tells Python to
   "run the code and then drop to the interactive interpreter". The following interpreter session
   demonstrates basic interaction with this class:
>>> a = MyFirstClass()
>>> b = MyFirstClass()
>>> print(a)
<__main__.MyFirstClass object at 0xb7b7faec>
>>> print(b)
<__main__.MyFirstClass object at 0xb7b7fbac>
>>>

   This code instantiates two objects from the new class, named a and b. Creating an instance of a class
   is a simple matter of typing the class name followed by a pair of parentheses. It looks much like a
   normal function call, but Python knows we're "calling" a class and not a function, so it understands
   that its job is to create a new object. When printed, the two objects tell us what class they are and
   what memory address they live at. Memory addresses aren't used much in Python code, but here,it
   demonstrates that there are two distinctly different objects involved.

Adding attributes
   Now, we have a basic class, but it's fairly useless. It doesn't contain any data, and it doesn't do
   anything. What do we have to do to assign an attribute to a given object?

   It turns out that we don't have to do anything special in the class definition. We can set arbitrary
   attributes on an instantiated object using the dot notation:
class Point:
    pass
p1 = Point()
p2 = Point()
p1.x = 5
p1.y = 4
p2.x = 3
p2.y = 6
print(p1.x, p1.y)
print(p2.x, p2.y)

   If we run this code, the two print statements at the end tell us the new attribute values on the two
   objects:
5 4
3 6

   This code creates an empty Point class with no data or behaviors. Then it creates two instances of
   that class and assigns each of those instances x and y coordinates to identify a point in two
   dimensions. All we need to do to assign a value to an attribute on an object is use the syntax
   <object>.<attribute>=<value>. This is sometimes referred to as dot notation. The value can be
   anything: a Python primitive, a built-in data type, another object. It can even be a function or
   another class!

Making it do something
   Now, having objects with attributes is great, but object-oriented programming is really about the
   interaction between objects. We're interested in invoking actions that cause things to happen to
   those attributes. It is time to add behaviors to our classes.

   Let's model a couple of actions on our Point class. We can start with a method called reset that
   moves the point to the origin (the origin is the point where x and y are both zero). This is a good
   introductory action because it doesn't require any parameters:
class Point:
    def reset(self):
        self.x = 0
        self.y = 0
p = Point()
p.reset()
print(p.x, p.y)

   That print statement shows us the two zeros on the attributes:
0 0

   A method in Python is identical to defining a function. It starts with the keyword def followed by a
   space and the name of the method. This is followed by a set of parentheses containing the parameter
   list (we'll discuss the self parameter in just a moment), and terminated with a colon. The next line
   is indented to contain the statements inside the method. These statements can be arbitrary Python
   code operating on the object itself and any parameters passed in as the method sees fit.

   The one difference between methods and normal functions is that all methods have one required
   argument. This argument is conventionally named self; I've never seen a programmer use any other name
   for this variable (convention is a very powerful thing). There's nothing stopping you, however, from
   calling it this or even Martha.

   The self argument to a method is simply a reference to the object that the method is being invoked
   on. We can access attributes and methods of that object as if it were any other object. This is
   exactly what we do inside the reset method when we set the x and y attributes of the self object.

   Notice that when we call the p.reset() method, we do not have to pass the self argument into it.
   Python automatically takes care of this for us. It knows we're calling a method on the p object, so
   it automatically passes that object to the method.

   However, the method really is just a function that happens to be on a class. Instead of calling the
   method on the object, we could invoke the function on the class, explicitly passing our object as the
   self argument:
p = Point()
Point.reset(p)
print(p.x, p.y)

   The output is the same as the previous example because, internally, the exact same process has
   occurred.

   What happens if we forget to include the self argument in our class definition? Python will bail with
   an error message:
>>> class Point:
...          def reset():
...              pass
...
>>> p = Point()
>>> p.reset()
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
TypeError: reset() takes no arguments (1 given)

   The error message is not as clear as it could be ("You silly fool, you forgot the self argument"
   would be more informative). Just remember that when you see an error message that indicates missing
   arguments, the first thing to check is whether you forgot self in the method definition.

   So how do we pass multiple arguments to a method? Let's add a new method that allows us to move a
   point to an arbitrary position, not just the origin. We can also include one that accepts another
   Point object as input and returns the distance between them:
import math
class Point:
    def move(self, x, y):
        self.x = x
        self.y = y
    def reset(self):
        self.move(0, 0)
    def calculate_distance(self, other_point):
        return math.sqrt((self.x - other_point.x)**2 +(self.y - other_point.y)
**2)
# how to use it:
point1 = Point()
point2 = Point()
point1.reset()
point2.move(5,0)
print(point2.calculate_distance(point1))
assert (point2.calculate_distance(point1) ==
        point1.calculate_distance(point2))
point1.move(3,4)
print(point1.calculate_distance(point2))
print(point1.calculate_distance(point1))

   The print statements at the end give us the following output:
5.0
4.472135955
0.0

   A lot has happened here. The class now has three methods. The move method accepts two arguments, x
   and y, and sets the values on the self object, much like the old reset method from the previous
   example. The old reset method now calls move, since a reset is just a move to a specific known
   location.

   The calculate_distance method uses the not-too-complex Pythagorean Theorem to calculate the distance
   between two points. I hope you understand the math (** means squared, and math.sqrt calculates a
   square root), but it's not a requirement for our current focus: learning how to write methods.

   The example code at the end shows how to call a method with arguments; simply include the arguments
   inside the parentheses, and use the same dot notation to access the method. I just picked some random
   positions to test the methods. The test code calls each method and prints the results on the console.
   The assert function is a simple test tool; the program will bail if the statement after assert is
   False (or zero, empty, or None). In this case, we use it to ensure that the distance is the same
   regardless of which point called the other point's calculate_distance method.

Initializing the object
   If we don't explicitly set the x and y positions on our Point object, either using move or by
   accessing them directly, we have a broken point with no real position. What will happen when we try
   to access it?

   Well, let's just try it and see. "Try it and see" is an extremely useful tool for Python study. Open
   up your interactive interpreter and type away. The following interactive session shows what happens
   if we try to access a missing attribute. If you saved the previous example as a file or are using the
   examples distributed in this article, you can load it into the Python interpreter with the command
   python -i filename.py.
>>> point = Point()
>>> point.x = 5
>>> print(point.x)
5
>>> print(point.y)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
AttributeError: 'Point' object has no attribute 'y'

   Well, at least it threw a useful exception. You've probably seen them before (especially the
   ubiquitous SyntaxError, which means you typed something incorrectly!). At this point, simply be aware
   that it means something went wrong.

   The output is useful for debugging. In the interactive interpreter it tells us the error occurred at
   line 1, which is only partially true (in an interactive session, only one line is executed at a
   time). If we were running a script in a file, it would tell us the exact line number, making it easy
   to find the offending code. In addition, it tells us the error is an AttributeError, and gives a
   helpful message telling us what that error means.

   We can catch and recover from this error, but in this case, it feels like we should have specified
   some sort of default value. Perhaps every new object should be reset() by default or maybe it would
   be nice if we could force the user to tell us what those positions should be when they create the
   object.

   Most object-oriented programming languages have the concept of a constructor, a special method that
   creates and initializes the object when it is created. Python is a little different; it has a
   constructor and an initializer. Normally, the constructor function is rarely ever used unless you're
   doing something exotic. So we'll start our discussion with the initialization method.

   The Python initialization method is the same as any other method, except it has a special name:
   __init__. The leading and trailing double underscores mean, "this is a special method that the Python
   interpreter will treat as a special case". Never name a function of your own with leading and
   trailing double underscores. It may mean nothing to Python, but there's always the possibility that
   the designers of Python will add a function that has a special purpose with that name in the future,
   and when they do, your code will break.

   Let's start with an initialization function on our Point class that requires the user to supply x and
   y coordinates when the Point object is instantiated:
class Point:
    def __init__(self, x, y):
        self.move(x, y)
    def move(self, x, y):
        self.x = x
        self.y = y
    def reset(self):
        self.move(0, 0)
# Constructing a Point
point = Point(3, 5)
print(point.x, point.y)

   Now, our point can never go without a y coordinate! If we try to construct a point without including
   the proper initialization parameters, it will fail with a not enough arguments error similar to the
   one we received earlier when we forgot the self argument.

   What if we don't want to make those two arguments required? Well then we can use the same syntax
   Python functions use to provide default arguments. The keyword argument syntax appends an equals sign
   after each variable name. If the calling object does not provide that argument, then the default
   argument is used instead; the variables will still be available to the function, but they will have
   the values specified in the argument list. Here's an example:
class Point:
    def __init__(self, x=0, y=0):
        self.move(x, y)

   Most of the time, we put our initialization statements in an __init__ function. But as mentioned
   earlier, Python has a constructor in addition to its initialization function. You may never need to
   use the other Python constructor, but it helps to know it exists, so we'll cover it briefly.

   The constructor function is called __new__ as opposed to __init__, and accepts exactly one argument,
   the class that is being constructed (it is called before the object is constructed, so there is no
   self argument). It also has to return the newly created object. This has interesting possibilities
   when it comes to the complicated art of meta-programming, but is not very useful in day-to-day
   programming. In practice, you will rarely, if ever, need to use __new__, and __init__ will be
   sufficient.

Explaining yourself
   Python is an extremely easy-to-read programming language; some might say it is self-documenting.
   However, when doing object-oriented programming, it is important to write API documentation that
   clearly summarizes what each object and method does. Keeping documentation up-to-date is difficult;
   the best way to do it is to write it right into our code.

   Python supports this through the use of docstrings. Each class, function, or method header can have a
   standard Python string as the first line following the definition (the line that ends in a colon).
   This line should be indented the same as the following code.

   Docstrings are simply Python strings enclosed with apostrophe (') or quote (") characters. Often,
   docstrings are quite long and span multiple lines (the style guide suggests that line-length should
   not exceed 80 characters), which can be formatted as multi-line strings, enclosed in matching triple
   apostrophe (''') or triple quote (""") characters.

   A docstring should clearly and concisely summarize the purpose of the class or method it is
   describing. It should explain any parameters whose usage is not immediately obvious, and is also a
   good place to include short examples of how to use the API. Any caveats or problems an unsuspecting
   user of the API should be aware of should also be noted.

   To illustrate the use of docstrings, we will end this part with our completely documented Point
   class:
import math
class Point:
    'Represents a point in two-dimensional geometric coordinates'
    def __init__(self, x=0, y=0):
          '''Initialize the position of a new point. The x and y
            coordinates can be specified. If they are not, the point
            defaults to the origin.'''
          self.move(x, y)
    def move(self, x, y):
        "Move the point to a new location in two-dimensional space."
        self.x = x
        self.y = y
    def reset(self):
        'Reset the point back to the geometric origin: 0, 0'
        self.move(0, 0)
    def calculate_distance(self, other_point):
        """Calculate the distance from this point to a second point
            passed as a parameter.
            This function uses the Pythagorean Theorem to calculate
            the distance between the two points. The distance is returned
            as a float."""
        return math.sqrt(
                    (self.x - other_point.x)**2 +
                    (self.y – other_point.y)**2)

   Try typing or loading (remember, it's python -i filename.py) this file into the interactive
   interpreter. Then enter help(Point)<enter> at the Python prompt. You should see nicely formatted
   documentation for the class, as shown in the following screenshot:

   Objects in Python

Modules and packages
   Now that we know how to create classes and instantiate objects, it is time to think about organizing
   them. For small programs, we can just put all our classes into one file and put some code at the end
   of the file to start them interacting. However, as our projects grow, it can become difficult to find
   one class that needs to be edited among the many classes we've defined. This is where modules come
   in. Modules are simply Python files, nothing more. The single file in our small program is a module.
   Two Python files are two modules. If we have two files in the same folder, we can load a class from
   one module for use in the other module.

   For example, if we are building an e-commerce system, we will likely be storing a lot of data in a
   database. We can put all the classes and functions related to database access into a separate file
   (we'll call it something sensible: database.py). Then our other modules (for example: customer
   models, product information, and inventory) can import classes from that module in order to access
   the database.

   The import statement is used for importing modules or specific classes or functions from modules.
   We've already seen an example of this in our Point class in the previous part. We used the import
   statement to get Python's built-in math module so we could use its sqrt function in our distance
   calculation.

   Here's a concrete example. Assume we have a module called database.py that contains a class called
   Database, and a second module called products.py that is responsible for product-related queries. At
   this point, we don't need to think too much about the contents of these files. What we know is that
   products.py needs to instantiate the Database class from database.py so it can execute queries on the
   product table in the database.

   There are several variations on the import statement syntax that can be used to access the class.
import database
db = database.Database()
# Do queries on db

   This version imports the database module into the products namespace (the list of names currently
   accessible in a module or function), so any class or function in the database module can be accessed
   using database.<something> notation. Alternatively, we can import just the one class we need using
   the from...import syntax:
from database import Database
db = Database()
# Do queries on db

   If, for some reason, products already has a class called Database, and we don't want the two names to
   be confused, we can rename the class when used inside the products module:
from database import Database as DB
db = DB()
# Do queries on db

   We can also import multiple items in one statement. If our database module also contains a Query
   class, we can import both classes using:
from database import Database, Query

   Some sources say that we can even import all classes and functions from the database module using
   this syntax:
from database import *

   Don't do this. Every experienced Python programmer will tell you that you should never use this
   syntax. They'll use obscure justifications like, "it clutters up the namespace", which doesn't make
   much sense to beginners. One way to learn why to avoid this syntax is to use it and try to understand
   your code two years later. But we can save some time and two years of poorly written code with a
   quick explanation now!

   When we explicitly import the database class at the top of our file using from database import
   Database, we can easily see where the Database class comes from. We might use db = Database() 400
   lines later in the file, and we can quickly look at the imports to see where that Database class came
   from. Then if we need clarification as to how to use the Database class, we can visit the original
   file (or import the module in the interactive interpreter and use the help(database.Database)
   command). However, if we use from database import * syntax, it takes a lot longer to find where that
   class is located. Code maintenance becomes a nightmare.

   In addition, many editors are able to provide extra functionality, such as reliable code completion
   or the ability to jump to the definition of a class if normal imports are used. The import * syntax
   usually completely destroys their ability to do this reliably.

   Finally, using the import * syntax can bring unexpected objects into our local namespace. Sure, it
   will import all the classes and functions defined in the module being imported from, but it will also
   import any classes or modules that were themselves imported into that file!

   In spite of all these warnings, you may think, "if I only use from X import * syntax for one module,
   I can assume any unknown imports come from that module". This is technically true, but it breaks down
   in practice. I promise that if you use this syntax, you (or someone else trying to understand your
   code) will have extremely frustrating moments of, "Where on earth can this class be coming from?"
   Every name used in a module should come from a well-specified place, whether it is defined in that
   module, or explicitly imported from another module. There should be no magic variables that seem to
   come out of thin air. We should always be able to immediately identify where the names in our current
   namespace originated.

Organizing the modules
   As a project grows into a collection of more and more modules, we may find that we want to add
   another level of abstraction, some kind of nested hierarchy on our modules' levels. But we can't put
   modules inside modules; one file can only hold one file, after all, and modules are nothing more than
   Python files.

   Files, however, can go in folders and so can modules. A package is a collection of modules in a
   folder. The name of the package is the name of the folder. All we need to do to tell Python that a
   folder is a package and place a (normally empty) file in the folder named __init__.py. If we forget
   this file, we won't be able to import modules from that folder.

   Let's put our modules inside an ecommerce package in our working folder, which will also contain a
   main.py to start the program. Let's additionally add another package in the ecommerce package for
   various payment options. The folder hierarchy will look like this:
parent_directory/
    main.py
    ecommerce/
        __init__.py
        database.py
        products.py
        payments/
            __init__.py
            paypal.py
            authorizenet.py

   When importing modules or classes between packages, we have to be cautious about the syntax. In
   Python 3, there are two ways of importing modules: absolute imports and relative imports.

Absolute imports

   Absolute imports specify the complete path to the module, function, or path we want to import. If we
   need access to the Product class inside the products module, we could use any of these syntaxes to do
   an absolute import:
import ecommerce.products
product = ecommerce.products.Product()

   or
from ecommerce.products import Product
product = Product()

   or
from ecommerce import products
product = products.Product()

   The import statements separate packages or modules using the period as a separator.

   These statements will work from any module. We could instantiate a Product using this syntax in
   main.py, in the database module, or in either of the two payment modules. Indeed, so long as the
   packages are available to Python, it will be able to import them. For example, the packages can also
   be installed to the Python site packages folder, or the PYTHONPATH environment variable could be
   customized to dynamically tell Python what folders to search for packages and modules it is going to
   import.

   So with these choices, which syntax do we choose? It depends on your personal taste and the
   application at hand. If there are dozens of classes and functions inside the products module that I
   want to use, I generally import the module name using the from ecommerce import products syntax and
   then access the individual classes using products.Product. If I only need one or two classes from the
   products module, I import them directly using the from ecommerce.proucts import Product syntax. I
   don't personally use the first syntax very often unless I have some kind of name conflict (for
   example, I need to access two completely different modules called products and I need to separate
   them). Do whatever you think makes your code look more elegant.

Relative imports
   When working with related modules in a package, it seems kind of silly to specify the full path; we
   know what our parent module is named. This is where relative imports come in. Relative imports are
   basically a way of saying "find a class, function, or module as it is positioned relative to the
   current module". For example, if we are working in the products module and we want to import the
   Database class from the database module "next" to it, we could use a relative import:
from .database import Database

   The period in front of database says, "Use the database module inside the current package". In this
   case, the current package is the package containing the products.py file we are currently editing,
   that is, the ecommerce package.

   If we were editing the paypal module inside the ecommerce.payments package, we would want to say,
   "Use the database package inside the parent package", instead. That is easily done with two periods:
from ..database import Database

   We can use more periods to go further up the hierarchy. Of course, we can also go down one side and
   back up the other. We don't have a deep enough example hierarchy to illustrate this properly, but the
   following would be a valid import if we had a ecommerce.contact package containing an email module
   and wanted to import the send_mail function into our paypal module:
from ..contact.email import send_mail

   This import uses two periods to say, "the parent of the payments package", then uses normal
   package.module syntax to go back "up" into the contact package.

   Inside any one module, we can specify variables, classes, or functions. They can be a handy way of
   storing global state without namespace conflicts. For example, we have been importing the Database
   class into various modules and then instantiating it, but it might make more sense to have only one
   database object globally available from the database module. The database module might look like
   this:
class Database:
    # the database implementation
    pass
database = Database()

   Then we can use any of the import methods we've discussed to access the database object, for example:
from ecommerce.database import database

   A problem with the above class is that the database object is created immediately when the module is
   first imported, which is usually when the program starts up. This isn't always ideal, since
   connecting to a database can take a while, slowing down startup, or the database connection
   information may not yet be available. We could delay creating the database until it is actually
   needed by calling an initialize_database function to create the module-level variable:
class Database:
    # the database implementation
    pass
database = None
def initialize_database():
    global database
    database = Database()

   The global keyword tells Python that the database variable inside initialize_database is the
   module-level one we just defined. If we had not specified the variable as global, Python would have
   created a new local variable that would be discarded when the method exits, leaving the module-level
   value unchanged.

   As these two examples illustrate, all code in a module is executed immediately at the time it is
   imported. However, if it is inside a method or function, the function will be created, but its
   internal code will not be executed until the function is called. This can be a tricky thing for
   scripts (like the main script in our e-commerce example) that perform execution. Often, we will write
   a program that does something useful, and then later find that we want to import a function or class
   from that module in a different program. But as soon as we import it, any code at the module level is
   immediately executed. If we are not careful, we can end up running the first program when we really
   only meant to access a couple functions inside that module.

   To solve this, we should always put our startup code in a function (conventionally called main) and
   only execute that function when we know we are executing as a script, but not when our code is being
   imported from a different script. But how do we know that?:
class UsefulClass:
    '''This class might be useful to other modules.'''
    pass
def main():
    '''creates a useful class and does something with it for our
module.'''
    useful = UsefulClass()
    print(useful)
if __name__ == "__main__":
    main()

   Every module has a __name__ special variable (remember, Python uses double underscores for special
   variables, like a class's __init__ method) that specifies the name of the module when it was
   imported. But when the module is executed directly with python module.py, it is never imported, so
   the __name__ is set to the string "__main__". Make it a policy to wrap all your scripts in an if
   __name__ == "__main__": test, just in case you write a function you will find useful to be imported
   by other code someday.

   So methods go in classes, which go in modules, which go in packages. Is that all there is to it?

   Actually, no. That is the typical order of things in a Python program, but it's not the only possible
   layout. Classes can be defined anywhere. They are typically defined at the module level, but they can
   also be defined inside a function or method, like so:
def format_string(string, formatter=None):
    '''Format a string using the formatter object, which
      is expected to have a format() method that accepts
      a string.'''
    class DefaultFormatter:
        '''Format a string in title case.'''
        def format(self, string):
            return str(string).title()
    if not formatter:
        formatter = DefaultFormatter()
    return formatter.format(string)
hello_string = "hello world, how are you today?"
print(" input: " + hello_string)
print("output: " + format_string(hello_string))

   Output:
input: hello world, how are you today?
output: Hello World, How Are You Today?

   The format_string function accepts a string and optional formatter object, and then applies the
   formatter to that string. If no formatter is supplied, it creates a formatter of its own as a local
   class and instantiates it. Since it is created inside the scope of the function, this class cannot be
   accessed from anywhere outside of that function. Similarly, functions can be defined inside other
   functions as well; in general, any Python statement can be executed at any time. These "inner"
   classes and functions are useful for "one-off" items that don't require or deserve their own scope at
   the module level, or only make sense inside a single method.

Summary

   In this article we have covered:
     * How to create classes and instantiate objects in Python
     * How to add attributes and behaviors to Python objects
     * How to organize classes into packages and modules
