filename: python-backup-script-with-rsync_20160512.txt
https://www.zufallsheld.de/2013/09/29/python-backup-script-with-rsync/

Python Backup Script with rsync
Posted on So 29 September 2013

UPDATE: I rewrote the whole script. You can find it here [***]!

I wanted to get into Python recently and to have a reason to actually learn the language, I thought to
myself, why not replace the bash-scripts I use on my private computer. I started with my backup script,
that saves my home-folder to my external usb-drive.

With this article I'll describe what I did and why. I'll have some thoughts in my mind on what the script
should do. You'll see these below. Afterwards I'll show how I accomplished these things.

Preliminary considerations
It should check if the directories actually exist.
It should ask for confirmation before doing anything
I needed the script to backup the specified folder to the specified location.
It should delete unnecessary files before backing up
Considering I used rsync in my bash-script I wanted the same functionality again
Writing the script

Check if directory exists
Python actually already has a function that checks if a directory exists: os.path.exists

So all I had to do was to use the built-in function and put it in my own little function, that performs
the checks and prints an error-message and exits, if the directory does not exist.
	<code>
	def check_dir_exist(os_dir):
	if not os.path.exists(os_dir):
	print os_dir, "does not exist."
	exit(1)
	</code>

Confirm on actions
I wanted to let the user confirm any actions he does before they are executed, so he or she can back
out if there was a mistake.

For that I built a function that asks for confirmation and if the answer is "yes", the variable
"exit_condition" should be 0, otherwise it is 1. So when the function is executed, depending on what
status the variable took, I can decide on how to continue in the script.
	<code>
	def confirm():
	    gogo = raw_input("Continue? yes/no\n")
	    global exit_condition
	    if gogo == 'yes':
		exit_condition = 0
		return exit_condition
	    elif gogo == "no":
		exit_condition = 1
		return exit_condition
	    else:
	    print "Please answer with yes or no."
	confirm()
	</code>

Defining backup paths
This one's simple. The script just asks for user input on the paths for what to backup and where to put
it. Afterwards there's the existence-check.
	<code>
	# Specify what and where to backup.
	backup_path = raw_input("What should be backed up today?\n")
	check_dir_exist(backup_path)
	print "Okay", backup_path, "will be saved."
	time.sleep(3)
	backup_to_path = raw_input("Where to backup?\n")
	check_dir_exist(backup_to_path)
	</code>

Delete files
I wanted to delete unecessary files like temporary or backup files before doing the backup. For this I
created to functions. The first functions takes an argument (in this case: file endings) as input and
searches in the backup path for files ending with the argument. It then deletes these files.
	<code>
	def delete_files(ending):
	    os.chdir(backup_path)
	    for r, d, f in os.walk(backup_path):
		for files in f:
		    if files.endswith("." + ending):
			os.remove(os.path.join(r, files))
	</code>

I use this function in a for-loop that iterates trough three file endings, each time asking the user if
he/she wants to delete the files.
	<code>
	# Delete files first
	print "First, let's cleanup unnecessary files in the backup path."
	file_types = ["tmp", "bak", "dmp"]
	for file_type in file_types:
	    print "Delete", file_type, "files?"
	    confirm()
	    if exit_condition == 0:
		delete_files(file_type)
	</code>
	
At last, the trash can of the user executing the script gets deleted. I uses shutil.rmtree for
this. It deletes the whole file-directory. Don't worry: it's recreated when a file is moved to the
trash. os.path.expanduser just expands the "~" to the user's home directory.
	<code>
	# Empty trash can
	print "Empty trash can?"
	confirm()
	if exit_condition == 0:
	    print "Emptying!"
	    shutil.rmtree(os.path.expanduser("~/.local/share/Trash/files"))
	</code>
 
Backing up the files
This is the important part of the script. I tried to find an rsync alternative in Python, I searched for
a method to mimic the rsync behaviour but I didn't find anything that was easy to understand, capable
of what it should do and not outdated. That is, until I found Rsyncbackup a Python script "to perform
automatic backups using the rsync command". It does exactly what it says it does, so I went on and used
it in my script.

So I used rsync itself in combination with sh. Sh let's me execute any program as if it were python native.
	<code>
	rsync("-auhv", "--delete", "--exclude=lost+found", "--exclude=/sys", "--exclude=/tmp", "--exclude=/proc",
	  "--exclude=/mnt", "--exclude=/dev", "--exclude=/backup", backup_path, backup_to_path)
	</code>

--------------------------------------------------------------------------------------------------------------
The result
Here's the whole script put together:
<code>
#!/usr/bin/env python

import os
import shutil
import time

from sh import rsync

# Functions

def check_dir_exist(os_dir):
    if not os.path.exists(os_dir):
        print os_dir, "does not exist."
        exit(1)

def confirm():
    gogo = raw_input("Continue? yes/no\n")
    global exit_condition
    if gogo == 'yes':
        exit_condition = 0
        return exit_condition
    elif gogo == "no":
        exit_condition = 1
        return exit_condition
    else:
        print "Please answer with yes or no."
        confirm()

def delete_files(ending):
    for r, d, f in os.walk(backup_path):
        for files in f:
            if files.endswith("." + ending):
                os.remove(os.path.join(r, files))

# Specify what and where to backup.
backup_path = raw_input("What should be backed up today?\n")
check_dir_exist(backup_path)
print "Okay", backup_path, "will be saved."
time.sleep(3)

backup_to_path = raw_input("Where to backup?\n")
check_dir_exist(backup_to_path)

# Delete files first
print "First, let's cleanup unnecessary files in the backup path."
file_types = ["tmp", "bak", "dmp"]
for file_type in file_types:
    print "Delete", file_type, "files?"
    confirm()
    if exit_condition == 0:
        delete_files(file_type)

# Empty trash can
print "Empty trash can?"
confirm()
if exit_condition == 0:
    print "Emptying!"
    shutil.rmtree(os.path.expanduser("~/.local/share/Trash/files"))

# Do the actual backup
print "Doing the backup now!"
confirm()
if exit_condition == 1:
        print "Aborting!"
        exit(1)

rsync("-auhv", "--delete", "--exclude=lost+found", "--exclude=/sys", "--exclude=/tmp", "--exclude=/proc",
  "--exclude=/mnt", "--exclude=/dev", "--exclude=/backup", backup_path, backup_to_path)
</code>
--------------------------------------------------------------------------------------------------------------

Releasing
Since this was my first python-project I thought to myself that i need to package and distribute it. Even
if it's only one file, I did it just for the sake of it.

So here it is, have fun with it on GitHub [https://github.com/rndmh3ro/home_backup].

Plans
I plan on adding several things to it, as I progress in learning Python:
- extensive Logging (I know, the Rsyncbackup already does logging, but I want the whole script to log)
- Automatization

##############################################################################################################
[***]
https://www.zufallsheld.de/2014/01/25/python-backup-script-revisited/

Python backup script revisited
Posted on Sa 25 Januar 2014

Here I wrote about my initial attempts with Python. I started with a backup script for my home-computer
because that's what I needed at the time. Now I'm reviewing and tweaking it.

My considerations at the time of writing the initial script were:
It should check if the directories actually exist.
It should ask for confirmation before doing anything
I needed the script to backup the specified folder to the specified location.
It should delete unnecessary files before backing up
Considering I used rsync in my bash-script I wanted the same functionality again

They are still the same for the new script, but I also had some improvements I wanted to make:
Logging
Automation
Exclusions

Adding Automation
I don't want my script to be interactive anymore. Instead I want to give all information the script
needs with variables before it runs, e.g.: ./home-backup.py --destination --source --delete-stuff

To do this, I use argparse, a library that let's you give arguments to your script. I will try to explain
the steps I did, but it'd be good to be comfortable with argparse.

First, import argparse and assign it to a variable.
	<code>
	import argparse

	parser = argparse.ArgumentParser(description=__doc__)
	</code>

When you assign the "__doc__" to the description-variable, the description you gave for the python-script
will be shown, when you let yourself show the usage of the script:
	<code>
	$  python2.7 home_backup.py -h
	usage: home_backup.py [-h] [-l LOGFILE] [-d] [-t] [-e EXCLUDE] BACKUPDIR DESTINATIONDIR
	</code>

This script backups everything from BACKUPDIR to DESTINATIONDIR using rsync.
Next, we have to define arguments that our little script will accept from the input.

The add_argument-object takes at least one variable, the name of the argument. To define a mandatory
argument, do not write a dash before the variable.
	parser.add_argument("BACKUPDIR")

To make it optional, add a dash.
	parser.add_argument("-l")

If you also want to use the long form of an argument, add two dashes and the long word as a second
variable, delimited with a comma.
	parser.add_argument("-l", "--logfile")

There's also the "help"-variable, where you define the description of the variable that is shown, when
the usage of your script is described.
	parser.add_argument("BACKUPDIR", help="Specify the directory to backup.")

You can also store Boolean-variables with arguments. That means, if the argument is defined, then it is
set to TRUE. You achieve this with the following option:
	parser.add_argument("-d", action="store_true")

Here are all arguments together.
	<code>
	parser.add_argument("BACKUPDIR", help="Specify the directory to backup.")
	parser.add_argument("DESTINATIONDIR", help="Specify the directory where the backup is stored.")
	parser.add_argument("-t", "--trash", help="Delete unnecessary files and empty the trash.", action="store_true")
	parser.add_argument("-e", "--exclude", help="Exlude the following directories from backup.", action="append")
	parser.add_argument("-l", "--logfile", help="Specify the logfile to monitor.")
	parser.add_argument("-q", "--quiet", help="Do not print to stdout.", action="store_true")
	</code>

And finally, activate the function:
	<code>
	args = parser.parse_args()
	</code>

Defining Paths
The old script had two non-interactive parts in the script: - Confirm on actions - Defining backup paths
They're gone, because argparse does the job now. If you want, you can read about it in the old blog post.
Now, all we have to do is define the path to backup and the destination path via command line.
	<code>
	parser.add_argument("BACKUPDIR", help="Specify the directory to backup.")
	parser.add_argument("DESTINATIONDIR", help="Specify the directory where the backup is stored.")
	</code>

I assigned two variables to these arguments to make working with them later easier:
	backupdir = args.BACKUPDIR
	destinationdir = args.DESTINATIONDIR

Logging
I need some simple logging-functionality in case anything goes wrong or I want to know, what got
deleted or saved. Therefore I used the built-in logging library of Python. First, I define the format
of the log-output. "asctime" is the default date format, "levelname" is the log-level (INFO, DEBUG,
ERROR,...) and "message" is the message to be logged.
	<code>
	import logging
	logFormatter = logging.Formatter("%(asctime)s %(levelname)s  %(message)s")
	</code>

I assign the configuration to the variable "logFormatter". This way I can use the configuration with
different logHandlers. Handler define where the log-messages are send to, e.g. a log-file or the
command-line. That is exactly what I want. So I have to have to handlers:
	<code>
	rootLogger = logging.getLogger()
	logfile = args.logfile

	if logfile:
	    fileHandler = logging.FileHandler(logfile)
	    fileHandler.setFormatter(logFormatter)
	    rootLogger.addHandler(fileHandler)
	</code>

The first line initializes the logger. The following configuration will only be used when the variable
"logfile" is used. The third line tells the file handler where to log to. The fourth line sets the format
of the logging to "logFormatter" which I defined earlier. The fifth line adds the file handler to the
root logger.
	<code>
	if not args.quiet:
	   consoleHandler = logging.StreamHandler()
	   consoleHandler.setFormatter(logFormatter)
	   rootLogger.addHandler(consoleHandler)
	</code>

The first if-statement looks for the argument "quiet". If it is False, add a console handler. These
three lines do the same as in the logfile-handler, except the output goes to the command-line instead
of the log-file.

Check if directory exists
Python actually already has a function that checks if a directory exists: os.path.exists

So all I have to do is to use the built-in function and put it in my own little function, that performs
the checks and prints an error-message and exits, if the directory does not exist.
	<code>
	# directory exist-check
	def check_dir_exist(os_dir):
	    if not os.path.exists(os_dir):
		logging.error("{} does not exist.".format(os_dir))
		exit(1)
	</code>

Delete files
I want to delete unnecessary files like temporary or backup files before doing the backup. For this I
created two functions. The first functions takes an argument (in this case: file endings) as input and
searches in the backup path for files ending with the argument. It then deletes these files. If it cannot
delete the file, a warning message is printed but the script execution is continued. All this should only
happen if I want it to. So I'm adding the argument "--trash" with the action "store_true". This means,
that if I run the script with the trash-argument, the variable "args.trash" will be a boolean variable,
so I can later check it and only delete files if "trash" is True.
	<code>
	 # delete function
	def delete_files(ending, indirectory):
	    for r, d, f in os.walk(indirectory):
		for files in f:
		    if files.endswith("." + ending):
			try:
			    os.remove(os.path.join(r, files))
			    logging.info("Deleting {}/{}".format(r, files))
			except OSError:
			    logging.warning("Could not delete {}/{}".format(r, files))
			    pass
	</code>

I use this function in a for-loop that iterates trough three file endings, but only if the argument
"trash" is provided via command-line.
	<code>
	if args.trash:
	    file_types = ["tmp", "bak", "dmp"]
	    for file_type in file_types:
		delete_files(file_type, backupdir)
	</code>

At last, the trash can of the user executing the script gets deleted. I use shutil.rmtree for
this. It deletes the whole file-directory. Don't worry: it's recreated when a file is moved to the
trash. os.path.expanduser just expands the "~" to the user's home directory.
	<code>
	# Delete actual files first
	if args.trash:
	    file_types = ["tmp", "bak", "dmp"]
	    for file_type in file_types:
		delete_files(file_type, backupdir)
	    # Empty trash can
	    try:
		rmtree(os.path.expanduser("~/.local/share/Trash/files"))
	    except OSError:
		logging.warning("Could not empty the trash or trash already empty.")
		    pass
	</code>

Again, if it cannot empty the trash, a warning message is printed but the script execution is continued.

Excluding files
I want to exclude certain files and directories from backup. Rsync has an exclusion-function and all I
needed to do is to pass the files and directories to this option. Again I used the argparse-arguments
to add excludes. The action for this argument is "append" so if I specify multiple exclusions, they are
appended to a list. I then read this list and append all exclusions to a variable. This variable is then
called in the rsync-backup.
	<code>
	# handle exclusions
	exclusions = []
	if args.exclude:
	    for argument in args.exclude:
		exclusions.append("--exclude={}".format(argument))
	</code>

Backing up the files
This is the important part of the script. I tried to find an rsync alternative in Python, I searched for
a method to mimic the rsync behavior but I didn't find anything that was easy to understand, capable of
what it should do and not be outdated. That is, until I found Rsyncbackup a Python script "to perform
automatic backups using the rsync command". It does exactly what it says it does, so I went on and used
it in my script.

So I used rsync itself in combination with sh. Sh let's me execute any program as if it were python native.

Here, I differencated fice possibilities: - Use logging, exclusions but be quiet on the commandline -
Use logging and exclusions - Use exclusions and be quiet on the commandline - Use logging but be quiet
on the commandline - Use nothing of the above - That is covered by several if-statement that check,
if the variables are empty or there. That's quite bulky but currently I don't know any other way. If
you know one, write it in the comments!
	<code>
	# Do the actual backup
	logging.info("Starting rsync.")
	if logfile and exclusions and args.quiet:
	    rsync("-auhv", exclusions, "--log-file={}".format(logfile), backupdir, destinationdir)
	elif logfile and exclusions:
	    print(rsync("-auhv", exclusions, "--log-file={}".format(logfile), backupdir, destinationdir))
	elif args.quiet and exclusions:
	    rsync("-av", exclusions, backupdir, destinationdir)
	elif logfile and args.quiet:
	    rsync("-av", "--log-file={}".format(logfile), backupdir, destinationdir)
	else:
	    rsync("-av", backupdir, destinationdir)
	</code>

--------------------------------------------------------------------------------------------------------------
The result
That's the whole script put together:

<code>
#!/usr/bin/env python

import os
from shutil import rmtree
import argparse
import logging
from sh import rsync


#Parse arguments
parser = argparse.ArgumentParser(
    description=__doc__)

parser.add_argument("BACKUPDIR", help="Specify the directory to backup.")
parser.add_argument("DESTINATIONDIR", help="Specify the directory where the backup is stored.")
parser.add_argument("-t", "--trash", help="Delete unnecessary files and empty the trash.",
action="store_true")
parser.add_argument("-e", "--exclude", help="Exlude the following directories from backup.", action="append")
parser.add_argument("-l", "--logfile", help="Specify the logfile to monitor.")
parser.add_argument("-q", "--quiet", help="Do not print to stdout.", action="store_true")

args = parser.parse_args()

# Define variables
backupdir = args.BACKUPDIR
destinationdir = args.DESTINATIONDIR
logfile = args.logfile

#Logging
rootLogger = logging.getLogger()
logFormatter = logging.Formatter("%(asctime)s - %(message)s")
rootLogger.setLevel(logging.INFO)
if logfile:
    fileHandler = logging.FileHandler(logfile)
    fileHandler.setFormatter(logFormatter)
    rootLogger.addHandler(fileHandler)

if not args.quiet:
    consoleHandler = logging.StreamHandler()
    consoleHandler.setFormatter(logFormatter)
    rootLogger.addHandler(consoleHandler)


# directory exist-check
def check_dir_exist(os_dir):
    if not os.path.exists(os_dir):
        logging.error("{} does not exist.".format(os_dir))
        exit(1)

check_dir_exist(backupdir)

# delete function
def delete_files(ending, indirectory):
    for r, d, f in os.walk(indirectory):
        for files in f:
            if files.endswith("." + ending):
                try:
                    os.remove(os.path.join(r, files))
                    logging.info("Deleting {}/{}".format(r, files))
                except OSError:
                    logging.warning("Could not delete {}/{}".format(r, files))
                    pass


# Delete actual files first
if args.trash:
    file_types = ["tmp", "bak", "dmp"]
    for file_type in file_types:
        delete_files(file_type, backupdir)
    # Empty trash can
    try:
        rmtree(os.path.expanduser("~/.local/share/Trash/files"))
    except OSError:
        logging.warning("Could not empty the trash or trash already empty.")
        pass

# handle exclusions
exclusions = []
if args.exclude:
    for argument in args.exclude:
        exclusions.append("--exclude={}".format(argument))


# Do the actual backup
logging.info("Starting rsync.")
if logfile and exclusions and args.quiet:
    rsync("-auhv", exclusions, "--log-file={}".format(logfile), backupdir, destinationdir)
elif logfile and exclusions:
    print(rsync("-auhv", exclusions, "--log-file={}".format(logfile), backupdir, destinationdir))
elif args.quiet and exclusions:
    rsync("-av", exclusions, backupdir, destinationdir)
elif logfile and args.quiet:
    rsync("-av", "--log-file={}".format(logfile), backupdir, destinationdir)
else:
    rsync("-av", backupdir, destinationdir)

logging.info("done.")
</code>
--------------------------------------------------------------------------------------------------------------

Also on GitHub. [https://github.com/rndmh3ro/home_backup]


---
https://www.zufallsheld.de/2013/12/20/python-script-check-last-exec-time-exit-code-script-2/
Python script to check last exec time and exit code of script
Posted on Fr 20 Dezember 2013

I needed a script that checks:
whether a cronjob ran at its determined date (that means it runs regulary)
if the cronjob ran successfully
It should also be monitor-able via Nagios. That means, it should provide a meaningful output for when
something went wrong with the cronjob, e.g. "CRITICAL: cronjob did not run!"

Of course, someone already had the same requirements and built a Perl-script for it, which in turn can
be used as a NRPE-plugin.

For this, the cronjob to be monitored has to be edited to log every output and it's exit code to a
logfile. The script then does the above mentioned checks. You can find a more detailed explanation here.

The Perl script is missing two things:
both parameters (last execution time and exit code) are mandatory

a Python implementation!
To fix these things, I wrote a small script by myself, that is hosted on Github and here (since it's
rather small):
	<code>
	#!/usr/bin/env python

	"""
	This script can check whether a file was last modified before a time X. If it was modified after that,
	an error is raised. It can also check, whether the file contains
	 a specific string (e.g. "exit 0"). If it's not there, an error is raised.

	 Example:
	 check_exit_code.py --exitcode -t 20 /path/to/logfile
	"""

	import os
	import argparse
	import time
	import re

	# Parse arguments
	parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.ArgumentDefaultsHelpFormatter)

	parser.add_argument("logfile", help="Specify the logfile to monitor.")
	parser.add_argument("-t", "--time", help="Time in minutes which a log file can be unmodified before raising CRITICAL alert.", type=int)
	parser.add_argument("--exitcode", help="If specified, check if \"exit 0\" exists in logfile.", action="store_true")

	args = parser.parse_args()

	if not (args.time or args.exitcode):
	    print "At least one argument (--time, --exitcode) is required."
	    exit(2)

	#variables
	log = args.logfile

	# Check if file exists and is readable by user
	try:
	    f = open(log)
	except IOError:
	    print "Cannot open the file. Check if it exists and you have the right permissions to open it."
	    exit(1)

	# check exit code
	if args.exitcode:
	    logfile = f.read()
	    if not re.search("exit 0", logfile, flags=re.I):
		print "CRITICAL: Exit code not found in File %s" % log
		exit(2)

	# Check last file modification time
	if args.time:
	    # File Modification time in seconds since epoch
	    file_mod_time = os.stat(log).st_mtime

	    # Time in seconds since epoch for time, in which logfile can be unmodified.
	    t = time.time()
	    should_time = t - (args.time * 3600)

	    # Time in minutes since last modification of file
	    last_time = (t - file_mod_time) / 60

	    if last_time > args.time:
		print "CRITICAL: {} last modified {:.2f} minutes. Threshold set to {:.2f} minutes".format(log,
		last_time,
												      args.time)
		exit(2)

	# If nothin went wrong, print OK and exit.
	print "OK. Exitcode found or last modification time not exceeded."
	exit(0)
	</code>
