filename: python_oop_V2-multif_20171005.txt
http://blog.thedigitalcatonline.com/blog/2014/08/20/python-3-oop-part-1-objects-and-types/

Python 3 OOP Part 1 - Objects and types
20/08/2014 Series Part 1 of "Python 3 OOP"

About this series
   Object-oriented programming (OOP) has been the leading programming paradigm for several decades now,
   starting from the initial attempts back in the 60s to some of the most important languages used
   nowadays. Being a set of programming concepts and design methodologies, OOP can never be said to be
   "correctly" or "fully" implemented by a language: indeed there are as many implementations as
   languages.

   So one of the most interesting aspects of OOP languages is to understand how they implement those
   concepts. In this post I am going to try and start analyzing the OOP implementation of the Python
   language. Due to the richness of the topic, however, I consider this attempt just like a set of
   thoughts for Python beginners trying to find their way into this beautiful (and sometimes peculiar)
   language.

   This series of posts wants to introduce the reader to the Python 3 implementation of Object Oriented
   Programming concepts. The content of this and the following posts will not be completely different
   from that of the previous "OOP Concepts in Python 2.x" series, however. The reason is that while some
   of the internal structures change a lot, the global philosophy doesn't, being Python 3 an evolution
   of Python 2 and not a new language.

   So I chose to split the previous series and to adapt the content to Python 3 instead of posting a
   mere list of corrections. I find this way to be more useful for new readers, that otherwise sould be
   forced to read the previous series.

Print
   One of the most noticeable changes introduced by Python 3 is the transformation of the print keyword
   into the print() function. This is indeed a very small change, compared to other modifications made
   to the internal structures, but is the most visual-striking one, and will be the source of 80% of
   your syntax errors when you will start writing Python 3 code.

   Remember that print is now a function so write print(a) and not print a.

Back to the Object
   Computer science deals with data and with procedures to manipulate that data. Everything, from the
   earliest Fortran programs to the latest mobile apps is about data and their manipulation.

   So if data are the ingredients and procedures are the recipes, it seems (and can be) reasonable to
   keep them separate.

   Let's do some procedural programming in Python
# This is some data
data = (13, 63, 5, 378, 58, 40)

# This is a procedure that computes the average
def avg(d):
    return sum(d)/len(d)

print(avg(data))

   As you can see the code is quite good and general: the procedure (function) operates on a sequence of
   data, and it returns the average of the sequence items. So far, so good: computing the average of
   some numbers leaves the numbers untouched and creates new data.

   The observation of the everyday world, however, shows that complex data mutate: an electrical device
   is on or off, a door is open or closed, the content of a bookshelf in your room changes as you buy
   new books.

   You can still manage it keeping data and procedures separate, for example
# These are two numbered doors, initially closed
door1 = [1, 'closed']
door2 = [2, 'closed']

# This procedure opens a door
def open_door(door):
    door[1] = 'open'

open_door(door1)
print(door1)

   I described a door as a structure containing a number and the status of the door (as you would do in
   languages like LISP, for example). The procedure knows how this structure is made and may alter it.

   This also works like a charm. Some problems arise, however, when we start building specialized types
   of data. What happens, for example, when I introduce a "lockable door" data type, which can be opened
   only when it is not locked? Let's see
# These are two standard doors, initially closed
door1 = [1, 'closed']
door2 = [2, 'closed']

# This is a lockable door, initially closed and unlocked
ldoor1 = [1, 'closed', 'unlocked']

# This procedure opens a standard door
def open_door(door):
    door[1] = 'open'

# This procedure opens a lockable door
def open_ldoor(door):
    if door[2] == 'unlocked':
        door[1] = 'open'

open_door(door1)
print(door1)

open_ldoor(ldoor1)
print(ldoor1)

   Everything still works, no surprises in this code. However, as you can see, I had to find a different
   name for the procedure that opens a locked door since its implementation differs from the procedure
   that opens a standard door. But, wait... I'm still opening a door, the action is the same, and it
   just changes the status of the door itself. So why shall I remember that a locked door shall be
   opened with open_ldoor() instead of open_door() if the verb is the same?

   Chances are that this separation between data and procedures doesn't perfectly fit some situations.
   The key problem is that the "open" action is not actually using the door; rather it is changing its
   state. So, just like the volume control buttons of your phone, which are on your phone, the "open"
   procedure should stick to the "door" data.

   This is exactly what leads to the concept of object: an object, in the OOP context, is a structure
   holding data and procedures operating on them.

What About Type?
   When you talk about data you immediately need to introduce the concept of type. This concept may have
   two meanings that are worth being mentioned in computer science: the behavioural and the structural
   one.

   The behavioural meaning represents the fact that you know what something is by describing how it
   acts. This is the foundation of the so-called "duck typing" (here "typing" means "to give a type" and
   not "to type on a keyboard"): if it [DEL: types :DEL] acts like a duck, it is a duck.

   The structural meaning identifies the type of something by looking at its internal structure. So two
   things that act in the same way but are internally different are of different type.

   Both points of view can be valid, and different languages may implement and emphasize one meaning of
   type or the other, and even both.

Class Games
   Objects in Python may be built describing their structure through a class. A class is the programming
   representation of a generic object, such as "a book", "a car", "a door": when I talk about "a door"
   everyone can understand what I'm saying, without the need of referring to a specific door in the
   room.

   In Python, the type of an object is represented by the class used to build the object: that is, in
   Python the word type has the same meaning of the word class.

   For example, one of the built-in classes of Python is int, which represents an integer number
>>> a = 6
>>> print(a)
6
>>> print(type(a))
<class 'int'>
>>> print(a.__class__)
<class 'int'>

   As you can see, the built-in function type() returns the content of the magic attribute __class__
   (magic here means that its value is managed by Python itself offstage). The type of the variable a,
   or its class, is int. (This is a very inaccurate description of this rather complex topic, so
   remember that at the moment we are just scratching the surface).

   Once you have a class you can instantiate it to get a concrete object (an instance) of that type,
   i.e. an object built according to the structure of that class. The Python syntax to instantiate a
   class is the same of a function call
>>> b = int()
>>> type(b)
<class 'int'>

   When you create an instance, you can pass some values, according to the class definition, to
   initialize it.
>>> b = int()
>>> print(b)
0
>>> c = int(7)
>>> print(c)
7

   In this example, the int class creates an integer with value 0 when called without arguments,
   otherwise it uses the given argument to initialize the newly created object.

   Let us write a class that represents a door to match the procedural examples done in the first
   section
class Door:
    def __init__(self, number, status):
        self.number = number
        self.status = status

    def open(self):
        self.status = 'open'

    def close(self):
        self.status = 'closed'

   The class keyword defines a new class named Door; everything indented under class is part of the
   class. The functions you write inside the object are called methods and don't differ at all from
   standard functions; the nomenclature changes only to highlight the fact that those functions now are
   part of an object.

   Methods of a class must accept as first argument a special value called self (the name is a
   convention but please never break it).

   The class can be given a special method called __init__() which is run when the class is
   instantiated, receiving the arguments passed when calling the class; the general name of such a
   method, in the OOP context, is constructor, even if the __init__() method is not the only part of
   this mechanism in Python.

   The self.number and self.status variables are called attributes of the object. In Python, methods and
   attributes are both members of the object and are accessible with the dotted syntax; the difference
   between attributes and methods is that the latter can be called (in Python lingo you say that a
   method is a callable).

   As you can see the __init__() method shall create and initialize the attributes since they are not
   declared elsewhere. This is very important in Python and is strictly linked with the way the language
   handles the type of variables. I will detail those concepts when dealing with polymorphism in a later
   post.

   The class can be used to create a concrete object
>>> door1 = Door(1, 'closed')
>>> type(door1)
<class '__main__.Door'>
>>> print(door1.number)
1
>>> print(door1.status)
closed

   Now door1 is an instance of the Door class; type() returns the class as __main__.Door since the class
   was defined directly in the interactive shell, that is in the current main module.

   To call a method of an object, that is to run one of its internal functions, you just access it as an
   attribute with the dotted syntax and call it like a standard function.
>>> door1.open()
>>> print(door1.number)
1
>>> print(door1.status)
open

   In this case, the open() method of the door1 instance has been called. No arguments have been passed
   to the open() method, but if you review the class declaration, you see that it was declared to accept
   an argument (self). When you call a method of an instance, Python automatically passes the instance
   itself to the method as the first argument.

   You can create as many instances as needed and they are completely unrelated each other. That is, the
   changes you make on one instance do not reflect on another instance of the same class.

Recap
   Objects are described by a class, which can generate one or more instances, unrelated each other. A
   class contains methods, which are functions, and they accept at least one argument called self, which
   is the actual instance on which the method has been called. A special method, __init__() deals with
   the initialization of the object, setting the initial value of the attributes.

Movie Trivia
   Section titles come from the following movies: Back to the Future (1985) , What About Bob? (1991),
   Wargames (1983).

Sources
   You will find a lot of documentation in:
   [http://www.reddit.com/r/Python/comments/226ahl/some_links_about_python_oop/] this Reddit post.
   Most of the information contained in this series come from those sources.


---
http://blog.thedigitalcatonline.com/blog/2014/08/20/python-3-oop-part-2-classes-and-members/

Python 3 OOP Part 2 - Classes and members
20/08/2014 Series Part 2 of "Python 3 OOP"

Python Classes Strike Again
   The Python implementation of classes has some peculiarities. The bare truth is that in Python the
   class of an object is an object itself. You can check this by issuing type() on the class
>>> a = 1
>>> type(a)
<class 'int'>
>>> type(int)
<class 'type'>

   This shows that the int class is an object, an instance of the type class.

   This concept is not so difficult to grasp as it can seem at first sight: in the real world we deal
   with concepts using them like things: for example we can talk about the concept of "door", telling
   people how a door looks like and how it works. In this case the concept of door is the topic of our
   discussion, so in our everyday experience the type of an object is an object itself. In Python this
   can be expressed by saying that everything is an object.

   If the class of an object is itself an instance it is a concrete object and is stored somewhere in
   memory. Let us leverage the inspection capabilities of Python and its id() function to check the
   status of our objects. The id() built-in function returns the memory position of an object.

   In the first post we defined this class
class Door:
    def __init__(self, number, status):
        self.number = number
        self.status = status

    def open(self):
        self.status = 'open'

    def close(self):
        self.status = 'closed'

   First of all, let's create two instances of the Door class and check that the two objects are stored
   at different addresses
>>> door1 = Door(1, 'closed')
>>> door2 = Door(1, 'closed')
>>> hex(id(door1))
'0xb67e148c'
>>> hex(id(door2))
'0xb67e144c'

   This confirms that the two instances are separate and unrelated. Please note that your values are
   very likely to be different from the ones I got. Being memory addresses they change at every
   execution. The second instance was given the same attributes of the first instance to show that the
   two are different objects regardless of the value of the attributes.

   However if we use id() on the class of the two instances we discover that the class is exactly the
   same
>>> hex(id(door1.__class__))
'0xb685f56c'
>>> hex(id(door2.__class__))
'0xb685f56c'

   Well this is very important. In Python, a class is not just the schema used to build an object.
   Rather, the class is a shared living object, which code is accessed at run time.

   As we already tested, however, attributes are not stored in the class but in every instance, due to
   the fact that __init__() works on self when creating them. Classes, however, can be given attributes
   like any other object; with a terrific effort of imagination, let's call them class attributes.

   As you can expect, class attributes are shared among the class instances just like their container
class Door:
    colour = 'brown'

    def __init__(self, number, status):
        self.number = number
        self.status = status

    def open(self):
        self.status = 'open'

    def close(self):
        self.status = 'closed'

   Pay attention: the colour attribute here is not created using self, so it is contained in the class
   and shared among instances
>>> door1 = Door(1, 'closed')
>>> door2 = Door(2, 'closed')
>>> Door.colour
'brown'
>>> door1.colour
'brown'
>>> door2.colour
'brown'

   Until here things are not different from the previous case. Let's see if changes of the shared value
   reflect on all instances
>>> Door.colour = 'white'
>>> Door.colour
'white'
>>> door1.colour
'white'
>>> door2.colour
'white'
>>> hex(id(Door.colour))
'0xb67e1500'
>>> hex(id(door1.colour))
'0xb67e1500'
>>> hex(id(door2.colour))
'0xb67e1500'

Raiders of the Lost Attribute
   Any Python object is automatically given a __dict__ attribute, which contains its list of attributes.
   Let's investigate what this dictionary contains for our example objects:
>>> Door.__dict__
mappingproxy({'open': <function Door.open at 0xb68604ac>,
    'colour': 'brown',
    '__dict__': <attribute '__dict__' of 'Door' objects>,
    '__weakref__': <attribute '__weakref__' of 'Door' objects>,
    '__init__': <function Door.__init__ at 0xb7062854>,
    '__module__': '__main__',
    '__doc__': None,
    'close': <function Door.close at 0xb686041c>})
>>> door1.__dict__
{'number': 1, 'status': 'closed'}

   Leaving aside the difference between a dictionary and a mappingproxy object, you can see that the
   colour attribute is listed among the Door class attributes, while status and number are listed for
   the instance.

   How comes that we can call door1.colour, if that attribute is not listed for that instance? This is a
   job performed by the magic __getattribute__() method; in Python the dotted syntax automatically
   invokes this method so when we write door1.colour, Python executes door1.__getattribute__('colour').
   That method performs the attribute lookup action, i.e. finds the value of the attribute by looking in
   different places.

   The standard implementation of __getattribute__() searches first the internal dictionary (__dict__)
   of an object, then the type of the object itself; in this case door1.__getattribute__('colour')
   executes first door1.__dict__['colour'] and then, since the latter raises a KeyError exception,
   door1.__class__.__dict__['colour']
>>> door1.__dict__['colour']
Traceback  (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'colour'
>>> door1.__class__.__dict__['colour']
'brown'

   Indeed, if we compare the objects' equality through the is operator we can confirm that both
   door1.colour and Door.colour are exactly the same object
>>> door1.colour is Door.colour
True

   When we try to assign a value to a class attribute directly on an instance, we just put in the
   __dict__ of the instance a value with that name, and this value masks the class attribute since it is
   found first by __getattribute__(). As you can see from the examples of the previous section, this is
   different from changing the value of the attribute on the class itself.
>>> door1.colour = 'white'
>>> door1.__dict__['colour']
'white'
>>> door1.__class__.__dict__['colour']
'brown'
>>> Door.colour = 'red'
>>> door1.__dict__['colour']
'white'
>>> door1.__class__.__dict__['colour']
'red'

Revenge of the Methods
   Let's play the same game with methods. First of all you can see that, just like class attributes,
   methods are listed only in the class __dict__. Chances are that they behave the same as attributes
   when we get them
>>> door1.open is Door.open
False

   Whoops. Let us further investigate the matter
>>> Door.__dict__['open']
<function Door.open at 0xb68604ac>
>>> Door.open
<function Door.open at 0xb68604ac>
>>> door1.open
<bound method Door.open of <__main__.Door object at 0xb67e162c>>

   So, the class method is listed in the members dictionary as function. So far, so good. The same
   happens when taking it directly from the class; here Python 2 needed to introduce unbound methods,
   which are not present in Python 3. Taking it from the instance returns a bound method.

   Well, a function is a procedure you named and defined with the def statement. When you refer to a
   function as part of a class in Python 3 you get a plain function, without any difference from a
   function defined outside a class.

   When you get the function from an instance, however, it becomes a bound method. The name method
   simply means "a function inside an object", according to the usual OOP definitions, while bound
   signals that the method is linked to that instance. Why does Python bother with methods being bound
   or not? And how does Python transform a function into a bound method?

   First of all, if you try to call a class function you get an error
>>> Door.open()
Traceback  (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: open() missing 1 required positional argument: 'self'

   Yes. Indeed the function was defined to require an argument called 'self', and calling it without an
   argument raises an exception. This perhaps means that we can give it one instance of the class and
   make it work
>>> Door.open(door1)
>>> door1.status
'open'

   Python does not complain here, and the method works as expected. So Door.open(door1) is the same as
   door1.open(), and this is the difference between a plain function coming from a class an a bound
   method: the bound method automatically passes the instance as an argument to the function.

   Again, under the hood, __getattribute__() is working to make everything work and when we call
   door1.open(), Python actually calls door1.__class__.open(door1). However, door1.__class__.open is a
   plain function, so there is something more that converts it into a bound method that Python can
   safely call.

   When you access a member of an object, Python calls __getattribute__() to satisfy the request. This
   magic method, however, conforms to a procedure known as descriptor protocol. For the read access
   __getattribute__() checks if the object has a __get__() method and calls this latter. So the
   converstion of a function into a bound method happens through such a mechanism. Let us review it by
   means of an example.
>>> door1.__class__.__dict__['open']
<function Door.open at 0xb68604ac>

   This syntax retrieves the function defined in the class; the function knows nothing about objects,
   but it is an object (remember "everything is an object"). So we can look inside it with the dir()
   built-in function
>>> dir(door1.__class__.__dict__['open'])
['__annotations__', '__call__', '__class__', '__closure__', '__code__',
 '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__',
 '__format__', '__ge__', '__get__', '__getattribute__', '__globals__',
 '__gt__', '__hash__', '__init__', '__kwdefaults__', '__le__', '__lt__',
 '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__',
 '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__',
 '__subclasshook__']
>>> door1.__class__.__dict__['open'].__get__
<method-wrapper '__get__' of function object at 0xb68604ac>

   As you can see, a __get__ method is listed among the members of the function, and Python recognizes
   it as a method-wrapper. This method shall connect the open function to the door1 instance, so we can
   call it passing the instance alone
>>> door1.__class__.__dict__['open'].__get__(door1)
<bound method Door.open of <__main__.Door object at 0xb67e162c>>

   and we get exactly what we were looking for. This complex syntax is what happens behind the scenes
   when we call a method of an instance.

When Methods met Classes
   Using type() on functions defined inside classes reveals some other details on their internal
   representation
>>> Door.open
<function Door.open at 0xb687e074>
>>> door1.open
<bound method Door.open of <__main__.Door object at 0xb6f9834c>>
>>> type(Door.open)
<class 'function'>
>>> type(door1.open)
<class 'method'>

   As you can see, Python tells the two apart recognizing the first as a function and the second as a
   method, where the second is a function bound to an instance.

   What if we want to define a function that operates on the class instead of operating on the instance?
   As we may define class attributes, we may also define class methods in Python, through the
   classmethod decorator. Class methods are functions that are bound to the class and not to an
   instance.
class Door:
    colour = 'brown'

    def __init__(self, number, status):
        self.number = number
        self.status = status

    @classmethod
    def knock(cls):
        print("Knock!")

    def open(self):
        self.status = 'open'

    def close(self):
        self.status = 'closed'

   Such a definition makes the method callable on both the instance and the class
>>> door1.knock()
Knock!
>>> Door.knock()
Knock!

   and Python identifies both as (bound) methods
>>> door1.__class__.__dict__['knock']
<classmethod object at 0xb67ff6ac>
>>> door1.knock
<bound method type.knock of <class '__main__.Door'>>
>>> Door.knock
<bound method type.knock of <class '__main__.Door'>>
>>> type(Door.knock)
<class 'method'>
>>> type(door1.knock)
<class 'method'>

   As you can see the knock() function accepts one argument, which is called cls just to remember that
   it is not an instance but the class itself. This means that inside the function we can operate on the
   class, and the class is shared among instances.
class Door:
    colour = 'brown'

    def __init__(self, number, status):
        self.number = number
        self.status = status

    @classmethod
    def knock(cls):
        print("Knock!")

    @classmethod
    def paint(cls, colour):
        cls.colour = colour

    def open(self):
        self.status = 'open'

    def close(self):
        self.status = 'closed'

   The paint() classmethod now changes the class attribute colour which is shared among instances. Let's
   check how it works
>>> door1 = Door(1, 'closed')
>>> door2 = Door(2, 'closed')
>>> Door.colour
'brown'
>>> door1.colour
'brown'
>>> door2.colour
'brown'
>>> Door.paint('white')
>>> Door.colour
'white'
>>> door1.colour
'white'
>>> door2.colour
'white'

   The class method can be called on the class, but this affects both the class and the instances, since
   the colour attribute of instances is taken at runtime from the shared class.
>>> door1.paint('yellow')
>>> Door.colour
'yellow'
>>> door1.colour
'yellow'
>>> door2.colour
'yellow'

   Class methods can be called on instances too, however, and their effect is the same as before. The
   class method is bound to the class, so it works on this latter regardless of the actual object that
   calls it (class or instance).

Movie Trivia
   Section titles come from the following movies: The Empire Strikes Back (1980), Raiders of the Lost
   Ark (1981), Revenge of the Nerds (1984), When Harry Met Sally (1989).


---
http://blog.thedigitalcatonline.com/blog/2014/08/20/python-3-oop-part-3-delegation-composition-and-inheritance/

Python 3 OOP Part 3 - Delegation: composition and inheritance
20/08/2014 Series Part 3 of "Python 3 OOP"

The Delegation Run
   If classes are objects what is the difference between types and instances?

   When I talk about "my cat" I am referring to a concrete instance of the "cat" concept, which is a
   subtype of "animal". So, despite being both objects, while types can be specialized, instances
   cannot.

   Usually an object B is said to be a specialization of an object A when:
     * B has all the features of A
     * B can provide new features
     * B can perform some or all the tasks performed by A in a different way

   Those targets are very general and valid for any system and the key to achieve them with the maximum
   reuse of already existing components is delegation. Delegation means that an object shall perform
   only what it knows best, and leave the rest to other objects.

   Delegation can be implemented with two different mechanisms: composition and inheritance. Sadly, very
   often only inheritance is listed among the pillars of OOP techniques, forgetting that it is an
   implementation of the more generic and fundamental mechanism of delegation; perhaps a better
   nomenclature for the two techniques could be explicit delegation (composition) and implicit
   delegation (inheritance).

   Please note that, again, when talking about composition and inheritance we are talking about focusing
   on a behavioural or structural delegation. Another way to think about the difference between
   composition and inheritance is to consider if the object knows who can satisfy your request or if the
   object is the one that satisfy the request.

   Please, please, please do not forget composition: in many cases, composition can lead to simpler
   systems, with benefits on maintainability and changeability.

   Usually composition is said to be a very generic technique that needs no special syntax, while
   inheritance and its rules are strongly dependent on the language of choice. Actually, the strong
   dynamic nature of Python softens the boundary line between the two techniques.

Inheritance Now
   In Python a class can be declared as an extension of one or more different classes, through the class
   inheritance mechanism. The child class (the one that inherits) has the same internal structure of the
   parent class (the one that is inherited), and for the case of multiple inheritance the language has
   very specific rules to manage possible conflicts or redefinitions among the parent classes. A very
   simple example of inheritance is
class SecurityDoor(Door):
    pass

   where we declare a new class SecurityDoor that, at the moment, is a perfect copy of the Door class.
   Let us investigate what happens when we access attributes and methods. First we instance the class
>>> sdoor = SecurityDoor(1, 'closed')

   The first check we can do is that class attributes are still global and shared
>>> SecurityDoor.colour is Door.colour
True
>>> sdoor.colour is Door.colour
True

   This shows us that Python tries to resolve instance members not only looking into the class the
   instance comes from, but also investigating the parent classes. In this case sdoor.colour becomes
   SecurityDoor.colour, that in turn becomes Door.colour. SecurityDoor is a Door.

   If we investigate the content of __dict__ we can catch a glimpse of the inheritance mechanism in
   action
>>> sdoor.__dict__
{'number': 1, 'status': 'closed'}
>>> sdoor.__class__.__dict__
mappingproxy({'__doc__': None, '__module__': '__main__'})
>>> Door.__dict__
mappingproxy({'__dict__': <attribute '__dict__' of 'Door' objects>,
    'colour': 'yellow',
    'open': <function Door.open at 0xb687e224>,
    '__init__': <function Door.__init__ at 0xb687e14c>,
    '__doc__': None,
    'close': <function Door.close at 0xb687e1dc>,
    'knock': <classmethod object at 0xb67ff6ac>,
    '__weakref__': <attribute '__weakref__' of 'Door' objects>,
    '__module__': '__main__',
    'paint': <classmethod object at 0xb67ff6ec>})

   As you can see the content of __dict__ for SecurityDoor is very narrow compared to that of Door. The
   inheritance mechanism takes care of the missing elements by climbing up the classes tree. Where does
   Python get the parent classes? A class always contains a __bases__ tuple that lists them
>>> SecurityDoor.__bases__
(<class '__main__.Door'>,)

   So an example of what Python does to resolve a class method call through the inheritance tree is
>>> sdoor.__class__.__bases__[0].__dict__['knock'].__get__(sdoor)
<bound method type.knock of <class '__main__.SecurityDoor'>>
>>> sdoor.knock
<bound method type.knock of <class '__main__.SecurityDoor'>>

   Please note that this is just an example that does not consider multiple inheritance.

   Let us try now to override some methods and attributes. In Python you can override (redefine) a
   parent class member simply by redefining it in the child class.
class SecurityDoor(Door):
    colour = 'gray'
    locked = True

    def open(self):
        if not self.locked:
            self.status = 'open'

   As you can forecast, the overridden members now are present in the __dict__ of the SecurityDoor class
>>> SecurityDoor.__dict__
mappingproxy({'__doc__': None,
    '__module__': '__main__',
    'open': <function SecurityDoor.open at 0xb6fcf89c>,
    'colour': 'gray',
    'locked': True})

   So when you override a member, the one you put in the child class is used instead of the one in the
   parent class simply because the former is found before the latter while climbing the class hierarchy.
   This also shows you that Python does not implicitly call the parent implementation when you override
   a method. So, overriding is a way to block implicit delegation.

   If we want to call the parent implementation we have to do it explicitly. In the former example we
   could write
class SecurityDoor(Door):
    colour = 'gray'
    locked = True

    def open(self):
        if self.locked:
            return
        Door.open(self)

   You can easily test that this implementation is working correctly.
>>> sdoor = SecurityDoor(1, 'closed')
>>> sdoor.status
'closed'
>>> sdoor.open()
>>> sdoor.status
'closed'
>>> sdoor.locked = False
>>> sdoor.open()
>>> sdoor.status
'open'

   This form of explicit parent delegation is heavily discouraged, however.

   The first reason is because of the very high coupling that results from explicitly naming the parent
   class again when calling the method. Coupling, in the computer science lingo, means to link two parts
   of a system, so that changes in one of them directly affect the other one, and is usually avoided as
   much as possible. In this case if you decide to use a new parent class you have to manually propagate
   the change to every method that calls it. Moreover, since in Python the class hierarchy can be
   dynamically changed (i.e. at runtime), this form of explicit delegation could be not only annoying
   but also wrong.

   The second reason is that in general you need to deal with multiple inheritance, where you do not
   know a priori which parent class implements the original form of the method you are overriding.

   To solve these issues, Python supplies the super() built-in function, that climbs the class hierarchy
   and returns the correct class that shall be called. The syntax for calling super() is
class SecurityDoor(Door):
    colour = 'gray'
    locked = True

    def open(self):
        if self.locked:
            return
        super().open()

   The output of super() is not exactly the Door class. It returns a super object which representation
   is <super: <class 'SecurityDoor'>, <SecurityDoor object>>. This object however acts like the parent
   class, so you can safely ignore its custom nature and use it just like you would do with the Door
   class in this case.

Enter the Composition
   Composition means that an object knows another object, and explicitly delegates some tasks to it.
   While inheritance is implicit, composition is explicit: in Python, however, things are far more
   interesting than this =).

   First of all let us implement classic composition, which simply makes an object part of the other as
   an attribute
class SecurityDoor:
    colour = 'gray'
    locked = True

    def __init__(self, number, status):
        self.door = Door(number, status)

    def open(self):
        if self.locked:
            return
        self.door.open()

    def close(self):
        self.door.close()

   The primary goal of composition is to relax the coupling between objects. This little example shows
   that now SecurityDoor is an object and no more a Door, which means that the internal structure of
   Door is not copied. For this very simple example both Door and SecurityDoor are not big classes, but
   in a real system objects can very complex; this means that their allocation consumes a lot of memory
   and if a system contains thousands or millions of objects that could be an issue.

   The composed SecurityDoor has to redefine the colour attribute since the concept of delegation
   applies only to methods and not to attributes, doesn't it?

   Well, no. Python provides a very high degree of indirection for objects manipulation and attribute
   access is one of the most useful. As you already discovered, accessing attributes is ruled by a
   special method called __getattribute__() that is called whenever an attribute of the object is
   accessed. Overriding __getattribute__(), however, is overkill; it is a very complex method, and,
   being called on every attribute access, any change makes the whole thing slower.

   The method we have to leverage to delegate attribute access is __getattr__(), which is a special
   method that is called whenever the requested attribute is not found in the object. So basically it is
   the right place to dispatch all attribute and method access our object cannot handle. The previous
   example becomes
class SecurityDoor:
    locked = True

    def __init__(self, number, status):
        self.door = Door(number, status)

    def open(self):
        if self.locked:
            return
        self.door.open()

    def __getattr__(self, attr):
        return getattr(self.door, attr)

   Using __getattr__() blends the separation line between inheritance and composition since after all
   the former is a form of automatic delegation of every member access.
class ComposedDoor:
    def __init__(self, number, status):
        self.door = Door(number, status)

    def __getattr__(self, attr):
        return getattr(self.door, attr)

   As this last example shows, delegating every member access through __getattr__() is very simple. Pay
   attention to getattr() which is different from __getattr__(). The former is a built-in that is
   equivalent to the dotted syntax, i.e. getattr(obj, 'someattr') is the same as obj.someattr, but you
   have to use it since the name of the attribute is contained in a string.

   Composition provides a superior way to manage delegation since it can selectively delegate the
   access, even mask some attributes or methods, while inheritance cannot. In Python you also avoid the
   memory problems that might arise when you put many objects inside another; Python handles everything
   through its reference, i.e. through a pointer to the memory position of the thing, so the size of an
   attribute is constant and very limited.

Movie Trivia
   Section titles come from the following movies: The Cannonball Run (1981), Apocalypse Now (1979),
   Enter the Dragon (1973).


---
http://blog.thedigitalcatonline.com/blog/2014/08/21/python-3-oop-part-4-polymorphism/


Python 3 OOP Part 4 - Polymorphism
21/08/2014 Series Part 4 of "Python 3 OOP" 

Good Morning, Polymorphism
   The term polymorphism, in the OOP lingo, refers to the ability of an object to adapt the code to the
   type of the data it is processing.

   Polymorphism has two major applications in an OOP language. The first is that an object may provide
   different implementations of one of its methods depending on the type of the input parameters. The
   second is that code written for a given type of data may be used on data with a derived type, i.e.
   methods understand the class hierarchy of a type.

   In Python polymorphism is one of the key concepts, and we can say that it is a built-in feature. Let
   us deal with it step by step.

   First of all, you know that in Python the type of a variable is not explicitly declared. Beware that
   this does not mean that Python variables are untyped. On the contrary, everything in Python has a
   type, it just happens that the type is implicitly assigned. If you remember the last paragraph of the
   previous post, I stated that in Python variables are just pointers (using a C-like nomenclature), in
   other words they just tell the language where in memory a variable has been stored. What is stored at
   that address is not a business of the variable.
>>> a = 5
>>> a
5
>>> type(a)
<class 'int'>
>>> hex(id(a))
'0x83fe540'
>>> a = 'five'
>>> a
'five'
>>> type(a)
<class 'str'>
>>> hex(id(a))
'0xb70d6560'

   This little example shows a lot about the Python typing system. The variable a is not statically
   declared, after all it can contain only one type of data: a memory address. When we assign the number
   5 to it, Python stores in a the address of the number 5 (0x83fe540 in my case, but your result will
   be different). The type() built-in function is smart enough to understand that we are not asking
   about the type of a (which is always a reference), but about the type of the content. When you store
   another value in a, the string 'five', Python shamelessly replaces the previous content of the
   variable with the new address.

   So, thanks to the reference system, Python type system is both strong and dynamic. The exact
   definition of those two concepts is not universal, so if you are interested be ready to dive into a
   broad matter. However, in Python, the meaning of those two words is the following:
     * type system is strong because everything has a well-defined type that you can check with the
       type() built-in function
     * type system is dynamic since the type of a variable is not explicitly declared, but changes with
       the content

   Onward! We just scratched the surface of the whole thing.

   To explore the subject a little more, try to define the simplest function in Python (apart from an
   empty function)
def echo(a):
    return a

   The function works as expected, just echoes the given parameter
>>> echo(5)
5
>>> echo('five')
'five'

   Pretty straightforward, isn't it? Well, if you come from a statically compiled language such as C or
   C++ you should be at least puzzled. What is a? I mean: what type of data does it contain? Moreover,
   how can Python know what it is returning if there is no type specification?

   Again, if you recall the references stuff everything becomes clear: that function accepts a reference
   and returns a reference. In other words we just defined a sort of universal function, that does the
   same thing regardless of the input.

   This is exactly the problem that polymorphism wants to solve. We want to describe an action
   regardless of the type of objects, and this is what we do when we talk among humans. When you
   describe how to move an object by pushing it, you may explain it using a box, but you expect the
   person you are addressing to be able to repeat the action even if you need to move a pen, or a book,
   or a bottle.

   There are two main strategies you can apply to get code that performs the same operation regardless
   of the input types.

   The first approach is to cover all cases, and this is a typical approach of procedural languages. If
   you need to sum two numbers that can be integers, float or complex, you just need to write three
   sum() functions, one bound to the integer type, the second bound to the float type and the third
   bound to the complex type, and to have some language feature that takes charge of choosing the
   correct implementation depending on the input type. This logic can be implemented by a compiler (if
   the language is statically typed) or by a runtime environment (if the language is dynamically typed)
   and is the approach chosen by C++. The disadvantage of this solution is that it requires the
   programmer to forecast all the possible situations: what if I need to sum an integer with a float?
   What if I need to sum two lists? (Please note that C++ is not so poorly designed, and the operator
   overloading technique allows to manage such cases, but the base polymorphism strategy of that
   language is the one exposed here).

   The second strategy, the one implemented by Python, is simply to require the input objects to solve
   the problem for you. In other words you ask the data itself to perform the operation, reversing the
   problem. Instead of writing a bunch of functions that sum all the possible types in every possible
   combination you just write one function that requires the input data to sum, trusting that they know
   how to do it. Does it sound complex? It is not.

   Let's look at the Python implementation of the + operator. When we write c = a + b, Python actually
   executes c = a.__add__(b). As you can see the sum operation is delegated to the first input variable.
   So if we write
def sum(a, b):
    return a + b

   there is no need to specify the type of the two input variables. The object a (the object contained
   in the variable a) shall be able to sum with the object b. This is a very beautiful and simple
   implementation of the polymorphism concept. Python functions are polymorphic simply because they
   accept everything and trust the input data to be able to perform some actions.

   Let us consider another simple example before moving on. The built-in len() function returns the
   length of the input object. For example
>>> l = [1, 2, 3]
>>> len(l)
3
>>> s = "Just a sentence"
>>> len(s)
15

   As you can see it is perfectly polymorphic: you can feed both a list or a string to it and it just
   computes its length. Does it work with any type? let's check
>>> d = {'a': 1, 'b': 2}
>>> len(d)
2
>>> i = 5
>>> len(i)
Traceback  (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: object of type 'int' has no len()

   Ouch! Seems that the len() function is smart enough to deal with dictionaries, but not with integers.
   Well, after all, the length of an integer is not defined.

   Indeed this is exactly the point of Python polymorphism: the integer type does not define a length
   operation. While you blame the len() function, the int type is at fault. The len() function just
   calls the __len__() method of the input object, as you can see from this code
>>> l.__len__()
3
>>> s.__len__()
15
>>> d.__len__()
2
>>> i.__len__()
Traceback  (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'int' object has no attribute '__len__'

   Very straightforward: the 'int' object does not define any __len__() method.

   So, to sum up what we discovered until here, I would say that Python polymorphism is based on
   delegation. In the following sections we will talk about the [14]EAFP Python principle, and you will
   see that the delegation principle is somehow ubiquitous in this language.

Type Hard
   Another real-life concept that polymorphism wants to bring into a programming language is the ability
   to walk the class hierarchy, that is to run code on specialized types. This is a complex sentence to
   say something we are used to do every day, and an example will clarify the matter.

   You know how to open a door, it is something you learned in your early years. Under an OOP point of
   view you are an object (sorry, no humiliation intended) which is capable of interacting with a wood
   rectangle rotating on hinges. When you can open a door, however, you can also open a window, which,
   after all, is a specialized type of wood-rectangle-with-hinges, hopefully with some glass in it too.
   You are also able to open the car door, which is also a specialized type (this one is a mix between a
   standard door and a window). This shows that, once you know how to interact with the most generic
   type (basic door) you can also interact with specialized types (window, car door) as soon as they act
   like the ancestor type (e.g. as soon as they rotate on hinges).

   This directly translates into OOP languages: polymorphism requires that code written for a given type
   may also be run on derived types. For example, a list (a generic list object, not a Python one) that
   can contain "numbers" shall be able to accept integers because they are numbers. The list could
   specify an ordering operation which requires the numbers to be able to compare each other. So, as
   soon as integers specify a way to compare each other they can be inserted into the list and ordered.

   Statically compiled languages shall provide specific language features to implement this part of the
   polymorphism concept. In C++, for example, the language needs to introduce the concept of pointer
   compatibility between parent and child classes.

   In Python there is no need to provide special language features to implement subtype polymorphism. As
   we already discovered Python functions accept any variable without checking the type and rely on the
   variable itself to provide the correct methods. But you already know that a subtype must provide the
   methods of the parent type, either redefining them or through implicit delegation, so as you can see
   Python implements subtype polymorphism from the very beginning.

   I think this is one of the most important things to understand when working with this language.
   Python is not really interested in the actual type of the variables you are working with. It is
   interested in how those variables act, that is it just wants the variable to provide the right
   methods. So, if you come from statically typed languages, you need to make a special effort to think
   about acting like instead of being. This is what we called "duck typing".

   Time to do an example. Let us define a Room class
class Room:
    def __init__(self, door):
        self.door = door

    def open(self):
        self.door.open()

    def close(self):
        self.door.close()

    def is_open(self):
        return self.door.is_open()

   A very simple class, as you can see, just enough to exemplify polymorphism. The Room class accepts a
   door variable, and the type of this variable is not specified. Duck typing in action: the actual type
   of door is not declared, there is no "acceptance test" built in the language. Indeed, the incoming
   variable shall export the following methods that are used in the Room class: open(), close(),
   is_open(). So we can build the following classes
class Door:
    def __init__(self):
        self.status = "closed"

    def open(self):
        self.status = "open"

    def close(self):
        self.status = "closed"

    def is_open(self):
        return self.status == "open"


class BooleanDoor:
    def __init__(self):
        self.status = True

    def open(self):
        self.status = True

    def close(self):
        self.status = False

    def is_open(self):
        return self.status

   Both represent a door that can be open or closed, and they implement the concept in two different
   ways: the first class relies on strings, while the second leverages booleans. Despite being two
   different types, both act the same way, so both can be used to build a Room object.
>>> door = Door()
>>> bool_door = BooleanDoor()
>>> room = Room(door)
>>> bool_room = Room(bool_door)

>>> room.open()
>>> room.is_open()
True
>>> room.close()
>>> room.is_open()
False

>>> bool_room.open()
>>> bool_room.is_open()
True
>>> bool_room.close()
>>> bool_room.is_open()
False

File Like Us
   File-like objects are a concrete and very useful example of polymorphism in Python. A file-like
   object is a class (or the instance of a class) that acts like a file, i.e. it provides those methods
   a file object exposes.

   Say for example that you code a class that parses an XML tree, and that you expect the XML code to be
   contained in a file. So your class accepts a file in its __init__() method, and reads the content
   from it
class XMLReader:
    def __init__(xmlfile):
        xmlfile.open()
        self.content = xmlfile.read()
        xmlfile.close()

[...]

   The class works well until your application shall be modified to receive XML content from a network
   stream. To use the class without modifying it you shall write the stream in a temporary file and load
   this latter, but this sounds a little overkill. So you plan to change the class to accept a string,
   but this way you shall change every single code that uses the class to read a file, since now you
   shall open, read and close the file on your own, outside the class.

   Polymorphism offers a better way. Why not storing the incoming stream inside an object that acts like
   a file, even if it is not an actual one? If you check the [15]io module you will find that such an
   object has been already invented and provided in the standard Python library.

   Other very useful file-like classes are those contained in the gzip, bz2, and zipfile modules (just
   to name some of the most used), which provide objects that allow you to manage compressed files just
   like plain files, hiding the decompression/compression machinery.

Unforgiveness
   EAFP is a Python acronym that stands for easier to ask for forgiveness than permission. This coding
   style is highly pushed in the Python community because it completely relies on the duck typing
   concept, thus fitting well with the language philosophy.

   The concept behind EAFP is fairly easy: instead of checking if an object has a given attribute or
   method before actually accessing or using it, just trust the object to provide what you need and
   manage the error case. This can be probably better understood by looking at some code. According to
   EAFP, instead of writing
if hasattr(someobj, 'open'):
    [...]
else:
    [...]

   you shall write
try:
    someobj.open()
    [...]
except AttributeError:
    [...]

   As you can see, the second snippet directly uses the method and deals with the possible
   AttributeError exception (by the way: managing exceptions is one of the top Black Magic Topics in
   Python, more on it in a future post. A very quick preview: I think we may learn something from Erlang
   - check [16]this).

   Why is this coding style pushed so much in the Python community? I think the main reason is that
   through EAFP you think polymorphically: you are not interested in knowing if the object has the open
   attribute, you are interested in knowing if the object can satisfy your request, that is to perform
   the open() method call.

Movie Trivia

   Section titles come from the following movies: Good Morning, Vietnam (1987), Die Hard (1988), Spies
   Like Us (1985), Unforgiven (1992).


---
http://blog.thedigitalcatonline.com/blog/2014/09/01/python-3-oop-part-5-metaclasses/

Python 3 OOP Part 5 - Metaclasses
01/09/2014 Series Part 5 of "Python 3 OOP"

The Type Brothers
   The first step into the most intimate secrets of Python objects comes from two components we already
   met in the first post: class and object. These two things are the very fundamental elements of Python
   OOP system, so it is worth spending some time to understand how they work and relate each other.

   First of all recall that in Python everything is an object, that is everything inherits from object.
   Thus, object seems to be the deepest thing you can find digging into Python variables. Let's check
   this
>>> a = 5
>>> type(a)
<class 'int'>
>>> a.__class__
<class 'int'>
>>> a.__class__.__bases__
(<class 'object'>,)
>>> object.__bases__
()

   The variable a is an instance of the int class, and this latter inherits from object, which inherits
   from nothing. This demonstrates that object is at the top of the class hierarchy. However, as you can
   see, both int and object are called classes (<class 'int'>, <class 'object'>). Indeed, while a is an
   instance of the int class, int itself is an instance of another class, a class that is instanced to
   build classes
>>> type(a)
<class 'int'>
>>> type(int)
<class 'type'>
>>> type(float)
<class 'type'>
>>> type(dict)
<class 'type'>

   Since in Python everything is an object, everything is the instance of a class, even classes. Well,
   type is the class that is instanced to get classes. So remember this: object is the base of every
   object, type is the class of every type. Sounds puzzling? It is not your fault, don't worry. However,
   just to strike you with the finishing move, this is what Python is built on
>>> type(object)
<class 'type'>
>>> type.__bases__
(<class 'object'>,)

   If you are not about to faint at this point chances are that you are Guido van Rossum of one of his
   friends down at the Python core development team (in this case let me thank you for your beautiful
   creation). You may get a cup of tea, if you need it.

   Jokes apart, at the very base of Python type system there are two things, object and type, which are
   inseparable. The previous code shows that object is an instance of type, and type inherits from
   object. Take your time to understand this subtle concept, as it is very important for the upcoming
   discussion about metaclasses.

   When you think you grasped the type/object matter read this and start thinking again
>>> type(type)
<class 'type'>

The Metaclasses Take Python
   You are now familiar with Python classes. You know that a class is used to create an instance, and
   that the structure of this latter is ruled by the source class and all its parent classes (until you
   reach object).

   Since classes are objects too, you know that a class itself is an instance of a (super)class, and
   this class is type. That is, as already stated, type is the class that is used to build classes.

   So for example you know that a class may be instanced, i.e. it can be called and by calling it you
   obtain another object that is linked with the class. What prepares the class for being called? What
   gives the class all its methods? In Python the class in charge of performing such tasks is called
   metaclass, and type is the default metaclass of all classes.

   The point of exposing this structure of Python objects is that you may change the way classes are
   built. As you know, type is an object, so it can be subclassed just like any other class. Once you
   get a subclass of type you need to instruct your class to use it as the metaclass instead of type,
   and you can do this by passing it as the metaclass keyword argument in the class definition.
>>> class MyType(type):
...  pass
...
>>> class MySpecialClass(metaclass=MyType):
...  pass
...
>>> msp = MySpecialClass()
>>> type(msp)
<class '__main__.MySpecialClass'>
>>> type(MySpecialClass)
<class '__main__.MyType'>
>>> type(MyType)
<class 'type'>

Metaclasses 2: Singleton Day
   Metaclasses are a very advanced topic in Python, but they have many practical uses. For example, by
   means of a custom metaclass you may log any time a class is instanced, which can be important for
   applications that shall keep a low memory usage or have to monitor it.

   I am going to show here a very simple example of metaclass, the Singleton. Singleton is a well known
   design pattern, and many description of it may be found on the Internet. It has also been heavily
   criticized mostly because its bad behaviour when subclassed, but here I do not want to introduce it
   for its technological value, but for its simplicity (so please do not question the choice, it is just
   an example).

   Singleton has one purpose: to return the same instance every time it is instanced, like a sort of
   object-oriented global variable. So we need to build a class that does not work like standard
   classes, which return a new instance every time they are called.

   "Build a class"? This is a task for metaclasses. The following implementation comes from [16]Python 3
   Patterns, Recipes and Idioms.
class Singleton(type):
    instance = None
    def __call__(cls, *args, **kw):
        if not cls.instance:
             cls.instance = super(Singleton, cls).__call__(*args, **kw)
        return cls.instance

   We are defining a new type, which inherits from type to provide all bells and whistles of Python
   classes. We override the __call__ method, that is a special method invoked when we call the class,
   i.e. when we instance it. The new method wraps the original method of type by calling it only when
   the instance attribute is not set, i.e. the first time the class is instanced, otherwise it just
   returns the recorded instance. As you can see this is a very basic cache class, the only trick is
   that it is applied to the creation of instances.

   To test the new type we need to define a new class that uses it as its metaclass
>>> class ASingleton(metaclass=Singleton):
...  pass
...
>>> a = ASingleton()
>>> b = ASingleton()
>>> a is b
True
>>> hex(id(a))
'0xb68030ec'
>>> hex(id(b))
'0xb68030ec'

   By using the is operator we test that the two objects are the very same structure in memory, that is
   their ids are the same, as explicitly shown. What actually happens is that when you issue a =
   ASingleton() the ASingleton class runs its __call__() method, which is taken from the Singleton type
   behind the class. That method recognizes that no instance has been created (Singleton.instance is
   None) and acts just like any standard class does. When you issue b = ASingleton() the very same
   things happen, but since Singleton.instance is now different from None its value (the previous
   instance) is directly returned.

   Metaclasses are a very powerful programming tool and leveraging them you can achieve very complex
   behaviours with a small effort. Their use is a must every time you are actually metaprogramming, that
   is you are writing code that has to drive the way your code works. Good examples are creational
   patterns (injecting custom class attributes depending on some configuration), testing, debugging, and
   performance monitoring.

Coming to Instance
   Before introducing you to a very smart use of metaclasses by talking about Abstract Base Classes
   (read: to save some topics for the next part of this series), I want to dive into the object creation
   procedure in Python, that is what happens when you instance a class. In the first post this procedure
   was described only partially, by looking at the __init__() method.

   In the first post I recalled the object-oriented concept of constructor, which is a special method of
   the class that is automatically called when the instance is created. The class may also define a
   destructor, which is called when the object is destroyed. In languages without a garbage collection
   mechanism such as C++ the destructor shall be carefully designed. In Python the destructor may be
   defined through the __del__() method, but it is hardly used.

   The constructor mechanism in Python is on the contrary very important, and it is implemented by two
   methods, instead of just one: __new__() and __init__(). The tasks of the two methods are very clear
   and distinct: __new__() shall perform actions needed when creating a new instance while __init__
   deals with object initialization.

   Since in Python you do not need to declare attributes due to its dynamic nature, __new__() is rarely
   defined by programmers, who may rely on __init__ to perform the majority of the usual tasks. Typical
   uses of __new__() are very similar to those listed in the previous section, since it allows to
   trigger some code whenever your class is instanced.

   The standard way to override __new__() is
class MyClass():
    def __new__(cls, *args, **kwds):
        obj = super().__new__(cls, *args, **kwds)
        [put your code here]
        return obj

   just like you usually do with __init__(). When your class inherits from object you do not need to
   call the parent method (object.__init__()), because it is empty, but you need to do it when
   overriding __new__.

   Remember that __new__() is not forced to return an instance of the class in which it is defined, even
   if you shall have very good reasons to break this behaviour. Anyway, __init__() will be called only
   if you return an instance of the container class. Please also note that __new__(), unlike __init__(),
   accepts the class as its first parameter. The name is not important in Python, and you can also call
   it self, but it is worth using cls to remember that it is not an instance.

Movie Trivia

   Section titles come from the following movies: The Blues Brothers (1980), The Muppets Take Manhattan
   (1984), Terminator 2: Judgement Day (1991), Coming to America (1988).


---
http://blog.thedigitalcatonline.com/blog/2014/09/04/python-3-oop-part-6-abstract-base-classes/

Python 3 OOP Part 6 - Abstract Base Classes
04/09/2014 Series Part 6 of "Python 3 OOP"

The Inspection Club
   As you know, Python leverages polymorphism at its maximum by dealing only with generic references to
   objects. This makes OOP not an addition to the language but part of its structure from the ground up.
   Moreover, Python pushes the EAFP appoach, which tries to avoid direct inspection of objects as much
   as possible.

   It is however very interesting to read what Guido van Rossum says in [16]PEP 3119: Invocation means
   interacting with an object by invoking its methods. Usually this is combined with polymorphism, so
   that invoking a given method may run different code depending on the type of an object. Inspection
   means the ability for external code (outside of the object's methods) to examine the type or
   properties of that object, and make decisions on how to treat that object based on that information.
   [...] In classical OOP theory, invocation is the preferred usage pattern, and inspection is actively
   discouraged, being considered a relic of an earlier, procedural programming style. However, in
   practice this view is simply too dogmatic and inflexible, and leads to a kind of design rigidity that
   is very much at odds with the dynamic nature of a language like Python.

   The author of Python recognizes that forcing the use of a pure polymorphic approach leads sometimes
   to solutions that are too complex or even incorrect. In this section I want to show some of the
   problems that can arise from a pure polymorphic approach and introduce Abstract Base Classes, which
   aim to solve them. I strongly suggest to read [17]PEP 3119 (as for any other PEP) since it contains a
   deeper and better explanation of the whole matter. Indeed I think that this PEP is so well written
   that any further explanation is hardly needed. I am however used to write explanations to check how
   much I understood about the topic, so I am going to try it this time too.

E.A.F.P the Extra Test Trial
   The EAFP coding style requires you to trust the incoming objects to provide the attributes and
   methods you need, and to manage the possible exceptions, if you know how to do it. Sometimes,
   however, you need to test if the incoming object matches a complex behaviour. For example, you could
   be interested in testing if the object acts like a list, but you quickly realize that the amount of
   methods a list provides is very big and this could lead to odd EAFP code like
try:
    obj.append
    obj.count
    obj.extend
    obj.index
    obj.insert
    [...]
except AttributeError:
    [...]

   where the methods of the list type are accessed (not called) just to force the object to raise the
   AttributeError exception if they are not present. This code, however, is not only ugly but also
   wrong. If you recall the "Enter the Composition" section of the [18]third post of this series, you
   know that in Python you can always customize the __getattr__() method, which is called whenever the
   requested attribute is not found in the object. So I could write a class that passes the test but
   actually does not act like a list
class FakeList:
    def fakemethod(self):
        pass

    def __getattr__(self, name):
        if name in ['append', 'count', 'extend', 'index', 'insert', ...]:
            return self.fakemethod

   This is obviously just an example, and no one will ever write such a class, but this demonstrates
   that just accessing methods does not guarantee that a class acts like the one we are expecting.

   There are many examples that could be done leveraging the highly dynamic nature of Python and its
   rich object model. I would summarize them by saying that sometimes you'd better to check the type of
   the incoming object.

   In Python you can obtain the type of an object using the type() built-in function, but to check it
   you'd better use isinstance(), which returns a boolean value. Let us see an example before moving on
>>> isinstance([], list)
True
>>> isinstance(1, int)
True
>>> class Door:
...  pass
...
>>> d = Door()
>>> isinstance(d, Door)
True
>>> class EnhancedDoor(Door):
...  pass
...
>>> ed = EnhancedDoor()
>>> isinstance(ed, EnhancedDoor)
True
>>> isinstance(ed, Door)
True

   As you can see the function can also walk the class hierarchy, so the check is not so trivial like
   the one you would obtain by directly using type().

   The isinstance() function, however, does not completely solve the problem. If we write a class that
   actually acts like a list but does not inherit from it, isinstance() does not recognize the fact that
   the two may be considered the same thing. The following code returns False regardless the content of
   the MyList class
>>> class MyList:
...  pass
...
>>> ml = MyList()
>>> isinstance(ml, list)
False

   since isinstance() does not check the content of the class or its behaviour, it just considers the
   class and its ancestors.

   The problem, thus, may be summed up with the following question: what is the best way to test that an
   object exposes a given interface? Here, the word interface is used for its natural meaning, without
   any reference to other programming solutions, which however address the same problem.

   A good way to address the problem could be to write inside an attribute of the object the list of
   interfaces it promises to implement, and to agree that any time we want to test the behaviour of an
   object we simply have to check the content of this attribute. This is exactly the path followed by
   Python, and it is very important to understand that the whole system is just about a promised
   behaviour.

   The solution proposed through PEP 3119 is, in my opinion, very simple and elegant, and it perfectly
   fits the nature of Python, where things are usually agreed rather than being enforced. Not only, the
   solution follows the spirit of polymorphism, where information is provided by the object itself and
   not extracted by the calling code.

   In the next sections I am going to try and describe this solution in its main building blocks. The
   matter is complex so my explanation will lack some details: please refer to the forementioned PEP
   3119 for a complete description.

Who Framed the Metaclasses
   As already described, Python provides two built-ins to inspect objects and classes, which are
   isinstance() and issubclass() and a solution to the inspection problem should allow the programmer to
   go on with using those two functions.

   This means that we need to find a way to inject the "behaviour promise" into both classes and
   instances. This is the reason why metaclasses come in play. Recall what we said about them in the
   fifth issue of this series: metaclasses are the classes used to build classes, which means that they
   are the preferred way to change the structure of a class, and, in consequence, of its instances.

   Another way to do the same job would be to leverage the inheritance mechanism, injecting the
   behaviour through a dedicated parent class. This solution has many downsides, which I'm am not going
   to detail. It is enough to say that affecting the class hierarchy may lead to complex situations or
   subtle bugs. Metaclasses may provide here a different entry point for the introduction of a "virtual
   base class" (as PEP 3119 specifies, this is not the same concept as in C++).

Overriding Places
   As said, isinstance() and issubclass() are built-in functions, not object methods, so we cannot
   simply override them providing a different implementation in a given class. So the first part of the
   solution is to change the behaviour of those two functions to first check if the class or the
   instance contain a special method, which is __instancecheck__() for isinstance() and
   __subclasscheck__() for issubclass(). So both built-ins try to run the respective special method,
   reverting to the standard algorithm if it is not present.

   A note about naming. Methods must accept the object they belong to as the first argument, so the two
   special methods shall have the form
def __instancecheck__(cls, inst):
   [...]

def __subclasscheck__(cls, sub):
   [...]

   where cls is the class where they are injected, that is the one representing the promised behaviour.
   The two built-ins, however, have a reversed argument order, where the behaviour comes after the
   tested object: when you write isinstance([], list) you want to check if the [] instance has the list
   behaviour. This is the reason behind the name choice: just calling the methods __isinstance__() and
   __issubclass__() and passing arguments in a reversed order would have been confusing.

This is ABC
   The proposed solution is thus called Abstract Base Classes, as it provides a way to attach to a
   concrete class a virtual class with the only purpose of signaling a promised behaviour to anyone
   inspecting it with isinstance() or issubclass().

   To help programmers implement Abstract Base Classes, the standard library has been given an abc
   module, thet contains the ABCMeta class (and other facilities). This class is the one that implements
   __instancecheck__() and __subclasscheck__() and shall be used as a metaclass to augment a standard
   class. This latter will then be able to register other classes as implementation of its behaviour.

   Sounds complex? An example may clarify the whole matter. The one from the official documentation is
   rather simple:
from abc import ABCMeta

class MyABC(metaclass=ABCMeta):
    pass

MyABC.register(tuple)

assert issubclass(tuple, MyABC)
assert isinstance((), MyABC)

   Here, the MyABC class is provided the ABCMeta metaclass. This puts the two __instancecheck__() and
   __subclasscheck__() methods inside MyABC so that, when issuing isinstance(), what Python actually
   ececutes is
>>> d = {'a': 1}
>>> isinstance(d, MyABC)
False
>>> MyABC.__class__.__instancecheck__(MyABC, d)
False
>>> isinstance((), MyABC)
True
>>> MyABC.__class__.__instancecheck__(MyABC, ())
True

   After the definition of MyABC we need a way to signal that a given class is an instance of the
   Abstract Base Class and this happens through the register() method, provided by the ABCMeta
   metaclass. Calling MyABC.register(tuple) we record inside MyABC the fact that the tuple class shall
   be identified as a subclass of MyABC itself. This is analogous to saying that tuple inherits from
   MyABC but not quite the same. As already said registering a class in an Abstract Base Class with
   register() does not affect the class hierarchy. Indeed, the whole tuple class is unchanged.

   The current implementation of ABCs stores the registered types inside the _abc_registry attribute.
   Actually it stores there weak references to the registered types (this part is outside the scope of
   this article, so I'm not detailing it)
>>> MyABC._abc_registry.data
{<weakref at 0xb682966c; to 'type' at 0x83dcca0 (tuple)>}

Movie Trivia

   Section titles come from the following movies: The Breakfast Club (1985), E.T. the Extra-Terrestrial
   (1982), Who Framed Roger Rabbit (1988), Trading Places (1983), This is Spinal Tap (1984).
