filename: c_using-external-librarie-multif_20211027.txt
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_17.html

2.7 Linking with external libraries

   A library is a collection of precompiled object files which can be linked into programs. The most
   common use of libraries is to provide system functions, such as the square root function sqrt found
   in the C math library.

   Libraries are typically stored in special archive files with the extension '.a', referred to as
   static libraries. They are created from object files with a separate tool, the GNU archiver ar, and
   used by the linker to resolve references to functions at compile-time. We will see later how to
   create libraries using the ar command (see section 10 Compiler-related tools). For simplicity,
   only static libraries are covered in this section--dynamic linking at runtime using shared libraries
   will be described in the next chapter.

   The standard system libraries are usually found in the directories '/usr/lib' and '/lib'.^(5) For
   example, the C math library is typically stored in the file '/usr/lib/libm.a' on Unix-like systems.
   The corresponding prototype declarations for the functions in this library are given in the header
   file '/usr/include/math.h'. The C standard library itself is stored in '/usr/lib/libc.a' and contains
   functions specified in the ANSI/ISO C standard, such as 'printf'---this library is linked by default
   for every C program.

   Here is an example program which makes a call to the external function sqrt in the math library
   'libm.a':
#include <math.h>
#include <stdio.h>

int main (void) {
	double x = sqrt (2.0);
	printf ("The square root of 2.0 is %f\n", x);
	return 0;
}

   Trying to create an executable from this source file alone causes the compiler to give an error at
   the link stage:
$> gcc -Wall calc.c -o calc
/tmp/ccbR6Ojm.o: In function `main':
/tmp/ccbR6Ojm.o(.text+0x19): undefined reference to `sqrt'

   The problem is that the reference to the sqrt function cannot be resolved without the external math
   library 'libm.a'. The function sqrt is not defined in the program or the default library 'libc.a',
   and the compiler does not link to the file 'libm.a' unless it is explicitly selected. Incidentally,
   the file mentioned in the error message '/tmp/ccbR60jm.o' is a temporary object file created by the
   compiler from 'calc.c', in order to carry out the linking process.

   To enable the compiler to link the sqrt function to the main program 'calc.c' we need to supply the
   library 'libm.a'. One obvious but cumbersome way to do this is to specify it explicitly on the
   command line:
$> gcc -Wall calc.c /usr/lib/libm.a -o calc

   The library 'libm.a' contains object files for all the mathematical functions, such as sin, cos, exp,
   log and sqrt. The linker searches through these to find the object file containing the sqrt function.

   Once the object file for the sqrt function has been found, the main program can be linked and a
   complete executable produced:
$> ./calc
The square root of 2.0 is 1.414214

   The executable file includes the machine code for the main function and the machine code for the sqrt
   function, copied from the corresponding object file in the library 'libm.a'.

   To avoid the need to specify long paths on the command line, the compiler provides a short-cut option
   '-l' for linking against libraries. For example, the following command,
$> gcc -Wall calc.c -lm -o calc

   is equivalent to the original command above using the full library name '/usr/lib/libm.a'.

   In general, the compiler option -lNAME will attempt to link object files with a library file
   'libNAME.a' in the standard library directories. Additional directories can specified with
   command-line options and environment variables, to be discussed shortly. A large program will
   typically use many -l options to link libraries such as the math library, graphics libraries and
   networking libraries.



---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_18.html

2.7.1 Link order of libraries

   The traditional behavior of linkers is to search for external functions from left to right in the
   libraries specified on the command line. This means that a library containing the definition of a
   function should appear after any source files or object files which use it. This includes libraries
   specified with the short-cut -l option, as shown in the following command:
$> gcc -Wall calc.c -lm -o calc   (correct order)

   With some linkers the opposite ordering (placing the -lm option before the file which uses it) would
   result in an error,
$> cc -Wall -lm calc.c -o calc    (incorrect order)
main.o: In function `main':
main.o(.text+0xf): undefined reference to `sqrt'

   because there is no library or object file containing sqrt after 'calc.c'. The option -lm should
   appear after the file 'calc.c'.

   When several libraries are being used, the same convention should be followed for the libraries
   themselves. A library which calls an external function defined in another library should appear
   before the library containing the function.

   For example, a program 'data.c' using the GNU Linear Programming library 'libglpk.a', which in turn
   uses the math library 'libm.a', should be compiled as,
$> gcc -Wall data.c -lglpk -lm

   since the object files in 'libglpk.a' use functions defined in 'libm.a'.

   Most current linkers will search all libraries, regardless of order, but since some do not do this it
   is best to follow the convention of ordering libraries from left to right.

   This is worth keeping in mind if you ever encounter unexpected problems with undefined references,
   and all the necessary libraries appear to be present on the command line.



---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_19.html

2.8 Using library header files

   When using a library it is essential to include the appropriate header files, in order to declare the
   function arguments and return values with the correct types. Without declarations, the arguments of a
   function can be passed with the wrong type, causing corrupted results.

   The following example shows another program which makes a function call to the C math library. In
   this case, the function pow is used to compute the cube of two (2 raised to the power of 3):
#include <stdio.h>

int
main (void) {
	double x = pow (2.0, 3.0);
	printf ("Two cubed is %f\n", x);
	return 0;
}

   However, the program contains an error--the #include statement for 'math.h' is missing, so the
   prototype double pow (double x, double y) given there will not be seen by the compiler.

   Compiling the program without any warning options will produce an executable file which gives
   incorrect results:
$> gcc badpow.c -lm
$> ./a.out
Two cubed is 2.851120    (incorrect result, should be 8)

   The results are corrupted because the arguments and return value of the call to pow are passed with
   incorrect types. This can be detected by turning on the warning option -Wall:
$> gcc -Wall badpow.c -lm
badpow.c: In function `main':
badpow.c:6: warning: implicit declaration of
  function `pow'

   This example shows again the importance of using the warning option -Wall to detect serious problems
   that could otherwise easily be overlooked.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_21.html

3.1 Setting search paths

   In the last chapter, we saw how to link to a program with functions in the C math library 'libm.a',
   using the short-cut option -lm and the header file 'math.h'.

   A common problem when compiling a program using library header files is the error:
FILE.h: No such file or directory

   This occurs if a header file is not present in the standard include file directories used by gcc. A
   similar problem can occur for libraries:
/usr/bin/ld: cannot find library

   This happens if a library used for linking is not present in the standard library directories used by
   gcc.

   By default, gcc searches the following directories for header files:
/usr/local/include/
/usr/include/

   and the following directories for libraries:
/usr/local/lib/
/usr/lib/

   The list of directories for header files is often referred to as the include path, and the list of
   directories for libraries as the library search path or link path.

   The directories on these paths are searched in order, from first to last in the two lists
   above. For example, a header file found in '/usr/local/include' takes precedence over a file
   with the same name in '/usr/include'. Similarly, a library found in '/usr/local/lib' takes precedence
   over a library with the same name in '/usr/lib'.

   When additional libraries are installed in other directories it is necessary to extend the search
   paths, in order for the libraries to be found. The compiler options -I and -L add new directories to
   the beginning of the include path and library search path respectively.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_22.html

3.1.1 Search path example

   The following example program uses a library that might be installed as an additional package on a
   system--the GNU Database Management Library (GDBM). The GDBM Library stores key-value pairs in a DBM
   file, a type of data file which allows values to be stored and indexed by a key (an arbitrary
   sequence of characters). Here is the example program 'dbmain.c', which creates a DBM file containing
   a key 'testkey' with the value 'testvalue':
#include <stdio.h>
#include <gdbm.h>

int main (void) {
	GDBM_FILE dbf;
	datum key = { "testkey", 7 };     /* key, length */
	datum value = { "testvalue", 9 }; /* value, length */

	printf ("Storing key-value pair... ");
	dbf = gdbm_open ("test", 0, GDBM_NEWDB, 0644, 0);
	gdbm_store (dbf, key, value, GDBM_INSERT);
	gdbm_close (dbf);
	printf ("done.\n");
	return 0;
}

   The program uses the header file 'gdbm.h' and the library 'libgdbm.a'. If the library has been
   installed in the default location of '/usr/local/lib', with the header file in '/usr/local/include',
   then the program can be compiled with the following simple command:
$> gcc -Wall dbmain.c -lgdbm

   Both these directories are part of the default gcc include and link paths.

   However, if GDBM has been installed in a different location, trying to compile the program will give
   the following error:
$> gcc -Wall dbmain.c -lgdbm
dbmain.c:1: gdbm.h: No such file or directory

   For example, if version 1.8.3 of the GDBM package is installed under the directory '/opt/gdbm-1.8.3'
   the location of the header file would be,
/opt/gdbm-1.8.3/include/gdbm.h

   which is not part of the default gcc include path. Adding the appropriate directory to the include
   path with the command-line option -I allows the program to be compiled, but not linked:
$> gcc -Wall -I/opt/gdbm-1.8.3/include dbmain.c -lgdbm
/usr/bin/ld: cannot find -lgdbm
collect2: ld returned 1 exit status

   The directory containing the library is still missing from the link path. It can be added to the link
   path using the following option:
-L/opt/gdbm-1.8.3/lib/

   The following command line allows the program to be compiled and linked:
$> gcc -Wall -I/opt/gdbm-1.8.3/include -L/opt/gdbm-1.8.3/lib dbmain.c -lgdbm

   This produces the final executable linked to the GDBM library. Before seeing how to run this
   executable we will take a brief look at the environment variables that affect the -I and -L options.

   Note that you should never place the absolute paths of header files in #include statements in your
   source code, as this will prevent the program from compiling on other systems. The -I option or the
   INCLUDE_PATH variable described below should always be used to set the include path for header files.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_23.html

3.1.2 Environment variables

   The search paths for header files and libraries can also be controlled through environment variables
   in the shell. These may be set automatically for each session using the appropriate login file, such
   as '.bash_profile' in the case of GNU Bash.

   Additional directories can be added to the include path using the environment variable C_INCLUDE_PATH
   (for C header files) or CPLUS_INCLUDE_PATH (for C++ header files). For example, the following
   commands will add '/opt/gdbm-1.8.3/include' to the include path when compiling C programs:
$> C_INCLUDE_PATH=/opt/gdbm-1.8.3/include
$> export C_INCLUDE_PATH

   and similarly for C++ programs:
$> CPLUS_INCLUDE_PATH=/opt/gdbm-1.8.3/include
$> export CPLUS_INCLUDE_PATH

   This directory will be searched after any directories specified on the command line with the option
   -I, and before the standard default directories (such as '/usr/local/include' and '/usr/include').
   The shell command export is needed to make the environment variable available to programs outside the
   shell itself, such as the compiler--it is only needed once for each variable in each shell session,
   and can also be set in the appropriate login file.

   Similarly, additional directories can be added to the link path using the environment variable
   LIBRARY_PATH. For example, the following commands will add '/opt/gdbm-1.8.3/lib' to the link path:
$> LIBRARY_PATH=/opt/gdbm-1.8.3/lib
$> export LIBRARY_PATH

   This directory will be searched after any directories specified on the command line with the option
   -L, and before the standard default directories (such as '/usr/local/lib' and '/usr/lib').

   With the environment variable settings given above the program 'dbmain.c' can be compiled without the
   -I and -L options,
$> gcc -Wall dbmain.c -lgdbm

   because the default paths now use the directories specified in the environment variables
   C_INCLUDE_PATH and LIBRARY_PATH. The same compilation command with g++ would use the environment
   variables CPLUS_INCLUDE_PATH and LIBRARY_PATH.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_24.html

3.1.3 Extended search paths

   Following the standard Unix convention for search paths, several directories can be specified
   together in an environment variable as a colon separated list:
DIR1:DIR2:DIR3:...

   The directories are then searched in order from left to right. A single dot '.' can be used to
   specify the current directory.

   For example, the following settings create default include and link paths for packages installed in
   the current directory '.' and the 'include' and 'lib' directories under '/opt/gdbm-1.8.3' and '/net'
   respectively:
$> C_INCLUDE_PATH=.:/opt/gdbm-1.8.3/include:/net/include
$> LIBRARY_PATH=.:/opt/gdbm-1.8.3/lib:/net/lib

   For C++ programs, use the environment variable CPLUS_INCLUDE_PATH instead of C_INCLUDE_PATH.

   To specify multiple search path directories on the command line, the options -I and -L can be
   repeated. For example, the following command,
$> gcc -I. -I/opt/gdbm-1.8.3/include -I/net/include -L. -L/opt/gdbm-1.8.3/lib -L/net/lib .....

   is equivalent to the environment variable settings given above.

   When environment variables and command-line options are used together the compiler searches the
   directories in the following order:
    1. command-line options -I and -L, from left to right
    2. directories specified by environment variables, such as C_INCLUDE_PATH (for C programs),
       CPLUS_INCLUDE_PATH (for C++ programs) and LIBRARY_PATH
    3. default system directories

   In day-to-day usage, directories are usually added to the search paths with the options -I and -L.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_25.html

3.2 Shared libraries and static libraries

   Although the example program above has been successfully compiled and linked, a final step is needed
   before being able to load and run the executable file.

   If an attempt is made to start the executable directly, the following error will occur on most
   systems:
$> ./a.out
./a.out: error while loading shared libraries:
libgdbm.so.3: cannot open shared object file:
No such file or directory

   This is because the GDBM package provides a shared library. This type of library requires special
   treatment--it must be loaded from disk before the executable will run.

   External libraries are usually provided in two forms: static libraries and shared libraries. Static
   libraries are the '.a' files seen earlier. When a program is linked against a static library, the
   machine code from the object files for any external functions used by the program is copied from the
   library into the final executable.

   Shared libraries are handled with a more advanced form of linking, which makes the executable file
   smaller. They use the extension '.so', which stands for shared object.

   An executable file linked against a shared library contains only a small table of the functions it
   requires, instead of the complete machine code from the object files for the external functions.
   Before the executable file starts running, the machine code for the external functions is copied into
   memory from the shared library file on disk by the operating system--a process referred to as dynamic
   linking.

   Dynamic linking makes executable files smaller and saves disk space, because one copy of a library
   can be shared between multiple programs. Most operating systems also provide a virtual memory
   mechanism which allows one copy of a shared library in physical memory to be used by all running
   programs, saving memory as well as disk space.

   Furthermore, shared libraries make it possible to update a library without recompiling the programs
   which use it (provided the interface to the library does not change).

   Because of these advantages gcc compiles programs to use shared libraries by default on most systems,
   if they are available. Whenever a static library 'libNAME.a' would be used for linking with the
   option -lNAME the compiler first checks for an alternative shared library with the same name and a
   '.so' extension.

   In this case, when the compiler searches for the 'libgdbm' library in the link path, it finds the
   following two files in the directory '/opt/gdbm-1.8.3/lib':
$> cd /opt/gdbm-1.8.3/lib
$> ls libgdbm.*
libgdbm.a  libgdbm.so

   Consequently, the 'libgdbm.so' shared object file is used in preference to the 'libgdbm.a' static
   library.

   However, when the executable file is started its loader function must find the shared library in
   order to load it into memory. By default the loader searches for shared libraries only in a
   predefined set of system directories, such as '/usr/local/lib' and '/usr/lib'. If the library is not
   located in one of these directories it must be added to the load path.

   The simplest way to set the load path is through the environment variable LD_LIBRARY_PATH. For
   example, the following commands set the load path to '/opt/gdbm-1.8.3/lib' so that 'libgdbm.so' can
   be found:
$> LD_LIBRARY_PATH=/opt/gdbm-1.8.3/lib
$> export LD_LIBRARY_PATH
$> ./a.out
Storing key-value pair... done.

   The executable now runs successfully, prints its message and creates a DBM file called 'test'
   containing the key-value pair 'testkey' and 'testvalue'.

   To save typing, the LD_LIBRARY_PATH environment variable can be set automatically for each session
   using the appropriate login file, such as '.bash_profile' for the GNU Bash shell.

   Several shared library directories can be placed in the load path, as a colon separated list
   DIR1:DIR2:DIR3:...:DIRN. For example, the following command sets the load path to use the 'lib'
   directories under '/opt/gdbm-1.8.3' and '/opt/gtk-1.4':
$> LD_LIBRARY_PATH=/opt/gdbm-1.8.3/lib:/opt/gtk-1.4/lib
$> export LD_LIBRARY_PATH

   If the load path contains existing entries, it can be extended using the syntax
   LD_LIBRARY_PATH=NEWDIRS:$LD_LIBRARY_PATH. For example, the following command adds the directory
   '/opt/gsl-1.5/lib' to the load path shown above:
$> LD_LIBRARY_PATH=/opt/gsl-1.5/lib:$LD_LIBRARY_PATH
$> echo $LD_LIBRARY_PATH
/opt/gsl-1.5/lib:/opt/gdbm-1.8.3/lib:/opt/gtk-1.4/lib

   It is possible for the system administrator to set the LD_LIBRARY_PATH variable for all users, by
   adding it to a default login script, such as '/etc/profile'. On GNU systems, a system-wide path can
   also be defined in the loader configuration file '/etc/ld.so.conf'.

   Alternatively, static linking can be forced with the -static option to gcc to avoid the use of shared
   libraries:
$> gcc -Wall -static -I/opt/gdbm-1.8.3/include/ -L/opt/gdbm-1.8.3/lib/ dbmain.c -lgdbm

   This creates an executable linked with the static library 'libgdbm.a' which can be run without
   setting the environment variable LD_LIBRARY_PATH or putting shared libraries in the default
   directories:
$> ./a.out
Storing key-value pair... done.

   As noted earlier, it is also possible to link directly with individual library files by specifying
   the full path to the library on the command line. For example, the following command will link
   directly with the static library 'libgdbm.a',
$> gcc -Wall -I/opt/gdbm-1.8.3/include dbmain.c /opt/gdbm-1.8.3/lib/libgdbm.a

   and the command below will link with the shared library file 'libgdbm.so':
$> gcc -Wall -I/opt/gdbm-1.8.3/include dbmain.c /opt/gdbm-1.8.3/lib/libgdbm.so

   In the latter case it is still necessary to set the library load path when running the executable.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_30.html

3.4 Warning options in -Wall

   As described earlier (see section 2.1 Compiling a simple C program), the warning option -Wall
   enables warnings for many common errors, and should always be used. It combines a large number of
   other, more specific, warning options which can also be selected individually. Here is a summary of
   these options:
   -Wcomment (included in -Wall)
          This option warns about nested comments. Nested comments typically arise when a section of
          code containing comments is later commented out:
/* commented out
double x = 1.23 ; /* x-position */
*/

          Nested comments can be a source of confusion--the safe way to "comment out" a section of code
          containing comments is to surround it with the preprocessor directive #if 0 ... #endif:
/* commented out */
#if 0
double x = 1.23 ; /* x-position */
#endif

   -Wformat (included in -Wall)
          This option warns about the incorrect use of format strings in functions such as printf and
          scanf, where the format specifier does not agree with the type of the corresponding function
          argument.
   -Wunused (included in -Wall)
          This option warns about unused variables. When a variable is declared but not used this can be
          the result of another variable being accidentally substituted in its place. If the variable is
          genuinely not needed it can be removed from the source code.
   -Wimplicit (included in -Wall)
          This option warns about any functions that are used without being declared. The most common
          reason for a function to be used without being declared is forgetting to include a header
          file.
   -Wreturn-type (included in -Wall)
          This option warns about functions that are defined without a return type but not declared
          void. It also catches empty return statements in functions that are not declared void. For
          example, the following program does not use an explicit return value:
#include <stdio.h>

int main (void) {
	printf ("hello world\n");
	return;
}

          The lack of a return value in the code above could be the result of an accidental omission by
          the programmer--the value returned by the main function is actually the return value of the
          printf function (the number of characters printed). To avoid ambiguity, it is preferable to
          use an explicit value in the return statement, either as a variable or a constant, such as
          return 0.

   The complete set of warning options included in -Wall can be found in the GCC Reference Manual "Using
   GCC" (see section Further reading). The options included in -Wall have the common characteristic
   that they report constructions which are always wrong, or can easily be rewritten in an unambiguously
   correct way. This is why they are so useful--any warning produced by -Wall can be taken as an
   indication of a potentially serious problem.


---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_31.html

3.5 Additional warning options

   GCC provides many other warning options that are not included in -Wall but are often useful.
   Typically these produce warnings for source code which may be technically valid but is very likely to
   cause problems. The criteria for these options are based on experience of common errors--they are not
   included in -Wall because they only indicate possibly problematic or "suspicious" code.

   Since these warnings can be issued for valid code it is not necessary to compile with them all the
   time. It is more appropriate to use them periodically and review the results, checking for anything
   unexpected, or to enable them for some programs or files.
   -W
          This is a general option similar to -Wall which warns about a selection of common programming
          errors, such as functions which can return without a value (also known as "falling off the end
          of the function body"), and comparisons between signed and unsigned values. For example, the
          following function tests whether an unsigned integer is negative (which is impossible, of
          course):
int foo (unsigned int x) {
	if (x < 0)
		return 0;  /* cannot occur */
	else
		return 1;
}

          Compiling this function with -Wall does not produce a warning,
$> gcc -Wall -c w.c

          but does give a warning with -W:
$> gcc -W -c w.c
w.c: In function `foo':
w.c:4: warning: comparison of unsigned
  expression < 0 is always false

          In practice, the options -W and -Wall are normally used together.
   -Wconversion
          This option warns about implicit type conversions that could cause unexpected results, such as
          conversions between floating-point and integer types, between signed and unsigned types and
          between types of different width (e.g. long and short integers). Conversions can occur in
          expressions and assignments, and in calls to functions if the types of the arguments do not
          match those specified in the prototype. For example, the integer absolute value function int
          abs(int i) is easily confused with the corresponding floating-point function double
          fabs(double x). This can lead to incorrect results, as shown in the following program:
#include <stdio.h>
#include <stdlib.h>

int main (void) {
	double x = -3.14;
	double y = abs(x);  /* should be fabs(x) */
	printf ("x = %g |x| = %g\n", x, y);
	return 0;
}

          Compiling this function with -Wall does not produce a warning,
$> gcc -Wall wabs.c
$> ./a.out
x = -3.14 |x| = 3  (incorrect)

          but does give a warning with -Wconversion:
gcc -Wall -Wconversion wabs.c
wabs.c: In function `main':
wabs.c:8: warning: passing arg 1 of `abs' as
integer rather than floating due to prototype

          The -Wconversion option also catches errors such as the assignment of a negative value to an
          unsigned variable, as in the following code,
unsigned int x = -1;

          This is technically allowed by the ANSI/ISO C standard (with the negative integer being
          converted to a positive integer, according to the machine representation) but could be a
          simple programming error. If you need to perform such a conversion you can use an explicit
          cast, such as (unsigned int)-1, to avoid any warnings from this option. On two's-complement
          machines the cast of -1 gives the maximum number that can be represented by an unsigned
          integer.
   -Wshadow
          This option warns about the redeclaration of a variable name in a scope where it has already
          been declared. This is referred to as variable shadowing, and causes confusion about which
          occurrence of the variable corresponds to which value. The following function declares a local
          variable y that shadows the declaration in the body of the function:
double test (double x) {
	double y = 1.0;
	{
		double y;
		y = x;
	}
	return y;
}

          This is valid ANSI/ISO C, where the return value is 1. The shadowing of the variable y might
          make it seem (incorrectly) that the return value is x, when looking at the line y = x
          (especially in a large and complicated function). Shadowing can also occur for function names.
          For example, the following program attempts to define a variable sin which shadows the
          standard function sin(x).
double sin_series (double x) {
	/* series expansion for small x */
	double sin = x * (1.0 - x * x / 6.0);
	return sin;
}

          This error will be detected by the -Wshadow option.
   -Wcast-qual
          This option warns about pointers that are cast to remove a type qualifier, such as const. For
          example, the following function discards the const qualifier from its input argument, allowing
          it to be overwritten:
void f (const char * str) {
	char * s = (char *)str;
	s[0] = '\0';
}

          The modification of the original contents of str is a violation of its const property. This
          option will warn about the improper cast of the variable str which allows the string to be
          modified.
   -Wwrite-strings
          This option implicitly gives all string constants defined in the program a const qualifier,
          causing a compile-time warning if there is an attempt to overwrite them. The result of
          modifying a string constant is not defined by the ANSI/ISO standard, and the use of writable
          string constants is deprecated in GCC.
   -Wtraditional
          This option warns about parts of the code which would be interpreted differently by an
          ANSI/ISO compiler and a "traditional" pre-ANSI compiler. When maintaining legacy
          software it may be necessary to investigate whether the traditional or ANSI/ISO interpretation
          was intended in the original code for warnings generated by this option.

   The options above produce diagnostic warning messages, but allow the compilation to continue and
   produce an object file or executable. For large programs it can be desirable to catch all the
   warnings by stopping the compilation whenever a warning is generated. The -Werror option changes the
   default behavior by converting warnings into errors, stopping the compilation whenever a warning
   occurs.



---
https://www.linuxtopia.org/online_books/an_introduction_to_gcc/gccintro_32.html

3.6 Recommended warning options

   The following options are a good choice for finding problems in C and C++ programs:
$> gcc -ansi -pedantic -Wall -W -Wconversion -Wshadow -Wcast-qual -Wwrite-strings

   While this list is not exhaustive, regular use of these options will catch many common errors.



---
https://www.cs.swarthmore.edu/~newhall/unixhelp/howto_C_libraries.html

C Libraries

In general, libraries are created from many library source files, and are either built as archive files
(libmine.a) that are statically linked into executables that use them, or as shared object files (libmine.so)
that are dynamically linked into executables that use them. To link in libraries of these types, use the
gcc command line options -L for the path to the library files and -l to link in a library (a .so or a .a):

    -L{path to file containing library} -l${library name}

For example, if I have a library named libmine.so in /home/newhall/lib/ then I'd do the following to
link it into my program:

$> gcc -o myprog myprog.c  -L/home/newhall/lib -lmine

You may also need to specify and include path so the compiler can find the library header file: -I
/home/newhall/include

If you create your own shared object files and do not install them in /usr/lib, then you need to set
your LD_LIBRARY_PATH environment variable so that the runtime linker can find them and load them at
run time. For example, if I put my .so files in a directory named lib in my home directory, I'd set my
LD_LIBRARY_PATH enviroment to the following:

  # if running bash:
  export LD_LIBRARY_PATH=/home/newhall/lib:$LD_LIBRARY_PATH

  # if running tcsh:
  setenv LD_LIBRARY_PATH /home/newhall/lib:$LD_LIBRARY_PATH

USING AND LINKING LIBRARY CODE
To use a Library that is not linked into your program automatically by
the compiler, you need to (1) include the library's header file in your
C source file (test.c in the example below), and (2) tell the compiler to
link in the code from the library .o file into your executable file:

    step 1: Add an include line (#include "somelib.h") in a program
            source file (e.g., test.c).

    step 2: Link the program's .c file with the library object file
	    (i.e. specify the somelib.o file as a command line argument to gcc):

$> gcc -o myprog test.c somelib.o

    The resulting executable file (myprog) will contain machine code
    for all the functions defined in test.c plus any mylib library
    functions that are called by

CREATING AND USING YOUR OWN LIBRARY CODE
To create a Library of code you need to do the following:

    (1) Create an INTERFACE to your library: mylib.h

    (2) Create an IMPLEMENTATION of your library: mylib.c

    (3) Create a LIBRARY OBJECT FILE (.o) that can be linked with programs that use your library

    (3a) or create a SHARED OBJECT FILE (.so) from many .o files that can be dynamically linked with
    programs that use your library

    (3b) or create an ARCHIVE FILE (.a) from many .o files that can be statically linked with programs
    that use your library

    (4) USE the library in other C code: (a) #include "mylib.h" (b) link in the libary code into a.out file

    (5) Set LD_LIBRARY_PATH environment variable for finding shared objects in non-standard locations
    at runtime

Details:
    (1) INTERFACE: the header file to your library should contain definitions for everything exported
    by your library:
	function prototypes with comments for users of your library functions
	definitions for types and global variables exported by your library

    You should have "boiler plate" code (#ifndef ... #endif) around the header file's contents, to
    ensures that the preprocessor only includes the mylib.h file one time.

    Here is what an example .h file might look like:

#ifndef _MYLIB_H_
#define _MYLIB_H_

// a constant definition exported by library:
#define MAX_FOO  20

// a type definition exported by library:
struct foo_struct {
	int x;
	float y;
};
typedef struct foo_struct foo_struct;

// a global variable exported by library
// "extern" means that this is not a variable declaration, it
// just defines that a variable named total_foo of type int
// exits and you can use it (its declaration is in some library source file)
extern int total_foo;

// a function prototype for a function exported by library:
extern int foo(float y, float z);   // a very bad function name

#endif

(2) IMPLEMENTATION: create a mylib.c file that #includes "mylib.h" and contains the implementation
of every function in your library.

#include "mylib.h"

...
int total_foo;

int foo(float y, float z) {
	...
}

    (3) create a LIBRARY OBJECT FILE that can be linked into other programs that use your library (use
    the -c option to gcc to tell it just to create an object file (a .o file) rather than an executable:

$> gcc -o mylib.o -c mylib.c

    you can then use the mylib.o file as the "library file" and statically link it into other programs
    that use it, or...

    (3a) alternately, you can create a SHARED OBJECT FILE from one or more .o files that can be linked
    into other programs that use your library A shared object file is the Unix name for a dynamically
    linked library whose code is loaded into the a.out file at runtime. To create a .so file use the
    -shared flag to gcc. Here is what an example build might look like:

$> gcc -shared -o libmylib.so  mylib.o blah.o grr.o  -lm

    (3b) you could also build an ARCHIVE FILE (a statically linked library, libmylib.a) from one or more
    .o files. If you link with a static library, its code is copied into the a.out file at runtime.

    See gcc documentation for more information on how to build .a and .so files.

    (4) USE the library in other programs:

	step 1: Add an include line (#include "mylib.h") in all program source files that use library
	definitions (e.g., test.c).

	step 2: Link the program's .c file with the library object file
		(i.e. specify the mylib.o file as a command line argument to gcc):

$> gcc  test.c mylib.o

	    OR to link in libmylib.so (or libmylib.a):

$> gcc  test.c -lmylib

	    OR to link with a library not in the standard path:

$> gcc  test.c -L/home/newhall/lib -lmylib

	    The resulting a.out out will contain machine code for all the functions
	    defined in test.c plus any mylib library functions that are called by
	    the test.c code.

    (5) RUNNING an executable linked with a shared object file:

       If the shared object file in not in /usr/lib, then you need to set your
       LD_LIBRARY_PATH environment variable so that the runtime linker can find
       and load your .so file into the executable at runtime:

       # in bash:
       export LD_LIBRARY_PATH=/home/newhall/lib:$LD_LIBRARY_PATH

       # in tcsh:
       setenv LD_LIBRARY_PATH /home/newhall/lib:$LD_LIBRARY_PATH



---
https://docencia.ac.upc.edu/FIB/USO/Bibliografia/unix-c-libraries.html

Building And Using Static And Shared "C" Libraries

   One of the problems with developed programs, is that they tend to grow larger and larger, bringing up
   overall compilation and linking time to a large figure, and polluting out makefile, and the directory
   where we placed the source files. The first time a program we write reaches this state, is normally
   when we look for a different way to manage our projects.

   It is this point where we start thinking about combining out source code into small units of related
   files, that can be managed with a separate makefile, possibly by a different programmer (for a
   multi-programmer project).

What Is A "C" Library? What Is It Good For?
   One of the tools that compilers supply us with are libraries. A library is a file containing several
   object files, that can be used as a single entity in a linking phase of a program. Normally the
   library is indexed, so it is easy to find symbols (functions, variables and so on) in them. For this
   reason, linking a program whose object files are ordered in libraries is faster than linking a
   program whose object files are separate on the disk. Also, when using a library, we have fewer files
   to look for and open, which even further speeds up linking.

   Unix systems (as well as most other modern systems) allow us to create and use two kinds of libraries
   - static libraries and shared (or dynamic) libraries.

   Static libraries are just collections of object files that are linked into the program during the
   linking phase of compilation, and are not relevant during runtime. This last comment seems obvious,
   as we already know that object files are also used only during the linking phase, and are not
   required during runtime - only the program's executable file is needed in order to run the program.

   Shared libraries (also called dynamic libraries) are linked into the program in two stages. First,
   during compile time, the linker verifies that all the symbols (again, functions, variables and the
   like) required by the program, are either linked into the program, or in one of its shared libraries.
   However, the object files from the dynamic library are not inserted into the executable file.
   Instead, when the program is started, a program in the system (called a dynamic loader) checks out
   which shared libraries were linked with the program, loads them to memory, and attaches them to the
   copy of the program in memory.

   The complex phase of dynamic loading makes launching the program slightly slower, but this is a very
   insignificant drawback, that is out-weighted by a great advantage - if a second program linked with
   the same shared library is executed, it can use the same copy of the shared library, thus saving a
   lot of memory. For example, the standard "C" library is normally a shared library, and is used by all
   C programs. Yet, only one copy of the library is stored in memory at any given time. This means we
   can use far less memory to run our programs, and the executable files are much smaller, thus saving a
   lot of disk space as well.

   However, there is one drawback to this arrangement. If we re-compile the dynamic library and try to
   run a second copy of our program with the new library, we'll soon get stuck - the dynamic loader will
   find that a copy of the library is already stored in memory, and thus will attach it to our program,
   and not load the new (modified) version from disk. There are ways around this too, as we'll see in
   the last section of our discussion.

Creating A Static "C" Library Using "ar" and "ranlib"
   The basic tool used to create static libraries is a program called 'ar', for 'archiver'. This program
   can be used to create static libraries (which are actually archive files), modify object files in the
   static library, list the names of object files in the library, and so on. In order to create a static
   library, we can use a command like this:
   ar rc libutil.a util_file.o util_net.o util_math.o
   This command creates a static library named 'libutil.a' and puts copies of the object files
   "util_file.o", "util_net.o" and "util_math.o" in it. If the library file already exists, it has the
   object files added to it, or replaced, if they are newer than those inside the library. The 'c' flag
   tells ar to create the library if it doesn't already exist. The 'r' flag tells it to replace older
   object files in the library, with the new object files.

   After an archive is created, or modified, there is a need to index it. This index is later used by
   the compiler to speed up symbol-lookup inside the library, and to make sure that the order of the
   symbols in the library won't matter during compilation (this will be better understood when we take a
   deeper look at the link process at the end of this tutorial). The command used to create or update
   the index is called 'ranlib', and is invoked as follows:
   ranlib libutil.a
   On some systems, the archiver (which is not always ar) already takes care of the index, so ranlib is
   not needed (for example, when Sun's C compiler creates an archive, it is already indexed). However,
   because 'ar' and 'ranlib' are used by many makefiles for many packages, such platforms tend to supply
   a ranlib command that does nothing. This helps using the same makefile on both types of platforms.

   Note: when an archive file's index generation date (stored inside the archive file) is older than the
   file's last modification date (stored in the file system), a compiler trying to use this library will
   complain its index is out of date, and abort. There are two ways to overcome the problem:
    1. Use 'ranlib' to re-generate the index.
    2. When copying the archive file to another location, use 'cp -p', instead of only 'cp'. The '-p'
       flag tells 'cp' to keep all attributes of the file, including its access permissions, owner (if
       "cp" is invoked by a superuser) and its last modification date. This will cause the compiler to
       think the index inside the file is still updated. This method is useful for makefiles that need
       to copy the library to another directory for some reason.

Using A "C" Library In A Program
   After we created our archive, we want to use it in a program. This is done by adding the library's
   name to the list of object file names given to the linker, using a special flag, normally '-l'. Here
   is an example:
$> cc main.o -L. -lutil -o prog
   This will create a program using object file "main.o", and any symbols it requires from the "util"
   static library. Note that we omitted the "lib" prefix and the ".a" suffix when mentioning the library
   on the link command. The linker attaches these parts back to the name of the library to create a name
   of a file to look for. Note also the usage of the '-L' flag - this flag tells the linker that
   libraries might be found in the given directory ('.', refering to the current directory), in addition
   to the standard locations where the compiler looks for system libraries.

   For an example of program that uses a static library, try looking at our static library example
   directory.

Creating A Shared "C" Library Using "ld"
   The creation of a shared library is rather similar to the creation of a static library. Compile a
   list of object files, then insert them all into a shared library file. However, there are two major
   differences:
    1. Compile for "Position Independent Code" (PIC) - When the object files are generated, we have no
       idea where in memory they will be inserted in a program that will use them. Many different
       programs may use the same library, and each load it into a different memory in address. Thus, we
       need that all jump calls ("goto", in assembly speak) and subroutine calls will use relative
       addresses, and not absolute addresses. Thus, we need to use a compiler flag that will cause this
       type of code to be generated.
       In most compilers, this is done by specifying '-fPIC' or '-fpic' on the compilation command.
    2. Library File Creation - unlike a static library, a shared library is not an archive file. It has
       a format that is specific to the architecture for which it is being created. Thus, we need to use
       the compiler (either the compiler's driver, or its linker) to generate the library, and tell it
       that it should create a shared library, not a final program file.
       This is done by using the '-G' flag with some compilers, or the '-shared' flag with other
       compilers.

   Thus, the set of commands we will use to create a shared library, would be something like this:
$> cc -fPIC -c util_file.c
$> cc -fPIC -c util_net.c
$> cc -fPIC -c util_math.c
$> cc -shared libutil.so util_file.o util_net.o util_math.o

   The first three commands compile the source files with the PIC option, so they will be suitable for
   use in a shared library (they may still be used in a program directly, even thought they were
   compiled with PIC). The last command asks the compiler to generate a shared library

Using A Shared "C" Library - Quirks And Solutions
   Using a shared library is done in two steps:
    1. Compile Time - here we need to tell the linker to scan the shared library while building the
       executable program, so it will be convinced that no symbols are missing. It will not really take
       the object files from the shared library and insert them into the program.
    2. Run Time - when we run the program, we need to tell the system's dynamic loader (the process in
       charge of automatically loading and linking shared libraries into the running process) where to
       find our shared library.

   The compilation part is easy. It is done almost the same as when linking with static libraries:
   cc main.o -L. -lutil -o prog
   The linker will look for the file 'libutil.so' (-lutil) in the current directory (-L.), and link it
   to the program, but will not place its object files inside the resulting executable file, 'prog'.

   The run-time part is a little trickier. Normally, the system's dynamic loader looks for shared
   libraries in some system specified directories (such as /lib, /usr/lib, /usr/X11/lib and so on). When
   we build a new shared library that is not part of the system, we can use the 'LD_LIBRARY_PATH'
   environment variable to tell the dynamic loader to look in other directories. The way to do that
   depends on the type of shell we use ('tcsh' and 'csh', versus 'sh', 'bash', 'ksh' and similar
   shells), as well as on whether or not 'LD_LIBRARY_PATH' is already defined. To check if you have this
   variable defined, try:
   echo $LD_LIBRARY_PATH
   If you get a message such as 'LD_LIBRARY_PATH: Undefined variable.', then it is not defined.

   Here is how to define this variable, in all four cases:
    1. 'tcsh' or 'csh', LD_LIBRARY_PATH is not defined:
    setenv LD_LIBRARY_PATH /full/path/to/library/directory

    2. 'tcsh' or 'csh', LD_LIBRARY_PATH already defined:
    setenv LD_LIBRARY_PATH /full/path/to/library/directory:${LD_LIBRARY_PATH}

    3. 'sh', 'bash' and similar, LD_LIBRARY_PATH is not defined:
    LD_LIBRARY_PATH=/full/path/to/library/directory
    export LD_LIBRARY_PATH

    4. 'sh', 'bash' and similar, LD_LIBRARY_PATH already defined:
    LD_LIBRARY_PATH=/full/path/to/library/directory:${LD_LIBRARY_PATH}
    export LD_LIBRARY_PATH

   After you've defined LD_LIBRARY_PATH, you can check if the system locates the library properly for a
   given program linked with this library:
$> ldd prog

   You will get a few lines, each listing a library name on the left, and a full path to the library on
   the right. If a library is not found in any of the system default directories, or the directories
   mentioned in 'LD_LIBRARY_PATH', you will get a 'library not found' message. In such a case, verify
   that you properly defined the path to the directory inside 'LD_LIBRARY_PATH', and fix it, if
   necessary. If all goes well, you can run your program now like running any other program, and see it
   role...

   For an example of a program that uses a shared library, try looking at our shared library example
   directory.

  Using A Shared "C" Library Dynamically - Programming Interface
   One of the less-commonly used feature of shared libraries is the ability to link them to a process
   anytime during its life. The linking method we showed earlier makes the shared library automatically
   loaded by the dynamic loader of the system. Yet, it is possible to make a linking operation at any
   other time, using the 'dl' library. This library provides us with a means to load a shared library,
   reference any of its symbols, call any of its functions, and finally detach it from the process when
   no longer needed.

   Here is a scenario where this might be appealing: suppose that we wrote an application that needs to
   be able to read files created by different word processors. Normally, our program might need to be
   able to read tens of different file formats, but in a single run, it is likely that only one or two
   such document formats will be needed. We could write one shared library for each such format, all
   having the same interface (readfile and writefile for example), and one piece of code that determines
   the file format. Thus, when our program is asked to open such a file, it will first determine its
   format, then load the relevant shared library that can read and translate that format, and call its
   readfile function to read the document. We might have tens of such libraries, but only one of them
   will be placed in memory at any given time, making our application use less system resources. It will
   also allow us to ship the application with a small set of supported file formats, and add new file
   formats without the need to replace the whole application, by simply sending the client an additional
   set of shared libraries.

  Loading A Shared Library Using dlopen()
   In order to open and load the shared library, one should use the dlopen() function. It is used this
   way:
#include <dlfcn.h>    /* defines dlopen(), etc.    */
.
.
void* lib_handle;    /* handle of the opened library */

lib_handle = dlopen("/full/path/to/library", RTLD_LAZY);
if (!lib_handle) {
	fprintf(stderr, "Error during dlopen(): %s\n", dlerror());
	exit(1);
}

   The dlopen() function gets two parameters. One is the full path to the shared library. The other is a
   flag defining whether all symbols refered to by the library need to be checked immediatly, or only
   when used. In our case, we may use the lazy approach (RTLD_LAZY) of checking only when used. The
   function returns a pointer to the loaded library, that may later be used to reference symbols in the
   library. It will return NULL in case an error occured. In that case, we may use the dlerror()
   function to print out a human-readable error message, as we did here.

Calling Functions Dynamically Using dlsym()
   After we have a handle to a loaded shared library, we can find symbols in it, of both functions and
   variables. We need to define their types properly, and we need to make sure we made no mistakes. The
   compiler won't be able to check those declarations, so we should be extra carefull when typing them.
   Here is how to find the address of a function named 'readfile' that gets one string parameter, and
   returns a pointer to a 'struct local_file' structure:

/* first define a function pointer variable to hold the function's address */
struct local_file* (*readfile)(const char* file_path);
/* then define a pointer to a possible error string */
const char* error_msg;
/* finally, define a pointer to the returned file */
struct local_file* a_file;

/* now locate the 'readfile' function in the library */
readfile = dlsym(lib_handle, "readfile");

/* check that no error occured */
error_msg = dlerror();
if (error_msg) {
	fprintf(stderr, "Error locating 'readfile' - %s\n", error_msg);
	exit(1);
}

/* finally, call the function, with a given file path */
a_file = (*readfile)("hello.txt");

   As you can see, errors might occur anywhere along the code, so we should be carefull to make
   extensive error checking. Surely, you'll also check that 'a_file' is not NULL, after you call your
   function.

Unloading A Shared Library Using dlclose()
   The final step is to close down the library, to free the memory it occupies. This should only be done
   if we are not intending to use it soon. If we do - it is better to leave it open, since library
   loading takes time. To close down the library, we use something like this:
   dlclose(lib_handle);
   This will free down all resources taken by the library (in particular, the memory its executable code
   takes up).

Automatic Startup And Cleanup Functions
   Finally, the dynamic loading library gives us the option of defining two special functions in each
   library, namely _init and _fini. The _init function, if found, is invoked automatically when the
   library is opened, and before dlopen() returns. It may be used to invoke some startup code needed to
   initialize data structures used by the library, read configuration files, and so on.

   The _fini function is called when the library is closed using dlclose(). It may be used to make
   cleanup operations required by the library (freeing data structures, closing files, etc.).

   For an example of a program that uses the 'dl' interface, try looking at our dynamic-shared
   library example directory.

Getting a Deeper Understanding - The Complete Linking Story

  The Importance Of Linking Order

   In order to fully understand the way linking is done, and be able to overcome linking problems, we
   should bare in mind that the order in which we present the object files and the libraries to the
   linker, is the order in which the linker links them into the resulting binary file.

   The linker checks each file in turn. If it is an object file, it is being placed fully into the
   executable file. If it is a library, the linker checks to see if any symbols referenced (i.e. used)
   in the previous object files but not defined (i.e. contained) in them, are in the library. If such a
   symbol is found, the whole object file from the library that contains the symbol - is being added to
   the executable file. This process continues until all object files and libraries on the command line
   were processed.

   This process means that if library 'A' uses symbols in library 'B', then library 'A' has to appear on
   the link command before library 'B'. Otherwise, symbols might be missing - the linker never turns
   back to libraries it has already processed. If library 'B' also uses symbols found in library 'A' -
   then the only way to assure successful linking is to mention library 'A' on the link command again
   after library 'B', like this:
   $(LD) ....... -lA -lB -lA
   This means that linking will be slower (library 'A' will be processed twice). This also hints that
   one should try not to have such mutual dependencies between two libraries. If you have such
   dependencies - then either re-design your libraries' contents, or combine the two libraries into one
   larger library.

   Note that object files found on the command line are always fully included in the executable file, so
   the order of mentioning them does not really matter. Thus, a good rule is to always mention the
   libraries after all object files.

Static Linking Vs. Dynamic Linking
   When we discussed static libraries we said that the linker will try to look for a file named
   'libutil.a'. We lied. Before looking for such a file, it will look for a file named 'libutil.so' - as
   a shared library. Only if it cannot find a shared library, will it look for 'libutil.a' as a static
   library. Thus, if we have created two copies of the library, one static and one shared, the shared
   will be preferred. This can be overridden using some linker flags ('-Wl,static' with some linkers,
   '-Bstatic' with other types of linkers. refer to the compiler's or the linker's manual for info about
   these flags).




---
https://www.cs.helsinki.fi/u/kuuppelo/C/S2009/c-sdl-demo/demo.html

Short introduction to use of external libraries
   This tutorial will show how to use external libraries within your code. We will create an
   application, that creates a window and draws sinc pulse into it. To create the window and the
   drawing we use library called SDL (Simple DirectMedia Layer). Our focus is not to completely
   explain how this library works, rather to show how the use of external libraries is done in general.

   To begin with we create sinc.c module, which is used to calculate the values of sinc function as
   parameter of time. We need to import math.h to use the sin function.

   sinc.h

<code>
#ifndef SINC_H
#define SINC_H

#include <math.h>

float sinc(float t);

#endif
</code>


   sinc.c

<code>
#include "sinc.h"
#define SINC_PI "3.14159265"

float sinc(float t) {
	if (!t) {
		return 1;
	}
	return sin(SINC_PI * t) / (SINC_PI * t);
}
</code>


     To compile

$> gcc -c sinc.c -Wall -Wextra -std=c99 // ( 1


     ( 1 If you are compiling with --std=c99 you need to define constant for pi by yourself

   Drawsinc module will initialize the SDL library, create the window, update framebuffer (ie. draw sinc
   pulse into it), process events, update the window (so that the sinc pulse is actually drawn) and
   finally call the exit handler of the library.

   drawsinc.h

<code>
#ifndef DRAWSINC_H
#define DRAWSINC_H

#include <stdlib.h>
#include <stdio.h>
#include <SDL.h>

#define SCREEN_WIDTH 640
#define SCREEN_HEIGHT 480
#define COLOR_DEPTH 32

void put_pixel( SDL_Surface *surface, int x, int y, int color );
void draw_sinc(SDL_Surface *screen, int screen_width, int screen_height);

#endif
</code>

   In header file drawsinc.h we include header files from standard library (stdlib.h, stdio.h) and one
   header file from SDL library (SDL.h). This allows us to use data types defined in SDL library (such
   SDL_Surface).

   drawsinc.c

<code>
#include "sinc.h"
#include "drawsinc.h"

void put_pixel( SDL_Surface *surface, int x, int y, int color ) {
	if (x < 0 || x > SCREEN_WIDTH)
		return;
	if (y < 0 || y > SCREEN_HEIGHT)
		return;
	unsigned int *pixels = (unsigned int *)surface->pixels;
	int lineoffset = y * (surface->pitch / 4);
	pixels[ lineoffset + x ] = color;
}

void draw_sinc(SDL_Surface *screen, int screen_width, int screen_height) {
	int x;

	for (x=0; x<screen_width; x++) {
		float sincvalue = 100*sinc(((float)(x - (screen_width / 2)))/10.0);
		put_pixel(screen, x, screen_height / 2 + -1 * sincvalue, 0x00ff00);
	}
}

int main(int argc, char *argv[]) {
	int running = 1;
	int flags = SDL_SWSURFACE;
	SDL_Surface *screen;
	SDL_Event event;
	SDL_Init(SDL_INIT_EVERYTHING);
	screen = SDL_SetVideoMode(SCREEN_WIDTH, SCREEN_HEIGHT, COLOR_DEPTH, flags);
	while (running) {
		while (SDL_PollEvent(&event)) {
			switch(event.type) {
				case SDL_KEYDOWN:
				case SDL_QUIT:
					running = 0;
					break;
				default:
					break;
			}
		}
	draw_sinc(screen, SCREEN_WIDTH, SCREEN_HEIGHT);
	SDL_Flip(screen);
	}
	SDL_Quit();
	return EXIT_SUCCESS;
}
</code>

   Some libraries require initialization before they can be used. That is the with SDL too, so in main
   function after the variable declarations we call function SDL_Init. Function definition is visible
   here, because we introduced it with other standard SDL functions when we included header file SDL.h.

   Precompiler is able to find all standard header files without any help from developer. These are
   usually located in /usr/include directory (such as /usr/include/stdlib.h). When using other libraries
   you most often need to tell to precompiler where to find required header files. GCC for example has
   handle "-I <path>", where path is directory where these header files are located.

   Compiler is able to finish its job with the information (function prototypes, data types, ...) it got
   from header files. But to create executable, we need to tell linker where to find the actual bodies
   for these library functions. GCC expects to find these from file starting with string "lib", so to
   link the executable with SDL library we give "-l SDL" handle to GCC. We can also specify the
   directory from where to search this library file with "-L <path>" handle.

   Some libraries also provide binaries to ease the compilation. SDL for example is distributed with
   application "sdl-config", which can find the compiler handles required to compile the application
   with SDL.

     To compile

$> gcc -c drawsinc.c -I /usr/include/SDL -Wall -Wextra -std=c99
     or
$> gcc -c drawsinc.c `sdl-config --cflags` -Wall -Wextra -std=c99


$> gcc -o drawsinc sinc.o drawsinc.o -lm -lSDL -L /usr/lib
     or
$> gcc -o drawsinc sinc.o drawsinc.o -lm `sdl-config --libs`



---
https://github.com/modelica/ModelicaSpecification/issues/1316

Naming of external libraries in Windows built with compilers other than Visual Studio

Hi, the specs says we should follow this structure:

ExternalFunctions
package.mo // contains the Modelica code from above

Resources
Include // contains the include files
	ExternalFunc1.h // C-header file
	ExternalFunc2.h // C-header file
	ExternalFunc3.c // C-source file
Library // contains the object libraries for different platforms
	win32
		ExternalLib1.lib // static link library for VisualStudio
		ExternalLib2.lib // statically linking the dynamic link library
		ExternalLib2.dll // dynamic link library (with manifest)
	linux32
		libExternalLib1.a // static link library
		libExternalLib2.so // shared library

   However, Windows is not restricted to Visual Studio. OpenModelica uses MinGW gcc to compile code and I
   guess other tools do the same.

   How should the library name should be mapped for other compilers than Visual Studio?

   If we don't specify it and leave it for the tools to handle it as they want then most certainly one
   will run into incompatibilities between tools.

   Any suggestions? I would go with:
   libExternalName1.a
   for MinGW gcc.

***
   Comment by beutlich on 9 Oct 2013 20:42 UTC
   Platform name or library extension is not the best choice to distinguish the external libs. Even on
   Windows C++ libs from Visual Studio 2005/2008 and Visual Studio 2010 are not compatible.
   I remember Matlab installations (on Windows) where they have subdirectories with precompiled libs for
   every supported compiler. So there should be win32\vc7, win32\vc8 etc, win32\borland, win32\lcc etc.
   I guess MinGW and Cygwin static link libraries are also not compatible. And I am also not sure about
   different versions of GCC.

***
   Here is what I meant. Precompiled libs are always compiler dependent.

***
   You're right, even combining different compiler versions of libs is a recipe for disaster.
   We should probably go for something like you propose, have compiler names in there.
   From my side I think is a good proposal.

***
     Platform name or library extension is not the best choice to distinguish the external libs. Even
     on Windows C++ libs from Visual Studio 2005/2008 and Visual Studio 2010 are not compatible.

   I would say it depends.

   If using C functions it is backwards compatible; with some exceptions that can be avoided.
   If using C++ (and C++ standard classes) VS 2008 is in my experience compatible with 2005; but 2005,
   2010 and 2012 are different. It could be that there are specific cases that differ between 2005 and
   2008; and it could be that some C++ classes are compatible between other versions.

   So having both common parts for all versions and version-specific sub-libraries as indicated by
   Beutlich would be one solution that handles both cases without unnecessary duplication.

   The problem is exactly how to handle VS 2005/VS 2008 and also bug-fixed for compilers (I believe
   those have sometimes caused issues if linking with an older version); i.e. defining which versions
   are relevant. One solution would be to just standarize on a rough sub-directory naming scheme and
   then leave the rest up to the vendors (for now).

   There are also different ways of linking the libraries - causing additional issues.

***
   Different versions of used standard libraries can also cause problems. For Visual Studio we have seen
   such problems with the same Visual Studio release, but different service packs applied.

***
   The same issue exists w.r.t. linux64 vs. x86_64-pc-linux-gnu

***
   I suggest adding compiler and version to the platform directories, as "platform/compiler/version"
   (e.g. "win32/GCC/4.7"). Library files would then be placed in the directory corresponding to the
   compiler they were built with.

   For backward compatibility, the old behavior would be used as a fallback.

***
   Is there any canonical source for these names (i.e. "GCC" vs. "gcc" vs. GNUCC", since otherwise we
   would have to maintain such a (long) list ourselves)? Preferably some macro, a compiler has to define
   to identify itself?

***
   There isn't any standardized macro, see e.g. https://sourceforge.net/p/predef/wiki/Compilers/.

***
   uname -m -o comes close to being some sort of thing specifying platform/CPU. I would suggest instead
   specifying how to define projects for the source code and letting the Modelica tool vendors deal with
   compiling C-code to its expected form since there are simply too many variants of code that one needs
   to compile for (different versions of MinGW are not compatible with each other, etc).

***
   That does not cover proprietary code where you do not want to distribute the source code. For
   Modelon's use case, we would only need to consider the limited number of compiler versions used by
   the tools that we release our libraries for. So you would need both the project/build system thing
   and a way to specify precompiled libraries for different compiler versions to cover all use cases,
   and both are useful each on their own.

***
     uname -m -o comes close to being some sort of thing specifying platform/CPU.

   I see that Jesper Mattsson answered, but wanted to address another issue:

   The platform does not define the compiler version (especially the compatibility for C++ code of
   Visual Studio need more, and then there is win32 vs. win64), and the uname I have does not support
   "-o".

   Note that there are usually multiple identifications for compilers:
   E.g. Visual Studio 2012 is version 11.0.(something build something) and _MSC_VER is 1700.

   That is in general a mess, and the macro name is the least useful for libraries, and the official
   name (VS 2012) seems good enough and most understandable for users, reducing the risk - even if there
   is always the risk that they change that numbering.

   There are also compilers that "compatible" with others (LLVM vs. gcc).

***
   Looking at the history of compilers I am not sure that we need the intermediate level, or should just
   have the current "win32"/"win64"/"linux32" directories and then gcc47, vs2012 etc.

   As in other industries it is also a bit of a mess, two cases to consider:
   The macro list contains LCC, there was also another LCC - Lattice C that some of us remember (it
   later became MS C Ver. 2, and then SAS/C).
   The Borland C++ compiler seems to have become C++Builder and then Clang-based for win64.
   I am sure others can add more.
   --
   But I also believe that the actual market is mostly focused on a smaller sub-set - especially for
   link-compatibility (with Gcc (and Clang is mostly compatible) and Visual Studio).

   Note that Matlab's list is slightly different. They control the list of compilers and versions,
   whereas we here have to consider a combination of different library suppliers and Modelica tools.

***
   The "win32"/"win64" directories may contain "gcc47", "vs2010", "vs2012" for specific versions of
   these compilers and these are used instead of the general "win32"/"win64" directories, and similarly
   for other platforms.
   If the directory for the specific compiler version is missing the platform specific directory is
   used. [A tool may give diagnostics if the directory corresponding to the selected compiler version is
   missing.]

   Poll:
   Favor: 9
   Against: 0
   Abstain: 8

   The directories may use symbolic links - or use a text-file as described below:
   e.g a text-file "vs2008" containing the text "../win32/vs2005" (or "vs2005") suggesting that it is
   compatible with vs2005.

   As normative text: 3
   As a comment: 5
   Not at all: 1

   Conclusion:
   The "win32"/"win64" directories may contain "gcc47", "vs2010", "vs2012" for specific versions of
   these compilers and these are used instead of the general "win32"/"win64" directories, and similarly
   for other platforms.

   If the directory for the specific compiler version is missing the platform specific directory is
   used. [A tool may give diagnostics if the directory corresponding to the selected compiler version is
   missing. The directories may use symbolic links - or use a text-file as described below:
   e.g a text-file "vs2008" containing the text "../win32/vs2005" (or "vs2005") suggesting that it is
   compatible with vs2005.]

***
   How to distinguish between, for example, GCC 4.7 on Win32 for MinGW or Cygwin then if win32/gcc47 is
   used as library directory?

***
   The OS is not win32, but for example msys2-win32 or cygwin-win32, I guess... But should probably be
   specified.



---

