filename: c-generational-references-20250801.txt
https://verdagon.dev/blog/generational-references

Memory Safety Strategy: Generational References and Regions
Updated July 9 2023 

Generational references are a memory management technique, an alternative to reference counting, tracing
garbage collection, or borrow checking.

In this technique, every reference remembers the ID ("generation") of the object it's pointing at.

If the user dereferences an object and Vale isn't certain it's still alive, it will insert a run-time check
that the reference's generation matches the object's generation.

We can safely skip these checks with static analysis, "linear style", or regions.

This article explains:
  * What a generation is.
  * How generational references work.
  * How linear style, static analysis, and regions make them faster.
  * How they all work together to form Vale's memory safety approach.

Memory Safety Strategy: Generational References and Regions
  * Generational References
  * Generational References are Fast
  * Skipping checks with single ownership
  * Linear Style: Moving data to skip checks
  * Skipping checks with regions
  * Blending linear style, regions, and generational references
  * How do we put data in other objects?
  * Pre-checking
  * Random Generational References
  * Hidden Benefits
  * Summary
  * Appendix: "Generation Tables" Option

In a way, it's like we're applying the generational indices technique to an entire programming language.

Generational References
Here's an explanation of the most basic kind of generational references. We'll add the more complex bits
further below, but this should be a useful stepping stone.

In C, whenever we allocate a struct on the heap, malloc remembers that that location is "in use". Until we 
free it, nobody else can allocate something there.

You could imagine that it internally has a bunch of Allocation structs, like this.

struct Allocation {
	bool currentlyInUse;
	char allocationBytes[];
};

By making a slight adjustment here, we can create a system that helps our programs' memory safety.

Let's add a
uint64_t currentGeneration; to it.

It starts at zero, and we increment it every time we allocate something to this spot in memory.

struct Allocation {
	bool currentlyInUse;
	uint64_t currentGeneration;
	char allocationBytes[];
};

Now, instead of malloc returning a void*, let's make a gmalloc that returns a "generational reference".
A generational reference is simply a pointer with a "remembered generation" number next to it.
Our codebase will use gmalloc instead of malloc, and use generational references instead of raw pointers.
gmalloc increments currentGeneration every time we allocate anything, and we would also have a gfree that
increments it whenever we free something.

struct GenerationalReference {
	void* alloc;
	uint64_t rememberedGeneration;
};

GenerationalReference gmalloc(int size) {
	// Find an Allocation not currentlyInUse.
	// Increment its currentGeneration.
	// Return it.
}

Now, to make our program memory-safe, we always follow the rule: always call __check before dereferencing a
generational reference.

Before:

struct Spaceship {
	int numWings;
};

int main() {
	Spaceship* ship = (Spaceship*)malloc(sizeof(Spaceship));

	// Set ship's numWings to 2
	ship->numWings = 2;
}

After:

struct Spaceship {
	int health;
	int numWings;
};

int main() {
	GenerationalReference shipRef = gmalloc(sizeof(Spaceship));

	// Set ship's numWings to 2
	__check(shipRef);
	((Ship*)shipRef.alloc)->numWings = 2;
}

That __check function looks at the 8 bytes above the object (at Allocation's currentGeneration), and make
sure that it matches the generational reference's rememberedGeneration. It could look something like this:

void __check(GenerationalReference genRef) {
	uint64_t currentGeneration = *(uint64_t*)((char*)genRef.alloc - 8);
	assert(genRef.rememberedGeneration == currentGeneration);
}

It's as if we're saying:
"Hello! I'm looking for the 11th inhabitant of this house, are they still around?"

and the person who opens the door says:
"No, sorry, I'm the 12th inhabitant of this house, the 11th inhabitant is no more."

or instead:
"Yes! That is me. Feel free to dereference!"

Here's the magical part: if we always call __check before dereferencing, then our code will be memory-safe.

Some extra details:
  * All these structs are on the heap. Further below we'll talk about how we can put data on the stack.
  * When a generation hits INT_MAX, we retire that spot and never allocate to it again.
  * The above __check uses assert, but we actually just manually raise a segmentation fault because it's
    faster.

Now, let's talk about speed!
The actual malloc uses a much faster and more interesting system than the one described here.

This is similar to the "generational indices" technique from C++ and Rust, but applied to the entire world
instead of just a specific vector.


How do we put data in other objects?
The main benefit of single ownership is that it allows us to embed a struct inside another struct, or a
struct inside an array. How do we do that with generational references?

Recall our __check function from before, and notice the hardcoded:

void __check(GenerationalReference genRef) {
	uint64_t currentGeneration = *(uint64_t*)((char*)genRef.allocation - 8);
	assert(genRef.rememberedGeneration == currentGeneration);
}

Instead of that, we're going to subtract a tiny offset-to-generation number that we put in the top byte of
the genRef.allocation pointer.

This will point us to the generation of the containing struct.

With this, our __check function becomes this:

void __check(GenerationalReference genRef) {
	uint8_t offsetToGen = genRef.allocation >> 56;
	uint64_t currentGeneration = *(uint64_t*)((char*)genRef.allocation - offsetToGen);
	assert(genRef.rememberedGeneration == currentGeneration);
}

Our __check function just went from 4 instructions to 5 (or 6 for certain CPUs 15). This isn't that much,
especially considering we eliminate most generation checks with linear style and regions. For that low price,
we can now embed structs in other structs.

This gives us more control over the layout of our data, which helps make our programs more cache-friendly.

Technically, we don't need single ownership for this. Languages like C# allow us to put value types (such as 
structs) directly inside classes and arrays. The real trick is whether we can take a reference to that
embedded data.

Note that the offset-to-generation number can only fit in a single byte, which means that if a struct is more
than 256 bytes wide, it will need another generation number inside it.

It's 5 instructions assuming we have top-byte ignore or the upcoming linear address masking. If we don't
it'll be 6 instructions as we add a bitwise-and to mask off those top 8 bits before we subtract.

Pre-checking
When the compiler is certain data won't change (such as when we're using immutable region borrowing), we can
"pre-check" our generational references once beforehand to skip a lot of checks later.

Here's a sample implementation of __precheck, which returns address 0 if the pre-check fails:

void *__precheck(GenerationalReference genRef) {
	uint64_t currentGeneration = *(uint64_t*)((char*)genRef.allocation - 8);
	return (genRef.rememberedGeneration == currentGeneration) * genRef.allocation;
}

Later, if the user tries to access a reference that failed its __precheck, the program will safely raise a
fault, similar to when a normal __check fails.

In the example above, we turned 200 __checks into just 1 __precheck.

That's the power of region borrowing!

On webassembly and specialized processors where 0 is a valid address, we would use e.g. INTPTR_MAX instead.
On even more specialized processors that don't fault when accessing invalid addresses, we wouldn't be able to
use pre-checking.

Fun fact: region borrowing can also be applied to a language that uses reference counting, to eliminate the
vast majority of increments and decrements. As far as I know, nobody has attempted this yet, but I think this
could single-handedly make RC competitive with GC again.

Random Generational References
This is where the scheme gets interesting, involving security, statistics, sorcery, and pragmatism. (Special
thanks to hc for this next key insight!)

Instead of remembering and incrementing an allocation's generation, we can just use a pseudo-random number
instead.

Whenever we put a struct on the stack, we just conjure up a pseudo-random number and put it above the struct.

And whenever the struct disappears, we overwrite the generation with a zero, so that later __checks on it
will fail.

This also has other benefits:
  * The language has to do less work!
  * The object can live on the stack, inside other objects, directly inside arrays, or even inside custom
    allocators.
  * We can use the regular malloc instead of the gmalloc we invented above.
  * We can reuse a specific spot in memory as many times as we want.
  * We're able to release memory back to the OS, in environments with virtual memory.

This is a very strong stochastic approach, similar to how passwords work.

It does have a theoretical downside. For example, if we have an invalid access in our server code that's
causing (worst case) six million loud errors a second and we decide to ignore it, then after 73,250 years
on average it could reuse the same generation as something that was there before, in which case the invalid
access bug could cause some unsafety.

Those well-versed in statistics will recognize that this isn't really a problem, but let's explore it a
little.

The odds of an invalid access happening undetected is always 1/2^64 for a 64-bit generation.

  * The odds don't change with the number of live objects.
  * The odds don't change with the how long the program's been running.
  * The odds don't change with the the number of objects that have lived in that particular location.
  * The odds don't change with the the number of previous generation check failures, because the first one
    brings down the entire process.

It also helps to keep in mind that these probabilities only apply to the error detection mechanism, not to
the program itself.

One of my beta readers asked:
"How does this compare to Rust? It seems like the probabilistic detection wouldn't be as good."

That would be true, except that most Rust programs use unsafe or have it in their dependencies, even when you
don't count the standard library.

When someone uses unsafe to get around the borrow checker's restrictions, even if they think really hard
about unsafe's more arcane interactions, bugs can remain hidden for a long time, stealthily causing undefined
behavior in the unsafe block and in the safe code around it.

We'd similarly use random generational references to get around the restrictions of linear style, and
fortunately, any invalid accesses are detected very loudly as a check failure brings down the entire program.
Bugs are discovered very quickly, instead of causing mysterious behavior for years.

Vale's design also goes one step further and replaces unsafe with a "skip-check dereference" operator to skip
__checks in release mode. The major benefit is that the compiler ignores these in dependencies by default, so
we no longer have to trust that our dependencies used unsafety well.

So it's better in some ways, worse in others. It's just a different approach.

If you've ever heard of Arm's memory tagging, this is like that but with a wider tag.

This pseudo-random number generator doesn't have to be that sophisticated. The most basic implementation
could be a simple global integer that we increment on every use, or we could do more interesting things like
periodically randomize it, shuffle it, or add prime numbers to it.

When destroying an object, overwriting a generation with zero is faster than incrementing what was there
before. Also, we don't have to check for overflow when a generation number hits 2^64.

This relies on the OS detecting accesses to released memory and raising segmentation faults.

We can still release memory to the OS, but we remap the virtual address space to a single shared page,
preferably read-only and filled with zeroes. This lets us not trigger a fault on __prechecks.

Given a 64 bit generation, it will take an average of 13 quintillion tries to trigger a false negative.

If there's only one failure per second, it's 439 billion years on average to cause unsafety.

If there's only one failure per week, it would take 266 quadrillion years on average to cause unsafety.

If there's six million check failures per second (the largest DDoS in history), it's 73,250 years on average
to cause any unsafety.

Comfortable odds, I'd say!

Hidden Benefits
Generational references and regions also enable some pretty amazing new features:

  * Seamless Concurrency: Since regions don't require any data coloring (like Sync/Send) or function coloring
    (like async or ?async) we can use structured concurrency without refactoring the surrounding program.
  * Perfect replayability: Since generational references don't require nondeterministic collection, Vale was
    designed to replay a past run of the program to perfectly reproduce any error.
  * Higher RAII: Vale's type system can use ownership to ensure that we don't forget to call a function at
    some point in the future, and its destructors can take in arguments and return values.

There are also a few more features that regions will enable, involving concurrency, transactions, and unique
security benefits. They're a little too early in the design phases to explain here, but stay tuned!

Summary
Generational references and regions are a pretty promising combination with a lot of benefits:

  * Easy to use, especially for anyone coming from more complex languages like C++ or Rust.
  * They let us choose which parts of our code should be simple, and which should be optimized further.
  * They enable a lot of interesting new features, like Seamless Concurrency, Perfect replayability, and
    Higher RAII.

There are some downsides, as with any memory safety paradigm:
  * It occasionally adds an 8-byte generation number to the top of allocations.
  * Most pointers will only be 8 bytes, 24 but some will have an additional 8-byte generation with them.
  * There will be __checks at run-time, unless the programmer chooses to optimize them away.

But overall, the technique looks very promising, and feels pretty good to use.


---

