filename: go_modules_directory_layout-multif_20200128.txt
https://stackoverflow.com/questions/55442878/organize-local-code-in-packages-using-go-modules

Organize local code in packages using Go modules

   I can not find a way to factor out some code from main.go into a local package when using Go modules
   (go version >= 1.11) outside of $GOPATH.

   I am not importing any external dependencies that need to be included into go.mod, I am just trying
   to organize locally the source code of this Go module.

   The file main.go:
package main

// this import does not work
import "./stuff"

func main() {
    stuff.PrintBaz()
}

   The file ./stuff/bar.go (pretending to be a local package):
package stuff

import "log"

type Bar struct {
    Baz int
}

func PrintBaz() {
    baz := Bar{42}
    log.Printf("Bar struct: %v", baz)
}

   The file go.mod (command go mod init foo):
module foo

go 1.12

   When executing go run main.go:
     * If I import "./stuff", then I see build command-line-arguments: cannot find module for path
       _/home/<PATH_TO>/fooprj/stuff.
     * If I import "stuff", then I see build command-line-arguments: cannot load stuff: cannot find
       module providing package stuff.
     * If I import stuff "./stuff" with a package alias, then I see again: build command-line-arguments:
       cannot find module for path _/home/<PATH_TO>/fooprj/stuff.

   I can not find a way to make local packages work with go modules.
     * What's wrong with the code above?
     * How can I import local packages into other Go code inside a project defined with Go modules (file
       go.mod)?

***
   First you have to choose a name for your project and write it to go.mod file. This name belongs to
   root directory of the project. Each new package you create must be located inside it's own
   subdirectory and its name should match directory name.

   go.mod:
module myprojectname

   or (preferred way, see @typical182's comment for details)
module github.com/myname/myproject

   Then import your project's packages like:
import myprojectname/stuff

   or
import github.com/myname/myproject/stuff

   Files of package stuff should be located inside project's stuff directory. You name these files as
   you like.

   Also it's possible to create deeper project structure. For instance, you decided to separate source
   code files from other ones (like app configs, docker files, static files, etc...). Let's move stuff
   directory inside pkg, every go file inside pkg/stuff still have stuff package name. To import stuff
   package just write:
import myprojectname/pkg/stuff

   Nothing stops you from creating more levels in the hierarchy like
   github.com/myuser/myproject/pkg/db/provider/postgresql, where:
     * github.com/myuser/myproject - project name.
     * postgresql - package name.
     * pkg/db/provider/postgresql - path to the package relative to project's root.

   You can read more about go modules here: https://github.com/golang/go/wiki/Modules

   Check out this repository to get useful information about various patterns used in project
   organizing: https://github.com/golang-standards/project-layout If you go inside pkg directory you
   will find out which open source projects use pkg directory in their structure.

***
     * Do you normally have your go.mod, go.sum, and main.go files in the root directory of your repo?
       - dmigo Jun 20 '19 at 14:16
     * go.mod and go.sum - yes. main.go is entry point to your program. If you have single entry point
       just place it in root directory, otherwise check cmd directory README.md file in
       github.com/golang-standards/project-layout - Vadim Ashikhman Jun 21 '19 at 20:54
     * Is the layout provided in the repo still way to go? Don't go modules change that? - dmigo Jun
       25 '19 at 16:21
     * Go modules do not define project layout structure, you can use go modules with any layout of your
       choice. You can read more about go modules here github.com/golang/go/wiki/Modules#modules
       - Vadim Ashikhman Jun 26 '19 at 10:43
     * 1
       Defining your module in the go.mod as module myprojectname (instead of module
       github.com/myname/myproject) is a bit dangerous, and will most likely fail later in a way that
       surprises you. It is almost always better to use the full path including a hostname of where you
       intend to publish it eventually, or pick as hostname as if it will be published someday (unless
       you are doing something throwaway like a quick test that starts go mod init tempmod and you
       intend to delete the module soon). Some more details in this answer. - typical182 Aug 1
       '19 at 17:51

***
Module structure

   The most common and easiest approach is:
     * Use a single go.mod per repository, and
     * Place the single go.mod file in the repository root, and
     * Use the repository name as the module path declared in the module line in the go.mod
          + (If you are using a custom import path such as me.io/mymod rather than using a VCS host
            based import path, then you would use the custom import path instead of the repository name
            in your go.mod).

   For example, if your repo is github.com/my/repo, then you would place a single go.mod in the repo
   root, with the first line reading module github.com/my/repo. That can be created by cd'ing to the
   repo root and running go mod init github.com/my/repo.

   Following this helps you stay on the happy path with modules, and it avoids multiple subtleties.

     For all but power users, you probably want to adopt the usual convention that one repo = one
     module. It's important for long-term evolution of code storage options that a repo can contain
     multiple modules, but it's almost certainly not something you want to do by default.

   There is much more about multi-module repositories in the "Multi-module Repositories" FAQ section
   on the modules wiki. Those 6 or so FAQs in that section should be read in their entirety by anyone
   considering veering off the recommendation above.

Arranging packages within a module
   Once you have set up your go.mod, you can arrange your packages in directories however you see fit in
   directories underneath the directory containing the go.mod, as well as in the directory with the
   go.mod. Three good articles about how to arrange your code in packages:
     * https://rakyll.org/style-packages/
     * https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.ds38va3pp
     * https://www.goinggo.net/2017/02/design-philosophy-on-packaging.html

   Those articles are classics that pre-date the introduction of modules, but the philosophies in them
   still apply to how to arrange your packages within a module.

Importing other packages in the same module
   When importing another package with modules, you always use the full path including the module path.
   This is true even when importing another package in the same module. For example, if a module
   declared its identity in its go.mod as module github.com/my/repo, and you had this organization:
repo/
+-- go.mod      <<<<< Note go.mod is located in repo root
+-- pkg1/
|   +-- pkg1.go
+-- pkg2/
    +-- pkg1.go

   Then pkg1 would import its peer package as import "github.com/my/repo/pkg2". Note that you cannot use
   relative import paths like import "../pkg2" or import "./subpkg". (This is part of what OP hit above
   with import "./stuff").

Modules vs. repositories vs. packages vs. import paths
   A Go module is a collection of related Go packages that are versioned together as a single unit.
   Modules record precise dependency requirements and create reproducible builds.

   Summarizing the relationship between repositories, modules, and packages:
     * A repository contains one or more Go modules (most often exactly one module in the repository
       root).
     * Each module contains one or more Go packages.
     * Each package consists of one or more Go source files that all reside in a single directory.
     * Go source code:
          + declares its own package with a package foo statement.
          + automatically has access to other Go source code in the same package.
          + imports code from another package via an import path supplied in an import statement such as
            import "github.com/my/repo/pkg1". The import path always starts with the module path of that
            package, regardless of whether that package is in the same module or a different module.


---
https://www.orsolabs.com/post/building-go-code-with-concourse/

Building Go code, with and without Go modules, with Concourse
Mar 26, 2019

   Before the introduction of Go modules with Go 1.11, building Go code required to follow the
   peculiar directory structure of GOPATH. We show how to build Go code, wether it already supports
   go.mod or not, with Concourse CI.

Introduction
   pipeline
   The example code is available in directory build-golang of repository concourse-pipelines,
   separated in 2 branches:
     * branch golang-pre-modules is, well, pre-modules and requires to follow the GOPATH directory
       structure.
     * branch master is the same code, but converted to modules.

   The directory structure:
build-golang/
+-- README.adoc
+-- ci/
|   +-- build-golang-pipeline.yml
|   +-- build-task.yml
|   +-- build.sh
|   +-- unit-task.yml
|   +-- unit.sh
+-- cmd/
|   +-- cake/        (1)
|       +-- main.go
+-- go.mod           (2)
+-- go.sum           (2)
+-- hello/           (3)
    +-- hello.go
    +-- hello_test.go

    1. An executable, that uses the hello package.
    2. Files go.mod and go.sum are added in the second example.
    3. The hello package.

Without Go modules
   We begin with a minimal pipeline, nothing special (the pipeline in the sample repository has also the
   build job shown in the image above):
resources:
- name: concourse-pipelines
  type: git
  source:
    uri: https://github.com/marco-m/concourse-pipelines.git
    branch: golang-pre-modules
    paths: [build-golang/*]     (1)

jobs:
- name: unit
  plan:
  - get: concourse-pipelines
    trigger: true
  - task: unit
    file: concourse-pipelines/build-golang/ci/unit-task.yml

    1. The paths: directive normally is not needed. We use it because the sample repo contains multiple,
       independent examples and we want to trigger this specific pipeline only when something changes
       below the build-golang/ directory, not anywhere in the repo.

   In the task configuration we use the optional task input path to create a directory structure
   compliant with GOPATH:
platform: linux

image_resource:
  type: registry-image
  source: {repository: golang}

inputs:
- name: concourse-pipelines
  path: gopath/src/github.com/marco-m/concourse-pipelines (1)

run:
  path: gopath/src/github.com/marco-m/concourse-pipelines/build-golang/ci/unit.sh (2)

    1. The task input path.
    2. The run script, specified according to the task input path.

   Note: Concourse enforces the input path to be relative, this is why we cannot specify a path like
   /go/src/... . On the other hand, this is not a problem, as we will see in a moment.

   Finally the run script:
export GOPATH=$PWD/gopath           (1)
export PATH=$PWD/gopath/bin:$PATH   (2)

cd gopath/src/github.com/marco-m/concourse-pipelines/build-golang (3)

echo
echo "Fetching dependencies..."
go get -v -t ./...        (4)

echo
echo "Running tests..."
go test -v ./...          (5)

    1. We set the GOPATH, using $PWD to make it absolute as Go requires.
    2. We update PATH accordingly. For this sample code this is not needed, but we show it nonetheless.
    3. We cd into the base directory of the project (one level below the task input path, as seen in the
       task configuration above).
    4. We explicitly fetch the dependencies.
    5. Finally we run the tests.

Optimization: task caching
   As-is, the run script keeps downloading over and over the same dependencies.
   We can use the task cache feature to cache the dependencies and so speed-up the build.
   In the task configuration we add:
caches:
- path: depspath/
- path: gopath/pkg/

   and in the run script we prepend the cache directories to the environment variables:
export GOPATH=$PWD/depspath:$PWD/gopath
export PATH=$PWD/depspath/bin:$PWD/gopath/bin:$PATH

   (check the full source in the sample repo in case of doubt)

   I took the trick about the 2-component GOPATH and depspath from the booklit project, which is a
   relatively simple Golang project built with Concourse, that I use as my reference. In case you are
   confused as I was the first time I saw it, depspath is not a special name, any name would do. It is
   simply the fact that
    1. It is the first component of GOPATH
    2. It is the cache

   that makes it work :-)

   Note also that with Go modules this 2-component path is not needed.

*** With Go modules ***
   Note
   This is not a tutorial about Go modules. Please refer to the official documentation at Go modules.

   Everything becomes simpler.

   We create the Go module go.mod if needed (don't forget to commit it to git, together with go.sum,
   that will be created automatically on first test/build):
> cd build-golang
> go mod init github.com/marco-m/concourse-pipelines/build-golang

   The task file becomes a classic Concourse task file:
platform: linux

image_resource:
  type: registry-image
  source: {repository: golang}

inputs:  (1)
- name: concourse-pipelines

caches:  (2)
- path: gopath/

run:
  path: concourse-pipelines/build-golang/ci/unit.sh

    1. No more path: directive.
    2. No more depspath.

   Also the run script becomes simpler:
#!/bin/bash

set -e -u -x

export GOPATH=$PWD/gopath           (1)
export PATH=$PWD/gopath/bin:$PATH

cd concourse-pipelines/build-golang (2)

echo
echo "Running tests..."             (3)
go test -v ./...

    1. Simple GOPATH.
    2. Concourse standard relative directory for the input.
    3. No more explicit fetching of the dependencies.

   That's it, happy building!


---
https://peter.bourgon.org/go-best-practices-2016/

Go best practices, six years in

   In 2014, I gave a talk at the inaugural GopherCon titled Best Practices in Production
   Environments. We were early adopters at SoundCloud, and by that point had been writing, running,
   and maintaining Go in production in one form or another for nearly 2 years. We had learned a few
   things, and I tried to distill and convey some of those lessons.

   Since then, I've continued working in Go full-time, later on the activities and infrastructure teams
   at SoundCloud, and now at Weaveworks, on Weave Scope and Weave Mesh. I've also been
   working hard on Go kit, an open-source toolkit for microservices. And all the while, I've been
   active in the Go community, meeting lots of developers at meetups and conferences throughout Europe
   and the US, and collecting their stories-both successes and failures.

   With the 6th anniversary of Go's release in November of 2015, I thought back to that first talk.
   Which of those best practices have stood the test of time? Which have become outmoded or
   counterproductive? Are there any new practices that have emerged? In March, I had the opportunity to
   give a talk at QCon London where I reviewed the best practices from 2014 and took a look at how
   Go has evolved in 2016. Here's the meat of that talk.

Development environment
   Go has development environment conventions centered around the GOPATH. In 2014 I advocated strongly
   for a single global GOPATH. My positioned has softened a bit. I still think that's the best idea, all
   else equal, but depending on your project or team, other things may make sense, too.

   If you or your organization produces primarily binaries, you might find some advantages with a
   per-project GOPATH. There's a new tool, gb, from Dave Cheney and contributors, which replaces the
   standard go tooling for this use-case. A lot of people are reporting a lot of success with it.

   Some Go developers use a two-entry GOPATH, e.g. $HOME/go/external:$HOME/go/internal. The go tool has
   always known how to deal with this: go get will fetch into the first path, so it can be useful if you
   need strict separation of third-party vs. internal code.

   One thing I've noticed some developers forget to do: put GOPATH/bin into your PATH. This allows you
   to easily run binaries you get via go get, and makes the (preferred) go install mechanism of building
   code easier to work with. No reason not to do it.

   Top Tip - Put $GOPATH/bin in your $PATH, so installed binaries are easily accessible.

   Regarding editors and IDEs, there's been a lot of steady improvement. If you're a vim warrior, life
   has never been better: thanks to the tireless and extremely capable efforts of Fatih Arslan, the
   vim-go plugin is in an absolutely exceptional state, best-in-class. I'm not as familiar with
   emacs, but Dominik Honnef's go-mode.el is still the big kahuna there.

   Moving up the stack, lots of folks are still using and having success with Sublime Text +
   GoSublime. And it's hard to beat the speed. But more attention seems to be paid lately to the
   Electron-powered editors. Atom + go-plus has many fans, especially those developers that have
   to frequently switch languages to JavaScript. The dark horse has been Visual Studio Code +
   vscode-go, which, while slower than Sublime Text, is noticably faster than Atom, and has
   excellent default support for important-to-me features, like click-to-definition. I've been using it
   daily for about half a year now, after being introduced to it by Thomas Adam. Lots of fun.

   In terms of full IDEs, the purpose-built LiteIDE has been receiving regular updates and certainly
   has its share of fans. And the IntelliJ Go plugin has been consistently improving as well.

Repository structure
   Update: Ben Johnson has written an excellent article titled Standard Package Layout with great
   advice for typical line-of-business applications.

   Update: Tim Hockin's go-build-template, adapted slightly, has proven to be a better general
   model. I've adapted this section since its original publication.

   We've had a lot of time for projects to mature, and some patterns have emerged. While I believe there
   is no single best repo structure, I think there is a good general model for many types of projects.
   It's especially useful for projects that provide both binaries and libraries, or combine Go code with
   other, non-Go assets.

   The basic idea is to have two top-level directories, pkg and cmd. Underneath pkg, create directories
   for each of your libraries. Underneath cmd, create directories for each of your binaries. All of your
   Go code should live exclusively in one of these locations.
github.com/peterbourgon/foo/
  circle.yml
  Dockerfile
  cmd/
    foosrv/
      main.go
    foocli/
      main.go
  pkg/
    fs/
      fs.go
      fs_test.go
      mock.go
      mock_test.go
    merge/
      merge.go
      merge_test.go
    api/
      api.go
      api_test.go

   All of your artifacts remain go gettable. The paths may be slightly longer, but the nomenclature is
   familiar to other Go developers. And you have space and isolation for non-Go assets. For example,
   Javascript can live in a client or ui subdirectory. Dockerfiles, continuous integration configs, or
   other build helpers can live in the project root or in a build subdirectory. And runtime
   configuration like Kubernetes manifests can have a home, too.

   Top Tip - Put library code under a pkg/ subdirectory. Put binaries under a cmd/ subdirectory.

   Of course, you'll still use fully-qualified import paths. That is, the main.go in cmd/foosrv should
   import "github.com/peterbourgon/foo/pkg/fs". And beware of the ramifications of including a
   vendor dir for downstream users.

   Top Tip - Always use fully-qualified import paths. Never use relative imports.

   This little bit of structure makes us play nice in the broader ecosystem, and hopefully continues to
   ensure our code is easy to consume.

Formatting and style
   Things have stayed largely the same here. This is one area that Go has gotten quite right, and I
   really appreciate the consensus in the community and stability in the language.

   The Code Review Comments are great, and should be the minimum set of critera you enforce during
   code review. And when there are disputes or inconsistencies in names, Andrew Gerrand's idiomatic
   naming conventions are a great set of guidelines.

   Top Tip - Defer to Andrew Gerrand's naming conventions.

   And in terms of tooling, things have only gotten better. You should configure your editor to invoke
   gofmt-or, better, goimports-on save. (At this point, I hope that's not in any way controversial.)
   The go vet tool produces (almost!) no false positives, so you might consider making it part of
   your precommit hook. And check out the excellent gometalinter for linting concerns. This can
   produce false positives, so it's not a bad idea to encode your own conventions somehow.

Configuration
   Configuration is the surface area between the runtime environment and the process. It should be
   explicit and well-documented. I still use and recommend package flag, but I admit at this point I
   wish it were less esoteric. I wish it had standard, getopts-style long- and short-form argument
   syntax, and I wish its usage text were much more compact.

   12-factor apps encourage you to use environment vars for configuration, and I think that's fine,
   provided each var is also defined as a flag. Explicitness is important: changing the runtime behavior
   of an application should happen in ways that are discoverable and documented.

   I said it in 2014 but I think it's important enough to say again: define and parse your flags in
   func main. Only func main has the right to decide the flags that will be available to the user. If
   your library code wants to parameterize its behavior, those parameters should be part of type
   constructors. Moving configuration to package globals has the illusion of convenience, but it's a
   false economy: doing so breaks code modularity, makes it more difficult for developers or future
   maintainers to understand dependency relationships, and makes writing independent, parallelizable
   tests much more difficult.

   Top Tip - Only func main has the right to decide which flags are available to the user.

   I think there's a great opportunity for a well-scoped flags package to emerge from the community,
   combining all of these characteristics. Maybe it already exists; if so, please let me know. I'd
   certainly use it.

Program design
   In the talk, I used configuration as a jumping-off point, to discuss a few other issues of program
   design. (I didn't cover this in the 2014 version.) To start, let's take a look at constructors. If we
   are properly parameterizing all of our dependencies, our constructors can get quite large.
foo, err := newFoo(
    *fooKey,
    bar,
    100 * time.Millisecond,
    nil,
)
if err != nil {
    log.Fatal(err)
}
defer foo.close()

   Sometimes this kind of construction is best expressed with a config object: a struct parameter to a
   constructor that takes optional parameters to the constructed object. Let's assume fooKey is a
   required parameter, and everything else either has a sensible default or is optional. Often, I see
   projects construct config objects in a sort of piecemeal way.
// Don't do this.
cfg := fooConfig{}
cfg.Bar = bar
cfg.Period = 100 * time.Millisecond
cfg.Output = nil

foo, err := newFoo(*fooKey, cfg)
if err != nil {
    log.Fatal(err)
}
defer foo.close()

   But it's considerably nicer to leverage so-called struct initialization syntax to construct the
   object all at once, in a single statement.
// This is better.
cfg := fooConfig{
    Bar:    bar,
    Period: 100 * time.Millisecond,
    Output: nil,
}

foo, err := newFoo(*fooKey, cfg)
if err != nil {
    log.Fatal(err)
}
defer foo.close()

   No statements go by where the object is in an intermediate, invalid state. And all of the fields are
   nicely delimited and indented, mirroring the fooConfig definition.

   Notice we construct and then immediately use the cfg object. In this case we can save another degree
   of intermediate state, and another line of code, by inlining the struct declaration into the newFoo
   constructor directly.
// This is even better.
foo, err := newFoo(*fooKey, fooConfig{
    Bar:    bar,
    Period: 100 * time.Millisecond,
    Output: nil,
})
if err != nil {
    log.Fatal(err)
}
defer foo.close()

   Nice.

   Top Tip - Use struct literal initialization to avoid invalid intermediate state. Inline struct
   declarations where possible.

   Let's turn to the subject of sensible defaults. Observe that the Output parameter is something that
   can take a nil value. For the sake of argument, assume it's an io.Writer. If we don't do anything
   special, when we want to use it in our foo object, we'll have to first perform a nil check.
func (f *foo) process() {
    if f.Output != nil {
        fmt.Fprintf(f.Output, "start\n")
    }
    // ...
}

   That's not great. It's much safer, and nicer, to be able to use output without having to check it for
   existence.
func (f *foo) process() {
     fmt.Fprintf(f.Output, "start\n")
     // ...
}

   So we should provide a usable default here. With interface types, one good way is to pass something
   that provides a no-op implementation of the interface. And it turns out that the stdlib ioutil
   package comes with a no-op io.Writer, called ioutil.Discard.

   Top Tip - Avoid nil checks via default no-op implementations.

   We could pass that into the fooConfig object, but that's still fragile. If the caller forgets to do
   it at the callsite, we'll still end up with a nil parameter. So, instead, we can create a sort of
   safety within the constructor.
func newFoo(..., cfg fooConfig) *foo {
    if cfg.Output == nil {
        cfg.Output = ioutil.Discard
    }
    // ...
}

   This is just an application of the Go idiom make the zero value useful. We allow the zero value of
   the parameter (nil) to yield good default behavior (no-op).

   Top Tip - Make the zero value useful, especially in config objects.

   Let's revisit the constructor. The parameters fooKey, bar, period, output are all dependencies. The
   foo object depends on each of them in order to start and run successfully. If there's a single lesson
   I've learned from writing Go code in the wild and observing large Go projects on a daily basis for
   the past six years, it is this: make dependencies explicit.

   Top Tip - Make dependencies explicit!

   An incredible amount of maintenance burden, confusion, bugs, and unpaid technical debt can, I
   believe, be traced back to ambiguous or implicit dependencies. Consider this method on the type foo.
func (f *foo) process() {
    fmt.Fprintf(f.Output, "start\n")
    result := f.Bar.compute()
    log.Printf("bar: %v", result) // Whoops!
    // ...
}

   fmt.Printf is self-contained and doesn't affect or depend on global state; in functional terms, it
   has something like referential transparency. So it is not a dependency. Obviously, f.Bar is a
   dependency. And, interestingly, log.Printf acts on a package-global logger object, it's just obscured
   behind the free function Printf. So it, too, is a dependency.

   What do we do with dependencies? We make them explicit. Because the process method prints to a log as
   part of its work, either the method or the foo object itself needs to take a logger object as a
   dependency. For example, log.Printf should become f.Logger.Printf.
func (f *foo) process() {
    fmt.Fprintf(f.Output, "start\n")
    result := f.Bar.compute()
    f.Logger.Printf("bar: %v", result) // Better.
    // ...
}

   We're conditioned to think of certain classes of work, like writing to a log, as incidental. So we're
   happy to leverage helpers, like package-global loggers, to reduce the apparent burden. But logging,
   like instrumentation, is often crucial to the operation of a service. And hiding dependencies in the
   global scope can and does come back to bite us, whether it's something as seemingly benign as a
   logger, or perhaps another, more important, domain-specific component that we haven't bothered to
   parameterize. Save yourself the future pain by being strict: make all your dependencies explicit.

   Top Tip - Loggers are dependencies, just like references to other components, database
   handles, commandline flags, etc.

   Of course, we should also be sure to take a sensible default for our logger.
func newFoo(..., cfg fooConfig) *foo {
    // ...
    if cfg.Logger == nil {
        cfg.Logger = log.New(ioutil.Discard, ...)
    }
    // ...
}

   Update: for more detail on this and the subject of magic, see the June 2017 blog post on a theory
   of modern Go.

Logging and instrumentation
   To speak about the problem generally for a moment: I've had a lot more production experience with
   logging, which has mostly just increased my respect for the problem. Logging is expensive, more
   expensive than you think, and can quickly become the bottleneck of your system. I wrote more
   extensively on the subject in a separate blog post, but to re-cap:
     * Log only actionable information, which will be read by a human or a machine
     * Avoid fine-grained log levels - info and debug are probably enough
     * Use structured logging - I'm biased, but I recommend go-kit/log
     * Loggers are dependencies!

   Where logging is expensive, instrumentation is cheap. You should be instrumenting every significant
   component of your codebase. If it's a resource, like a queue, instrument it according to Brendan
   Gregg's USE method: utilization, saturation, and error count (rate). If it's something like an
   endpoint, instrument it according to Tom Wilkie's RED method: request count (rate), error count
   (rate), and duration.

   If you have any choice in the matter, Prometheus is probably the instrumentation system you
   should be using. And, of course, metrics are dependencies, too!

   Let's use loggers and metrics to pivot and address global state more directly. Here are some facts
   about Go:
     * log.Print uses a fixed, global log.Logger
     * http.Get uses a fixed, global http.Client
     * http.Server, by default, uses a fixed, global log.Logger
     * database/sql uses a fixed, global driver registry
     * func init exists only to have side effects on package-global state

   These facts are convenient in the small, but awkward in the large. That is, how can we test the log
   output of components that use the fixed global logger? We must redirect its output, but then how can
   we test in parallel? Just don't? That seems unsatisfactory. Or, if we have two independent components
   both making HTTP requests with different requirements, how do we manage that? With the default global
   http.Client, it's quite difficult. Consider this example.
func foo() {
    resp, err := http.Get("http://zombo.com")
    // ...
}

   http.Get calls on a global in package http. It has an implicit global dependency. Which we can
   eliminate pretty easily.
func foo(client *http.Client) {
    resp, err := client.Get("http://zombo.com")
    // ...
}

   Just pass an http.Client as a parameter. But that is a concrete type, which means if we want to test
   this function we also need to provide a concrete http.Client, which likely forces us to do actual
   HTTP communication. Not great. We can do one better, by passing an interface which can Do (execute)
   HTTP requests.
type Doer interface {
    Do(*http.Request) (*http.Response, error)
}

func foo(d Doer) {
    req, _ := http.NewRequest("GET", "http://zombo.com", nil)
    resp, err := d.Do(req)
    // ...
}

   http.Client satisfies our Doer interface automatically, but now we have the freedom to pass a mock
   Doer implementation in our test. And that's great: a unit test for func foo is meant to test only the
   behavior of foo, it can safely assume that the http.Client is going to work as advertised.

   Speaking of testing...

Testing
   In 2014, I reflected on our experience with various testing frameworks and helper libraries, and
   concluded that we never found a great deal of utility in any of them, recommending the stdlib's
   approach of plain package testing with table-based tests. Broadly, I still think this is the best
   advice. The important thing to remember about testing in Go is that it is just programming. It is not
   sufficiently different from other programming that it warrants its own metalanguage. And so package
   testing continues to be well-suited to the task.

   TDD/BDD packages bring new, unfamiliar DSLs and control structures, increasing the cognitive burden
   on you and your future maintainers. I haven't personally seen a codebase where that cost has paid off
   in benefits. Like global state, I believe these packages represent a false economy, and more often
   than not are the product of cargo-culting behaviors from other languages and ecosystems. When in Go,
   do as Gophers do: we already have a language for writing simple, expressive tests-it's called Go, and
   you probably know it pretty well.

   With that said, I do recognize my own context and biases. Like with my opinions on the GOPATH, I've
   softened a bit, and defer to those teams and organizations for whom a testing DSL or framework may
   make sense. If you know you want to use a package, go for it. Just be sure you're doing it for
   well-defined reasons.

   Another incredibly interesting topic has been designing for testing. Mitchell Hashimoto recently gave
   a great talk on the subject here in Berlin (SpeakerDeck, YouTube) which I think should be
   required viewing.

   In general, the thing that seems to work the best is to write Go in a generally functional style,
   where dependencies are explicitly enumerated, and provided as small, tightly-scoped interfaces
   whenever possible. Beyond being good software engineering discipline in itself, it feels like it
   automatically optimizes your code for easy testing.

   Top Tip - Use many small interfaces to model dependencies.

   As in the http.Client example just above, remember that unit tests should be written to test the
   thing being tested, and nothing more. If you're testing a process function, there's no reason to also
   test the HTTP transport the request came in on, or the path on disk the results get written to.
   Provide inputs and outputs as fake implementations of interface parameters, and focus on the business
   logic of the method or component exclusively.

   Top Tip - Tests only need to test the thing being tested.

Dependency management
   Ever the hot topic. In 2014, things were nascent, and about the only concrete advice I could give was
   to vendor. That advice still holds today: vendoring is still the solution to dependency management
   for binaries. In particular, the GO15VENDOREXPERIMENT and its concomittant vendor/ subdirectory have
   become default in Go 1.6. So you'll be using that layout. And, thankfully, the tools have gotten a
   lot better. Some I can recommend:
     * FiloSottile/gvt takes a minimal approach, basically just extracting the vendor subcommand
       from the gb tool so it can be used standalone.
     * Masterminds/glide takes a maximal approach, attempting to recreate the feel and finish of a
       fully-featured dependency management tool using vendoring under the hood.
     * kardianos/govendor sits in the middle, providing probably the richest interface to
       vendoring-specific nouns and verbs, and is driving the conversation on the manifest file.
     * constabulary/gb abandons the go tooling altogether in favor of a different repository layout
       and build mechanism. Great if you produce binaries and can mandate the build environment, e.g. in
       a corporate setting.

   Top Tip - Use a top tool to vendor dependencies for your binary.

   A big caveat for libraries. In Go, dependency management is a concern of the binary author. Libraries
   with vendored dependencies are very difficult to use; so difficult that it is probably better said
   that they are impossible to use. There are many corner cases and edge conditions that have played out
   in the months since vendoring was officially introduced in 1.5. (You can dig in to one of these
   forum posts if you're particularly interested in the details.) Without getting too deep in the
   weeds, the lesson is clear: libraries should never vendor dependencies.

   Top Tip - Libraries should never vendor their dependencies.

   You can carve out an exception for yourself if your library has hermetically sealed its dependencies,
   so that none of them escape to the exported (public) API layer. No dependent types referenced in any
   exported functions, method signatures, structures-anything.

   If you have the common task of maintaining an open-source repository that contains both binaries and
   libraries, unfortunately, you are stuck between a rock and a hard place. You want to vendor your deps
   for your binaries, but you shouldn't vendor them for your libraries, and the GO15VENDOREXPERIMENT
   doesn't admit this level of granularity, from what appears to me to be regrettable oversight.

   Bluntly, I don't have an answer to this. The etcd folks have hacked together a solution using
   symlinks which I cannot in good faith recommend, as symlinks are not well-supported by the go
   toolchain and break entirely on Windows. That this works at all is more a happy accident than any
   consequence of design. I and others have raised all of these concerns to the core team, and I
   hope something will happen in the near term.

Build and deploy
   Regarding building, one important lesson learned, with a hat tip to Dave Cheney: prefer go install to
   go build. The install verb caches build artifacts from dependencies in $GOPATH/pkg, making builds
   faster. It also puts binaries in $GOPATH/bin, making them easier to find and invoke.

   Top Tip - Prefer go install to go build.

   If you produce a binary, don't be afraid to try out new build tools like gb, which may
   significantly reduce your cognitive burden. Conversely, remember that since Go 1.5 cross-compilation
   is built-in; just set the appropriate GOOS and GOARCH environment variables, and invoke the
   appropriate go command. So there's no need for extra tools here anymore.

   Regarding deployment, we Gophers have it pretty easy compared to languages like Ruby or Python, or
   even the JVM. One note: if you deploy in containers, follow the advice of Kelsey Hightower and
   do it FROM scratch. Go gives us this incredible opportunity; it's a shame not to use it.

   As more general advice, think carefully before choosing a platform or orchestration system-if you
   even choose one at all. Likewise for jumping onto the microservices bandwagon. An elegant monolith,
   deployed as an AMI to an autoscaling EC2 group, is a very productive setup for small teams. Resist,
   or at least carefully consider, the hype.

Conclusion
   The Top Tips:
    1. Put $GOPATH/bin in your $PATH, so installed binaries are easily accessible.
    2. Put library code under a pkg/ subdirectory. Put binaries under a cmd/ subdirectory.
    3. Always use fully-qualified import paths. Never use relative imports.
    4. Defer to Andrew Gerrand's naming conventions.
    5. Only func main has the right to decide which flags are available to the user.
    6. Use struct literal initialization to avoid invalid intermediate state.
    7. Avoid nil checks via default no-op implementations.
    8. Make the zero value useful, especially in config objects.
    9. Make dependencies explicit!
   10. Loggers are dependencies, just like references to other components, database handles, commandline
       flags, etc.
   11. Use many small interfaces to model dependencies.
   12. Tests only need to test the thing being tested.
   13. Use a top tool to vendor dependencies for your binary.
   14. Libraries should never vendor their dependencies.
   15. Prefer go install to go build.

   Go has always been a conservative language, and its maturity has brought relatively few surprises and
   effectively no major changes. Consequently, and predictably, the community also hasn't dramatically
   shifted its stances on what's considered best practice. Instead, we've seen a reification of tropes
   and proverbs that were reasonably well-known in the early years, and a gradual movement "up the
   stack" as design patterns, libraries, and program structures are explored and transformed into
   idiomatic Go.


---
https://tutorialedge.net/golang/go-project-structure-best-practices/

Go Project Structure Best Practices
Dec 5, 2019

   The structure your Go applications should follow is a somewhat contentious subject. Some people are
   adamant that everyone should follow the well known golang-standards/project-layout structure for
   absolutely every project.

   However, with the introduction of Go Modules as the standard going forward for handling dependencies,
   this structure starts to present challenges. Going with the traditional structure, you will find that
   some folders within your structure will not have access to folders such as internal or pkg and you
   will have to implement somewhat hacky solutions in order for these to work as-is.

   In this article, I will be presenting a range of options that you can choose from when it comes to
   structuring your Go applications in the new world order.

     Note - When it comes to structuring your applications, there is no "once-and-done" approach. As
     your application evolves, so too must your method of structuring your project.

Small Applications - Flat Structure
   Every project starts out small and gradually grows arms and legs depending on how successful it is,
   or how much time developers are willing to contribute into it.
application/
 - main.go
 - main_test.go
 - utils.go
 - utils_test.go
 - ...

   Starting with a flat folder structure in these situations like the one outlined above is highly
   recommended. By keeping the structure of your project simple to begin with, you as a developer can
   focus on delivering the highest value features to whoever your intended audience is as quickly as
   possible, without the cognitive overhead of a complex structure.

   Too often have I seen developers spending more time arranging and re-arranging their codebase at the
   early stages of their projects, before anything of real value has been delivered and ultimately it
   leads to longer feedback loops between you as a developer or team of developers and your intended
   audience.

Benefits
   This flat folder structure is ideal when it comes to developing:
     * Microservices - tiny applications deployed in a distributed fashion that are built to do one
       thing, and one thing only.
     * Small Tools and libraries - Command line tools or small libraries that focus on doing a handful
       of tasks really well.

Examples of This Structure
   Let's have a look at some examples of where this structure works:
     * tidwall/gjson - This project almost perfectly illustrates the point about how a project can
       still be successful with an incredibly minimalist structure. They've kept everything incredibly
       flat and not overcomplicated things from the start whilst focusing on delivering real value to
       the people that use the project.
     * go-yaml/yaml - Another very cool project that features a completely flat project structure.

Medium/Large Sized Applications - Modularization
   As your projects grow in size and complexity, you'll quickly see it start to outgrow the flat
   structure which is when you should start to consider modularizing your codebase.

   Let's take for example a REST API that powers a website. This REST API might have endpoints that
   handle user registration and login, and another group which handle a users' content in a CRUD-like
   fashion.

   It is at this point where we should start to consider picking apart our application into semantic
   groups of functionality and potentially centralizing any core logic shared across these components
   into a shared package within our project.
rest-api/
- main.go
- user/
- - user.go
- - login.go
- - registration.go
- articles/
- - articles.go
- utils/
- - common_utils.go

Examples of This Structure
   Here are just a few Go projects that have adopted this structure.
     * google/go-cloud - This is an excellent example of a project that has adopted this structure.
       They have broken up the project into packages for each of the IAAS Cloud Providers, and each
       package contains all of the code pertinent to that specific cloud provider.
     * hashicorp/consul - This is another great example of a large project that has chosen to go
       down the modular approach.
     * ipfs/go-ipfs - IPFS is a very cool peer-to-peer filesystem written in Go based off of
       previous systems such as Git and BitTorrent. Again, they've chosen to go for a modular approach
       when developing their system.
     * gohugoio/hugo - The very awesome framework which is currently used as the backend of this
       site!

Mature Projects
   You will absolutely still see projects that adhere to the older project structure, but this is very
   much a byproduct of the time in which these applications were developed.

   Large applications such as Hashicorp's Terraform or Google's own Kubernetes tend to feature remnants
   of the old style of structure which worked very well when the $GOPATH reigned supreme. You'll see
   that they still feature internal and pkg folders which encapsulate some of the inner workings of the
   projects.
     * hashicorp/terraform
     * Kubernetes/kubernetes

   This structure has worked exceptionally well and allowed the developers to deliver incredible value
   to the development community, however I think that as Go Modules start to become more prevalent, we
   will start to see a migration of these applications away from the more traditional structure and into
   a newer structure.

Splitting Up Projects
   After a certain point, it may make sense to completely rip out certain parts of your project that
   make sense into separate repositories that have their own life cycle.

   This will feature it's own set of drawbacks such as increased overhead when it comes to managing
   updates across your project's estate. However, it also means that your projects will be easier to
   digest for newcomers to the project who want to contribute and help.

Conclusion
   Hopefully this article has helped you in your development efforts and given you some ideas when you
   start modeling your next Go project!

   These are my own findings based off my own personal development experience developing services and
   service brokers in my day job. Your own mileage may vary when using these structures but I would love
   to hear your own thoughts and tips on how you structure your Go applications in the comments section
   below!


---
https://manfred.life/golang-project-layout

Golang project layout
September 22, 2019

   In a previous blogpost, I talked about why I always trash the V1 of my projects. At Berty, we
   recently decided to start a clean V2, based on everything we learned from the V1.

What works well
     * having a monorepo
     * being protobuf-first and generating a lot of code
     * the codebase was "big-refactor"-friendly, including several refactors that modified 50+ files at
       once
     * we've learned a lot about:
          + our project, the features, the roadmap, the difficulties, etc
          + about our dependencies (IPFS, gomobile, react-native, BLE, etc.)

What needs to be improved
     * The code was too complex to read
     * The codebase was too complex to update safely
     * There were not enough rules about:
          + where to implement something, how to name things
          + how to implement things
     * Makefile rules, and CI can be improved
     * The tests should be more reliable
     * We need to learn more about our future protocol, for now, it's only in our head, and we will
       undoubtedly fail to implement the v1 of the protocol, I prefer to fail fast!

   I passed the last three days reading blog posts, slides, repositories, and watching videos about what
   other people are doing right now.

   Then, I looked back on Berty and my other projects and listed a set of rules I like the most.

New rules
   As usual, a rule is something that can always have exceptions :)
     * Focus on readability, it's a very good pattern to check what the godoc looks like to know if the
       API seems easy to adopt.
     * Avoid magic, no global vars, no func init()
     * Sharing logic / reusable business functionality is most of the time over-engineering
     * Enumerate requirements at function constructors. Use dependency injection (not dependency
       containers!), make go build your best friend; the logger should also be injected
     * If your project is small enough, put everything at the root of the project -> mono package
     * When you are creating a very powerful and complex library, it can be a good thing to make its
       little-sister library that will wrap the most permissive one in a light opinionated library
     * Embrace middlewares to lose coupling for timeout handling, retry mechanisms, authentication
       checks, etc
     * Reduce comments, focus on useful variable and function naming
          + Function and variable names are important to review
     * Limit the number of packages, the number of functions, the number of interfaces
          + Keep things simple and do not split into too many components at the beginning, split only
            because of a problem, not because of an anticipation
     * Try always to have a minimal indentation level
     * Use short function and variable names
          + Variables can even be one or two letters long (initials) when used near to their
            initialization
          + Receiver name should always be 1 or 2 letters long
     * Prefer synchronous functions to asynchronous ones, it's easy to make an asynchronous wrapper over
       asynchronous function, not the opposite
     * Use named results (return) for documentation
     * Be flat, only use {cmd,pkg,internal}/<package-name>/<files>.go
     * Use pkg/ for packages you want other people to use, and internal/ for the code your
       implementation details; most of the code should start in internal/ before being moved to pkg/,
       only after you are sure it can be useful for someone else and after it becomes mature enough, so
       it has less risk of changing.
     * use feature-flags to configure the app, feature-flags are "documentation"! They also allow you to
       have (multiple) (unfinished) (long-running) experiments merged more quickly
     * Flags should be taken into account in this order: CLI > config > env
     * use a structured logger, bind it with std logger
       (https://github.com/go-kit/kit/tree/master/log#interact-with-stdlib-logger)
     * If your repo uses multiple main languages, they should be namespaced in their directory to make
       everything easier to manipulate for the tools.
     * Put your .proto files in an api/ directory, but you can configure them to generate files in your
       existing go packages.
     * Go routines
          + Should always have a well-defined lifecycle
          + You can use https://godoc.org/github.com/oklog/run
          + Look at those patterns: Nursery, Futures, Scatter/Gather
     * Package names should be:
          + the same as the directory name (always)
          + singular, lowercase, alpha-num
          + unique in your project; unique with go core packages too, if possible
     * Use -race when building and testing from the beginning
     * Context
          + context.Value is only used for request-scoped information and only when it can't be passed
            in another way
          + Do not hesitate to pass context.Context as the first var of most of your functions (I need
            to investigate more and have a more strict rule here)
     * Always put a doc.go file in the pkg/* packages to configure the package vanity URLs and put some
       documentation. When your package has multiple go files, it will be easier to know where to edit
       those things
     * Avoid having too many interfaces, and when doing some, try to always declare them in the caller
       package, not the implementer one
     * Tests
          + go test should always work after a fresh clone! If you have unreliable/specific tests, use
            flags, env vars
          + The tests should be easily readable and explaining, it's probably the best place to
            "document" the edge cases of your library
          + Use table-driven tests a lot
          + If you are manipulating test-fixtures often, you can add a test -update flag
          + If you write mock, they should be implemented in the same package than the real
            implementation, in a testing.go file; a mock should, in general, return a fully started
            in-memory server.
          + If you need to write tests at runtime, you can use
            http://github.com/mitchellh/go-testing-interface
          + If you have a complex struct, i.e., a server, do not hesitate to add a Test bool field that
            configures it to be testing-friendly
          + When testing complex structs, compare a string representation (JSON, or something like that)
          + Only test exported functions; unexported functions are implementation details
          + If you write helpers, they should not return an error but take testing.T as an argument and
            call t.Fail directly
     * Most of the rules defined here can be skipped entirely in the internal/ directory. This directory
       is the perfect place for things that changes often.
     * Add a githook that run goimports.

Unanswered questions
     * When is it better to have a ListsUser(query) instead of ListAllUsers() + ListUsersByGroup() +
       ListActiveUsers()...?
     * What the best way of organizing code that involves multiple languages, i.e., bridges?
     * When does it makes sense to have an iface package?
     * When does it make sense to have a model package vs. a user package?

Suggested project layout for the monorepo of a big project

* api/
  * a.proto
  * a.swagger.json (generated)
  * b.proto
  * b.swagger.json (generated)
* assets/
  * logo.png
* build/
  * ci/
    * script.sh
  * package/
    * script.sh
* configs/
  * prod.json
  * dev.json
* deployments/
  * c/
    * docker-compose.yml
  * d/
    * docker-compose.yml
* docs/
  * files.md
* examples/
  * descriptive-dirname/
    * ...
* githooks/
  * pre-commit
* go/
  * cmd/
    * mybinary/
      * main.go
  * internal
    * e/
      * doc.go
      * e.go
    * f/
      * doc.go
      * f.go
  * pkg/
    * g/
      * doc.go
      * g.go
    * h/
      * doc.go
      * h.go
  * Makefile
  * go.mo
* js/
* test/
  * testdata/
    * blob.json
* tools/
  * docker-protoc/
    * Dockerfile
  * script.sh
* Makefile
* Dockerfile

     I however also run into cases where I end up accidentally writing Java-style interfaces -
     typically after I come back from a stint of writing code in Python or Java. The desire to
     overengineer and "class all the things" something is quite strong, especially when writing Go code
     after writing a lot of object-oriented code.
     * http://www.brendangregg.com/usemethod.html
     * https://en.m.wikipedia.org/wiki/Extreme_programming
     * https://github.com/golang-standards/project-layout
     * https://github.com/golang/go/wiki/CodeReviewComments
     * https://github.com/mishudark/eventhus
     * https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1
     * https://medium.com/@rdsubhas/10-modern-software-engineering-mistakes-bc67fbef4fc8

     TL;DR - The House (Business) Always Wins - In my 15-year involvement with coding, I have never
     seen a single business "converge" on requirements. They only diverge. It is simply the nature of
     business and its not the business people's fault.
     TL;DR - Duplication is better than the wrong abstraction - Designs are always playing catch up to
     changing real-world requirements. So even if we found a perfect abstraction by a miracle, it comes
     tagged with an expiry date because #1 - The House wins in the end. The best quality of a Design
     today is how well it can be undesigned. There is an amazing article on write code that is easy to
     delete, not easy to extend.
     TL;DR - Wrappers are an exception, not the norm. Don't wrap good libraries for the sake of
     wrapping.
     TL;DR - Don't let <X>-ities go unchallenged. Clearly define and evaluate the
     Scenario/Story/Need/Usage. Tip: Ask a simple question - "What's an example story/scenario?" - And
     then dig deep on that scenario. This exposes flaws in most <X>-ities.
     * https://peter.bourgon.org/blog/2017/02/21/metrics-tracing-and-logging.html
     * https://peter.bourgon.org/blog/2017/06/09/theory-of-modern-go.html
     * https://peter.bourgon.org/go-for-industrial-programming/

     Industrial programming means writing code once and maintaining it into perpetuity. Maintenance is
     the continuous practice of reading and refactoring. Therefore, industrial programming
     overwhelmingly favors reads, and on the spectrum of easy to read vs. easy to write, we should bias
     strongly towards the former.
     Looking at interfaces as a way to classify implementations is the wrong approach; instead, look at
     interfaces as a way to identify code that expects common sets of behaviors.
     * https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to

     Instead of making code easy-to-delete, we are trying to keep the hard-to-delete parts as far away
     as possible from the easy-to-delete parts.
     Write more boilerplate. You are writing more lines of code, but you are writing those lines of
     code in the easy-to-delete parts.
     I'm not advocating you go out and create a /protocol/ and a /policy/ directory, but you do want to
     try and keep your util directory free of business logic, and build simpler-to-use libraries on top
     of simpler-to-implement ones. You don't have to finish writing one library to start writing
     another atop.
     Layering is less about writing code we can delete later, but making the hard to remove code
     pleasant to use (without contaminating it with business logic).
     You've copy-pasted, you've refactored, you've layered, you've composed, but the code still has to
     do something at the end of the day. Sometimes it's best just to give up and write a substantial
     amount of trashy code to hold the rest together.
     Business logic is code characterized by a never-ending series of edge cases and quick and dirty
     hacks. This is fine. I am ok with this. Other styles like 'game code', or 'founder code' are the
     same thing: cutting corners to save a considerable amount of time.
     The reason? Sometimes it's easier to delete one big mistake than try to delete 18 smaller
     interleaved mistakes. A lot of programming is exploratory, and it's quicker to get it wrong a few
     times and iterate than think to get it right first time.
       the whole step 5 is <3

     I'm not suggesting you write the same ball of mud ten times over, perfecting your mistakes. To
     quote Perlis: "Everything should be built top-down, except the first time". You should be trying
     to make new mistakes each time, take new risks, and slowly build up through iteration.
     Instead of breaking code into parts with common functionality, we break code apart by what it does
     not share with the rest. We isolate the most frustrating parts to write, maintain, or delete away
     from each other.; We are not building modules around being able to re-use them, but being able to
     change them.
     When a module does two things, it is usually because changing one part requires changing the
     other. It is often easier to have one awful component with a simple interface, than two components
     requiring a careful co-ordination between them.
     The strategies I've talked about - layering, isolation, common interfaces, composition - are not
     about writing good software, but how to build software that can change over time.
     * https://rakyll.org/style-packages/
     * https://www.martinfowler.com/articles/designDead.html
     * https://youtu.be/ZsHMHukIlJY

     A common fallacy is to assume authors of incomprehensible code will somehow be able to express
     themselves lucidly and clearly in comments.


---
https://revel.github.io/manual/organization.html

Organization
   Revel requires itself and the user application to be installed into a GOPATH layout as prescribed by
   the go command line tool. (See "GOPATH Environment Variable" in the go command documentation)

Default Layout
   Below is the recommended layout of a Revel application, supplemented with domain entities and
   services.
     * my_gocode/ - GOPATH root
          + src/ - GOPATH src/ directory
               o github.com/revel/revel/ - Revel source code
               o bitbucket.org/me/sample/ - Sample app root
                    # entities/ - domain entities
                    # app/ - app sources
                         @ controllers/ - app controllers
                              - init.go - interceptor registration
                         @ models/ - app domain models
                         @ jobs/ - app domain jobs
                         @ services/ - app domain services
                         @ routes/ - reverse routes (generated code)
                         @ views/ - templates
                         @ tmp/ - app main file, generated code
                    # tests/ - test suites
                    # conf/ - configuration files
                         @ app.conf - main configuration file
                         @ routes - routes definition file
                    # messages/ - i18n message files
                    # public/ - static/public assets
                         @ css/ - stylesheet files
                         @ js/ - javascript files
                         @ images/ - image files
                    # vendor/ - vendor folder used for version control
                    # Gopkg.toml - vendor dependency management file

app/ directory
   The app/ directory contains the source code and templates for your application.
     * app/controllers/ - All controllers are required here
     * app/views - All templates are required here

   Beyond that, the application may organize its code however it wishes. Revel will watch all
   directories under app/ and rebuild when it notices any changes. Any dependencies outside of app/ will
   not be watched for changes, it is the developer's responsibility to recompile when necessary.

   Additionally, Revel will import any packages within app/ (or imported modules) that contain
   init() functions on startup, to ensure that all of the developer's code is initialized.

   The app/init.go file is a conventional location to register all of the interceptor hooks. The
   order of init() functions is undefined between source files from the same package, so collecting all
   of the interceptor definitions into the same file allows the developer to specify (and know) the
   order in which they are run. (It could also be used for other order-sensitive initialization in the
   future.)

conf/ directory
   The conf/ directory contains the application's configuration files. There are two main configuration
   files:
     * app.conf - the main configuration file for the application
     * routes - the URL routing definition file.

messages/ directory
   The messages/ directory contains all localized message files.

public/ directory
   Resources stored in the public/ directory are static assets that are served directly by the web
   server. Typically it is split into three standard sub-directories for images/, css/ stylesheets and
   js/ JavaScript files.

   The names of these directories may be anything and the developer need only update the routes.

vendor/ directory
   Used by the dep tool for storing dependent packages (instead of using the GOPATH) see versions.
   To initialize a vendor application see the Revel tool


---
https://www.reddit.com/r/golang/comments/2lq3it/is_there_a_way_to_arrange_go_code_into_multiple/

Is there a way to arrange Go code into multiple subdirectories?

   I have done some Go programming and there have been times where I think it'd make sense to organize
   my project by putting some of the code into subdirectories of the project's main directory. Is there
   any way to do that in Go?

***
   I will try and give a practical answer since most answers here tend to be "No don't do that."

   Essentially, what you probably want to do is organize your code into "sub-packages". Though you might
   need to change your code structure so that each sub-package doesn't introduce cyclic dependencies.
   Each package in your project should either be a leaf package (no inter-dependencies with your
   other packages), or your root package (your main application).

   And make sure your set GOPATH to be the root of your project.

   Your project directory will look something like this:
$GOPATH/
    projectmain.go
    src/
        yournamespace/
            yourpackage1/
                file1.go
                file2.go
            yourpackage2/
                file3.go
                file4.go
        code.google.com/
             ...
        github.com/
             ...

   In your code. your imports would be something like:
import (
    "yournamespace/yourpackage1"
    "yournamespace/yourpackage2"
    ...
)

***
   If a package grows so much that I need to split it into several directories to handle my code (go
   allows to split it into multiple files in one directory), then I would think about my code
   organization. Large functions, types (classes in other languages), files, or packages tend to become
   hard to maintain. So in case of your concrete code create sub-packages and bundle the functionality
   in a logical way there. Other packages, like also your main package, then can use these packages.

   Take a look at my private code at http://github.com/tideland or our company project, which really
   has a large code base, at http://github.com/juju/juju.

   
---
https://github.com/golang-standards/project-layout/issues/18

Best project structure when using go 1.11
Oct 31, 2018

   The first thing you will run into when using go.mod, putting code outside GOPATH, and using the
   recommended folder structure is that your cmd/ does not have access to your internal or pkg folder.
   Therefore you are automatically required to resort to using the require/replace fix to actually get
   access to the code or actually split your code into actual modules and upload separately.

   While the require/replace fix works and builds, your IDE will probably still have problems picking up
   the imports for good code navigation unless you manually update your go.mod file in the pkg or
   internal folder. (you cant use go build to update your go.mod/sum file as there is nothing to build
   in the folder) Of course, this is more of an IDE problem.
module some-api

replace some-pkg v0.0.0 => ../../pkg

require (
        some-pkg v0.0.0
)

   Would people still recommend this folder layout when using go modules, have multiple cmd
   applications, and especially when putting code outside the gopath? I am curious as I see more and
   more people starting to use modules and putting their code in a GOPATH-less environment and this is
   for sure bound to create problems and confusion when using modules as it requires "some" custom
   setup. Of course, nothing major once you figure it out.

   Come to think of it, this is more of a general issue with go mod. You will run into this issue from
   the moment you put your main.go file in a subfolder and not the root.

***
   I've found that Go modules tend to not work all to well when it comes to the whole mono-repo approach
   that was encouraged by the use of $GOPATH. Go modules are still in the works however as of Go 1.11,
   and will be finalised in Go 1.12 as stated here.

   For now I've just done as you have, and resorted to using replace in the go.mod file so I can locally
   pull in packages as I'm developing them. This isn't ideal though, as I've found building the
   application to be somewhat slower than just having it be pulled from a repo, however the alternative
   of having to tag, push, then build just to pick up on the changes I've made not that ideal either.

***
   I simply use the whole repository address in go.mod (which is exactly what is described here):
module github.com/user-or-org/some-api

require (
        [other requirements]
)

   Do you have a problem with this approach?

***
   @tiramiseb one problem I've encountered is that unless I put the replace [package] => ../../ in
   the go.mod file I won't be able to build with the latest changes I've made unless I tag it, then push
   it up to the remote.

   For projects where I only have one go.mod file in the root of the project this isn't an issue, but
   for projects where I would have multiple go.mod files within sub-directories of the cmd/ directory
   this has been an issue.
project/
+-- go.mod
+-- cmd/
    +-- command-one/
    |   +-- go.mod
    +-- command-two/
        +-- go.mod

   Consider the above project structure, if I made any changes to any packages I have in the top-level
   project/ directory, I would want the two sub modules, command-one, and command-two to pick up on
   those changes when I run go build in either of them. With Go modules I can do this by tagging a new
   release, and pushing up to the repo so when I run go build in either command-one, or command-two the
   most recent changes will be included. Or I could use replace project => ../../ in both go.mod files
   during development phases so I don't have to create needless tags.

   I hope I've explained this well enough, but the short of it is this: with Go modules I have ran into
   issues when taking a mono-repo approach in development. If I am missing something, or
   misunderstanding certain concepts then please do tell me.

***
   Indeed. I only have go.mod at the root of the project. I see your point...

***
   @tiramiseb I'm in the same boat, only a go.mod at the root, but I hit the same issue as
   @ypeckstadt if I moved my main.go into cmd/something.

   Did you (or anyone else) have a project structure that allowed for a single go.mod at repo root, but
   with all other code contained in subdirs? Or have I missed something here in structuring my code?

   Ideally, I'd like to end up with something similar to the standard structure many projects use with
   Gopkg.toml at the root, but basically all code inside cmd/ or pkg/ (substituting go.mod for
   Gopkg.toml of course).

***
   This is exactly what I am doing : .go files only in pkg/ or cmd/, with a single go.mod at the root of
   the repository.

***
   EDIT: Came back to this and noticed it had a lot of reactions! Here's a similar, simple project
   building binaries in and out of the root folder: https://github.com/alexeldeib/godemo

   I must be missing something -- I read that doc several times and haven't been able to figure out my
   issue. If for example I use this structure (example):
.
+-- cmd
|   +-- app
|       +-- main.go
|       +-- main_test.go
+-- go.mod
+-- go.sum
+-- pkg
    +-- handlers
    |   +-- handlers.go
    +-- types
    |   +-- types.go
    +-- util
        +-- util.go

   I can hit the imports successfully, but if I do e.g., go build at the root of the module I see:
   can't load package...unknown import path github.com/alexeldeib/repo...cannot find module providing
   package <same path as before>. Apologies if i'm missing something basic here, I admit I'm no Go
   aficionado

   I'm not sure this necessarily should work, but if not I'm unsure how I would go about this otherwise.
   Could you possibly share a an example project structure you use, with the application entrypoint in
   cmd/?

**
   Have you put the complete package address in the go.mod header (and not only its name), as explained
   above?

***
   edited

   $DIR/go.mod:
module github.com/alexeldeib/app

require (
        github.com/go-playground/locales v0.12.1 // indirect
        github.com/go-playground/universal-translator v0.16.0 // indirect
        .
        .
        . // etc
)


   $DIR/cmd/app/main.go:
package app # WRONG -- should be package main, see below or github.com/alexeldeib/godemo

import (
        "net/http"
        "os"
)

func main() {
    // Do stuff
}

   and then go build run from $DIR yields the previous error. I feel like there's some misalignment
   between the package naming and module naming that is causing confusion? Should I be using the full
   repository + pkg name inside my .go files too?

   Appreciate your advice!

   EDIT: If you're looking at this example, it should be package main

***
   The only difference I see is that I run go build from the $DIR/cmd/app/ directory...

***
   D'oh. That was it. Thank you!!

***
   Since I created this issue I really haven't run into any problems anymore while working with a
   project that has many folders and that follows the go-lang standard folder layout recommendations.
   As mentioned before just put the go mod in the root and everything works just fine. Having
   experienced this now, to be honest, I don't even understand my initial problem anymore :) Probably
   because I tried to have multiple modules while I didn't need to I guess.

***
   Go does not support relative imports.

   https://stackoverflow.com/questions/38517593/relative-imports-in-go

   But, like others, I've had no problems structuring large applications with lots of directories. You
   need to give the module a name, and then use it with all imports. Example:

   https://github.com/simpleiot/simpleiot/blob/master/cmd/siot/main.go

   If you set up your editor to use use goimports, then the imports automatically get added/removed as
   needed, so it requires almost no effort to manage imports. Works pretty well for me.

***
   You can have a look into kubernetes project structure which is following a similar topology.
   Though it also needs require/replace in go.mod

   My idea of go-dev can be:
     * Using IDE for the purpose of browsing (including navigating to function definition), editing,
       golint, gofmt with automatic expansion etc. This uses go installation (on VM) with GOPATH set.
     * Using layered Dockerfiles with source mounted or copied in container. This uses go setup with
       GOPATH unset and using GO111MODULE=on. Layered Dockerfile can be divided to mod, build and run.

   This has advantage that go mod/build layer can be reused to save overall build time. Also resulting
   app/run image can be based on alpine to have significantly less image size.

***
   if project use replace to import package in the same project, other who want to import the package
   will not find the package, because the path is ../package-name.

***
   Are there any examples without 'github.com/' and $GOPATH prefixes?

***
   Shouldn't it be "package main", rather than "package app", in $DIR/cmd/app/main.go
   The following works for me with go 1.13, in a random directory outside of GOPATH.

   I first did go mod init example.com/foo, then created source files so it looks like this:
==> go.mod <==
module example.com/foo

go 1.13

==> cmd/hello/main.go <==
package main

import (
        "fmt"
        "example.com/foo/internal"
)

func main() {
        ans := ultimate.Answer()
        fmt.Printf("The answer is %d\n", ans)
}

==> internal/answer.go <==
package ultimate

func Answer() int {
    return 42
}

   (I chose different package name than the directory name just to demonstrate)

   If I cd cmd/hello and go build, I get hello built in the current directory. Good so far.

   Also, at the top level I can do go build example.com/foo/cmd/hello. That works, although this time I
   get the binary written in the top level too. (Can override with go build -o filename ...)

   The problem is, if I put public library code in a pkg/ directory, then I have to do:
go build example.com/foo/pkg

   ... and I presume this means the users would have to import it the same way. If I want users to
   import example.com/foo then it seems the package code needs to sit in the top-level directory.

   Looking in Kubernetes source (which has a go.mod and a top-level pkg directory), it looks like the
   resulting /pkg/ does indeed appear as part of the path in all the import statements.

   I did consider putting another go.mod inside the pkg directory, but I wonder if that will complicate
   matters sharing code with the cmd executables.

***
   Executable commands must always use package main. (quoting
   https://golang.org/doc/code.html, under "Package names")

   Here's a demo project producing three binaries: https://github.com/alexeldeib/godemo

***
   edited

   Yup, editing my typo and answering completely for later visitors.

   Note also that /pkg/ is convention -- some projects (particularly those which are exclusively used as
   libraries) forgo the use of top level /pkg and expose their contents directly.

   e.g. https://github.com/google/go-cloud

   Some go even flatter:
   https://github.com/hashicorp/memberlist
   https://github.com/packethost/packngo

***
   I think that to close this, a note should be added under the /pkg heading explaining the
   consequences if you choose to use this directory together with go.mod.

   If I understand correctly, they are:
    1. The users of your package will need to specify the /pkg suffix when they import your package -
       e.g. import "github.com/username/libname/pkg"
    2. If you release later versions, the version number will be buried in the path (e.g. import
       "github.com/username/libname/v2/pkg")
    3. If your library contains subpackages, then /pkg is further buried (e.g. import
       "github.com/username/libname/v2/pkg/widget")

   In short, /pkg becomes part of your public API, rather than a hidden implementation detail. As far as
   I can see, the way to avoid this is to put your top-level .go files and subdirectories containing
   other public packages directly into the top level directory. You can still use /internal for private
   code.

   Someone please correct me if I'm wrong.


---
https://github.com/golang/go/issues/30841

x/tools/cmd/gopls: should support modules in rootURI subdirectories #30841

What version of Go are you using (go version)?
$ go version
go version go1.12 linux/amd64

Does this issue reproduce with the latest release?
   Yes

What operating system and processor architecture are you using (go env)?

   go env Output
$ go env
GOARCH="amd64"
GOBIN=""
GOCACHE="/home/vince/.cache/go-build"
GOEXE=""
GOFLAGS=""
GOHOSTARCH="amd64"
GOHOSTOS="linux"
GOOS="linux"
GOPATH="/home/vince"
GOPROXY=""
GORACE=""
GOROOT="/home/vince/go"
GOTMPDIR=""
GOTOOLDIR="/home/vince/go/pkg/tool/linux_amd64"
GCCGO="gccgo"
CC="gcc"
CXX="g++"
CGO_ENABLED="1"
GOMOD="/home/vince/dev/go.mod"

What did you do?
   I am using vscode to edit a project consisting of several subdirectories, one of them being the root
   of my go module.
- doc
- resources
...
- src
    go.mod
    go.sum

What did you expect to see?
   The root directory /home/vince/dev is opened in vscode, the go module is at
   /home/vince/dev/src/go.mod. When opening src/admin/file.go I'd like to have working completion /
   hover / ...

What did you see instead?
   gopls does not work: the newColumnMap function returns an error "no file information for
   file:///home/vince/dev/src/admin/file.go"
   (tok := f.GetToken(ctx) returns nil)

   Manually updating the packages.Config.Dir path in server.go (line 108) works around the problem (Dir:
   rootPath + "/src") but of course this is not a proper fix

   Should gopls try to find the appropriate go module for each given file by itself ? Or should the
   vscode-go plugin be responsible for it ? (In this case this bug should be reassigned to
   https://github.com/Microsoft/vscode-go)

***
   I found this, too.

   go list (and therefore go/packages) only seems to work properly when its pwd is inside the module
   being resolved.
~/issue30841 $ tree
.
+-- a
    +-- b
    |   +-- go.mod
    |   +-- main.go
    +-- c
    |   +-- main.go
    +-- go.mod
    +-- main.go

3 directories, 5 files

   Works:
~/issue30841/a $ go list $(pwd)
github.com/broady/issue30841/a

~/issue30841/a $ go list $(pwd)/c
github.com/broady/issue30841/a/c

~/issue30841/a/c $ go list $(pwd)
github.com/broady/issue30841/a/c

~/issue30841/a/b $ go list $(pwd)
github.com/broady/issue30841/a/b

   Does not work (pwd is outside module):
~/issue30841 $ go list $(pwd)/a
go: cannot find main module; see 'go help modules'
Exit code 1

~/issue30841/a $ go list $(pwd)/b
can't load package: package github.com/broady/issue30841/a/b: unknown import path "github.com/broady/issue3084
1/a/b": cannot find module providing package github.com/broady/issue30841/a/b

   I found this diff seems to load everything properly in vscode, but I'm not sure if it's the correct
   fix, since some tests fail:
diff --git a/internal/lsp/cache/check.go b/internal/lsp/cache/check.go
index 2082b47d..7a912bd4 100644
--- a/internal/lsp/cache/check.go
+++ b/internal/lsp/cache/check.go
@@ -99,6 +99,7 @@ func (v *View) checkMetadata(ctx context.Context, f *File) ([]packages.Error, er
        if v.reparseImports(ctx, f, filename) {
                cfg := v.Config
                cfg.Mode = packages.LoadImports
+               cfg.Dir = filepath.Dir(filename)
                pkgs, err := packages.Load(&cfg, fmt.Sprintf("file=%s", filename))
                if len(pkgs) == 0 {
                        if err == nil {

***
   @broady : I applied your change locally and it makes the language server work properly for me at

***
   This issue is a duplicate of #29174, and as the discussion there suggests, @broady's fix will
   not actually work. We are trying to figure out a good approach for fixing this problem, but it's
   difficult because LSP sends a rootURI when it is initialized, so we can't just use the current
   working directory.

***
   edited

     We are trying to figure out a good approach for fixing this problem, but it's difficult because
     LSP sends a rootURI when it is initialized, so we can't just use the current working directory.

   Encounter this problem too, based on @broady's fix, I use the following approach for the time
   being. Looking forward to the official fix!
        originDir := cfg.Dir

        fdir := filepath.Dir(f.filename)
        if !strings.HasPrefix(fdir, filepath.Join(os.Getenv("GOPATH"), "pkg")) {
                cfg.Dir = fdir
        }
        pkgs, err := packages.Load(&cfg, fmt.Sprintf("file=%s", f.filename))

        cfg.Dir = originDir

***
Since the `go list` command, which is a necessary command to resolve the
packages, is running at the rootURI folder, we have to run server at
rootURI too, see golang/go#30841.

***
   The official fix is already in, we support multiple workspace folders now.
   The job of finding the go.mod files that people care about and adding their folders to the workspace
   is up to either the user or the editor/client, but once that has happened, gopls will correctly work
   in those directories.

***
     The job of finding the go.mod files that people care about and adding their folders to the
     workspace is up to either the user or the editor/client, but once that has happened, gopls will
     correctly work in those directories.

   @ianthehat :
     * is there already some support in the vscode-go plugin for this ? I had a look but see nothing
       related in the changelog
     * is there a reason why the gopls server couldn't find the proper go.mod file by itself (by
       scanning the rootURI subdirectories for example), I don't understand why every editor/client
       should have to implement this by itself

***
   No, there is no automatic support, just add the directories to your workspace by hand.
   The trouble as discussed in the other bugs is that there is no correct answer.
   If you think through the edge cases of nested modules and replace directives with differing versions
   of dependancies there is no reasonable way to pick the right target of a cross module jump without
   understanding the flow that got the user to that point.
   This means it is a question of intent and style, and thus cannot (and should not be) be answered
   automatically by gopls.


---
